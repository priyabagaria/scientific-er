-DOCSTART- -X- O
Proceedings -X- _ O
of -X- _ O
the -X- _ O
Fourth -X- _ O
International -X- _ O
Workshop -X- _ O
on -X- _ O
Semantic -X- _ O
Evaluations -X- _ O
( -X- _ O
SemEval2007 -X- _ O
) -X- _ O
. -X- _ O

Future -X- _ O
work -X- _ O
should -X- _ O
explore -X- _ O
new -X- _ O
methods -X- _ O
for -X- _ O
corrupting -X- _ O
documents -X- _ O
for -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
, -X- _ O
perhaps -X- _ O
tailoring -X- _ O
them -X- _ O
to -X- _ O
specific -X- _ O
end -X- _ O
tasks -X- _ O
. -X- _ O

BART -X- _ B-MethodName
achieves -X- _ O
similar -X- _ O
performance -X- _ O
to -X- _ O
RoBERTa -X- _ B-MethodName
on -X- _ O
discriminative -X- _ O
tasks -X- _ O
, -X- _ O
while -X- _ O
achieving -X- _ O
new -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
theart -X- _ O
results -X- _ O
on -X- _ O
a -X- _ O
number -X- _ O
of -X- _ O
text -X- _ O
generation -X- _ O
tasks -X- _ O
. -X- _ O

8 -X- _ O
Conclusions -X- _ O
We -X- _ O
introduced -X- _ O
BART -X- _ B-MethodName
, -X- _ O
a -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
approach -X- _ O
that -X- _ O
learns -X- _ O
to -X- _ O
map -X- _ O
corrupted -X- _ O
documents -X- _ O
to -X- _ O
the -X- _ O
original -X- _ O
. -X- _ O

We -X- _ O
show -X- _ O
how -X- _ O
BART -X- _ B-MethodName
can -X- _ O
be -X- _ O
used -X- _ O
to -X- _ O
improve -X- _ O
machine -X- _ O
translation -X- _ O
decoders -X- _ O
. -X- _ O

Other -X- _ O
work -X- _ O
has -X- _ O
shown -X- _ O
that -X- _ O
encoders -X- _ O
can -X- _ O
be -X- _ O
improved -X- _ O
using -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
representations -X- _ O
( -X- _ O
Edunov -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
but -X- _ O
gains -X- _ O
in -X- _ O
decoders -X- _ O
are -X- _ O
more -X- _ O
limited -X- _ O
. -X- _ O

The -X- _ O
largest -X- _ O
improvements -X- _ O
have -X- _ O
come -X- _ O
from -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
on -X- _ O
both -X- _ O
source -X- _ O
and -X- _ O
target -X- _ O
languages -X- _ O
( -X- _ O
Song -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Lample -X- _ O
& -X- _ O
Conneau -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
but -X- _ O
this -X- _ O
requires -X- _ O
pretraining -X- _ O
on -X- _ O
all -X- _ O
languages -X- _ O
of -X- _ O
interest -X- _ O
. -X- _ O

Several -X- _ O
papers -X- _ O
have -X- _ O
explored -X- _ O
using -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
representations -X- _ O
to -X- _ O
improve -X- _ O
machine -X- _ B-TaskName
translation -X- _ I-TaskName
. -X- _ O

In -X- _ O
contrast -X- _ O
, -X- _ O
the -X- _ O
BART -X- _ B-MethodName
decoder -X- _ O
works -X- _ O
left -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
right -X- _ O
during -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
, -X- _ O
matching -X- _ O
the -X- _ O
setting -X- _ O
during -X- _ O
generation -X- _ O
. -X- _ O

This -X- _ O
objective -X- _ O
allows -X- _ O
predictions -X- _ O
to -X- _ O
condition -X- _ O
on -X- _ O
both -X- _ O
left -X- _ O
and -X- _ O
right -X- _ O
context -X- _ O
. -X- _ O

dicting -X- _ O
masked -X- _ O
tokens -X- _ O
auto -X- _ O
- -X- _ O
regressively -X- _ O
in -X- _ O
a -X- _ O
permuted -X- _ O
order -X- _ O
. -X- _ O

Summaries -X- _ O
combine -X- _ O
information -X- _ O
from -X- _ O
across -X- _ O
the -X- _ O
article -X- _ O
and -X- _ O
prior -X- _ O
knowledge -X- _ O
. -X- _ O

For -X- _ O
clarity -X- _ O
, -X- _ O
only -X- _ O
relevant -X- _ O
excerpts -X- _ O
of -X- _ O
the -X- _ O
source -X- _ O
are -X- _ O
shown -X- _ O
. -X- _ O

Table -X- _ O
7 -X- _ O
: -X- _ O
Example -X- _ O
summaries -X- _ O
from -X- _ O
the -X- _ O
XSum -X- _ B-DatasetName
- -X- _ O
tuned -X- _ O
BART -X- _ B-MethodName
model -X- _ O
on -X- _ O
WikiNews -X- _ O
articles -X- _ O
. -X- _ O

Source -X- _ O
Document -X- _ O
( -X- _ O
abbreviated -X- _ O
) -X- _ O
BART -X- _ B-MethodName
Summary -X- _ O

XL -X- _ B-MethodName
- -X- _ I-MethodName
Net -X- _ I-MethodName
( -X- _ O
Yang -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
extends -X- _ O
BERT -X- _ O
by -X- _ O
pre -X- _ O

MASS -X- _ B-MethodName
is -X- _ O
less -X- _ O
effective -X- _ O
for -X- _ O
discriminative -X- _ O
tasks -X- _ O
, -X- _ O
because -X- _ O
disjoint -X- _ O
sets -X- _ O
of -X- _ O
tokens -X- _ O
are -X- _ O
fed -X- _ O
into -X- _ O
the -X- _ O
encoder -X- _ O
and -X- _ O
decoder -X- _ O
. -X- _ O

An -X- _ O
input -X- _ O
sequence -X- _ O
where -X- _ O
a -X- _ O
contiguous -X- _ O
span -X- _ O
of -X- _ O
tokens -X- _ O
is -X- _ O
masked -X- _ O
is -X- _ O
mapped -X- _ O
to -X- _ O
a -X- _ O
sequence -X- _ O
consisting -X- _ O
of -X- _ O
the -X- _ O
missing -X- _ O
tokens -X- _ O
. -X- _ O

MASS -X- _ B-MethodName
( -X- _ O
Song -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
is -X- _ O
perhaps -X- _ O
the -X- _ O
most -X- _ O
similar -X- _ O
model -X- _ O
to -X- _ O
BART -X- _ B-MethodName
. -X- _ O

BART -X- _ B-MethodName
reduces -X- _ O
the -X- _ O
mismatch -X- _ O
between -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
and -X- _ O
generation -X- _ O
tasks -X- _ O
, -X- _ O
because -X- _ O
the -X- _ O
decoder -X- _ O
is -X- _ O
always -X- _ O
trained -X- _ O
on -X- _ O
uncorrupted -X- _ O
context -X- _ O
. -X- _ O

A -X- _ O
difference -X- _ O
is -X- _ O
that -X- _ O
UniLM -X- _ B-MethodName
predictions -X- _ O
are -X- _ O
conditionally -X- _ O
independent -X- _ O
, -X- _ O
whereas -X- _ O
BART -X- _ B-MethodName
’s -X- _ I-MethodName
are -X- _ O
autoregressive -X- _ O
. -X- _ O

Like -X- _ O
BART -X- _ B-MethodName
, -X- _ O
this -X- _ O
allows -X- _ O
UniLM -X- _ B-MethodName
to -X- _ O
be -X- _ O
used -X- _ O
for -X- _ O
both -X- _ O
generative -X- _ O
and -X- _ O
discriminative -X- _ O
tasks -X- _ O
. -X- _ O

UniLM -X- _ B-MethodName
( -X- _ O
Dong -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
fine -X- _ O
- -X- _ O
tunes -X- _ O
BERT -X- _ O
with -X- _ O
an -X- _ O
ensemble -X- _ O
of -X- _ O
masks -X- _ O
, -X- _ O
some -X- _ O
of -X- _ O
which -X- _ O
allow -X- _ O
only -X- _ O
leftward -X- _ O
context -X- _ O
. -X- _ O

Predictions -X- _ O
are -X- _ O
not -X- _ O
made -X- _ O
auto -X- _ O
- -X- _ O
regressively -X- _ O
, -X- _ O
reducing -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
BERT -X- _ B-MethodName
for -X- _ O
generation -X- _ O
tasks -X- _ O
. -X- _ O

Recent -X- _ O
work -X- _ O
has -X- _ O
shown -X- _ O
that -X- _ O
very -X- _ O
strong -X- _ O
performance -X- _ O
can -X- _ O
be -X- _ O
achieved -X- _ O
by -X- _ O
training -X- _ O
for -X- _ O
longer -X- _ O
( -X- _ O
Liu -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
by -X- _ O
tying -X- _ O
parameters -X- _ O
across -X- _ O
layers -X- _ O
( -X- _ O
Lan -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
by -X- _ O
masking -X- _ O
spans -X- _ O
instead -X- _ O
of -X- _ O
words -X- _ O
( -X- _ O
Joshi -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O

BERT -X- _ B-MethodName
( -X- _ O
Devlin -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
introduced -X- _ O
masked -X- _ O
language -X- _ O
modelling -X- _ O
, -X- _ O
which -X- _ O
allows -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
to -X- _ O
learn -X- _ O
interactions -X- _ O
between -X- _ O
left -X- _ O
and -X- _ O
right -X- _ O
context -X- _ O
words -X- _ O
. -X- _ O

Radford -X- _ O
et -X- _ O
al. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
demonstrated -X- _ O
that -X- _ O
very -X- _ O
large -X- _ O
language -X- _ O
models -X- _ O
can -X- _ O
act -X- _ O
as -X- _ O
unsupervised -X- _ O
multitask -X- _ O
models -X- _ O
. -X- _ O

ELMo -X- _ B-MethodName
( -X- _ O
Peters -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
concatenates -X- _ O
left -X- _ O
- -X- _ O
only -X- _ O
and -X- _ O
right -X- _ O
- -X- _ O
only -X- _ O
representations -X- _ O
, -X- _ O
but -X- _ O
does -X- _ O
not -X- _ O
pre -X- _ O
- -X- _ O
train -X- _ O
interactions -X- _ O
between -X- _ O
these -X- _ O
features -X- _ O
. -X- _ O

GPT -X- _ B-MethodName
( -X- _ O
Radford -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
only -X- _ O
models -X- _ O
leftward -X- _ O
context -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
problematic -X- _ O
for -X- _ O
some -X- _ O
tasks -X- _ O
. -X- _ O

Related -X- _ O
Work -X- _ O
Early -X- _ O
methods -X- _ O
for -X- _ O
pretraining -X- _ O
were -X- _ O
based -X- _ O
on -X- _ O
language -X- _ O
models -X- _ O
. -X- _ O

To -X- _ O
understand -X- _ O
BART -X- _ B-MethodName
’s -X- _ I-MethodName
performance -X- _ O
beyond -X- _ O
automated -X- _ O
metrics -X- _ O
, -X- _ O
we -X- _ O
analyse -X- _ O
its -X- _ O
generations -X- _ O
qualitatively -X- _ O
. -X- _ O

6 -X- _ O
Qualitative -X- _ O
Analysis -X- _ O
BART -X- _ B-MethodName
shows -X- _ O
large -X- _ O
improvements -X- _ O
on -X- _ O
summarization -X- _ O
metrics -X- _ O
, -X- _ O
of -X- _ O
up -X- _ O
to -X- _ O
6 -X- _ B-MetricValue
points -X- _ I-MetricValue
over -X- _ O
the -X- _ O
prior -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
. -X- _ O

Preliminary -X- _ O
results -X- _ O
suggested -X- _ O
that -X- _ O
our -X- _ O
approach -X- _ O
was -X- _ O
less -X- _ O
effective -X- _ O
without -X- _ O
back -X- _ O
- -X- _ O
translation -X- _ O
data -X- _ O
, -X- _ O
and -X- _ O
prone -X- _ O
to -X- _ O
overfitting -X- _ O
— -X- _ O
future -X- _ O
work -X- _ O
should -X- _ O
explore -X- _ O
additional -X- _ O
regularization -X- _ O
techniques -X- _ O
. -X- _ O

We -X- _ O
use -X- _ O
a -X- _ O
beam -X- _ B-HyperparameterName
width -X- _ I-HyperparameterName
of -X- _ O
5 -X- _ B-HyperparameterValue
and -X- _ O
a -X- _ O
length -X- _ B-HyperparameterName
penalty -X- _ I-HyperparameterName
of -X- _ I-HyperparameterName
α -X- _ I-HyperparameterName
= -X- _ O
1 -X- _ B-HyperparameterValue
. -X- _ O

For -X- _ O
each -X- _ O
row -X- _ O
we -X- _ O
experiment -X- _ O
on -X- _ O
the -X- _ O
original -X- _ O
WMT16 -X- _ B-DatasetName
Romanian -X- _ I-DatasetName
- -X- _ I-DatasetName
English -X- _ I-DatasetName
augmented -X- _ O
with -X- _ O
back -X- _ O
- -X- _ O
translation -X- _ O
data -X- _ O
. -X- _ O

We -X- _ O
show -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
both -X- _ O
steps -X- _ O
of -X- _ O
our -X- _ O
model -X- _ O
in -X- _ O
the -X- _ O
fixed -X- _ O
BART -X- _ B-MethodName
and -X- _ O
tuned -X- _ O
BART -X- _ B-MethodName
rows -X- _ O
. -X- _ O

We -X- _ O
compare -X- _ O
our -X- _ O
results -X- _ O
against -X- _ O
a -X- _ O
baseline -X- _ O
Transformer -X- _ O
architecture -X- _ O
( -X- _ O
Vaswani -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
with -X- _ O
Transformerlarge -X- _ O
settings -X- _ O
( -X- _ O
the -X- _ O
baseline -X- _ O
row -X- _ O
) -X- _ O
. -X- _ O

Experiment -X- _ O
results -X- _ O
are -X- _ O
presented -X- _ O
in -X- _ O
Table -X- _ O
6 -X- _ O
. -X- _ O

We -X- _ O
use -X- _ O
a -X- _ O
6 -X- _ B-HyperparameterValue
- -X- _ O
layer -X- _ B-HyperparameterName
transformer -X- _ O
source -X- _ O
encoder -X- _ O
to -X- _ O
map -X- _ O
Romanian -X- _ O
into -X- _ O
a -X- _ O
representation -X- _ O
that -X- _ O
BART -X- _ B-MethodName
is -X- _ O
able -X- _ O
to -X- _ O
de -X- _ O
- -X- _ O
noise -X- _ O
into -X- _ O
English -X- _ O
, -X- _ O
following -X- _ O
the -X- _ O
approach -X- _ O
introduced -X- _ O
in -X- _ O
§ -X- _ O
3.4 -X- _ O
. -X- _ O

5.4 -X- _ O
Translation -X- _ B-TaskName
We -X- _ O
also -X- _ O
evaluated -X- _ O
performance -X- _ O
on -X- _ O
WMT16 -X- _ B-DatasetName
RomanianEnglish -X- _ I-DatasetName
, -X- _ O
augmented -X- _ O
with -X- _ O
back -X- _ O
- -X- _ O
translation -X- _ O
data -X- _ O
from -X- _ O
Sennrich -X- _ O
et -X- _ O
al. -X- _ O
( -X- _ O
2016 -X- _ O
) -X- _ O
. -X- _ O

We -X- _ O
find -X- _ O
BART -X- _ B-MethodName
outperforms -X- _ O
the -X- _ O
best -X- _ O
previous -X- _ O
work -X- _ O
by -X- _ O
1.2 -X- _ B-MetricValue
ROUGE -X- _ B-MetricName
- -X- _ I-MetricName
L -X- _ I-MetricName
, -X- _ O
but -X- _ O
the -X- _ O
dataset -X- _ O
remains -X- _ O
a -X- _ O
challenging -X- _ O
, -X- _ O
because -X- _ O
answers -X- _ O
are -X- _ O
only -X- _ O
weakly -X- _ O
specified -X- _ O
by -X- _ O
the -X- _ O
question -X- _ O
. -X- _ O

7 -X- _ O
Abstractive -X- _ B-TaskName
QA -X- _ I-TaskName
We -X- _ O
use -X- _ O
the -X- _ O
recently -X- _ O
proposed -X- _ O
ELI5 -X- _ B-DatasetName
dataset -X- _ O
to -X- _ O
test -X- _ O
the -X- _ O
model -X- _ O
’s -X- _ O
ability -X- _ O
to -X- _ O
generate -X- _ O
long -X- _ O
freeform -X- _ O
answers -X- _ O
. -X- _ O

These -X- _ O
samples -X- _ O
demonstrate -X- _ O
that -X- _ O
the -X- _ O
BART -X- _ B-MethodName
pretraining -X- _ O
has -X- _ O
learned -X- _ O
a -X- _ O
strong -X- _ O
combination -X- _ O
of -X- _ O
natural -X- _ O
language -X- _ O
understanding -X- _ O
and -X- _ O
generation -X- _ O
. -X- _ O

However -X- _ O
, -X- _ O
the -X- _ O
claim -X- _ O
that -X- _ O
the -X- _ O
work -X- _ O
was -X- _ O
published -X- _ O
in -X- _ O
Science -X- _ O
is -X- _ O
not -X- _ O
supported -X- _ O
by -X- _ O
the -X- _ O
source -X- _ O
. -X- _ O

Table -X- _ O
7 -X- _ O
shows -X- _ O
example -X- _ O
summaries -X- _ O
generated -X- _ O
by -X- _ O
BART -X- _ B-MethodName
. -X- _ O

BART -X- _ B-MethodName
improves -X- _ O
over -X- _ O
a -X- _ O
strong -X- _ O
backtranslation -X- _ O
( -X- _ O
BT -X- _ O
) -X- _ O
baseline -X- _ O
by -X- _ O
using -X- _ O
monolingual -X- _ O
English -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
. -X- _ O

RO -X- _ B-DatasetName
- -X- _ I-DatasetName
EN -X- _ I-DatasetName
Baseline -X- _ B-MethodName
Fixed -X- _ B-MethodName
BART -X- _ I-MethodName
Tuned -X- _ B-MethodName
BART -X- _ I-MethodName
36.80 -X- _ B-MetricValue
36.29 -X- _ B-MetricValue
37.96 -X- _ B-MetricValue
Table -X- _ O
6 -X- _ O
: -X- _ O
The -X- _ O
performance -X- _ O
( -X- _ O
BLEU -X- _ B-MetricName
) -X- _ O
of -X- _ O
baseline -X- _ O
and -X- _ O
BART -X- _ B-MethodName
on -X- _ O
WMT’16 -X- _ B-DatasetName
RO -X- _ I-DatasetName
- -X- _ I-DatasetName
EN -X- _ I-DatasetName
augmented -X- _ O
with -X- _ O
backtranslation -X- _ O
data -X- _ O
. -X- _ O

Best -X- _ B-MethodName
Extractive -X- _ I-MethodName
Language -X- _ I-MethodName
Model -X- _ I-MethodName
Seq2Seq -X- _ B-MethodName
Seq2Seq -X- _ B-MethodName
Multitask -X- _ I-MethodName
BART -X- _ B-MethodName
R1 -X- _ B-MetricName
ELI5 -X- _ B-DatasetName
R2 -X- _ B-MetricName
RL -X- _ B-MetricName
23.5 -X- _ B-MetricValue
27.8 -X- _ B-MetricValue
28.3 -X- _ B-MetricValue
28.9 -X- _ B-MetricValue
30.6 -X- _ B-MetricValue
3.1 -X- _ B-MetricValue
4.7 -X- _ B-MetricValue
5.1 -X- _ B-MetricValue
5.4 -X- _ B-MetricValue
6.2 -X- _ B-MetricValue
17.5 -X- _ B-MetricValue
23.1 -X- _ B-MetricValue
22.8 -X- _ B-MetricValue
23.1 -X- _ B-MetricValue
24.3 -X- _ B-MetricValue
Table -X- _ O
5 -X- _ O
: -X- _ O
BART -X- _ B-MethodName
achieves -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
results -X- _ O
on -X- _ O
the -X- _ O
challenging -X- _ O
ELI5 -X- _ B-DatasetName
abstractive -X- _ O
question -X- _ O
answering -X- _ O
dataset -X- _ O
. -X- _ O

BART -X- _ B-MethodName
outperforms -X- _ O
previous -X- _ O
work -X- _ O
on -X- _ O
two -X- _ O
automated -X- _ O
metrics -X- _ O
. -X- _ O

Dialogue -X- _ B-TaskName
We -X- _ O
evaluate -X- _ O
dialogue -X- _ B-TaskName
response -X- _ I-TaskName
generation -X- _ I-TaskName
on -X- _ O
C -X- _ B-DatasetName
ONVAI2 -X- _ I-DatasetName
( -X- _ O
Dinan -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
in -X- _ O
which -X- _ O
agents -X- _ O
must -X- _ O
generate -X- _ O
responses -X- _ O
conditioned -X- _ O
on -X- _ O
both -X- _ O
the -X- _ O
previous -X- _ O
context -X- _ O
and -X- _ O
a -X- _ O
textually -X- _ O
- -X- _ O
specified -X- _ O
persona -X- _ O
. -X- _ O

BART -X- _ B-MethodName
outperforms -X- _ O
the -X- _ O
best -X- _ O
previous -X- _ O
work -X- _ O
, -X- _ O
which -X- _ O
leverages -X- _ O
BERT -X- _ B-MethodName
, -X- _ O
by -X- _ O
roughly -X- _ O
6.0 -X- _ B-MetricValue
points -X- _ I-MetricValue
on -X- _ O
all -X- _ O
ROUGE -X- _ B-MetricName
metrics -X- _ O
— -X- _ O
representing -X- _ O
a -X- _ O
significant -X- _ O
advance -X- _ O
in -X- _ O
performance -X- _ O
on -X- _ O
this -X- _ O
problem -X- _ O
. -X- _ O

In -X- _ O
contrast -X- _ O
, -X- _ O
XSum -X- _ B-DatasetName
is -X- _ O
highly -X- _ O
abstractive -X- _ O
, -X- _ O
and -X- _ O
extractive -X- _ O
models -X- _ O
perform -X- _ O
poorly -X- _ O
. -X- _ O

Nevertheless -X- _ O
, -X- _ O
BART -X- _ B-MethodName
outperforms -X- _ O
all -X- _ O
existing -X- _ O
work -X- _ O
. -X- _ O

Summaries -X- _ O
in -X- _ O
the -X- _ O
CNN -X- _ B-DatasetName
/ -X- _ I-DatasetName
DailyMail -X- _ I-DatasetName
tend -X- _ O
to -X- _ O
resemble -X- _ O
source -X- _ O
sentences -X- _ O
. -X- _ O

Summarization -X- _ B-TaskName
To -X- _ O
provide -X- _ O
a -X- _ O
comparison -X- _ O
with -X- _ O
the -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
in -X- _ O
summarization -X- _ O
, -X- _ O
we -X- _ O
present -X- _ O
results -X- _ O
on -X- _ O
two -X- _ O
summarization -X- _ O
datasets -X- _ O
, -X- _ O
CNN -X- _ B-DatasetName
/ -X- _ I-DatasetName
DailyMail -X- _ I-DatasetName
and -X- _ O
XSum -X- _ B-DatasetName
, -X- _ O
which -X- _ O
have -X- _ O
distinct -X- _ O
properties -X- _ O
. -X- _ O

Perplexities -X- _ B-MetricName
are -X- _ O
renormalized -X- _ O
based -X- _ O
on -X- _ O
official -X- _ O
tokenizer -X- _ O
for -X- _ O
ConvAI2 -X- _ B-DatasetName
. -X- _ O

Attention -X- _ B-MethodName
Best -X- _ B-MethodName
System -X- _ I-MethodName
BART -X- _ B-MethodName
16.02 -X- _ B-MetricValue
19.09 -X- _ B-MetricValue
20.72 -X- _ B-MetricValue
35.07 -X- _ B-MetricValue
17.51 -X- _ B-MetricValue
11.85 -X- _ B-MetricValue
Table -X- _ O
4 -X- _ O
: -X- _ O
BART -X- _ B-MethodName
outperforms -X- _ O
previous -X- _ O
work -X- _ O
on -X- _ O
conversational -X- _ B-TaskName
response -X- _ I-TaskName
generation -X- _ I-TaskName
. -X- _ O

ConvAI2 -X- _ B-DatasetName
Valid -X- _ B-MetricName
F1 -X- _ I-MetricName
Valid -X- _ B-MetricName
PPL -X- _ I-MetricName
Seq2Seq -X- _ B-MethodName
+ -X- _ I-MethodName

During -X- _ O
generation -X- _ O
, -X- _ O
we -X- _ O
set -X- _ O
beam -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
as -X- _ O
5 -X- _ B-HyperparameterValue
, -X- _ O
remove -X- _ O
duplicated -X- _ O
trigrams -X- _ O
in -X- _ O
beam -X- _ O
search -X- _ O
, -X- _ O
and -X- _ O
tuned -X- _ O
the -X- _ O
model -X- _ O
with -X- _ O
min -X- _ O
- -X- _ O
len -X- _ O
, -X- _ O
max -X- _ O
- -X- _ O
len -X- _ O
, -X- _ O
length -X- _ O
penalty -X- _ O
on -X- _ O
the -X- _ O
validation -X- _ O
set -X- _ O
( -X- _ O
Fan -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O

During -X- _ O
finetuning -X- _ O
we -X- _ O
use -X- _ O
a -X- _ O
label -X- _ O
smoothed -X- _ O
cross -X- _ O
entropy -X- _ O
loss -X- _ O
( -X- _ O
Pereyra -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
, -X- _ O
with -X- _ O
the -X- _ O
smoothing -X- _ B-HyperparameterName
parameter -X- _ I-HyperparameterName
set -X- _ O
to -X- _ O
0.1 -X- _ B-HyperparameterValue
. -X- _ O

BART -X- _ B-MethodName
is -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
as -X- _ O
a -X- _ O
standard -X- _ O
sequence -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
sequence -X- _ O
model -X- _ O
from -X- _ O
the -X- _ O
input -X- _ O
to -X- _ O
the -X- _ O
output -X- _ O
text -X- _ O
. -X- _ O

5.3 -X- _ O
Generation -X- _ B-TaskName
Tasks -X- _ I-TaskName
We -X- _ O
also -X- _ O
experiment -X- _ O
with -X- _ O
several -X- _ O
text -X- _ B-TaskName
generation -X- _ I-TaskName
tasks -X- _ O
. -X- _ O

suggesting -X- _ O
that -X- _ O
BART -X- _ B-MethodName
’s -X- _ I-MethodName
improvements -X- _ O
on -X- _ O
generation -X- _ B-TaskName
tasks -X- _ I-TaskName
do -X- _ O
not -X- _ O
come -X- _ O
at -X- _ O
the -X- _ O
expense -X- _ O
of -X- _ O
classification -X- _ O
performance -X- _ O
. -X- _ O

Overall -X- _ O
, -X- _ O
BART -X- _ B-MethodName
performs -X- _ O
similarly -X- _ O
, -X- _ O
with -X- _ O
only -X- _ O
small -X- _ O
differences -X- _ O
between -X- _ O
the -X- _ O
models -X- _ O
on -X- _ O
most -X- _ O
tasks -X- _ O
. -X- _ O

The -X- _ O
most -X- _ O
directly -X- _ O
comparable -X- _ O
baseline -X- _ O
is -X- _ O
RoBERTa -X- _ B-MethodName
, -X- _ O
which -X- _ O
was -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
with -X- _ O
the -X- _ O
same -X- _ O
resources -X- _ O
, -X- _ O
but -X- _ O
a -X- _ O
different -X- _ O
objective -X- _ O
. -X- _ O

5.2 -X- _ O
Discriminative -X- _ O
Tasks -X- _ O
Table -X- _ O
2 -X- _ O
compares -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
BART -X- _ B-MethodName
with -X- _ O
several -X- _ O
recent -X- _ O
approaches -X- _ O
on -X- _ O
the -X- _ O
well -X- _ O
- -X- _ O
studied -X- _ O
SQuAD -X- _ B-DatasetName
and -X- _ O
GLUE -X- _ B-DatasetName
tasks -X- _ O
( -X- _ O
Warstadt -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Socher -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2013 -X- _ O
; -X- _ O
Dolan -X- _ O
& -X- _ O
Brockett -X- _ O
, -X- _ O
2005 -X- _ O
; -X- _ O
Agirre -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2007 -X- _ O
; -X- _ O
Williams -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Dagan -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2006 -X- _ O
; -X- _ O
Levesque -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2011 -X- _ O
) -X- _ O
. -X- _ O

To -X- _ O
help -X- _ O
the -X- _ O
model -X- _ O
better -X- _ O
fit -X- _ O
the -X- _ O
data -X- _ O
, -X- _ O
we -X- _ O
disabled -X- _ O
dropout -X- _ B-HyperparameterName
for -X- _ O
the -X- _ O
final -X- _ O
10 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
of -X- _ O
training -X- _ B-HyperparameterName
steps -X- _ I-HyperparameterName
. -X- _ O

on -X- _ O
the -X- _ O
CNN -X- _ B-DatasetName
/ -X- _ I-DatasetName
DM -X- _ I-DatasetName
summarization -X- _ I-DatasetName
dataset -X- _ I-DatasetName
, -X- _ O
we -X- _ O
hypothesised -X- _ O
that -X- _ O
larger -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
models -X- _ O
may -X- _ O
be -X- _ O
better -X- _ O
able -X- _ O
to -X- _ O
learn -X- _ O
from -X- _ O
this -X- _ O
task -X- _ O
. -X- _ O

BART -X- _ B-MethodName
outperforms -X- _ O
previous -X- _ O
work -X- _ O
on -X- _ O
summarization -X- _ O
on -X- _ O
two -X- _ O
tasks -X- _ O
and -X- _ O
all -X- _ O
metrics -X- _ O
, -X- _ O
with -X- _ O
gains -X- _ O
of -X- _ O
roughly -X- _ O
6 -X- _ B-MetricValue
points -X- _ I-MetricValue
on -X- _ O
the -X- _ O
more -X- _ O
abstractive -X- _ O
dataset -X- _ O
. -X- _ O

PTGEN+COV -X- _ B-MethodName
( -X- _ O
See -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
UniLM -X- _ B-MethodName
BERTSUMABS -X- _ B-MethodName
( -X- _ O
Liu -X- _ O
& -X- _ O
Lapata -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
BERTSUMEXTABS -X- _ B-MethodName
( -X- _ O
Liu -X- _ O
& -X- _ O
Lapata -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
40.42 -X- _ B-MetricValue
36.44 -X- _ B-MetricValue
39.53 -X- _ B-MetricValue
43.33 -X- _ B-MetricValue
41.72 -X- _ B-MetricValue
42.13 -X- _ B-MetricValue
17.62 -X- _ B-MetricValue
15.66 -X- _ B-MetricValue
17.28 -X- _ B-MetricValue
20.21 -X- _ B-MetricValue
19.39 -X- _ B-MetricValue
19.60 -X- _ B-MetricValue
36.67 -X- _ B-MetricValue
33.42 -X- _ B-MetricValue
36.38 -X- _ B-MetricValue
40.51 -X- _ B-MetricValue
38.76 -X- _ B-MetricValue
39.18 -X- _ B-MetricValue
16.30 -X- _ B-MetricValue
29.70 -X- _ B-MetricValue
28.10 -X- _ B-MetricValue
38.76 -X- _ B-MetricValue
38.81 -X- _ B-MetricValue
1.60 -X- _ B-MetricValue
9.21 -X- _ B-MetricValue
8.02 -X- _ B-MetricValue
16.33 -X- _ B-MetricValue
16.50 -X- _ B-MetricValue
11.95 -X- _ B-MetricValue
23.24 -X- _ B-MetricValue
21.72 -X- _ B-MetricValue
31.15 -X- _ B-MetricValue
31.27 -X- _ B-MetricValue
BART -X- _ B-MethodName
44.16 -X- _ B-MetricValue
21.28 -X- _ B-MetricValue
40.90 -X- _ B-MetricValue
45.14 -X- _ B-MetricValue
22.27 -X- _ B-MetricValue
37.25 -X- _ B-MetricValue
Table -X- _ O
3 -X- _ O
: -X- _ O
Results -X- _ O
on -X- _ O
two -X- _ O
standard -X- _ O
summarization -X- _ O
datasets -X- _ O
. -X- _ O

CNN -X- _ B-DatasetName
/ -X- _ I-DatasetName
DailyMail -X- _ I-DatasetName
R1 -X- _ B-MetricName
R2 -X- _ B-MetricName
RL -X- _ B-MetricName
R1 -X- _ B-MetricName
XSum -X- _ B-DatasetName
R2 -X- _ B-MetricName
RL -X- _ B-MetricName
Lead-3 -X- _ B-MethodName
PTGEN -X- _ B-MethodName
( -X- _ O
See -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O

BART -X- _ B-MethodName
performs -X- _ O
comparably -X- _ O
to -X- _ O
RoBERTa -X- _ B-MethodName
and -X- _ O
XLNet -X- _ B-MethodName
, -X- _ O
suggesting -X- _ O
that -X- _ O
BART -X- _ B-MethodName
’s -X- _ O
uni -X- _ O
- -X- _ O
directional -X- _ O
decoder -X- _ O
layers -X- _ O
do -X- _ O
not -X- _ O
reduce -X- _ O
performance -X- _ O
on -X- _ O
discriminative -X- _ O
tasks -X- _ O
. -X- _ O

88.9/94.6 -X- _ B-MetricValue
88.8/94.6 -X- _ B-MetricValue
79.0/81.8 -X- _ B-MetricValue
80.5/83.4 -X- _ B-MetricValue
86.1/88.8 -X- _ B-MetricValue
86.5/89.4 -X- _ B-MetricValue
86.1/89.2 -X- _ B-MetricValue
86.6/87.0/85.9 -X- _ B-MetricValue
89.8/90.2/90.2 -X- _ B-MetricValue
89.9/90.1 -X- _ B-MetricValue
93.2 -X- _ B-MetricValue
94.5 -X- _ B-MetricValue
95.6 -X- _ B-MetricValue
96.4 -X- _ B-MetricValue
96.6 -X- _ B-MetricValue
91.3 -X- _ B-MetricValue
91.8 -X- _ B-MetricValue
92.2 -X- _ B-MetricValue
92.5 -X- _ B-MetricValue
92.3 -X- _ B-MetricValue
92.7 -X- _ B-MetricValue
93.9 -X- _ B-MetricValue
94.7 -X- _ B-MetricValue
94.9 -X- _ B-MetricValue
90.0 -X- _ B-MetricValue
91.8 -X- _ B-MetricValue
92.4 -X- _ B-MetricValue
91.2 -X- _ B-MetricValue
70.4 -X- _ B-MetricValue
70.9 -X- _ B-MetricValue
83.8 -X- _ B-MetricValue
86.6 -X- _ B-MetricValue
87.0 -X- _ B-MetricValue
88.0 -X- _ B-MetricValue
89.2 -X- _ B-MetricValue
90.9 -X- _ B-MetricValue
90.4 -X- _ B-MetricValue
60.6 -X- _ B-MetricValue
61.1 -X- _ B-MetricValue
63.6 -X- _ B-MetricValue
68.0 -X- _ B-MetricValue
62.8 -X- _ B-MetricValue
BERT -X- _ B-MethodName
UniLM -X- _ B-MethodName
XLNet -X- _ B-MethodName
RoBERTa -X- _ B-MethodName
BART -X- _ B-MethodName
Table -X- _ O
2 -X- _ O
: -X- _ O
Results -X- _ O
for -X- _ O
large -X- _ O
models -X- _ O
on -X- _ O
SQuAD -X- _ B-DatasetName
and -X- _ O
GLUE -X- _ B-DatasetName
tasks -X- _ O
. -X- _ O

Acc -X- _ B-MetricName
STS -X- _ B-DatasetName
- -X- _ I-DatasetName
B -X- _ I-DatasetName
Acc -X- _ B-MetricName
RTE -X- _ B-DatasetName
Acc -X- _ B-MetricName
MRPC -X- _ B-DatasetName
Acc -X- _ B-MetricName
CoLA -X- _ B-DatasetName
Mcc -X- _ B-MetricName
84.1/90.9 -X- _ B-MetricValue
-/89.0/94.5 -X- _ B-MetricValue

m -X- _ B-MetricName
/ -X- _ O
mm -X- _ B-MetricName
SST -X- _ B-DatasetName
Acc -X- _ B-MetricName
QQP -X- _ B-DatasetName
Acc -X- _ B-MetricName
QNLI -X- _ B-DatasetName

SQuAD -X- _ B-DatasetName
1.1 -X- _ I-DatasetName
EM -X- _ B-MetricName
/ -X- _ O
F1 -X- _ B-MetricName
SQuAD -X- _ B-DatasetName
2.0 -X- _ I-DatasetName
EM -X- _ B-MetricName
/ -X- _ O
F1 -X- _ B-MetricName
MNLI -X- _ B-DatasetName

Documents -X- _ O
are -X- _ O
tokenized -X- _ O
with -X- _ O
the -X- _ O
same -X- _ O
byte -X- _ O
- -X- _ O
pair -X- _ O
encoding -X- _ O
as -X- _ O
GPT-2 -X- _ B-MethodName
( -X- _ O
Radford -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O

Following -X- _ O
RoBERTa -X- _ B-MethodName
( -X- _ O
Liu -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
a -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
8000 -X- _ B-HyperparameterValue
, -X- _ O
and -X- _ O
train -X- _ O
the -X- _ O
model -X- _ O
for -X- _ O
500000 -X- _ B-HyperparameterValue
steps -X- _ B-HyperparameterName
. -X- _ O

5.1 -X- _ O
Experimental -X- _ O
Setup -X- _ O
We -X- _ O
pre -X- _ O
- -X- _ O
train -X- _ O
a -X- _ O
large -X- _ O
model -X- _ O
with -X- _ O
12 -X- _ B-HyperparameterValue
layers -X- _ B-HyperparameterName
in -X- _ O
each -X- _ O
of -X- _ O
the -X- _ O
encoder -X- _ O
and -X- _ O
decoder -X- _ O
, -X- _ O
and -X- _ O
a -X- _ O
hidden -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
1024 -X- _ B-HyperparameterValue
. -X- _ O

To -X- _ O
test -X- _ O
how -X- _ O
well -X- _ O
BART -X- _ B-MethodName
performs -X- _ O
in -X- _ O
this -X- _ O
regime -X- _ O
, -X- _ O
and -X- _ O
to -X- _ O
create -X- _ O
a -X- _ O
useful -X- _ O
model -X- _ O
for -X- _ O
downstream -X- _ O
tasks -X- _ O
, -X- _ O
we -X- _ O
trained -X- _ O
BART -X- _ B-MethodName
using -X- _ O
the -X- _ O
same -X- _ O
scale -X- _ O
as -X- _ O
the -X- _ O
RoBERTa -X- _ B-MethodName
model -X- _ O
. -X- _ O

Large -X- _ O
- -X- _ O
scale -X- _ O
Pre -X- _ O
- -X- _ O
training -X- _ O
Experiments -X- _ O
Recent -X- _ O
work -X- _ O
has -X- _ O
shown -X- _ O
that -X- _ O
downstream -X- _ O
performance -X- _ O
can -X- _ O
dramatically -X- _ O
improve -X- _ O
when -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
is -X- _ O
scaled -X- _ O
to -X- _ O
large -X- _ O
batch -X- _ B-HyperparameterName
sizes -X- _ I-HyperparameterName
( -X- _ O
Yang -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Liu -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
and -X- _ O
corpora -X- _ O
. -X- _ O

The -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
objective -X- _ O
is -X- _ O
not -X- _ O
the -X- _ O
only -X- _ O
important -X- _ O
factor -X- _ O
Our -X- _ O
Permuted -X- _ O
Language -X- _ O
Model -X- _ O
performs -X- _ O
less -X- _ O
well -X- _ O
than -X- _ O
XLNet -X- _ B-MethodName
( -X- _ O
Yang -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O

However -X- _ O
, -X- _ O
BART -X- _ B-MethodName
achieves -X- _ O
similar -X- _ O
performance -X- _ O
with -X- _ O
only -X- _ O
half -X- _ B-HyperparameterValue
the -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
bidirectional -X- _ I-HyperparameterName
layers -X- _ I-HyperparameterName
. -X- _ O

Bidirectional -X- _ O
encoders -X- _ O
are -X- _ O
crucial -X- _ O
for -X- _ O
SQuAD -X- _ B-DatasetName
As -X- _ O
noted -X- _ O
in -X- _ O
previous -X- _ O
work -X- _ O
( -X- _ O
Devlin -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
just -X- _ O
left -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
right -X- _ O
decoder -X- _ O
performs -X- _ O
poorly -X- _ O
on -X- _ O
SQuAD -X- _ B-DatasetName
, -X- _ O
because -X- _ O
future -X- _ O
context -X- _ O
is -X- _ O
crucial -X- _ O
in -X- _ O
classification -X- _ O
decisions -X- _ O
. -X- _ O

With -X- _ O
the -X- _ O
exception -X- _ O
of -X- _ O
ELI5 -X- _ B-DatasetName
, -X- _ O
BART -X- _ B-MethodName
models -X- _ O
using -X- _ O
text -X- _ O
- -X- _ O
infilling -X- _ O
perform -X- _ O
well -X- _ O
on -X- _ O
all -X- _ O
tasks -X- _ O
. -X- _ O

BART -X- _ B-MethodName
achieves -X- _ O
the -X- _ O
most -X- _ O
consistently -X- _ O
strong -X- _ O
performance -X- _ O
. -X- _ O

A -X- _ O
pure -X- _ O
language -X- _ O
model -X- _ O
performs -X- _ O
best -X- _ O
, -X- _ O
suggesting -X- _ O
that -X- _ O
BART -X- _ B-MethodName
is -X- _ O
less -X- _ O
effective -X- _ O
when -X- _ O
the -X- _ O
output -X- _ O
is -X- _ O
only -X- _ O
loosely -X- _ O
constrained -X- _ O
by -X- _ O
the -X- _ O
input -X- _ O
. -X- _ O

Pure -X- _ O
language -X- _ O
models -X- _ O
perform -X- _ O
best -X- _ O
on -X- _ O
ELI5 -X- _ B-DatasetName
The -X- _ O
ELI5 -X- _ B-DatasetName
dataset -X- _ O
is -X- _ O
an -X- _ O
outlier -X- _ O
, -X- _ O
with -X- _ O
much -X- _ O
higher -X- _ O
perplexities -X- _ B-MetricName
than -X- _ O
other -X- _ O
tasks -X- _ O
, -X- _ O
and -X- _ O
is -X- _ O
the -X- _ O
only -X- _ O
generation -X- _ B-TaskName
task -X- _ I-TaskName
where -X- _ O
other -X- _ O
models -X- _ O
outperform -X- _ O
BART -X- _ B-MethodName
. -X- _ O

Deletion -X- _ O
appears -X- _ O
to -X- _ O
outperform -X- _ O
masking -X- _ O
on -X- _ O
generation -X- _ B-TaskName
tasks -X- _ O
. -X- _ O

For -X- _ O
example -X- _ O
, -X- _ O
a -X- _ O
simple -X- _ O
language -X- _ O
model -X- _ O
achieves -X- _ O
the -X- _ O
best -X- _ O
ELI5 -X- _ B-DatasetName
performance -X- _ O
, -X- _ O
but -X- _ O
the -X- _ O
worst -X- _ O
SQUAD -X- _ B-DatasetName
results -X- _ O
. -X- _ O

Performance -X- _ O
varies -X- _ O
considerably -X- _ O
across -X- _ O
tasks -X- _ O
, -X- _ O
but -X- _ O
the -X- _ O
BART -X- _ B-MethodName
models -X- _ O
with -X- _ O
text -X- _ O
infilling -X- _ O
demonstrate -X- _ O
the -X- _ O
most -X- _ O
consistently -X- _ O
strong -X- _ O
performance -X- _ O
. -X- _ O

All -X- _ O
models -X- _ O
are -X- _ O
of -X- _ O
comparable -X- _ O
size -X- _ O
and -X- _ O
are -X- _ O
trained -X- _ O
for -X- _ O
1 -X- _ B-HyperparameterValue
M -X- _ I-HyperparameterValue
steps -X- _ B-HyperparameterName
on -X- _ O
a -X- _ O
combination -X- _ O
of -X- _ O
books -X- _ O
and -X- _ O
Wikipedia -X- _ O
data -X- _ O
. -X- _ O

Shuffling -X- _ O
w/ -X- _ O
Text -X- _ O
Infilling -X- _ O
+ -X- _ O
Sentence -X- _ O
Shuffling -X- _ O
90.4 -X- _ B-MetricValue
90.4 -X- _ B-MetricValue
90.8 -X- _ B-MetricValue
77.2 -X- _ B-MetricValue
85.4 -X- _ B-MetricValue
90.8 -X- _ B-MetricValue
84.1 -X- _ B-MetricValue
84.1 -X- _ B-MetricValue
84.0 -X- _ B-MetricValue
75.3 -X- _ B-MetricValue
81.5 -X- _ B-MetricValue
83.8 -X- _ B-MetricValue
25.05 -X- _ B-MetricValue
24.61 -X- _ B-MetricValue
24.26 -X- _ B-MetricValue
53.69 -X- _ B-MetricValue
41.87 -X- _ B-MetricValue
24.17 -X- _ B-MetricValue
7.08 -X- _ B-MetricValue
6.90 -X- _ B-MetricValue
6.61 -X- _ B-MetricValue
17.14 -X- _ B-MetricValue
10.93 -X- _ B-MetricValue
6.62 -X- _ B-MetricValue
11.73 -X- _ B-MetricValue
11.46 -X- _ B-MetricValue
11.05 -X- _ B-MetricValue
19.87 -X- _ B-MetricValue
16.67 -X- _ B-MetricValue
11.12 -X- _ B-MetricValue
6.10 -X- _ B-MetricValue
5.87 -X- _ B-MetricValue
5.83 -X- _ B-MetricValue
10.59 -X- _ B-MetricValue
7.89 -X- _ B-MetricValue
5.41 -X- _ B-MetricValue
Table -X- _ O
1 -X- _ O
: -X- _ O
Comparison -X- _ O
of -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
objectives -X- _ O
. -X- _ O

Acc -X- _ B-MetricName
ELI5 -X- _ B-DatasetName
PPL -X- _ B-MetricName
XSum -X- _ B-DatasetName
PPL -X- _ B-MetricName
ConvAI2 -X- _ B-DatasetName
PPL -X- _ B-MetricName
CNN -X- _ B-DatasetName
/ -X- _ I-DatasetName
DM -X- _ I-DatasetName
PPL -X- _ B-MetricName
BERT -X- _ B-MethodName
Base -X- _ I-MethodName
( -X- _ O
Devlin -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
88.5 -X- _ B-MetricValue
84.3 -X- _ B-MetricValue
Masked -X- _ O
Language -X- _ O
Model -X- _ O
Masked -X- _ O
Seq2seq -X- _ O
Language -X- _ O
Model -X- _ O
Permuted -X- _ O
Language -X- _ O
Model -X- _ O
Multitask -X- _ O
Masked -X- _ O
Language -X- _ O
Model -X- _ O
90.0 -X- _ B-MetricValue
87.0 -X- _ B-MetricValue
76.7 -X- _ B-MetricValue
89.1 -X- _ B-MetricValue
89.2 -X- _ B-MetricValue
83.5 -X- _ B-MetricValue
82.1 -X- _ B-MetricValue
80.1 -X- _ B-MetricValue
83.7 -X- _ B-MetricValue
82.4 -X- _ B-MetricValue
24.77 -X- _ B-MetricValue
23.40 -X- _ B-MetricValue
21.40 -X- _ B-MetricValue
24.03 -X- _ B-MetricValue
23.73 -X- _ B-MetricValue
7.87 -X- _ B-MetricValue
6.80 -X- _ B-MetricValue
7.00 -X- _ B-MetricValue
7.69 -X- _ B-MetricValue
7.50 -X- _ B-MetricValue
12.59 -X- _ B-MetricValue
11.43 -X- _ B-MetricValue
11.51 -X- _ B-MetricValue
12.23 -X- _ B-MetricValue
12.39 -X- _ B-MetricValue
7.06 -X- _ B-MetricValue
6.19 -X- _ B-MetricValue
6.56 -X- _ B-MetricValue
6.96 -X- _ B-MetricValue
6.74 -X- _ B-MetricValue
BART -X- _ B-MethodName
Base -X- _ I-MethodName
w/ -X- _ O

Model -X- _ O
SQuAD -X- _ B-DatasetName
1.1 -X- _ I-DatasetName
F1 -X- _ B-MetricName
MNLI -X- _ B-DatasetName

CNN -X- _ B-DatasetName
/ -X- _ I-DatasetName
DM -X- _ I-DatasetName
( -X- _ O
Hermann -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
, -X- _ O
a -X- _ O
news -X- _ O
summarization -X- _ B-TaskName
dataset -X- _ O
. -X- _ O

ConvAI2 -X- _ B-DatasetName
( -X- _ O
Dinan -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
a -X- _ O
dialogue -X- _ B-TaskName
response -X- _ I-TaskName
generation -X- _ I-TaskName
task -X- _ I-TaskName
, -X- _ O
conditioned -X- _ O
on -X- _ O
context -X- _ O
and -X- _ O
a -X- _ O
persona -X- _ O
. -X- _ O

XSum -X- _ B-DatasetName
( -X- _ O
Narayan -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
a -X- _ O
news -X- _ O
summarization -X- _ B-TaskName
dataset -X- _ O
with -X- _ O
highly -X- _ O
abstractive -X- _ O
summaries -X- _ O
. -X- _ O

ELI5 -X- _ B-DatasetName
( -X- _ O
Fan -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
a -X- _ O
long -X- _ B-TaskName
- -X- _ I-TaskName
form -X- _ I-TaskName
abstractive -X- _ I-TaskName
question -X- _ I-TaskName
answering -X- _ I-TaskName
dataset -X- _ O
. -X- _ O

In -X- _ O
contrast -X- _ O
to -X- _ O
BERT -X- _ B-MethodName
, -X- _ O
the -X- _ O
representation -X- _ O
of -X- _ O
the -X- _ O
EOS -X- _ O
token -X- _ O
is -X- _ O
used -X- _ O
to -X- _ O
classify -X- _ O
the -X- _ O
sentences -X- _ O
relations -X- _ O
. -X- _ O

The -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
model -X- _ O
concatenates -X- _ O
the -X- _ O
two -X- _ O
sentences -X- _ O
with -X- _ O
appended -X- _ O
an -X- _ O
EOS -X- _ O
token -X- _ O
, -X- _ O
and -X- _ O
passes -X- _ O
them -X- _ O
to -X- _ O
both -X- _ O
the -X- _ O
BART -X- _ B-MethodName
encoder -X- _ O
and -X- _ O
decoder -X- _ O
. -X- _ O

MNLI -X- _ B-DatasetName
( -X- _ O
Williams -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
, -X- _ O
a -X- _ O
bitext -X- _ B-TaskName
classification -X- _ I-TaskName
task -X- _ I-TaskName
to -X- _ O
predict -X- _ O
whether -X- _ O
one -X- _ O
sentence -X- _ O
entails -X- _ O
another -X- _ O
. -X- _ O

Similar -X- _ O
to -X- _ O
BERT -X- _ B-MethodName
( -X- _ O
Devlin -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
concatenated -X- _ O
question -X- _ O
and -X- _ O
context -X- _ O
as -X- _ O
input -X- _ O
to -X- _ O
the -X- _ O
encoder -X- _ O
of -X- _ O
BART -X- _ B-MethodName
, -X- _ O
and -X- _ O
additionally -X- _ O
pass -X- _ O
them -X- _ O
to -X- _ O
the -X- _ O
decoder -X- _ O
. -X- _ O

Tasks -X- _ O
SQuAD -X- _ B-DatasetName
( -X- _ O
Rajpurkar -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2016)a -X- _ O
an -X- _ O
extractive -X- _ B-TaskName
question -X- _ I-TaskName
answering -X- _ I-TaskName
task -X- _ I-TaskName
on -X- _ O
Wikipedia -X- _ O
paragraphs -X- _ O
. -X- _ O

Masked -X- _ O
Seq -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
Seq -X- _ O
Inspired -X- _ O
by -X- _ O
MASS -X- _ B-MethodName
( -X- _ O
Song -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O

As -X- _ O
in -X- _ O
UniLM -X- _ B-MethodName
( -X- _ O
Dong -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
train -X- _ O
a -X- _ O
Masked -X- _ O
Language -X- _ O
Model -X- _ O
with -X- _ O
additional -X- _ O
self -X- _ O
- -X- _ O
attention -X- _ O
masks -X- _ O
. -X- _ O

Masked -X- _ O
Language -X- _ O
Model -X- _ O
Following -X- _ O
BERT -X- _ B-MethodName
( -X- _ O
Devlin -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
replace -X- _ O
15 -X- _ O
% -X- _ O
of -X- _ O
tokens -X- _ O
with -X- _ O
[ -X- _ O
MASK -X- _ O
] -X- _ O
symbols -X- _ O
, -X- _ O
and -X- _ O
train -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
independently -X- _ O
predict -X- _ O
the -X- _ O
original -X- _ O
tokens -X- _ O
. -X- _ O

For -X- _ O
consistency -X- _ O
with -X- _ O
other -X- _ O
models -X- _ O
, -X- _ O
we -X- _ O
do -X- _ O
not -X- _ O
implement -X- _ O
the -X- _ O
relative -X- _ O
positional -X- _ O
embeddings -X- _ O
or -X- _ O
attention -X- _ O
across -X- _ O
segments -X- _ O
from -X- _ O
XLNet -X- _ B-MethodName
. -X- _ O

Permuted -X- _ O
Language -X- _ O
Model -X- _ O
Based -X- _ O
on -X- _ O
XLNet -X- _ B-MethodName
( -X- _ O
Yang -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
sample -X- _ O
1/6 -X- _ O
of -X- _ O
the -X- _ O
tokens -X- _ O
, -X- _ O
and -X- _ O
generate -X- _ O
them -X- _ O
in -X- _ O
a -X- _ O
random -X- _ O
order -X- _ O
autoregressively -X- _ O
. -X- _ O

This -X- _ O
model -X- _ O
is -X- _ O
equivalent -X- _ O
to -X- _ O
the -X- _ O
BART -X- _ B-MethodName
decoder -X- _ O
, -X- _ O
without -X- _ O
cross -X- _ O
- -X- _ O
attention -X- _ O
. -X- _ O

To -X- _ O
most -X- _ O
directly -X- _ O
compare -X- _ O
our -X- _ O
models -X- _ O
on -X- _ O
their -X- _ O
ability -X- _ O
to -X- _ O
model -X- _ O
their -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
objective -X- _ O
( -X- _ O
the -X- _ O
log -X- _ O
likelihood -X- _ O
of -X- _ O
the -X- _ O
human -X- _ O
text -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
report -X- _ O
perplexity -X- _ O
in -X- _ O
Table -X- _ O
1 -X- _ O
. -X- _ O
4.2 -X- _ O
Language -X- _ O
Model -X- _ O
Similarly -X- _ O
to -X- _ O
GPT -X- _ B-MethodName
( -X- _ O
Radford -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
train -X- _ O
a -X- _ O
left -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
right -X- _ O
Transformer -X- _ O
language -X- _ O
model -X- _ O
. -X- _ O

We -X- _ O
find -X- _ O
the -X- _ O
former -X- _ O
works -X- _ O
better -X- _ O
for -X- _ O
BART -X- _ B-MethodName
models -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
latter -X- _ O
for -X- _ O
other -X- _ O
models -X- _ O
. -X- _ O

For -X- _ O
reference -X- _ O
, -X- _ O
we -X- _ O
compare -X- _ O
our -X- _ O
implementations -X- _ O
with -X- _ O
published -X- _ O
numbers -X- _ O
from -X- _ O
BERT -X- _ B-MethodName
, -X- _ O
which -X- _ O
was -X- _ O
also -X- _ O
trained -X- _ O
for -X- _ O
1 -X- _ B-HyperparameterValue
M -X- _ I-HyperparameterValue
steps -X- _ B-HyperparameterName
on -X- _ O
a -X- _ O
combination -X- _ O
of -X- _ O
books -X- _ O
and -X- _ O
Wikipedia -X- _ O
data -X- _ O
. -X- _ O

However -X- _ O
, -X- _ O
we -X- _ O
do -X- _ O
make -X- _ O
minor -X- _ O
changes -X- _ O
to -X- _ O
the -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
and -X- _ O
usage -X- _ O
of -X- _ O
layer -X- _ B-HyperparameterName
normalisation -X- _ I-HyperparameterName
in -X- _ O
order -X- _ O
to -X- _ O
improve -X- _ O
performance -X- _ O
( -X- _ O
tuning -X- _ O
these -X- _ O
separately -X- _ O
for -X- _ O
each -X- _ O
objective -X- _ O
) -X- _ O
. -X- _ O

Figure -X- _ O
3 -X- _ O
: -X- _ O
Fine -X- _ O
tuning -X- _ O
BART -X- _ B-MethodName
for -X- _ O
classification -X- _ B-TaskName
and -X- _ O
translation -X- _ B-TaskName
. -X- _ O
re -X- _ O
- -X- _ O
implement -X- _ O
strong -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
approaches -X- _ O
recently -X- _ O
proposed -X- _ O
for -X- _ O
discriminative -X- _ O
and -X- _ O
generation -X- _ O
tasks -X- _ O
. -X- _ O

, -X- _ O
we -X- _ O
learn -X- _ O
a -X- _ O
small -X- _ O
additional -X- _ O
encoder -X- _ O
that -X- _ O
replaces -X- _ O
the -X- _ O
word -X- _ O
embeddings -X- _ O
in -X- _ O
BART -X- _ B-MethodName
. -X- _ O

β -X- _ O
γ -X- _ O
δ -X- _ O
ε -X- _ O
( -X- _ O
b -X- _ O
) -X- _ O
For -X- _ O
machine -X- _ B-TaskName
translation -X- _ I-TaskName

A -X- _ O
B -X- _ O
C -X- _ O
D -X- _ O
E -X- _ O
label -X- _ O
Pre -X- _ O
- -X- _ O
trained -X- _ O
Encoder -X- _ O
Pre -X- _ O
- -X- _ O
trained -X- _ O
Decoder -X- _ O
A -X- _ O
B -X- _ O
C -X- _ O
D -X- _ O
E -X- _ O
< -X- _ O
s -X- _ O
> -X- _ O
A -X- _ O
B -X- _ O
C -X- _ O
D -X- _ O
E -X- _ O
( -X- _ O
a -X- _ O
) -X- _ O
To -X- _ O
use -X- _ O
BART -X- _ B-MethodName
for -X- _ O
classification -X- _ O
problems -X- _ O
, -X- _ O
the -X- _ O
same -X- _ O
input -X- _ O
is -X- _ O
fed -X- _ O
into -X- _ O
the -X- _ O
encoder -X- _ O
and -X- _ O
decoder -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
representation -X- _ O
from -X- _ O
the -X- _ O
final -X- _ O
output -X- _ O
is -X- _ O
used -X- _ O
. -X- _ O

We -X- _ O
compare -X- _ O
a -X- _ O
range -X- _ O
of -X- _ O
options -X- _ O
using -X- _ O
base -X- _ O
- -X- _ O
size -X- _ O
models -X- _ O
( -X- _ O
6 -X- _ B-HyperparameterValue
encoder -X- _ O
and -X- _ O
6 -X- _ B-HyperparameterValue
decoder -X- _ O
layers -X- _ B-HyperparameterName
, -X- _ O
with -X- _ O
a -X- _ O
hidden -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
768 -X- _ B-HyperparameterValue
) -X- _ O
, -X- _ O
evaluated -X- _ O
on -X- _ O
a -X- _ O
representative -X- _ O
subset -X- _ O
of -X- _ O
the -X- _ O
tasks -X- _ O
we -X- _ O
will -X- _ O
consider -X- _ O
for -X- _ O
the -X- _ O
full -X- _ O
large -X- _ O
scale -X- _ O
experiments -X- _ O
in -X- _ O
§ -X- _ O
5 -X- _ O
. -X- _ O
4.1 -X- _ O
Comparison -X- _ O
Objectives -X- _ O
While -X- _ O
many -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
objectives -X- _ O
have -X- _ O
been -X- _ O
proposed -X- _ O
, -X- _ O
fair -X- _ O
comparisons -X- _ O
between -X- _ O
these -X- _ O
have -X- _ O
been -X- _ O
difficult -X- _ O
to -X- _ O
perform -X- _ O
, -X- _ O
at -X- _ O
least -X- _ O
in -X- _ O
part -X- _ O
due -X- _ O
to -X- _ O
differences -X- _ O
in -X- _ O
training -X- _ O
data -X- _ O
, -X- _ O
training -X- _ O
resources -X- _ O
, -X- _ O
architectural -X- _ O
differences -X- _ O
between -X- _ O
models -X- _ O
, -X- _ O
and -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
procedures -X- _ O
. -X- _ O

4 -X- _ O
Comparing -X- _ O
Pre -X- _ O
- -X- _ O
training -X- _ O
Objectives -X- _ O
BART -X- _ B-MethodName
supports -X- _ O
a -X- _ O
much -X- _ O
wider -X- _ O
range -X- _ O
of -X- _ O
noising -X- _ O
schemes -X- _ O
during -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
than -X- _ O
previous -X- _ O
work -X- _ O
. -X- _ O

In -X- _ O
the -X- _ O
second -X- _ O
step -X- _ O
, -X- _ O
we -X- _ O
train -X- _ O
all -X- _ O
model -X- _ O
parameters -X- _ O
for -X- _ O
a -X- _ O
small -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
iterations -X- _ I-HyperparameterName
. -X- _ O

In -X- _ O
the -X- _ O
first -X- _ O
step -X- _ O
, -X- _ O
we -X- _ O
freeze -X- _ O
most -X- _ O
of -X- _ O
BART -X- _ B-MethodName
parameters -X- _ O
and -X- _ O
only -X- _ O
update -X- _ O
the -X- _ O
randomly -X- _ O
initialized -X- _ O
source -X- _ O
encoder -X- _ O
, -X- _ O
the -X- _ O
BART -X- _ B-MethodName
positional -X- _ O
embeddings -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
self -X- _ O
- -X- _ O
attention -X- _ O
input -X- _ O
projection -X- _ O
matrix -X- _ O
of -X- _ O
BART -X- _ B-MethodName
’s -X- _ I-MethodName
encoder -X- _ O
first -X- _ O
layer -X- _ O
. -X- _ O

We -X- _ O
train -X- _ O
the -X- _ O
source -X- _ O
encoder -X- _ O
in -X- _ O
two -X- _ O
steps -X- _ O
, -X- _ O
in -X- _ O
both -X- _ O
cases -X- _ O
backpropagating -X- _ O
the -X- _ O
cross -X- _ O
- -X- _ O
entropy -X- _ O
loss -X- _ O
from -X- _ O
the -X- _ O
output -X- _ O
of -X- _ O
the -X- _ O
BART -X- _ B-MethodName
model -X- _ O
. -X- _ O

The -X- _ O
new -X- _ O
encoder -X- _ O
can -X- _ O
use -X- _ O
a -X- _ O
separate -X- _ O
vocabulary -X- _ O
from -X- _ O
the -X- _ O
original -X- _ O
BART -X- _ B-MethodName
model -X- _ O
. -X- _ O

The -X- _ O
model -X- _ O
is -X- _ O
trained -X- _ O
end -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
end -X- _ O
, -X- _ O
which -X- _ O
trains -X- _ O
the -X- _ O
new -X- _ O
encoder -X- _ O
to -X- _ O
map -X- _ O
foreign -X- _ O
words -X- _ O
into -X- _ O
an -X- _ O
input -X- _ O
that -X- _ O
BART -X- _ B-MethodName
can -X- _ O
de -X- _ O
- -X- _ O
noise -X- _ O
to -X- _ O
English -X- _ O
. -X- _ O

More -X- _ O
precisely -X- _ O
, -X- _ O
we -X- _ O
replace -X- _ O
BART -X- _ B-MethodName
’s -X- _ O
encoder -X- _ O
embedding -X- _ O
layer -X- _ O
with -X- _ O
a -X- _ O
new -X- _ O
randomly -X- _ O
initialized -X- _ O
encoder -X- _ O
. -X- _ O

We -X- _ O
show -X- _ O
that -X- _ O
it -X- _ O
is -X- _ O
possible -X- _ O
to -X- _ O
use -X- _ O
the -X- _ O
entire -X- _ O
BART -X- _ B-MethodName
model -X- _ O
( -X- _ O
both -X- _ O
encoder -X- _ O
and -X- _ O
decoder -X- _ O
) -X- _ O
as -X- _ O
a -X- _ O
single -X- _ O
pretrained -X- _ O
decoder -X- _ O
for -X- _ O
machine -X- _ B-TaskName
translation -X- _ I-TaskName
, -X- _ O
by -X- _ O
adding -X- _ O
a -X- _ O
new -X- _ O
set -X- _ O
of -X- _ O
encoder -X- _ O
parameters -X- _ O
that -X- _ O
are -X- _ O
learned -X- _ O
from -X- _ O
bitext -X- _ O
( -X- _ O
see -X- _ O
Figure -X- _ O
3b -X- _ O
) -X- _ O
. -X- _ O

3.4 -X- _ O
Machine -X- _ B-TaskName
Translation -X- _ I-TaskName
We -X- _ O
also -X- _ O
explore -X- _ O
using -X- _ O
BART -X- _ B-MethodName
to -X- _ O
improve -X- _ O
machine -X- _ O
translation -X- _ O
decoders -X- _ O
for -X- _ O
translating -X- _ O
into -X- _ O
English -X- _ O
. -X- _ O

3.3 -X- _ O
Sequence -X- _ B-TaskName
Generation -X- _ I-TaskName
Tasks -X- _ O
Because -X- _ O
BART -X- _ B-MethodName
has -X- _ O
an -X- _ O
autoregressive -X- _ O
decoder -X- _ O
, -X- _ O
it -X- _ O
can -X- _ O
be -X- _ O
directly -X- _ O
fine -X- _ O
tuned -X- _ O
for -X- _ O
sequence -X- _ O
generation -X- _ O
tasks -X- _ O
such -X- _ O
as -X- _ O
abstractive -X- _ B-TaskName
question -X- _ I-TaskName
answering -X- _ I-TaskName
and -X- _ O
summarization -X- _ B-TaskName
. -X- _ O

This -X- _ O
representation -X- _ O
is -X- _ O
used -X- _ O
to -X- _ O
classify -X- _ O
the -X- _ O
token -X- _ O
. -X- _ O

3.2 -X- _ O
Token -X- _ B-TaskName
Classification -X- _ I-TaskName
Tasks -X- _ O
For -X- _ O
token -X- _ O
classification -X- _ O
tasks -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
answer -X- _ B-TaskName
endpoint -X- _ I-TaskName
classification -X- _ I-TaskName
for -X- _ O
SQuAD -X- _ B-DatasetName
, -X- _ O
we -X- _ O
feed -X- _ O
the -X- _ O
complete -X- _ O
document -X- _ O
into -X- _ O
the -X- _ O
encoder -X- _ O
and -X- _ O
decoder -X- _ O
, -X- _ O
and -X- _ O
use -X- _ O
the -X- _ O
top -X- _ O
hidden -X- _ O
state -X- _ O
of -X- _ O
the -X- _ O
decoder -X- _ O
as -X- _ O
a -X- _ O
representation -X- _ O
for -X- _ O
each -X- _ O
word -X- _ O
. -X- _ O

This -X- _ O
approach -X- _ O
is -X- _ O
related -X- _ O
to -X- _ O
the -X- _ O
CLS -X- _ O
token -X- _ O
in -X- _ O
BERT -X- _ B-MethodName
; -X- _ O
however -X- _ O
we -X- _ O
add -X- _ O
the -X- _ O
additional -X- _ O
token -X- _ O
to -X- _ O
the -X- _ O
end -X- _ O
so -X- _ O
that -X- _ O
representation -X- _ O
for -X- _ O
the -X- _ O
token -X- _ O
in -X- _ O
the -X- _ O
decoder -X- _ O
can -X- _ O
attend -X- _ O
to -X- _ O
decoder -X- _ O
states -X- _ O
from -X- _ O
the -X- _ O
complete -X- _ O
input -X- _ O
( -X- _ O
Figure -X- _ O
3a -X- _ O
) -X- _ O
. -X- _ O

3.1 -X- _ O
Sequence -X- _ B-TaskName
Classification -X- _ I-TaskName
Tasks -X- _ O
For -X- _ O
sequence -X- _ B-TaskName
classification -X- _ I-TaskName
tasks -X- _ O
, -X- _ O
the -X- _ O
same -X- _ O
input -X- _ O
is -X- _ O
fed -X- _ O
into -X- _ O
the -X- _ O
encoder -X- _ O
and -X- _ O
decoder -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
final -X- _ O
hidden -X- _ O
state -X- _ O
of -X- _ O
the -X- _ O
final -X- _ O
decoder -X- _ O
token -X- _ O
is -X- _ O
fed -X- _ O
into -X- _ O
new -X- _ O
multi -X- _ O
- -X- _ O
class -X- _ O
linear -X- _ O
classifier -X- _ O
. -X- _ O

The -X- _ O
representations -X- _ O
produced -X- _ O
by -X- _ O
BART -X- _ B-MethodName
can -X- _ O
be -X- _ O
used -X- _ O
in -X- _ O
several -X- _ O
ways -X- _ O
for -X- _ O
downstream -X- _ O
applications -X- _ O
. -X- _ O

3 -X- _ O
Fine -X- _ O
- -X- _ O
tuning -X- _ O
BART -X- _ B-MethodName

Text -X- _ O
infilling -X- _ O
is -X- _ O
inspired -X- _ O
by -X- _ O
SpanBERT -X- _ B-MethodName
( -X- _ O
Joshi -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
but -X- _ O
SpanBERT -X- _ B-MethodName
samples -X- _ O
span -X- _ O
lengths -X- _ O
from -X- _ O
a -X- _ O
different -X- _ O
( -X- _ O
clamped -X- _ O
geometric -X- _ O
) -X- _ O
distribution -X- _ O
, -X- _ O
and -X- _ O
replaces -X- _ O
each -X- _ O
span -X- _ O
with -X- _ O
a -X- _ O
sequence -X- _ O
of -X- _ O
[ -X- _ O
MASK -X- _ O
] -X- _ O
tokens -X- _ O
of -X- _ O
exactly -X- _ O
the -X- _ O
same -X- _ O
length -X- _ O
. -X- _ O

In -X- _ O
contrast -X- _ O
to -X- _ O
token -X- _ O
masking -X- _ O
, -X- _ O
the -X- _ O
model -X- _ O
must -X- _ O
decide -X- _ O
which -X- _ O
positions -X- _ O
are -X- _ O
missing -X- _ O
inputs -X- _ O
. -X- _ O

Token -X- _ O
Deletion -X- _ O
Random -X- _ O
tokens -X- _ O
are -X- _ O
deleted -X- _ O
from -X- _ O
the -X- _ O
input -X- _ O
. -X- _ O

Token -X- _ O
Masking -X- _ O
Following -X- _ O
BERT -X- _ B-MethodName
( -X- _ O
Devlin -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
random -X- _ O
tokens -X- _ O
are -X- _ O
sampled -X- _ O
and -X- _ O
replaced -X- _ O
with -X- _ O
[ -X- _ O
MASK -X- _ O
] -X- _ O
elements -X- _ O
. -X- _ O

The -X- _ O
transformations -X- _ O
we -X- _ O
used -X- _ O
are -X- _ O
summarized -X- _ O
below -X- _ O
, -X- _ O
and -X- _ O
examples -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
2 -X- _ O
. -X- _ O

We -X- _ O
experiment -X- _ O
with -X- _ O
several -X- _ O
previously -X- _ O
proposed -X- _ O
and -X- _ O
novel -X- _ O
transformations -X- _ O
, -X- _ O
but -X- _ O
we -X- _ O
believe -X- _ O
there -X- _ O
is -X- _ O
a -X- _ O
significant -X- _ O
potential -X- _ O
for -X- _ O
development -X- _ O
of -X- _ O
other -X- _ O
new -X- _ O
alternatives -X- _ O
. -X- _ O

In -X- _ O
the -X- _ O
extreme -X- _ O
case -X- _ O
, -X- _ O
where -X- _ O
all -X- _ O
information -X- _ O
about -X- _ O
the -X- _ O
source -X- _ O
is -X- _ O
lost -X- _ O
, -X- _ O
BART -X- _ B-MethodName
is -X- _ O
equivalent -X- _ O
to -X- _ O
a -X- _ O
language -X- _ O
model -X- _ O
. -X- _ O

Unlike -X- _ O
existing -X- _ O
denoising -X- _ O
autoencoders -X- _ O
, -X- _ O
which -X- _ O
are -X- _ O
tailored -X- _ O
to -X- _ O
specific -X- _ O
noising -X- _ O
schemes -X- _ O
, -X- _ O
BART -X- _ B-MethodName
allows -X- _ O
us -X- _ O
to -X- _ O
apply -X- _ O
any -X- _ O
type -X- _ O
of -X- _ O
document -X- _ O
corruption -X- _ O
. -X- _ O

2.2 -X- _ O
Pre -X- _ O
- -X- _ O
training -X- _ O
BART -X- _ B-MethodName
BART -X- _ B-MethodName
is -X- _ O
trained -X- _ O
by -X- _ O
corrupting -X- _ O
documents -X- _ O
and -X- _ O
then -X- _ O
optimizing -X- _ O
a -X- _ O
reconstruction -X- _ O
loss -X- _ O
— -X- _ O
the -X- _ O
cross -X- _ O
- -X- _ O
entropy -X- _ O
between -X- _ O
the -X- _ O
decoder -X- _ O
’s -X- _ O
output -X- _ O
and -X- _ O
the -X- _ O
original -X- _ O
document -X- _ O
. -X- _ O

In -X- _ O
total -X- _ O
, -X- _ O
BART -X- _ B-MethodName
contains -X- _ O
roughly -X- _ O
10 -X- _ O
% -X- _ O
more -X- _ O
parameters -X- _ O
than -X- _ O
the -X- _ O
equivalently -X- _ O
sized -X- _ O
BERT -X- _ B-MethodName
model -X- _ O
. -X- _ O

The -X- _ O
architecture -X- _ O
is -X- _ O
closely -X- _ O
related -X- _ O
to -X- _ O
that -X- _ O
used -X- _ O
in -X- _ O
BERT -X- _ B-MethodName
, -X- _ O
with -X- _ O
the -X- _ O
following -X- _ O
differences -X- _ O
: -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
each -X- _ O
layer -X- _ O
of -X- _ O
the -X- _ O
decoder -X- _ O
additionally -X- _ O
performs -X- _ O
cross -X- _ O
- -X- _ O
attention -X- _ O
over -X- _ O
the -X- _ O
final -X- _ O
hidden -X- _ O
layer -X- _ O
of -X- _ O
the -X- _ O
encoder -X- _ O
( -X- _ O
as -X- _ O
in -X- _ O
the -X- _ O
transformer -X- _ O
sequence -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
sequence -X- _ O
model -X- _ O
) -X- _ O
; -X- _ O
and -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
BERT -X- _ B-MethodName
uses -X- _ O
an -X- _ O
additional -X- _ O
feed -X- _ O
- -X- _ O
forward -X- _ O
network -X- _ O
before -X- _ O
wordprediction -X- _ O
, -X- _ O
which -X- _ O
BART -X- _ B-MethodName
does -X- _ O
not -X- _ O
. -X- _ O

For -X- _ O
our -X- _ O
base -X- _ O
model -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
6 -X- _ B-HyperparameterValue
layers -X- _ B-HyperparameterName
in -X- _ O
the -X- _ O
encoder -X- _ O
and -X- _ O
de -X- _ O
coder -X- _ O
, -X- _ O
and -X- _ O
for -X- _ O
our -X- _ O
large -X- _ O
model -X- _ O
we -X- _ O
use -X- _ O
12 -X- _ B-HyperparameterValue
layers -X- _ B-HyperparameterName
in -X- _ O
each -X- _ O
. -X- _ O

2.1 -X- _ O
Architecture -X- _ O
BART -X- _ B-MethodName
uses -X- _ O
the -X- _ O
standard -X- _ O
sequence -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
sequence -X- _ O
Transformer -X- _ O
architecture -X- _ O
from -X- _ O
( -X- _ O
Vaswani -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
, -X- _ O
except -X- _ O
, -X- _ O
following -X- _ O
GPT -X- _ B-MethodName
, -X- _ O
that -X- _ O
we -X- _ O
modify -X- _ O
ReLU -X- _ O
activation -X- _ O
functions -X- _ O
to -X- _ O
GeLUs -X- _ O
( -X- _ O
Hendrycks -X- _ O
& -X- _ O
Gimpel -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
and -X- _ O
initialise -X- _ O
parameters -X- _ O
from -X- _ O
N -X- _ O
( -X- _ O
0 -X- _ O
, -X- _ O
0.02 -X- _ O
) -X- _ O
. -X- _ O

For -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
, -X- _ O
we -X- _ O
optimize -X- _ O
the -X- _ O
negative -X- _ O
log -X- _ O
likelihood -X- _ O
of -X- _ O
the -X- _ O
original -X- _ O
document -X- _ O
. -X- _ O

It -X- _ O
is -X- _ O
implemented -X- _ O
as -X- _ O
a -X- _ O
sequence -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
sequence -X- _ O
model -X- _ O
with -X- _ O
a -X- _ O
bidirectional -X- _ O
encoder -X- _ O
over -X- _ O
corrupted -X- _ O
text -X- _ O
and -X- _ O
a -X- _ O
left -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
right -X- _ O
autoregressive -X- _ O
decoder -X- _ O
. -X- _ O

2 -X- _ O
Model -X- _ O
BART -X- _ B-MethodName
is -X- _ O
a -X- _ O
denoising -X- _ O
autoencoder -X- _ O
that -X- _ O
maps -X- _ O
a -X- _ O
corrupted -X- _ O
document -X- _ O
to -X- _ O
the -X- _ O
original -X- _ O
document -X- _ O
it -X- _ O
was -X- _ O
derived -X- _ O
from -X- _ O
. -X- _ O

We -X- _ O
find -X- _ O
that -X- _ O
BART -X- _ B-MethodName
exhibits -X- _ O
the -X- _ O
most -X- _ O
consistently -X- _ O
strong -X- _ O
performance -X- _ O
across -X- _ O
the -X- _ O
full -X- _ O
range -X- _ O
of -X- _ O
tasks -X- _ O
we -X- _ O
consider -X- _ O
. -X- _ O

This -X- _ O
study -X- _ O
allows -X- _ O
us -X- _ O
to -X- _ O
carefully -X- _ O
control -X- _ O
for -X- _ O
a -X- _ O
number -X- _ O
of -X- _ O
factors -X- _ O
, -X- _ O
including -X- _ O
data -X- _ O
and -X- _ O
optimization -X- _ O
parameters -X- _ O
, -X- _ O
which -X- _ O
have -X- _ O
been -X- _ O
shown -X- _ O
to -X- _ O
be -X- _ O
as -X- _ O
important -X- _ O
for -X- _ O
overall -X- _ O
performance -X- _ O
as -X- _ O
the -X- _ O
selection -X- _ O
of -X- _ O
training -X- _ O
objectives -X- _ O
( -X- _ O
Liu -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O

To -X- _ O
better -X- _ O
understand -X- _ O
these -X- _ O
effects -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
report -X- _ O
an -X- _ O
ablation -X- _ O
analysis -X- _ O
that -X- _ O
replicates -X- _ O
other -X- _ O
recently -X- _ O
proposed -X- _ O
training -X- _ O
objectives -X- _ O
. -X- _ O

This -X- _ O
approach -X- _ O
improves -X- _ O
performance -X- _ O
over -X- _ O
a -X- _ O
strong -X- _ O
back -X- _ O
- -X- _ O
translation -X- _ O
MT -X- _ B-TaskName
baseline -X- _ O
by -X- _ O
1.1 -X- _ B-MetricValue
BLEU -X- _ B-MetricName
on -X- _ O
the -X- _ O
WMT -X- _ B-DatasetName
Romanian -X- _ I-DatasetName
- -X- _ I-DatasetName
English -X- _ I-DatasetName
benchmark -X- _ I-DatasetName
. -X- _ O

English -X- _ O
, -X- _ O
by -X- _ O
propagation -X- _ O
through -X- _ O
BART -X- _ B-MethodName
, -X- _ O
thereby -X- _ O
using -X- _ O
BART -X- _ B-MethodName
as -X- _ O
a -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
target -X- _ O
- -X- _ O
side -X- _ O
language -X- _ O
model -X- _ O
. -X- _ O

Figure -X- _ O
1 -X- _ O
: -X- _ O
A -X- _ O
schematic -X- _ O
comparison -X- _ O
of -X- _ O
BART -X- _ B-MethodName
with -X- _ O
BERT -X- _ B-MethodName
( -X- _ O
Devlin -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
and -X- _ O
GPT -X- _ B-MethodName
( -X- _ O
Radford -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O

For -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
, -X- _ O
an -X- _ O
uncorrupted -X- _ O
document -X- _ O
is -X- _ O
input -X- _ O
to -X- _ O
both -X- _ O
the -X- _ O
encoder -X- _ O
and -X- _ O
decoder -X- _ O
, -X- _ O
and -X- _ O
we -X- _ O
use -X- _ O
representations -X- _ O
from -X- _ O
the -X- _ O
final -X- _ O
hidden -X- _ O
state -X- _ O
of -X- _ O
the -X- _ O
decoder -X- _ O
. -X- _ O

The -X- _ O
corrupted -X- _ O
document -X- _ O
( -X- _ O
left -X- _ O
) -X- _ O
is -X- _ O
encoded -X- _ O
with -X- _ O
a -X- _ O
bidirectional -X- _ O
model -X- _ O
, -X- _ O
and -X- _ O
then -X- _ O
the -X- _ O
likelihood -X- _ O
of -X- _ O
the -X- _ O
original -X- _ O
document -X- _ O
( -X- _ O
right -X- _ O
) -X- _ O
is -X- _ O
calculated -X- _ O
with -X- _ O
an -X- _ O
autoregressive -X- _ O
decoder -X- _ O
. -X- _ O

Here -X- _ O
, -X- _ O
a -X- _ O
document -X- _ O
has -X- _ O
been -X- _ O
corrupted -X- _ O
by -X- _ O
replacing -X- _ O
spans -X- _ O
of -X- _ O
text -X- _ O
with -X- _ O
mask -X- _ O
symbols -X- _ O
. -X- _ O

Inputs -X- _ O
to -X- _ O
the -X- _ O
encoder -X- _ O
need -X- _ O
not -X- _ O
be -X- _ O
aligned -X- _ O
with -X- _ O
decoder -X- _ O
outputs -X- _ O
, -X- _ O
allowing -X- _ O
arbitary -X- _ O
noise -X- _ O
transformations -X- _ O
. -X- _ O

E -X- _ O
< -X- _ O
s -X- _ O
> -X- _ O
A -X- _ O
B -X- _ O
C -X- _ O
D -X- _ O
( -X- _ O
c -X- _ O
) -X- _ O
BART -X- _ B-MethodName
: -X- _ O

A -X- _ O
B -X- _ O
C -X- _ O
D -X- _ O
E -X- _ O
Bidirectional -X- _ O
Encoder -X- _ O
Autoregressive -X- _ O
Decoder -X- _ O
A -X- _ O
_ -X- _ O
B -X- _ O
_ -X- _ O

However -X- _ O
words -X- _ O
can -X- _ O
only -X- _ O
condition -X- _ O
on -X- _ O
leftward -X- _ O
context -X- _ O
, -X- _ O
so -X- _ O
it -X- _ O
can -X- _ O
not -X- _ O
learn -X- _ O
bidirectional -X- _ O
interactions -X- _ O
. -X- _ O

( -X- _ O
b -X- _ O
) -X- _ O
GPT -X- _ B-MethodName
: -X- _ O
Tokens -X- _ O
are -X- _ O
predicted -X- _ O
auto -X- _ O
- -X- _ O
regressively -X- _ O
, -X- _ O
meaning -X- _ O
GPT -X- _ B-MethodName
can -X- _ O
be -X- _ O
used -X- _ O
for -X- _ O
generation -X- _ O
. -X- _ O

Missing -X- _ O
tokens -X- _ O
are -X- _ O
predicted -X- _ O
independently -X- _ O
, -X- _ O
so -X- _ O
BERT -X- _ B-MethodName
can -X- _ O
not -X- _ O
easily -X- _ O
be -X- _ O
used -X- _ O
for -X- _ O
generation -X- _ O
. -X- _ O

Random -X- _ O
tokens -X- _ O
are -X- _ O
replaced -X- _ O
with -X- _ O
masks -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
document -X- _ O
is -X- _ O
encoded -X- _ O
bidirectionally -X- _ O
. -X- _ O

E -X- _ O
< -X- _ O
s -X- _ O
> -X- _ O
A -X- _ O
B -X- _ O
C -X- _ O
D -X- _ O
( -X- _ O
a -X- _ O
) -X- _ O
BERT -X- _ B-MethodName
: -X- _ O

C -X- _ O
_ -X- _ O

B -X- _ O
A -X- _ O
B -X- _ O
C -X- _ O
D -X- _ O
E -X- _ O
D -X- _ O
Bidirectional -X- _ O
Encoder -X- _ O
Autoregressive -X- _ O
Decoder -X- _ O
A -X- _ O
_ -X- _ O

These -X- _ O
layers -X- _ O
are -X- _ O
trained -X- _ O
to -X- _ O
essentially -X- _ O
translate -X- _ O
the -X- _ O
foreign -X- _ O
language -X- _ O
to -X- _ O
noised -X- _ O

We -X- _ O
present -X- _ O
a -X- _ O
new -X- _ O
scheme -X- _ O
for -X- _ O
machine -X- _ O
translation -X- _ O
where -X- _ O
a -X- _ O
BART -X- _ B-MethodName
model -X- _ O
is -X- _ O
stacked -X- _ O
above -X- _ O
a -X- _ O
few -X- _ O
additional -X- _ O
transformer -X- _ O
layers -X- _ O
. -X- _ O

BART -X- _ B-MethodName
also -X- _ O
opens -X- _ O
up -X- _ O
new -X- _ O
ways -X- _ O
of -X- _ O
thinking -X- _ O
about -X- _ O
fine -X- _ O
tuning -X- _ O
. -X- _ O

For -X- _ O
example -X- _ O
, -X- _ O
it -X- _ O
improves -X- _ O
performance -X- _ O
by -X- _ O
6 -X- _ B-MetricValue
ROUGE -X- _ B-MetricName
over -X- _ O
previous -X- _ O
work -X- _ O
on -X- _ O
XSum -X- _ B-DatasetName
( -X- _ O
Narayan -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O

It -X- _ O
matches -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
RoBERTa -X- _ B-MethodName
( -X- _ O
Liu -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
with -X- _ O
comparable -X- _ O
training -X- _ O
resources -X- _ O
on -X- _ O
GLUE -X- _ B-DatasetName
( -X- _ O
Wang -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
and -X- _ O
SQuAD -X- _ B-DatasetName
( -X- _ O
Rajpurkar -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
achieves -X- _ O
new -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
results -X- _ O
on -X- _ O
a -X- _ O
range -X- _ O
of -X- _ O
abstractive -X- _ B-TaskName
dialogue -X- _ I-TaskName
, -X- _ O
question -X- _ B-TaskName
answering -X- _ I-TaskName
, -X- _ O
and -X- _ O
summarization -X- _ B-TaskName
tasks -X- _ O
. -X- _ O

BART -X- _ B-MethodName
is -X- _ O
particularly -X- _ O
effective -X- _ O
when -X- _ O
fine -X- _ O
tuned -X- _ O
for -X- _ O
text -X- _ B-TaskName
generation -X- _ I-TaskName
but -X- _ O
also -X- _ O
works -X- _ O
well -X- _ O
for -X- _ O
comprehension -X- _ B-TaskName
tasks -X- _ O
. -X- _ O

This -X- _ O
approach -X- _ O
generalizes -X- _ O
the -X- _ O
original -X- _ O
word -X- _ O
masking -X- _ O
and -X- _ O
next -X- _ O
sentence -X- _ O
prediction -X- _ O
objectives -X- _ O
in -X- _ O
BERT -X- _ B-MethodName
by -X- _ O
forcing -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
reason -X- _ O
more -X- _ O
about -X- _ O
overall -X- _ O
sentence -X- _ O
length -X- _ O
and -X- _ O
make -X- _ O
longer -X- _ O
range -X- _ O
transformations -X- _ O
to -X- _ O
the -X- _ O
input -X- _ O
. -X- _ O

We -X- _ O
evaluate -X- _ O
a -X- _ O
number -X- _ O
of -X- _ O
noising -X- _ O
approaches -X- _ O
, -X- _ O
finding -X- _ O
the -X- _ O
best -X- _ O
performance -X- _ O
by -X- _ O
both -X- _ O
randomly -X- _ O
shuffling -X- _ O
the -X- _ O
order -X- _ O
of -X- _ O
the -X- _ O
original -X- _ O
sentences -X- _ O
and -X- _ O
using -X- _ O
a -X- _ O
novel -X- _ O
in -X- _ O
- -X- _ O
filling -X- _ O
scheme -X- _ O
, -X- _ O
where -X- _ O
arbitrary -X- _ O
length -X- _ O
spans -X- _ O
of -X- _ O
text -X- _ O
( -X- _ O
including -X- _ O
zero -X- _ O
length -X- _ O
) -X- _ O
are -X- _ O
replaced -X- _ O
with -X- _ O
a -X- _ O
single -X- _ O
mask -X- _ O
token -X- _ O
. -X- _ O

A -X- _ O
key -X- _ O
advantage -X- _ O
of -X- _ O
this -X- _ O
setup -X- _ O
is -X- _ O
the -X- _ O
noising -X- _ O
flexibility -X- _ O
; -X- _ O
arbitrary -X- _ O
transformations -X- _ O
can -X- _ O
be -X- _ O
applied -X- _ O
to -X- _ O
the -X- _ O
original -X- _ O
text -X- _ O
, -X- _ O
including -X- _ O
changing -X- _ O
its -X- _ O
length -X- _ O
. -X- _ O

BART -X- _ B-MethodName
uses -X- _ O
a -X- _ O
standard -X- _ O
Tranformer -X- _ O
- -X- _ O
based -X- _ O
neural -X- _ O
machine -X- _ O
translation -X- _ O
architecture -X- _ O
which -X- _ O
, -X- _ O
despite -X- _ O
its -X- _ O
simplicity -X- _ O
, -X- _ O
can -X- _ O
be -X- _ O
seen -X- _ O
as -X- _ O
generalizing -X- _ O
BERT -X- _ B-MethodName
( -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
bidirectional -X- _ O
encoder -X- _ O
) -X- _ O
, -X- _ O
GPT -X- _ B-MethodName
( -X- _ O
with -X- _ O
the -X- _ O
left -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
right -X- _ O
decoder -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
many -X- _ O
other -X- _ O
more -X- _ O
recent -X- _ O
pretraining -X- _ O
schemes -X- _ O
( -X- _ O
see -X- _ O
Figure -X- _ O
1 -X- _ O
) -X- _ O
. -X- _ O

Pretraining -X- _ O
has -X- _ O
two -X- _ O
stages -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
text -X- _ O
is -X- _ O
corrupted -X- _ O
with -X- _ O
an -X- _ O
arbitrary -X- _ O
noising -X- _ O
function -X- _ O
, -X- _ O
and -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
a -X- _ O
sequence -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
sequence -X- _ O
model -X- _ O
is -X- _ O
learned -X- _ O
to -X- _ O
reconstruct -X- _ O
the -X- _ O
original -X- _ O
text -X- _ O
. -X- _ O

BART -X- _ B-MethodName
is -X- _ O
a -X- _ O
denoising -X- _ O
autoencoder -X- _ O
built -X- _ O
with -X- _ O
a -X- _ O
sequence -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
sequence -X- _ O
model -X- _ O
that -X- _ O
is -X- _ O
applicable -X- _ O
to -X- _ O
a -X- _ O
very -X- _ O
wide -X- _ O
range -X- _ O
of -X- _ O
end -X- _ O
tasks -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
present -X- _ O
BART -X- _ B-MethodName
, -X- _ O
which -X- _ O
pre -X- _ O
- -X- _ O
trains -X- _ O
a -X- _ O
model -X- _ O
combining -X- _ O
Bidirectional -X- _ O
and -X- _ O
Auto -X- _ O
- -X- _ O
Regressive -X- _ O
Transformers -X- _ O
. -X- _ O

However -X- _ O
, -X- _ O
these -X- _ O
methods -X- _ O
typically -X- _ O
focus -X- _ O
on -X- _ O
particular -X- _ O
types -X- _ O
of -X- _ O
end -X- _ O
tasks -X- _ O
( -X- _ O
e.g. -X- _ O
span -X- _ B-TaskName
prediction -X- _ I-TaskName
, -X- _ O
generation -X- _ B-TaskName
, -X- _ O
etc -X- _ O
. -X- _ O
) -X- _ O
, -X- _ O
limiting -X- _ O
their -X- _ O
applicability -X- _ O
. -X- _ O

Recent -X- _ O
work -X- _ O
has -X- _ O
shown -X- _ O
gains -X- _ O
by -X- _ O
improving -X- _ O
the -X- _ O
distribution -X- _ O
of -X- _ O
masked -X- _ O
tokens -X- _ O
( -X- _ O
Joshi -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
order -X- _ O
in -X- _ O
which -X- _ O
masked -X- _ O
tokens -X- _ O
are -X- _ O
predicted -X- _ O
( -X- _ O
Yang -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
available -X- _ O
context -X- _ O
for -X- _ O
replacing -X- _ O
masked -X- _ O
tokens -X- _ O
( -X- _ O
Dong -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O

The -X- _ O
most -X- _ O
successful -X- _ O
approaches -X- _ O
have -X- _ O
been -X- _ O
variants -X- _ O
of -X- _ O
masked -X- _ O
language -X- _ O
models -X- _ O
, -X- _ O
which -X- _ O
are -X- _ O
denoising -X- _ O
autoencoders -X- _ O
that -X- _ O
are -X- _ O
trained -X- _ O
to -X- _ O
reconstruct -X- _ O
text -X- _ O
where -X- _ O
a -X- _ O
random -X- _ O
subset -X- _ O
of -X- _ O
the -X- _ O
words -X- _ O
has -X- _ O
been -X- _ O
masked -X- _ O
out -X- _ O
. -X- _ O

We -X- _ O
present -X- _ O
BART -X- _ B-MethodName
, -X- _ O
a -X- _ O
denoising -X- _ O
autoencoder -X- _ O
for -X- _ O
pretraining -X- _ O
sequence -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
sequence -X- _ O
models -X- _ O
. -X- _ O

1 -X- _ O
Introduction -X- _ O
Self -X- _ O
- -X- _ O
supervised -X- _ O
methods -X- _ O
have -X- _ O
achieved -X- _ O
remarkable -X- _ O
success -X- _ O
in -X- _ O
a -X- _ O
wide -X- _ O
range -X- _ O
of -X- _ O
NLP -X- _ O
tasks -X- _ O
( -X- _ O
Mikolov -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2013 -X- _ O
; -X- _ O
Peters -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Devlin -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Joshi -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Yang -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Liu -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O

We -X- _ O
also -X- _ O
report -X- _ O
ablation -X- _ O
experiments -X- _ O
that -X- _ O
replicate -X- _ O
other -X- _ O
pretraining -X- _ O
schemes -X- _ O
within -X- _ O
the -X- _ O
BART -X- _ B-MethodName
framework -X- _ O
, -X- _ O
to -X- _ O
better -X- _ O
measure -X- _ O
which -X- _ O
factors -X- _ O
most -X- _ O
influence -X- _ O
end -X- _ O
- -X- _ O
task -X- _ O
performance -X- _ O
. -X- _ O

BART -X- _ B-MethodName
also -X- _ O
provides -X- _ O
a -X- _ O
1.1 -X- _ B-MetricValue
BLEU -X- _ B-MetricName
increase -X- _ O
over -X- _ O
a -X- _ O
back -X- _ O
- -X- _ O
translation -X- _ O
system -X- _ O
for -X- _ O
machine -X- _ B-TaskName
translation -X- _ I-TaskName
, -X- _ O
with -X- _ O
only -X- _ O
target -X- _ O
language -X- _ O
pretraining -X- _ O
. -X- _ O

It -X- _ O
matches -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
RoBERTa -X- _ B-MethodName
with -X- _ O
comparable -X- _ O
training -X- _ O
resources -X- _ O
on -X- _ O
GLUE -X- _ B-DatasetName
and -X- _ O
SQuAD -X- _ B-DatasetName
, -X- _ O
achieves -X- _ O
new -X- _ O
stateof -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
results -X- _ O
on -X- _ O
a -X- _ O
range -X- _ O
of -X- _ O
abstractive -X- _ B-TaskName
dialogue -X- _ I-TaskName
, -X- _ O
question -X- _ B-TaskName
answering -X- _ I-TaskName
, -X- _ O
and -X- _ O
summarization -X- _ B-TaskName
tasks -X- _ O
, -X- _ O
with -X- _ O
gains -X- _ O
of -X- _ O
up -X- _ O
to -X- _ O
6 -X- _ B-MetricValue
ROUGE -X- _ B-MetricName
. -X- _ O

BART -X- _ B-MethodName
is -X- _ O
particularly -X- _ O
effective -X- _ O
when -X- _ O
fine -X- _ O
tuned -X- _ O
for -X- _ O
text -X- _ B-TaskName
generation -X- _ I-TaskName
but -X- _ O
also -X- _ O
works -X- _ O
well -X- _ O
for -X- _ O
comprehension -X- _ B-TaskName
tasks -X- _ I-TaskName
. -X- _ O

We -X- _ O
evaluate -X- _ O
a -X- _ O
number -X- _ O
of -X- _ O
noising -X- _ O
approaches -X- _ O
, -X- _ O
finding -X- _ O
the -X- _ O
best -X- _ O
performance -X- _ O
by -X- _ O
both -X- _ O
randomly -X- _ O
shuffling -X- _ O
the -X- _ O
order -X- _ O
of -X- _ O
the -X- _ O
original -X- _ O
sentences -X- _ O
and -X- _ O
using -X- _ O
a -X- _ O
novel -X- _ O
in -X- _ O
- -X- _ O
filling -X- _ O
scheme -X- _ O
, -X- _ O
where -X- _ O
spans -X- _ O
of -X- _ O
text -X- _ O
are -X- _ O
replaced -X- _ O
with -X- _ O
a -X- _ O
single -X- _ O
mask -X- _ O
token -X- _ O
. -X- _ O

It -X- _ O
uses -X- _ O
a -X- _ O
standard -X- _ O
Tranformer -X- _ O
- -X- _ O
based -X- _ O
neural -X- _ O
machine -X- _ O
translation -X- _ O
architecture -X- _ O
which -X- _ O
, -X- _ O
despite -X- _ O
its -X- _ O
simplicity -X- _ O
, -X- _ O
can -X- _ O
be -X- _ O
seen -X- _ O
as -X- _ O
generalizing -X- _ O
BERT -X- _ B-MethodName
( -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
bidirectional -X- _ O
encoder -X- _ O
) -X- _ O
, -X- _ O
GPT -X- _ B-MethodName
( -X- _ O
with -X- _ O
the -X- _ O
left -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
right -X- _ O
decoder -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
many -X- _ O
other -X- _ O
more -X- _ O
recent -X- _ O
pretraining -X- _ O
schemes -X- _ O
. -X- _ O

BART -X- _ B-MethodName
is -X- _ O
trained -X- _ O
by -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
corrupting -X- _ O
text -X- _ O
with -X- _ O
an -X- _ O
arbitrary -X- _ O
noising -X- _ O
function -X- _ O
, -X- _ O
and -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
learning -X- _ O
a -X- _ O
model -X- _ O
to -X- _ O
reconstruct -X- _ O
the -X- _ O
original -X- _ O
text -X- _ O
. -X- _ O

[ -X- _ O
cs -X- _ O
. -X- _ O
CL -X- _ O
] -X- _ O
29 -X- _ O
Oct -X- _ O
2019 -X- _ O

Denoising -X- _ O
Sequence -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
Sequence -X- _ O
Pre -X- _ O
- -X- _ O
training -X- _ O
for -X- _ O
Natural -X- _ B-TaskName
Language -X- _ I-TaskName
Generation -X- _ I-TaskName
, -X- _ O
Translation -X- _ B-TaskName
, -X- _ O
and -X- _ O
Comprehension -X- _ B-TaskName
Mike -X- _ O
Lewis -X- _ O
* -X- _ O
, -X- _ O
Yinhan -X- _ O
Liu -X- _ O
* -X- _ O
, -X- _ O
Naman -X- _ O
Goyal -X- _ O
* -X- _ O
, -X- _ O
Marjan -X- _ O
Ghazvininejad -X- _ O
, -X- _ O
Abdelrahman -X- _ O
Mohamed -X- _ O
, -X- _ O
Omer -X- _ O
Levy -X- _ O
, -X- _ O
Ves -X- _ O
Stoyanov -X- _ O
, -X- _ O
Luke -X- _ O
Zettlemoyer -X- _ O
Facebook -X- _ O
AI -X- _ O
{ -X- _ O
mikelewis,yinhanliu,naman}@fb.com -X- _ O
Abstract -X- _ O
arXiv:1910.13461v1 -X- _ O

BART -X- _ B-MethodName
: -X- _ O

