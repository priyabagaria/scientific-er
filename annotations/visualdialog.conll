-DOCSTART- -X- O
This -X- _ O
work -X- _ O
was -X- _ O
partially -X- _ O
supported -X- _ O
by -X- _ O
the -X- _ O
Research -X- _ O
Grants -X- _ O
Council -X- _ O
of -X- _ O
the -X- _ O
Hong -X- _ O
Kong -X- _ O
Special -X- _ O
Administrative -X- _ O
Region -X- _ O
, -X- _ O
China -X- _ O
( -X- _ O
No -X- _ O
. -X- _ O
CUHK -X- _ O
14210717 -X- _ O
, -X- _ O
General -X- _ O
Research -X- _ O
Fund -X- _ O
; -X- _ O
No -X- _ O
. -X- _ O
CUHK -X- _ O
2300174 -X- _ O
, -X- _ O
Collaborative -X- _ O
Research -X- _ O
Fund -X- _ O
) -X- _ O
. -X- _ O

Acknowledgements -X- _ O
We -X- _ O
thank -X- _ O
Chien -X- _ O
- -X- _ O
Sheng -X- _ O
Wu -X- _ O
, -X- _ O
Jiashi -X- _ O
Feng -X- _ O
, -X- _ O
Jiaxin -X- _ O
Qi -X- _ O
, -X- _ O
and -X- _ O
our -X- _ O
anonymous -X- _ O
reviewers -X- _ O
for -X- _ O
their -X- _ O
insightful -X- _ O
feedback -X- _ O
on -X- _ O
our -X- _ O
paper -X- _ O
. -X- _ O

Without -X- _ O
pretraining -X- _ O
on -X- _ O
external -X- _ O
visionlanguage -X- _ O
datasets -X- _ O
, -X- _ O
our -X- _ O
model -X- _ O
establishes -X- _ O
new -X- _ O
stateof -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
performance -X- _ O
in -X- _ O
the -X- _ O
discriminative -X- _ O
setting -X- _ O
and -X- _ O
shows -X- _ O
promising -X- _ O
results -X- _ O
in -X- _ O
the -X- _ O
generative -X- _ O
setting -X- _ O
on -X- _ O
the -X- _ O
visual -X- _ B-TaskName
dialog -X- _ I-TaskName
benchmarks -X- _ O
. -X- _ O

Besides -X- _ O
, -X- _ O
it -X- _ O
can -X- _ O
either -X- _ O
rank -X- _ O
or -X- _ O
generate -X- _ O
answers -X- _ O
seamlessly -X- _ O
. -X- _ O

VD -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
is -X- _ O
capable -X- _ O
of -X- _ O
modeling -X- _ O
all -X- _ O
the -X- _ O
interactions -X- _ O
between -X- _ O
an -X- _ O
image -X- _ O
and -X- _ O
a -X- _ O
multi -X- _ B-TaskName
- -X- _ I-TaskName
turn -X- _ I-TaskName
dialog -X- _ I-TaskName
within -X- _ O
a -X- _ O
single -X- _ O
- -X- _ O
stream -X- _ O
Transformer -X- _ O
encoder -X- _ O
and -X- _ O
enables -X- _ O
the -X- _ O
effective -X- _ O
fusion -X- _ O
of -X- _ O
features -X- _ O
from -X- _ O
both -X- _ O
modalities -X- _ O
via -X- _ O
simple -X- _ O
visually -X- _ O
grounded -X- _ O
training -X- _ O
. -X- _ O

Conclusion -X- _ O
We -X- _ O
have -X- _ O
presented -X- _ O
VD -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
, -X- _ O
a -X- _ O
unified -X- _ B-MethodName
visiondialog -X- _ I-MethodName
Transformer -X- _ I-MethodName
model -X- _ O
that -X- _ O
exploits -X- _ O
the -X- _ O
pretrained -X- _ O
BERT -X- _ O
language -X- _ O
models -X- _ O
for -X- _ O
visual -X- _ B-TaskName
dialog -X- _ I-TaskName
. -X- _ O

We -X- _ O
provide -X- _ O
more -X- _ O
qualitative -X- _ O
examples -X- _ O
in -X- _ O
Figure -X- _ O
6 -X- _ O
and -X- _ O
7 -X- _ O
. -X- _ O

More -X- _ O
interestingly -X- _ O
, -X- _ O
it -X- _ O
can -X- _ O
even -X- _ O
resolve -X- _ O
visual -X- _ O
pronoun -X- _ O
coreference -X- _ O
of -X- _ O
he -X- _ O
in -X- _ O
the -X- _ O
question -X- _ O
to -X- _ O
the -X- _ O
man -X- _ O
in -X- _ O
the -X- _ O
image -X- _ O
( -X- _ O
see -X- _ O
the -X- _ O
middle -X- _ O
red -X- _ O
box -X- _ O
) -X- _ O
. -X- _ O

As -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
5(b -X- _ O
) -X- _ O
, -X- _ O
VD -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
can -X- _ O
ground -X- _ O
entities -X- _ O
and -X- _ O
discover -X- _ O
some -X- _ O
object -X- _ O
relations -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
helmet -X- _ O
is -X- _ O
precisely -X- _ O
related -X- _ O
to -X- _ O
the -X- _ O
man -X- _ O
and -X- _ O
the -X- _ O
motorcycle -X- _ O
in -X- _ O
the -X- _ O
image -X- _ O
( -X- _ O
see -X- _ O
the -X- _ O
rightmost -X- _ O
red -X- _ O
box -X- _ O
) -X- _ O
. -X- _ O

In -X- _ O
contrast -X- _ O
to -X- _ O
other -X- _ O
vision -X- _ O
- -X- _ O
language -X- _ O
tasks -X- _ O
, -X- _ O
visual -X- _ B-TaskName
dialog -X- _ I-TaskName
has -X- _ O
a -X- _ O
more -X- _ O
complex -X- _ O
multi -X- _ O
- -X- _ O
turn -X- _ O
structure -X- _ O
, -X- _ O
thereby -X- _ O
posing -X- _ O
a -X- _ O
hurdle -X- _ O
for -X- _ O
effective -X- _ O
fusion -X- _ O
. -X- _ O

Next -X- _ O
, -X- _ O
we -X- _ O
examine -X- _ O
how -X- _ O
our -X- _ O
VD -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
captures -X- _ O
the -X- _ O
interactions -X- _ O
between -X- _ O
image -X- _ O
and -X- _ O
multi -X- _ B-TaskName
- -X- _ I-TaskName
turn -X- _ I-TaskName
dialog -X- _ I-TaskName
. -X- _ O

Besides -X- _ O
, -X- _ O
heads -X- _ O
at -X- _ O
higher -X- _ O
layers -X- _ O
tend -X- _ O
to -X- _ O
have -X- _ O
a -X- _ O
sharper -X- _ O
focus -X- _ O
on -X- _ O
specific -X- _ O
objects -X- _ O
like -X- _ O
the -X- _ O
man -X- _ O
and -X- _ O
the -X- _ O
motorcycles -X- _ O
in -X- _ O
the -X- _ O
image -X- _ O
. -X- _ O

We -X- _ O
observe -X- _ O
that -X- _ O
many -X- _ O
heads -X- _ O
at -X- _ O
different -X- _ O
layers -X- _ B-HyperparameterName
can -X- _ O
correctly -X- _ O
ground -X- _ O
some -X- _ O
entities -X- _ O
like -X- _ O
person -X- _ O
and -X- _ O
motorcycle -X- _ O
in -X- _ O
the -X- _ O
image -X- _ O
, -X- _ O
and -X- _ O
even -X- _ O
reveal -X- _ O
some -X- _ O
high -X- _ O
- -X- _ O
level -X- _ O
semantic -X- _ O
correlations -X- _ O
such -X- _ O
as -X- _ O
person↔motorcycle -X- _ O
( -X- _ O
at -X- _ O
L8H2 -X- _ O
) -X- _ O
and -X- _ O
motorcycle↔street -X- _ O
( -X- _ O
at -X- _ O
L1H11 -X- _ O
) -X- _ O
. -X- _ O

To -X- _ O
interpret -X- _ O
our -X- _ O
VD -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
, -X- _ O
we -X- _ O
visualize -X- _ O
the -X- _ O
attention -X- _ O
weights -X- _ O
on -X- _ O
the -X- _ O
top -X- _ O
10 -X- _ O
detected -X- _ O
objects -X- _ O
from -X- _ O
its -X- _ O
caption -X- _ O
in -X- _ O
Figure -X- _ O
5(a -X- _ O
) -X- _ O
. -X- _ O

5.4 -X- _ O
6 -X- _ O
Attention -X- _ O
Visualization -X- _ O

Fine -X- _ O
- -X- _ O
tuning -X- _ O
on -X- _ O
dense -X- _ O
annotations -X- _ O
gives -X- _ O
our -X- _ O
model -X- _ O
huge -X- _ O
improvements -X- _ O
across -X- _ O
all -X- _ O
the -X- _ O
question -X- _ O
types -X- _ O
, -X- _ O
especially -X- _ O
for -X- _ O
Others -X- _ O
with -X- _ O
over -X- _ O
30 -X- _ O
% -X- _ O
absolute -X- _ O
gain -X- _ O
. -X- _ O

Our -X- _ O
model -X- _ O
outperforms -X- _ O
DAN -X- _ B-MethodName
by -X- _ O
over -X- _ O
10 -X- _ O
% -X- _ O
in -X- _ O
most -X- _ O
of -X- _ O
the -X- _ O
question -X- _ O
types -X- _ O
except -X- _ O
Color -X- _ O
. -X- _ O

For -X- _ O
question -X- _ O
types -X- _ O
, -X- _ O
we -X- _ O
observe -X- _ O
that -X- _ O
Yes -X- _ O
/ -X- _ O
no -X- _ O
is -X- _ O
the -X- _ O
major -X- _ O
type -X- _ O
( -X- _ O
76 -X- _ O
% -X- _ O
) -X- _ O
and -X- _ O
also -X- _ O
the -X- _ O
easiest -X- _ O
one -X- _ O
, -X- _ O
while -X- _ O
Number -X- _ O
is -X- _ O
the -X- _ O
most -X- _ O
challenging -X- _ O
and -X- _ O
least -X- _ O
frequent -X- _ O
one -X- _ O
( -X- _ O
3 -X- _ O
% -X- _ O
) -X- _ O
. -X- _ O

These -X- _ O
results -X- _ O
validate -X- _ O
that -X- _ O
the -X- _ O
misalignment -X- _ O
of -X- _ O
the -X- _ O
sparse -X- _ O
and -X- _ O
dense -X- _ O
annotations -X- _ O
is -X- _ O
the -X- _ O
key -X- _ O
reason -X- _ O
for -X- _ O
the -X- _ O
inconsistency -X- _ O
between -X- _ O
NDCG -X- _ B-MetricName
and -X- _ O
other -X- _ O
metrics -X- _ O
. -X- _ O

As -X- _ O
the -X- _ O
degree -X- _ O
of -X- _ O
such -X- _ O
mismatch -X- _ O
increases -X- _ O
( -X- _ O
relevance -X- _ O
score -X- _ O
changes -X- _ O
1.0 -X- _ O
→ -X- _ O
0.0 -X- _ O
) -X- _ O
, -X- _ O
both -X- _ O
DAN -X- _ B-MethodName
and -X- _ O
our -X- _ O
model -X- _ O
witness -X- _ O
a -X- _ O
plunge -X- _ O
in -X- _ O
NDCG -X- _ B-MetricName
( -X- _ O
63.29 -X- _ B-MetricValue
→ -X- _ O
43.86 -X- _ B-MetricValue
and -X- _ O
70.25 -X- _ B-MetricValue
→ -X- _ O
48.07 -X- _ B-MetricValue
) -X- _ O
, -X- _ O
while -X- _ O
dense -X- _ O
annotation -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
significantly -X- _ O
boosts -X- _ O
NDCG -X- _ B-MetricName
scores -X- _ O
for -X- _ O
all -X- _ O
groups -X- _ O
, -X- _ O
especially -X- _ O
for -X- _ O
the -X- _ O
most -X- _ O
misaligned -X- _ O
one -X- _ O
( -X- _ O
48.07 -X- _ B-MetricValue
→ -X- _ O
82.84 -X- _ B-MetricValue
for -X- _ O
our -X- _ O
model -X- _ O
) -X- _ O
. -X- _ O

By -X- _ O
examining -X- _ O
the -X- _ O
distribution -X- _ O
of -X- _ O
the -X- _ O
relevance -X- _ O
scores -X- _ O
, -X- _ O
we -X- _ O
find -X- _ O
that -X- _ O
only -X- _ O
31 -X- _ O
% -X- _ O
of -X- _ O
them -X- _ O
are -X- _ O
aligned -X- _ O
well -X- _ O
with -X- _ O
the -X- _ O
sparse -X- _ O
annotations -X- _ O
and -X- _ O
9 -X- _ O
% -X- _ O
are -X- _ O
totally -X- _ O
misaligned -X- _ O
. -X- _ O

We -X- _ O
choose -X- _ O
DAN -X- _ B-MethodName
as -X- _ O
it -X- _ O
achieves -X- _ O
good -X- _ O
NDCG -X- _ B-MetricName
scores -X- _ O
( -X- _ O
Table -X- _ O
1 -X- _ O
) -X- _ O
and -X- _ O
provides -X- _ O
the -X- _ O
source -X- _ O
code -X- _ O
to -X- _ O
reproduce -X- _ O
their -X- _ O
predictions -X- _ O
. -X- _ O

We -X- _ O
then -X- _ O
analyze -X- _ O
the -X- _ O
NDCG -X- _ B-MetricName
scores -X- _ O
assigned -X- _ O
by -X- _ O
DAN -X- _ B-MethodName
( -X- _ O
Kang -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
and -X- _ O
our -X- _ O
VD -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
with -X- _ O
and -X- _ O
without -X- _ O
dense -X- _ O
annotation -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
. -X- _ O

We -X- _ O
consider -X- _ O
four -X- _ O
bins -X- _ O
{ -X- _ O
0.0 -X- _ O
, -X- _ O
0.2 -X- _ O
∼ -X- _ O
0.4 -X- _ O
, -X- _ O
0.6 -X- _ O
∼ -X- _ O
0.8 -X- _ O
, -X- _ O
1.0 -X- _ O
} -X- _ O
for -X- _ O
the -X- _ O
relevance -X- _ O
score -X- _ O
and -X- _ O
four -X- _ O
question -X- _ O
types -X- _ O
: -X- _ O
Yes -X- _ O
/ -X- _ O
no -X- _ O
, -X- _ O
Number -X- _ O
, -X- _ O
Color -X- _ O
, -X- _ O
and -X- _ O
Others -X- _ O
. -X- _ O

For -X- _ O
further -X- _ O
analysis -X- _ O
, -X- _ O
we -X- _ O
classify -X- _ O
the -X- _ O
2 -X- _ O
, -X- _ O
064 -X- _ O
instances -X- _ O
in -X- _ O
VisDial -X- _ B-DatasetName
v1.0 -X- _ O
val -X- _ O
set -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
ground -X- _ O
- -X- _ O
truth -X- _ O
’s -X- _ O
relevance -X- _ O
score -X- _ O
and -X- _ O
question -X- _ O
type -X- _ O
( -X- _ O
Table -X- _ O
4 -X- _ O
) -X- _ O
. -X- _ O

We -X- _ O
observe -X- _ O
that -X- _ O
NDCG -X- _ B-MetricName
keeps -X- _ O
increasing -X- _ O
with -X- _ O
more -X- _ O
epochs -X- _ O
of -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
, -X- _ O
while -X- _ O
other -X- _ O
metrics -X- _ O
such -X- _ O
as -X- _ O
Recall@K -X- _ B-MetricName
and -X- _ O
MRR -X- _ B-MetricName
) -X- _ O
drop -X- _ O
. -X- _ O

For -X- _ O
this -X- _ O
experiment -X- _ O
, -X- _ O
we -X- _ O
randomly -X- _ O
sample -X- _ O
200 -X- _ O
instances -X- _ O
from -X- _ O
VisDial -X- _ B-DatasetName
v1.0 -X- _ O
val -X- _ O
as -X- _ O
the -X- _ O
test -X- _ O
data -X- _ O
and -X- _ O
use -X- _ O
the -X- _ O
rest -X- _ O
for -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
with -X- _ O
the -X- _ O
ListNet -X- _ O
ranking -X- _ O
method -X- _ O
. -X- _ O

We -X- _ O
first -X- _ O
show -X- _ O
how -X- _ O
various -X- _ O
metrics -X- _ O
change -X- _ O
for -X- _ O
finetuning -X- _ O
in -X- _ O
Figure -X- _ O
4 -X- _ O
. -X- _ O

Relevance -X- _ O
Score -X- _ O
and -X- _ O
Question -X- _ O
Type -X- _ O
Analysis -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
case -X- _ O
, -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
instead -X- _ O
makes -X- _ O
our -X- _ O
model -X- _ O
fail -X- _ O
to -X- _ O
predict -X- _ O
the -X- _ O
correct -X- _ O
answer -X- _ O
despite -X- _ O
the -X- _ O
increase -X- _ O
of -X- _ O
NDCG -X- _ B-MetricName
score -X- _ O
. -X- _ O

In -X- _ O
the -X- _ O
example -X- _ O
at -X- _ O
the -X- _ O
bottom -X- _ O
, -X- _ O
we -X- _ O
spot -X- _ O
a -X- _ O
mismatch -X- _ O
between -X- _ O
the -X- _ O
sparse -X- _ O
and -X- _ O
dense -X- _ O
annotations -X- _ O
: -X- _ O
the -X- _ O
ground -X- _ O
truth -X- _ O
answer -X- _ O
“ -X- _ O
no -X- _ O
, -X- _ O
it -X- _ O
’s -X- _ O
empty -X- _ O
” -X- _ O
is -X- _ O
only -X- _ O
given -X- _ O
a -X- _ O
0.4 -X- _ O
relevance -X- _ O
score -X- _ O
, -X- _ O
while -X- _ O
uncertain -X- _ O
answers -X- _ O
like -X- _ O
“ -X- _ O
i -X- _ O
do -X- _ O
n’t -X- _ O
know -X- _ O
” -X- _ O
are -X- _ O
considered -X- _ O
to -X- _ O
be -X- _ O
more -X- _ O
relevant -X- _ O
. -X- _ O

For -X- _ O
the -X- _ O
example -X- _ O
at -X- _ O
the -X- _ O
top -X- _ O
, -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
helps -X- _ O
our -X- _ O
model -X- _ O
to -X- _ O
assign -X- _ O
higher -X- _ O
ranks -X- _ O
to -X- _ O
the -X- _ O
answers -X- _ O
that -X- _ O
share -X- _ O
similar -X- _ O
semantics -X- _ O
with -X- _ O
the -X- _ O
ground -X- _ O
truth -X- _ O
answer -X- _ O
and -X- _ O
should -X- _ O
also -X- _ O
be -X- _ O
regarded -X- _ O
as -X- _ O
correct -X- _ O
( -X- _ O
“ -X- _ O
yes -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
” -X- _ O
and -X- _ O
“ -X- _ O
yep -X- _ O
” -X- _ O
vs. -X- _ O
“ -X- _ O
yes -X- _ O
” -X- _ O
) -X- _ O
. -X- _ O

We -X- _ O
provide -X- _ O
two -X- _ O
examples -X- _ O
to -X- _ O
qualitatively -X- _ O
demonstrate -X- _ O
how -X- _ O
dense -X- _ O
annotation -X- _ O
finetuning -X- _ O
results -X- _ O
in -X- _ O
better -X- _ O
NDCG -X- _ B-MetricName
scores -X- _ O
in -X- _ O
Figure -X- _ O
3 -X- _ O
. -X- _ O

Case -X- _ O
Study -X- _ O
. -X- _ O

5.3 -X- _ O
Fine -X- _ O
- -X- _ O
tuning -X- _ O
on -X- _ O
Dense -X- _ O
Annotations -X- _ O
In -X- _ O
this -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
focus -X- _ O
on -X- _ O
the -X- _ O
effect -X- _ O
of -X- _ O
dense -X- _ O
annotation -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
and -X- _ O
try -X- _ O
to -X- _ O
analyze -X- _ O
the -X- _ O
reason -X- _ O
of -X- _ O
the -X- _ O
inconsistency -X- _ O
issue -X- _ O
between -X- _ O
NDCG -X- _ B-MetricName
and -X- _ O
other -X- _ O
ranking -X- _ O
metrics -X- _ O
( -X- _ O
see -X- _ O
Table -X- _ O
1 -X- _ O
) -X- _ O
in -X- _ O
the -X- _ O
following -X- _ O
. -X- _ O

The -X- _ O
diverse -X- _ O
set -X- _ O
of -X- _ O
them -X- _ O
leads -X- _ O
to -X- _ O
the -X- _ O
best -X- _ O
performance -X- _ O
. -X- _ O

We -X- _ O
observe -X- _ O
that -X- _ O
EPOCH -X- _ B-HyperparameterName
contributes -X- _ O
the -X- _ O
least -X- _ O
to -X- _ O
the -X- _ O
ensemble -X- _ O
performance -X- _ O
while -X- _ O
RANK -X- _ O
models -X- _ O
are -X- _ O
more -X- _ O
helpful -X- _ O
than -X- _ O
LENGTH -X- _ O
models -X- _ O
. -X- _ O

We -X- _ O
use -X- _ O
four -X- _ O
predictions -X- _ O
from -X- _ O
each -X- _ O
criterion -X- _ O
and -X- _ O
combine -X- _ O
their -X- _ O
diverse -X- _ O
predictions -X- _ O
( -X- _ O
DIVERSE -X- _ O
) -X- _ O
by -X- _ O
summing -X- _ O
up -X- _ O
their -X- _ O
normalized -X- _ O
ranking -X- _ O
scores -X- _ O
. -X- _ O

We -X- _ O
consider -X- _ O
three -X- _ O
criteria -X- _ O
, -X- _ O
E -X- _ B-HyperparameterName
POCH -X- _ I-HyperparameterName
, -X- _ O
L -X- _ O
ENGTH -X- _ O
, -X- _ O
and -X- _ O
R -X- _ O
ANK -X- _ O
that -X- _ O
respectively -X- _ O
refer -X- _ O
to -X- _ O
predictions -X- _ O
from -X- _ O
different -X- _ O
epochs -X- _ B-HyperparameterName
of -X- _ O
a -X- _ O
single -X- _ O
model -X- _ O
, -X- _ O
from -X- _ O
different -X- _ O
models -X- _ O
trained -X- _ O
with -X- _ O
varying -X- _ O
context -X- _ O
lengths -X- _ O
and -X- _ O
with -X- _ O
different -X- _ O
ranking -X- _ O
methods -X- _ O
in -X- _ O
Table -X- _ O
3(b)-(c -X- _ O
) -X- _ O
. -X- _ O

We -X- _ O
also -X- _ O
explore -X- _ O
ways -X- _ O
to -X- _ O
achieve -X- _ O
the -X- _ O
best -X- _ O
ensemble -X- _ O
performance -X- _ O
with -X- _ O
various -X- _ O
model -X- _ O
selection -X- _ O
criteria -X- _ O
in -X- _ O
Table -X- _ O
3(d -X- _ O
) -X- _ O
. -X- _ O

Therefore -X- _ O
, -X- _ O
we -X- _ O
employ -X- _ O
the -X- _ O
ListNet -X- _ O
as -X- _ O
our -X- _ O
ranking -X- _ O
module -X- _ O
. -X- _ O

Among -X- _ O
these -X- _ O
methods -X- _ O
, -X- _ O
ListNet -X- _ O
yields -X- _ O
the -X- _ O
best -X- _ O
NDCG -X- _ B-MetricName
and -X- _ O
Mean -X- _ B-MetricName
Rank -X- _ I-MetricName
, -X- _ O
while -X- _ O
the -X- _ O
approxNDCG -X- _ O
achieves -X- _ O
the -X- _ O
best -X- _ O
MRR -X- _ B-MetricName
and -X- _ O
Recall -X- _ B-MetricName
on -X- _ O
VisDial -X- _ B-DatasetName
v1.0 -X- _ O
test -X- _ O
- -X- _ O
std -X- _ O
. -X- _ O

In -X- _ O
Table -X- _ O
3(c -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
compare -X- _ O
Cross -X- _ O
Entropy -X- _ O
( -X- _ O
CE -X- _ O
) -X- _ O
training -X- _ O
with -X- _ O
a -X- _ O
bunch -X- _ O
of -X- _ O
other -X- _ O
listwise -X- _ O
ranking -X- _ O
optimization -X- _ O
methods -X- _ O
: -X- _ O
ListNet -X- _ O
( -X- _ O
Cao -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2007 -X- _ O
) -X- _ O
, -X- _ O
ListMLE -X- _ O
( -X- _ O
Xia -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2008 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
approxNDCG -X- _ O
( -X- _ O
Qin -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2010 -X- _ O
) -X- _ O
. -X- _ O

However -X- _ O
, -X- _ O
this -X- _ O
version -X- _ O
still -X- _ O
obtains -X- _ O
comparable -X- _ O
results -X- _ O
to -X- _ O
the -X- _ O
“ -X- _ O
No -X- _ O
history -X- _ O
” -X- _ O
variant -X- _ O
, -X- _ O
revealing -X- _ O
that -X- _ O
textual -X- _ O
information -X- _ O
dominates -X- _ O
the -X- _ O
VisDial -X- _ B-DatasetName
task -X- _ O
. -X- _ O

If -X- _ O
we -X- _ O
remove -X- _ O
the -X- _ O
visual -X- _ O
cues -X- _ O
from -X- _ O
the -X- _ O
“ -X- _ O
Full -X- _ O
history -X- _ O
” -X- _ O
model -X- _ O
, -X- _ O
we -X- _ O
see -X- _ O
a -X- _ O
drop -X- _ O
in -X- _ O
all -X- _ O
metrics -X- _ O
, -X- _ O
especially -X- _ O
, -X- _ O
on -X- _ O
NDCG -X- _ B-MetricName
. -X- _ O

dicates -X- _ O
that -X- _ O
dense -X- _ O
relevance -X- _ O
scores -X- _ O
might -X- _ O
be -X- _ O
annotated -X- _ O
with -X- _ O
less -X- _ O
consideration -X- _ O
of -X- _ O
dialog -X- _ O
history -X- _ O
. -X- _ O

GT -X- _ O
: -X- _ O
ground -X- _ O
truth -X- _ O
. -X- _ O

NDCG=91.80 -X- _ B-MetricName
Figure -X- _ O
3 -X- _ O
: -X- _ O
The -X- _ O
effects -X- _ O
of -X- _ O
dense -X- _ O
annotation -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
in -X- _ O
our -X- _ O
VD -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
for -X- _ O
two -X- _ O
examples -X- _ O
. -X- _ O

not -X- _ O
that -X- _ O
i -X- _ O
can -X- _ O
see -X- _ O
( -X- _ O
0.6 -X- _ O
) -X- _ O
Base -X- _ O
Model -X- _ O
W/ -X- _ O
Fine -X- _ O
- -X- _ O
tuning -X- _ O
NDCG=42.19 -X- _ B-MetricName

definitely -X- _ O
( -X- _ O
0.6 -X- _ O
) -X- _ O
W/ -X- _ O
Fine -X- _ O
- -X- _ O
tuning -X- _ O
NDCG=41.31 -X- _ B-MetricName
NDCG=97.06 -X- _ B-MetricName
1 -X- _ O
. -X- _ O

With -X- _ O
longer -X- _ O
dialog -X- _ O
history -X- _ O
( -X- _ O
“ -X- _ O
Full -X- _ O
history -X- _ O
” -X- _ O
) -X- _ O
, -X- _ O
our -X- _ O
model -X- _ O
indeed -X- _ O
yields -X- _ O
better -X- _ O
results -X- _ O
in -X- _ O
most -X- _ O
of -X- _ O
the -X- _ O
ranking -X- _ O
metrics -X- _ O
, -X- _ O
while -X- _ O
the -X- _ O
one -X- _ O
without -X- _ O
using -X- _ O
any -X- _ O
dialog -X- _ O
history -X- _ O
obtains -X- _ O
the -X- _ O
highest -X- _ O
NDCG -X- _ B-MetricName
score -X- _ O
. -X- _ O

We -X- _ O
then -X- _ O
examine -X- _ O
the -X- _ O
impact -X- _ O
of -X- _ O
varying -X- _ O
the -X- _ O
dialog -X- _ O
context -X- _ O
used -X- _ O
for -X- _ O
training -X- _ O
in -X- _ O
Table -X- _ O
3(b -X- _ O
) -X- _ O
. -X- _ O

We -X- _ O
also -X- _ O
find -X- _ O
that -X- _ O
the -X- _ O
visually -X- _ O
grounded -X- _ O
MLM -X- _ O
is -X- _ O
crucial -X- _ O
for -X- _ O
transferring -X- _ O
BERT -X- _ O
into -X- _ O
the -X- _ O
multimodal -X- _ O
setting -X- _ O
, -X- _ O
indicated -X- _ O
by -X- _ O
a -X- _ O
large -X- _ O
performance -X- _ O
drop -X- _ O
when -X- _ O
using -X- _ O
only -X- _ O
NSP -X- _ O
. -X- _ O

Another -X- _ O
possible -X- _ O
reason -X- _ O
might -X- _ O
be -X- _ O
that -X- _ O
the -X- _ O
VisDial -X- _ B-DatasetName
data -X- _ O
with -X- _ O
more -X- _ O
than -X- _ O
one -X- _ O
million -X- _ O
image -X- _ O
- -X- _ O
dialog -X- _ O
turn -X- _ O
pairs -X- _ O
can -X- _ O
provide -X- _ O
adequate -X- _ O
contexts -X- _ O
to -X- _ O
adapt -X- _ O
BERT -X- _ O
for -X- _ O
effective -X- _ O
vision -X- _ O
and -X- _ O
dialog -X- _ O
fusion -X- _ O
. -X- _ O

It -X- _ O
might -X- _ O
be -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
domain -X- _ O
discrepancy -X- _ O
between -X- _ O
image -X- _ O
captions -X- _ O
and -X- _ O
multi -X- _ B-MethodName
- -X- _ I-MethodName
turn -X- _ I-MethodName
dialogs -X- _ I-MethodName
, -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
the -X- _ O
slightly -X- _ O
different -X- _ O
experiment -X- _ O
settings -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
we -X- _ O
extract -X- _ O
36 -X- _ O
objects -X- _ O
from -X- _ O
image -X- _ O
compared -X- _ O
to -X- _ O
their -X- _ O
100 -X- _ O
objects -X- _ O
) -X- _ O
. -X- _ O

Surprisingly -X- _ O
, -X- _ O
the -X- _ O
model -X- _ O
initialized -X- _ O
with -X- _ O
the -X- _ O
weights -X- _ O
from -X- _ O
VLP -X- _ O
that -X- _ O
was -X- _ O
pretrained -X- _ O
on -X- _ O
Conceptual -X- _ B-DatasetName
Captions -X- _ I-DatasetName
( -X- _ O
Sharma -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
does -X- _ O
not -X- _ O
work -X- _ O
better -X- _ O
than -X- _ O
the -X- _ O
one -X- _ O
initialized -X- _ O
from -X- _ O
BERT -X- _ O
. -X- _ O

We -X- _ O
observe -X- _ O
that -X- _ O
initializing -X- _ O
the -X- _ O
model -X- _ O
with -X- _ O
weights -X- _ O
from -X- _ O
BERT -X- _ O
indeed -X- _ O
benefits -X- _ O
the -X- _ O
visual -X- _ O
dialog -X- _ O
task -X- _ O
a -X- _ O
lot -X- _ O
, -X- _ O
increasing -X- _ O
the -X- _ O
NDCG -X- _ B-MetricName
score -X- _ O
by -X- _ O
about -X- _ O
7 -X- _ B-MetricValue
% -X- _ I-MetricValue
absolute -X- _ O
over -X- _ O
the -X- _ O
model -X- _ O
trained -X- _ O
from -X- _ O
scratch -X- _ O
. -X- _ O

5.2 -X- _ O
Ablation -X- _ O
Study -X- _ O
We -X- _ O
first -X- _ O
study -X- _ O
how -X- _ O
different -X- _ O
training -X- _ O
settings -X- _ O
influence -X- _ O
the -X- _ O
results -X- _ O
in -X- _ O
Table -X- _ O
3(a -X- _ O
) -X- _ O
. -X- _ O

By -X- _ O
contrast -X- _ O
, -X- _ O
VisDial -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
can -X- _ O
only -X- _ O
support -X- _ O
the -X- _ O
discriminative -X- _ O
setting -X- _ O
. -X- _ O

This -X- _ O
validates -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
our -X- _ O
VD -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
in -X- _ O
both -X- _ O
settings -X- _ O
using -X- _ O
a -X- _ O
unified -X- _ O
Transformer -X- _ O
encoder -X- _ O
. -X- _ O

Our -X- _ O
model -X- _ O
continues -X- _ O
to -X- _ O
yield -X- _ O
much -X- _ O
better -X- _ O
results -X- _ O
in -X- _ O
the -X- _ O
discriminative -X- _ O
setting -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
70.04 -X- _ B-MetricValue
MRR -X- _ B-MetricName
compared -X- _ O
to -X- _ O
DVAN -X- _ B-MethodName
’s -X- _ O
66.67 -X- _ B-MetricValue
) -X- _ O
Table -X- _ O
3 -X- _ O
: -X- _ O
Extensive -X- _ O
ablation -X- _ O
studies -X- _ O
: -X- _ O
training -X- _ O
with -X- _ O
( -X- _ O
a -X- _ O
) -X- _ O
various -X- _ O
settings -X- _ O
and -X- _ O
( -X- _ O
b -X- _ O
) -X- _ O
contexts -X- _ O
on -X- _ O
v1.0 -X- _ O
val -X- _ O
; -X- _ O
dense -X- _ O
annotation -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
with -X- _ O
( -X- _ O
c -X- _ O
) -X- _ O
varying -X- _ O
ranking -X- _ O
methods -X- _ O
and -X- _ O
( -X- _ O
d -X- _ O
) -X- _ O
various -X- _ O
ensemble -X- _ O
strategies -X- _ O
on -X- _ O
v1.0 -X- _ O
test -X- _ O
- -X- _ O
std -X- _ O
. -X- _ O
and -X- _ O
comparable -X- _ O
results -X- _ O
with -X- _ O
the -X- _ O
state -X- _ O
of -X- _ O
the -X- _ O
art -X- _ O
in -X- _ O
the -X- _ O
generative -X- _ O
setting -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
55.95 -X- _ B-MetricValue
MRR -X- _ B-MetricName
score -X- _ O
vs. -X- _ O
DVAN -X- _ B-MethodName
’s -X- _ O
55.94 -X- _ B-MetricValue
) -X- _ O
. -X- _ O

These -X- _ O
models -X- _ O
employ -X- _ O
dual -X- _ O
decoders -X- _ O
for -X- _ O
each -X- _ O
setting -X- _ O
separately -X- _ O
. -X- _ O

For -X- _ O
comparison -X- _ O
, -X- _ O
we -X- _ O
choose -X- _ O
LF -X- _ O
, -X- _ O
HRE -X- _ O
, -X- _ O
HREA -X- _ O
, -X- _ O
MN -X- _ O
( -X- _ O
Das -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
, -X- _ O
HCIAE -X- _ O
( -X- _ O
Lu -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
, -X- _ O
CoAtt -X- _ O
( -X- _ O
Wu -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
RvA -X- _ O
, -X- _ O
and -X- _ O
DVAN -X- _ O
as -X- _ O
they -X- _ O
contain -X- _ O
results -X- _ O
in -X- _ O
both -X- _ O
settings -X- _ O
on -X- _ O
the -X- _ O
v0.9 -X- _ O
val -X- _ O
split -X- _ O
. -X- _ O

We -X- _ O
further -X- _ O
show -X- _ O
both -X- _ O
discriminative -X- _ O
and -X- _ O
generative -X- _ O
results -X- _ O
on -X- _ O
v0.9 -X- _ O
val -X- _ O
split -X- _ O
in -X- _ O
Table -X- _ O
2 -X- _ O
. -X- _ O

Results -X- _ O
on -X- _ O
VisDial -X- _ B-DatasetName
v0.9 -X- _ O
val -X- _ O
. -X- _ O

Besides -X- _ O
, -X- _ O
while -X- _ O
VisDial -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
does -X- _ O
not -X- _ O
observe -X- _ O
improvements -X- _ O
by -X- _ O
ensembling -X- _ O
, -X- _ O
we -X- _ O
endeavor -X- _ O
to -X- _ O
design -X- _ O
an -X- _ O
effective -X- _ O
ensemble -X- _ O
strategy -X- _ O
to -X- _ O
increase -X- _ O
the -X- _ O
NDCG -X- _ B-MetricName
score -X- _ O
to -X- _ O
75.35 -X- _ B-MetricValue
for -X- _ O
VD -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
. -X- _ O

Compare -X- _ O
to -X- _ O
that -X- _ O
, -X- _ O
our -X- _ O
VD -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
achieves -X- _ O
slightly -X- _ O
better -X- _ O
results -X- _ O
( -X- _ O
74.54 -X- _ B-MetricValue
NDCG -X- _ B-MetricName
) -X- _ O
, -X- _ O
however -X- _ O
, -X- _ O
note -X- _ O
that -X- _ O
we -X- _ O
did -X- _ O
not -X- _ O
pretrain -X- _ O
on -X- _ O
large -X- _ O
- -X- _ O
scale -X- _ O
external -X- _ O
vision -X- _ O
- -X- _ O
language -X- _ O
datasets -X- _ O
like -X- _ O
Conceptual -X- _ B-DatasetName
Captions -X- _ I-DatasetName
( -X- _ O
Sharma -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
and -X- _ O
VQA -X- _ B-DatasetName
( -X- _ O
Antol -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
as -X- _ O
VisDialBERT -X- _ B-MethodName
does -X- _ O
. -X- _ O

It -X- _ O
only -X- _ O
reports -X- _ O
the -X- _ O
single -X- _ O
- -X- _ O
model -X- _ O
performance -X- _ O
of -X- _ O
74.47 -X- _ B-MetricValue
NDCG -X- _ B-MetricName
. -X- _ O

VisDial -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
is -X- _ O
a -X- _ O
concurrent -X- _ O
work -X- _ O
to -X- _ O
ours -X- _ O
that -X- _ O
also -X- _ O
exploits -X- _ O
vision -X- _ O
- -X- _ O
language -X- _ O
pretrained -X- _ O
models -X- _ O
for -X- _ O
visual -X- _ B-TaskName
dialog -X- _ I-TaskName
. -X- _ O

• -X- _ O
Our -X- _ O
VD -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
is -X- _ O
simpler -X- _ O
and -X- _ O
more -X- _ O
effective -X- _ O
than -X- _ O
VisDial -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
. -X- _ O

We -X- _ O
provide -X- _ O
a -X- _ O
detailed -X- _ O
analysis -X- _ O
of -X- _ O
this -X- _ O
phenomenon -X- _ O
in -X- _ O
§ -X- _ O
5.3 -X- _ O
. -X- _ O

Such -X- _ O
a -X- _ O
phenomenon -X- _ O
has -X- _ O
also -X- _ O
been -X- _ O
observed -X- _ O
in -X- _ O
other -X- _ O
recent -X- _ O
models -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
MReal -X- _ B-MethodName
- -X- _ I-MethodName
BDAI -X- _ I-MethodName
, -X- _ O
VisDialBERT -X- _ B-MethodName
, -X- _ O
Tohoku -X- _ B-MethodName
- -X- _ I-MethodName
CV -X- _ I-MethodName
Lab -X- _ O
, -X- _ O
and -X- _ O
P1 -X- _ B-MethodName
P2 -X- _ I-MethodName
, -X- _ O
whose -X- _ O
NDCG -X- _ B-MetricName
scores -X- _ O
surpass -X- _ O
others -X- _ O
without -X- _ O
dense -X- _ O
annotation -X- _ O
finetuning -X- _ O
by -X- _ O
at -X- _ O
least -X- _ O
around -X- _ O
10 -X- _ O
% -X- _ O
absolute -X- _ O
points -X- _ O
while -X- _ O
other -X- _ O
metrics -X- _ O
drop -X- _ O
dramatically -X- _ O
. -X- _ O

While -X- _ O
dense -X- _ O
annotation -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
yields -X- _ O
huge -X- _ O
improvements -X- _ O
on -X- _ O
NDCG -X- _ B-MetricName
, -X- _ O
we -X- _ O
also -X- _ O
notice -X- _ O
that -X- _ O
it -X- _ O
has -X- _ O
a -X- _ O
severe -X- _ O
countereffect -X- _ O
on -X- _ O
other -X- _ O
metrics -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
reducing -X- _ O
the -X- _ O
MRR -X- _ B-MetricName
score -X- _ O
from -X- _ O
65.44 -X- _ B-MetricValue
to -X- _ O
46.72 -X- _ B-MetricValue
for -X- _ O
VD -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
. -X- _ O

• -X- _ O
Inconsistency -X- _ O
between -X- _ O
NDCG -X- _ B-MetricName
and -X- _ O
other -X- _ O
metrics -X- _ O
. -X- _ O

Moreover -X- _ O
, -X- _ O
our -X- _ O
designed -X- _ O
ensemble -X- _ O
version -X- _ O
yields -X- _ O
new -X- _ O
state -X- _ O
of -X- _ O
the -X- _ O
art -X- _ O
( -X- _ O
75.35 -X- _ O
NDCG -X- _ O
) -X- _ O
, -X- _ O
outperforming -X- _ O
the -X- _ O
2019 -X- _ O
VisDial -X- _ B-DatasetName
challenge -X- _ O
winner -X- _ O
MRealBDAI -X- _ B-MethodName
( -X- _ O
74.02 -X- _ B-MetricValue
NDCG -X- _ B-MetricName
) -X- _ O
by -X- _ O
over -X- _ O
1.3 -X- _ O
absolute -X- _ O
points -X- _ O
. -X- _ O

scores -X- _ O
. -X- _ O

This -X- _ O
indicates -X- _ O
that -X- _ O
dense -X- _ O
annotation -X- _ O
finetuning -X- _ O
plays -X- _ O
a -X- _ O
crucial -X- _ O
role -X- _ O
in -X- _ O
boosting -X- _ O
the -X- _ O
NDCG -X- _ B-MetricName
1 -X- _ O
https://evalai.cloudcv.org/web/ -X- _ O
challenges -X- _ O
/ -X- _ O
challenge -X- _ O
- -X- _ O
page/161/ -X- _ O
leaderboard/483#leaderboardrank-1 -X- _ O
3330 -X- _ O

With -X- _ O
further -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
on -X- _ O
dense -X- _ O
annotations -X- _ O
, -X- _ O
the -X- _ O
NDCG -X- _ B-MetricName
score -X- _ O
increases -X- _ O
quite -X- _ O
sharply -X- _ O
, -X- _ O
from -X- _ O
59.96 -X- _ B-MetricValue
to -X- _ O
74.54 -X- _ B-MetricValue
with -X- _ O
nearly -X- _ O
15 -X- _ O
% -X- _ O
absolute -X- _ O
improvement -X- _ O
, -X- _ O
setting -X- _ O
a -X- _ O
new -X- _ O
state -X- _ O
of -X- _ O
the -X- _ O
art -X- _ O
in -X- _ O
the -X- _ O
single -X- _ O
- -X- _ O
model -X- _ O
setting -X- _ O
. -X- _ O

Our -X- _ O
single -X- _ O
- -X- _ O
model -X- _ O
VD -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
significantly -X- _ O
outperforms -X- _ O
all -X- _ O
of -X- _ O
its -X- _ O
single -X- _ O
- -X- _ O
model -X- _ O
counterparts -X- _ O
across -X- _ O
various -X- _ O
metrics -X- _ O
, -X- _ O
even -X- _ O
including -X- _ O
some -X- _ O
ensemble -X- _ O
variants -X- _ O
such -X- _ O
as -X- _ O
Synergistic -X- _ B-MethodName
, -X- _ O
DAN -X- _ B-MethodName
( -X- _ O
except -X- _ O
R@10 -X- _ B-MetricName
) -X- _ O
, -X- _ O
and -X- _ O
ReDAN -X- _ B-MethodName
( -X- _ O
except -X- _ O
NDCG -X- _ B-MetricName
) -X- _ O
. -X- _ O

• -X- _ O
New -X- _ O
state -X- _ O
of -X- _ O
the -X- _ O
art -X- _ O
for -X- _ O
both -X- _ O
single -X- _ O
- -X- _ O
model -X- _ O
and -X- _ O
ensemble -X- _ O
settings -X- _ O
. -X- _ O

We -X- _ O
report -X- _ O
the -X- _ O
comparison -X- _ O
results -X- _ O
on -X- _ O
VisDial -X- _ B-DatasetName
v1.0 -X- _ O
test -X- _ O
- -X- _ O
std -X- _ O
split -X- _ O
in -X- _ O
Table -X- _ O
1 -X- _ O
and -X- _ O
make -X- _ O
the -X- _ O
following -X- _ O
observations -X- _ O
. -X- _ O

Results -X- _ O
on -X- _ O
VisDial -X- _ B-DatasetName
v1.0 -X- _ O
test -X- _ O
- -X- _ O
std -X- _ O
. -X- _ O

sults -X- _ O
from -X- _ O
the -X- _ O
leaderboard1 -X- _ O
for -X- _ O
a -X- _ O
more -X- _ O
up -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
date -X- _ O
comparison -X- _ O
, -X- _ O
where -X- _ O
some -X- _ O
can -X- _ O
be -X- _ O
found -X- _ O
in -X- _ O
the -X- _ O
arXiv -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
MVAN -X- _ B-MethodName
( -X- _ O
Park -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
SGLNs -X- _ B-MethodName
( -X- _ O
Kang -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
VisDial -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
( -X- _ O
Murahari -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
Tohoku -X- _ B-MethodName
- -X- _ I-MethodName
CV -X- _ I-MethodName
( -X- _ O
Nguyen -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O

The -X- _ O
best -X- _ O
and -X- _ O
second -X- _ O
- -X- _ O
best -X- _ O
results -X- _ O
in -X- _ O
each -X- _ O
column -X- _ O
are -X- _ O
in -X- _ O
bold -X- _ O
and -X- _ O
underlined -X- _ O
respectively -X- _ O
. -X- _ O

The -X- _ O
“ -X- _ O
↑ -X- _ O
” -X- _ O
denotes -X- _ O
higher -X- _ O
value -X- _ O
for -X- _ O
better -X- _ O
performance -X- _ O
and -X- _ O
“ -X- _ O
↓ -X- _ O
” -X- _ O
is -X- _ O
the -X- _ O
opposite -X- _ O
. -X- _ O

“ -X- _ O
† -X- _ O
” -X- _ O
denotes -X- _ O
ensemble -X- _ O
model -X- _ O
and -X- _ O
“ -X- _ O
∗ -X- _ O
” -X- _ O
indicates -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
on -X- _ O
dense -X- _ O
annotations -X- _ O
. -X- _ O

The -X- _ O
results -X- _ O
are -X- _ O
reported -X- _ O
by -X- _ O
the -X- _ O
test -X- _ O
server -X- _ O
. -X- _ O

Since -X- _ O
the -X- _ O
2018 -X- _ O
VisDial -X- _ B-DatasetName
challenge -X- _ O
( -X- _ O
after -X- _ O
the -X- _ O
acquisition -X- _ O
of -X- _ O
dense -X- _ O
annotations -X- _ O
) -X- _ O
, -X- _ O
NDCG -X- _ B-MetricName
metric -X- _ O
that -X- _ O
considers -X- _ O
the -X- _ O
relevance -X- _ O
degree -X- _ O
of -X- _ O
each -X- _ O
answer -X- _ O
candidate -X- _ O
, -X- _ O
has -X- _ O
been -X- _ O
adopted -X- _ O
as -X- _ O
the -X- _ O
main -X- _ O
metric -X- _ O
to -X- _ O
determine -X- _ O
the -X- _ O
winner -X- _ O
. -X- _ O

For -X- _ O
dense -X- _ O
annotation -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
in -X- _ O
the -X- _ O
discriminative -X- _ O
setting -X- _ O
, -X- _ O
we -X- _ O
train -X- _ O
with -X- _ O
the -X- _ O
ListNet -X- _ O
loss -X- _ O
for -X- _ O
5 -X- _ B-HyperparameterValue
epochs -X- _ B-HyperparameterName
. -X- _ O

After -X- _ O
that -X- _ O
, -X- _ O
we -X- _ O
train -X- _ O
for -X- _ O
another -X- _ O
10 -X- _ B-HyperparameterValue
epochs -X- _ B-HyperparameterName
with -X- _ O
full -X- _ O
dialog -X- _ O
history -X- _ O
using -X- _ O
either -X- _ O
NSP -X- _ O
in -X- _ O
the -X- _ O
discriminative -X- _ O
setting -X- _ O
or -X- _ O
MLM -X- _ O
on -X- _ O
the -X- _ O
answer -X- _ O
sequence -X- _ O
in -X- _ O
the -X- _ O
generative -X- _ O
setting -X- _ O
. -X- _ O

For -X- _ O
instances -X- _ O
where -X- _ O
the -X- _ O
appended -X- _ O
answer -X- _ O
candidate -X- _ O
is -X- _ O
incorrect -X- _ O
, -X- _ O
we -X- _ O
do -X- _ O
not -X- _ O
conduct -X- _ O
MLM -X- _ O
on -X- _ O
the -X- _ O
answer -X- _ O
sequence -X- _ O
to -X- _ O
reduce -X- _ O
the -X- _ O
noise -X- _ O
introduced -X- _ O
by -X- _ O
the -X- _ O
negative -X- _ O
samples -X- _ O
. -X- _ O

Here -X- _ O
we -X- _ O
only -X- _ O
utilize -X- _ O
one -X- _ O
previous -X- _ O
dialog -X- _ O
turn -X- _ O
for -X- _ O
training -X- _ O
efficiency -X- _ O
. -X- _ O

We -X- _ O
first -X- _ O
train -X- _ O
VD -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
for -X- _ O
30 -X- _ B-HyperparameterValue
epochs -X- _ B-HyperparameterName
on -X- _ O
a -X- _ O
cluster -X- _ O
of -X- _ O
4 -X- _ O
V100 -X- _ O
GPUs -X- _ O
with -X- _ O
16 -X- _ O
G -X- _ O
memory -X- _ O
using -X- _ O
MLM -X- _ O
and -X- _ O
NSP -X- _ O
losses -X- _ O
( -X- _ O
with -X- _ O
equal -X- _ O
coefficients -X- _ O
) -X- _ O
. -X- _ O

A -X- _ O
linear -X- _ B-HyperparameterName
learning -X- _ I-HyperparameterName
rate -X- _ I-HyperparameterName
decay -X- _ I-HyperparameterName
schedule -X- _ I-HyperparameterName
with -X- _ O
a -X- _ O
warmup -X- _ O
of -X- _ O
0.1 -X- _ B-HyperparameterValue
is -X- _ O
employed -X- _ O
. -X- _ O

We -X- _ O
use -X- _ O
Adam -X- _ B-HyperparameterName
( -X- _ O
Kingma -X- _ O
and -X- _ O
Ba -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
with -X- _ O
an -X- _ O
initial -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
of -X- _ O
3e -X- _ B-HyperparameterValue
− -X- _ I-HyperparameterValue
5 -X- _ I-HyperparameterValue
and -X- _ O
a -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
32 -X- _ B-HyperparameterValue
to -X- _ O
train -X- _ O
our -X- _ O
model -X- _ O
. -X- _ O

We -X- _ O
keep -X- _ O
the -X- _ O
max -X- _ B-HyperparameterName
input -X- _ I-HyperparameterName
sequence -X- _ I-HyperparameterName
length -X- _ I-HyperparameterName
( -X- _ O
including -X- _ O
36 -X- _ O
visual -X- _ O
objects -X- _ O
) -X- _ O
to -X- _ O
250 -X- _ B-HyperparameterValue
. -X- _ O

We -X- _ O
use -X- _ O
BERTBASE -X- _ O
as -X- _ O
the -X- _ O
backbone -X- _ O
, -X- _ O
which -X- _ O
consists -X- _ O
of -X- _ O
12 -X- _ B-HyperparameterValue
Transformer -X- _ B-HyperparameterName
blocks -X- _ I-HyperparameterName
, -X- _ O
each -X- _ O
with -X- _ O
12 -X- _ B-HyperparameterValue
attention -X- _ B-HyperparameterName
heads -X- _ I-HyperparameterName
and -X- _ O
a -X- _ O
hidden -X- _ B-HyperparameterName
state -X- _ I-HyperparameterName
dimensions -X- _ I-HyperparameterName
of -X- _ O
768 -X- _ B-HyperparameterValue
. -X- _ O

Mean -X- _ B-MetricName
↓ -X- _ O

We -X- _ O
further -X- _ O
report -X- _ O
re -X- _ O
MRR↑ -X- _ B-MetricName
R@1↑ -X- _ B-MetricName
R@5↑ -X- _ B-MetricName
R@10↑ -X- _ B-MetricName

We -X- _ O
consider -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
published -X- _ O
baselines -X- _ O
, -X- _ O
including -X- _ O
NMN -X- _ B-MethodName
( -X- _ O
Hu -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
, -X- _ O
CorefNMN -X- _ B-MethodName
( -X- _ O
Kottur -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
GNN -X- _ B-MethodName
( -X- _ O
Zheng -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
FGA -X- _ B-MethodName
( -X- _ O
Schwartz -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
DVAN -X- _ B-MethodName
( -X- _ O
Guo -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019b -X- _ O
) -X- _ O
, -X- _ O
RvA -X- _ B-MethodName
( -X- _ O
Niu -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
DualVD -X- _ B-MethodName
( -X- _ O
Jiang -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
HACAN -X- _ B-MethodName
( -X- _ O
Yang -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
Synergistic -X- _ B-MethodName
( -X- _ O
Guo -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019a -X- _ O
) -X- _ O
, -X- _ O
DAN -X- _ B-MethodName
( -X- _ O
Kang -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
ReDAN -X- _ B-MethodName
( -X- _ O
Gan -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
CAG -X- _ B-MethodName
( -X- _ O
Guo -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
Square -X- _ B-MethodName
( -X- _ O
Kim -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
MCA -X- _ B-MethodName
( -X- _ O
Agarwal -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
MReal -X- _ B-MethodName
- -X- _ I-MethodName
BDAI -X- _ I-MethodName
and -X- _ O
P1 -X- _ B-MethodName
P2 -X- _ I-MethodName
( -X- _ O
Qi -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O

5.1 -X- _ O
Main -X- _ O
Results -X- _ O
Comparison -X- _ O
. -X- _ O

Lastly -X- _ O
, -X- _ O
we -X- _ O
interpret -X- _ O
how -X- _ O
it -X- _ O
attains -X- _ O
the -X- _ O
effective -X- _ O
fusion -X- _ O
of -X- _ O
vision -X- _ O
and -X- _ O
dialog -X- _ O
via -X- _ O
attention -X- _ O
visualization -X- _ O
( -X- _ O
§ -X- _ O
5.4 -X- _ O
) -X- _ O
. -X- _ O

Then -X- _ O
we -X- _ O
conduct -X- _ O
ablation -X- _ O
studies -X- _ O
to -X- _ O
examine -X- _ O
various -X- _ O
aspects -X- _ O
of -X- _ O
our -X- _ O
model -X- _ O
( -X- _ O
§ -X- _ O
5.2 -X- _ O
) -X- _ O
, -X- _ O
followed -X- _ O
by -X- _ O
an -X- _ O
in -X- _ O
- -X- _ O
depth -X- _ O
analysis -X- _ O
of -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
on -X- _ O
dense -X- _ O
annotations -X- _ O
( -X- _ O
§ -X- _ O
5.3 -X- _ O
) -X- _ O
. -X- _ O

5 -X- _ O
Results -X- _ O
and -X- _ O
Analysis -X- _ O
We -X- _ O
first -X- _ O
compare -X- _ O
VD -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
with -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
models -X- _ O
on -X- _ O
VisDial -X- _ B-DatasetName
datasets -X- _ O
( -X- _ O
§ -X- _ O
5.1 -X- _ O
) -X- _ O
. -X- _ O

Following -X- _ O
Das -X- _ O
et -X- _ O
al. -X- _ O
( -X- _ O
2017 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
evaluate -X- _ O
our -X- _ O
model -X- _ O
using -X- _ O
the -X- _ O
ranking -X- _ O
metrics -X- _ O
like -X- _ O
Recall@K -X- _ B-MetricName
( -X- _ O
K -X- _ O
∈ -X- _ O
{ -X- _ O
1 -X- _ O
, -X- _ O
5 -X- _ O
, -X- _ O
10 -X- _ O
} -X- _ O
) -X- _ O
, -X- _ O
Mean -X- _ B-MetricName
Reciprocal -X- _ I-MetricName
Rank -X- _ I-MetricName
( -X- _ O
MRR -X- _ B-MetricName
) -X- _ O
, -X- _ O
and -X- _ O
Mean -X- _ B-MetricName
Rank -X- _ I-MetricName
, -X- _ O
where -X- _ O
only -X- _ O
one -X- _ O
3329 -X- _ O

Evaluation -X- _ O
Metric -X- _ O
. -X- _ O

The -X- _ O
dense -X- _ O
annotation -X- _ O
specifies -X- _ O
a -X- _ O
relevance -X- _ O
score -X- _ O
for -X- _ O
each -X- _ O
answer -X- _ O
candidate -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
fact -X- _ O
that -X- _ O
some -X- _ O
candidates -X- _ O
with -X- _ O
similar -X- _ O
semantics -X- _ O
to -X- _ O
the -X- _ O
ground -X- _ O
truth -X- _ O
answer -X- _ O
can -X- _ O
also -X- _ O
be -X- _ O
considered -X- _ O
as -X- _ O
correct -X- _ O
or -X- _ O
partially -X- _ O
correct -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
“ -X- _ O
brown -X- _ O
and -X- _ O
tan -X- _ O
” -X- _ O
and -X- _ O
“ -X- _ O
brown -X- _ O
” -X- _ O
in -X- _ O
Figure -X- _ O
2 -X- _ O
. -X- _ O

For -X- _ O
the -X- _ O
v1.0 -X- _ O
validation -X- _ O
split -X- _ O
and -X- _ O
a -X- _ O
part -X- _ O
of -X- _ O
v1.0 -X- _ O
train -X- _ O
split -X- _ O
( -X- _ O
2,000 -X- _ O
images -X- _ O
) -X- _ O
, -X- _ O
extra -X- _ O
dense -X- _ O
annotations -X- _ O
for -X- _ O
the -X- _ O
answer -X- _ O
candidates -X- _ O
are -X- _ O
provided -X- _ O
to -X- _ O
make -X- _ O
the -X- _ O
evaluation -X- _ O
more -X- _ O
reasonable -X- _ O
. -X- _ O

For -X- _ O
each -X- _ O
question -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
paired -X- _ O
with -X- _ O
a -X- _ O
list -X- _ O
of -X- _ O
100 -X- _ O
answer -X- _ O
candidates -X- _ O
, -X- _ O
one -X- _ O
of -X- _ O
which -X- _ O
is -X- _ O
regarded -X- _ O
as -X- _ O
the -X- _ O
correct -X- _ O
answer -X- _ O
. -X- _ O

Each -X- _ O
image -X- _ O
is -X- _ O
associated -X- _ O
with -X- _ O
one -X- _ O
caption -X- _ O
and -X- _ O
10 -X- _ O
question -X- _ O
- -X- _ O
answer -X- _ O
pairs -X- _ O
. -X- _ O

The -X- _ O
v1.0 -X- _ O
dataset -X- _ O
combines -X- _ O
the -X- _ O
training -X- _ O
and -X- _ O
validation -X- _ O
sets -X- _ O
of -X- _ O
v0.9 -X- _ O
into -X- _ O
one -X- _ O
training -X- _ O
set -X- _ O
and -X- _ O
adds -X- _ O
another -X- _ O
2,064 -X- _ O
images -X- _ O
for -X- _ O
validation -X- _ O
and -X- _ O
8 -X- _ O
, -X- _ O
000 -X- _ O
images -X- _ O
for -X- _ O
testing -X- _ O
( -X- _ O
hosted -X- _ O
blindly -X- _ O
in -X- _ O
the -X- _ O
task -X- _ O
organizers -X- _ O
’ -X- _ O
server -X- _ O
) -X- _ O
. -X- _ O

Specifically -X- _ O
, -X- _ O
v0.9 -X- _ O
contains -X- _ O
a -X- _ O
training -X- _ O
set -X- _ O
of -X- _ O
82,783 -X- _ O
images -X- _ O
and -X- _ O
a -X- _ O
validation -X- _ O
set -X- _ O
of -X- _ O
40 -X- _ O
, -X- _ O
504 -X- _ O
images -X- _ O
. -X- _ O

We -X- _ O
evaluate -X- _ O
our -X- _ O
model -X- _ O
on -X- _ O
the -X- _ O
VisDial -X- _ B-DatasetName
v0.9 -X- _ O
and -X- _ O
v1.0 -X- _ O
datasets -X- _ O
( -X- _ O
Das -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O

To -X- _ O
fine -X- _ O
- -X- _ O
tune -X- _ O
on -X- _ O
this -X- _ O
, -X- _ O
we -X- _ O
combine -X- _ O
the -X- _ O
Datasets -X- _ O
. -X- _ O

As -X- _ O
some -X- _ O
answer -X- _ O
candidates -X- _ O
may -X- _ O
be -X- _ O
semantically -X- _ O
similar -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
“ -X- _ O
brown -X- _ O
and -X- _ O
tan -X- _ O
” -X- _ O
vs -X- _ O
“ -X- _ O
brown -X- _ O
” -X- _ O
in -X- _ O
Figure -X- _ O
2 -X- _ O
) -X- _ O
, -X- _ O
VisDial -X- _ B-DatasetName
v1.0 -X- _ O
additionally -X- _ O
provides -X- _ O
dense -X- _ O
annotations -X- _ O
that -X- _ O
specify -X- _ O
real -X- _ O
- -X- _ O
valued -X- _ O
relevance -X- _ O
scores -X- _ O
for -X- _ O
the -X- _ O
100 -X- _ O
answer -X- _ O
candidates -X- _ O
, -X- _ O
[ -X- _ O
s1 -X- _ O
, -X- _ O
... -X- _ O
, -X- _ O
s100 -X- _ O
] -X- _ O
with -X- _ O
si -X- _ O
∈ -X- _ O
[ -X- _ O
0 -X- _ O
, -X- _ O
1 -X- _ O
] -X- _ O
. -X- _ O

Fine -X- _ O
- -X- _ O
tuning -X- _ O
with -X- _ O
Rank -X- _ O
Optimization -X- _ O

| -X- _ O
{ -X- _ O
z -X- _ O
} -X- _ O
N -X- _ O
X -X- _ O

3.3 -X- _ O
f -X- _ O
( -X- _ O
si -X- _ O
) -X- _ O
log(f -X- _ O
( -X- _ O
pi -X- _ O
) -X- _ O
) -X- _ O
, -X- _ O
i=1 -X- _ O
4 -X- _ O
x -X- _ O
, -X- _ O
( -X- _ O
I -X- _ O
, -X- _ O
w -X- _ O
) -X- _ O
= -X- _ O
( -X- _ O
I -X- _ O
, -X- _ O
Ht -X- _ O
, -X- _ O
Qt -X- _ O
, -X- _ O
Ât -X- _ O
) -X- _ O
. -X- _ O

The -X- _ O
decoding -X- _ O
process -X- _ O
is -X- _ O
based -X- _ O
on -X- _ O
greedy -X- _ O
sampling -X- _ O
and -X- _ O
terminated -X- _ O
when -X- _ O
a -X- _ O
[ -X- _ O
SEP -X- _ O
] -X- _ O
is -X- _ O
emitted -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
resulting -X- _ O
log -X- _ O
- -X- _ O
likelihood -X- _ O
scores -X- _ O
will -X- _ O
be -X- _ O
used -X- _ O
for -X- _ O
ranking -X- _ O
the -X- _ O
answer -X- _ O
candidates -X- _ O
. -X- _ O

Specifically -X- _ O
, -X- _ O
we -X- _ O
recursively -X- _ O
append -X- _ O
a -X- _ O
[ -X- _ O
MASK -X- _ O
] -X- _ O
token -X- _ O
to -X- _ O
the -X- _ O
end -X- _ O
of -X- _ O
the -X- _ O
sequence -X- _ O
to -X- _ O
trigger -X- _ O
a -X- _ O
one -X- _ O
- -X- _ O
step -X- _ O
prediction -X- _ O
and -X- _ O
then -X- _ O
replace -X- _ O
it -X- _ O
with -X- _ O
the -X- _ O
predicted -X- _ O
token -X- _ O
for -X- _ O
the -X- _ O
next -X- _ O
token -X- _ O
prediction -X- _ O
. -X- _ O

During -X- _ O
inference -X- _ O
, -X- _ O
we -X- _ O
rely -X- _ O
on -X- _ O
the -X- _ O
same -X- _ O
unified -X- _ O
Transformer -X- _ O
encoder -X- _ O
with -X- _ O
sequential -X- _ O
MLM -X- _ O
operations -X- _ O
without -X- _ O
an -X- _ O
explicit -X- _ O
decoder -X- _ O
. -X- _ O

For -X- _ O
the -X- _ O
answer -X- _ O
sequence -X- _ O
, -X- _ O
we -X- _ O
mask -X- _ O
out -X- _ O
( -X- _ O
by -X- _ O
setting -X- _ O
−∞ -X- _ O
in -X- _ O
M -X- _ O
) -X- _ O
the -X- _ O
“ -X- _ O
future -X- _ O
” -X- _ O
tokens -X- _ O
to -X- _ O
get -X- _ O
autoregressive -X- _ O
attentions -X- _ O
( -X- _ O
see -X- _ O
the -X- _ O
red -X- _ O
dots -X- _ O
in -X- _ O
Figure -X- _ O
2 -X- _ O
) -X- _ O
. -X- _ O

Experimental -X- _ O
Setup -X- _ O
( -X- _ O
6 -X- _ O
) -X- _ O
context -X- _ O
We -X- _ O
allow -X- _ O
tokens -X- _ O
in -X- _ O
the -X- _ O
context -X- _ O
to -X- _ O
be -X- _ O
fully -X- _ O
visible -X- _ O
for -X- _ O
attending -X- _ O
by -X- _ O
setting -X- _ O
the -X- _ O
left -X- _ O
part -X- _ O
of -X- _ O
M -X- _ O
to -X- _ O
all -X- _ O
0s -X- _ O
. -X- _ O

To -X- _ O
better -X- _ O
leverage -X- _ O
the -X- _ O
contrastive -X- _ O
signals -X- _ O
from -X- _ O
the -X- _ O
dense -X- _ O
annotations -X- _ O
, -X- _ O
the -X- _ O
sub -X- _ O
- -X- _ O
sampling -X- _ O
method -X- _ O
first -X- _ O
picks -X- _ O
randomly -X- _ O
the -X- _ O
candidates -X- _ O
with -X- _ O
non -X- _ O
- -X- _ O
zero -X- _ O
relevance -X- _ O
scores -X- _ O
, -X- _ O
and -X- _ O
then -X- _ O
it -X- _ O
picks -X- _ O
the -X- _ O
ones -X- _ O
from -X- _ O
zero -X- _ O
scores -X- _ O
( -X- _ O
about -X- _ O
12 -X- _ O
% -X- _ O
of -X- _ O
candidates -X- _ O
are -X- _ O
non -X- _ O
- -X- _ O
zero -X- _ O
on -X- _ O
average -X- _ O
) -X- _ O
. -X- _ O

For -X- _ O
training -X- _ O
efficiency -X- _ O
, -X- _ O
we -X- _ O
sub -X- _ O
- -X- _ O
sample -X- _ O
the -X- _ O
candidate -X- _ O
list -X- _ O
and -X- _ O
use -X- _ O
only -X- _ O
N -X- _ B-HyperparameterName
= -X- _ O
30 -X- _ B-HyperparameterValue
answers -X- _ O
( -X- _ O
out -X- _ O
of -X- _ O
100 -X- _ O
) -X- _ O
for -X- _ O
each -X- _ O
instance -X- _ O
. -X- _ O

PN -X- _ O
, -X- _ O
i -X- _ O
= -X- _ O
1 -X- _ O
, -X- _ O
... -X- _ O
, -X- _ O
N. -X- _ O
exp -X- _ O
( -X- _ O
x -X- _ O
) -X- _ O
j -X- _ O
j=1 -X- _ O
( -X- _ O
8) -X- _ O
Here -X- _ O
N -X- _ O
is -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
answer -X- _ O
candidates -X- _ O
. -X- _ O

We -X- _ O
adopt -X- _ O
ListNet -X- _ O
( -X- _ O
Cao -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2007 -X- _ O
) -X- _ O
with -X- _ O
the -X- _ O
top-1 -X- _ O
approximation -X- _ O
as -X- _ O
the -X- _ O
ranking -X- _ O
module -X- _ O
for -X- _ O
VD -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
: -X- _ O
LListN -X- _ O
et -X- _ O
= -X- _ O
− -X- _ O
( -X- _ O
7 -X- _ O
) -X- _ O
exp -X- _ O
( -X- _ O
xi -X- _ O
) -X- _ O
f -X- _ O
( -X- _ O
xi -X- _ O
) -X- _ O
= -X- _ O

As -X- _ O
dense -X- _ O
annotation -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
is -X- _ O
typically -X- _ O
a -X- _ O
Learning -X- _ O
to -X- _ O
Rank -X- _ O
( -X- _ O
LTR -X- _ O
) -X- _ O
problem -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
make -X- _ O
use -X- _ O
of -X- _ O
some -X- _ O
ranking -X- _ O
optimization -X- _ O
methods -X- _ O
( -X- _ O
see -X- _ O
the -X- _ O
Appendix -X- _ O
B.1 -X- _ O
for -X- _ O
more -X- _ O
details -X- _ O
) -X- _ O
. -X- _ O

[ -X- _ O
p1 -X- _ O
, -X- _ O
... -X- _ O
, -X- _ O
p100 -X- _ O
] -X- _ O
. -X- _ O

For -X- _ O
this -X- _ O
, -X- _ O
we -X- _ O
divide -X- _ O
the -X- _ O
input -X- _ O
sequence -X- _ O
to -X- _ O
each -X- _ O
Transformer -X- _ O
block -X- _ O
into -X- _ O
two -X- _ O
subsequences -X- _ O
, -X- _ O
context -X- _ O
and -X- _ O
answer -X- _ O
: -X- _ O
NSP -X- _ O
scores -X- _ O
from -X- _ O
the -X- _ O
model -X- _ O
for -X- _ O
all -X- _ O
answer -X- _ O
candidates -X- _ O
together -X- _ O
into -X- _ O
a -X- _ O
vector -X- _ O

In -X- _ O
order -X- _ O
to -X- _ O
autoregressively -X- _ O
generate -X- _ O
an -X- _ O
answer -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
train -X- _ O
VD -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
with -X- _ O
the -X- _ O
sequence -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
sequence -X- _ O
( -X- _ O
seq2seq -X- _ O
) -X- _ O
self -X- _ O
- -X- _ O
attention -X- _ O
mask -X- _ O
( -X- _ O
Dong -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O

Generative -X- _ O
Setting -X- _ O
. -X- _ O

During -X- _ O
inference -X- _ O
, -X- _ O
we -X- _ O
rank -X- _ O
the -X- _ O
answer -X- _ O
candidates -X- _ O
according -X- _ O
to -X- _ O
the -X- _ O
positive -X- _ O
class -X- _ O
score -X- _ O
of -X- _ O
their -X- _ O
NSP -X- _ O
heads -X- _ O
. -X- _ O

every -X- _ O
positive -X- _ O
one -X- _ O
at -X- _ O
different -X- _ O
epochs -X- _ B-HyperparameterName
. -X- _ O

To -X- _ O
encourage -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
penalize -X- _ O
more -X- _ O
on -X- _ O
negative -X- _ O
instances -X- _ O
, -X- _ O
we -X- _ O
randomly -X- _ O
resample -X- _ O
a -X- _ O
negative -X- _ O
example -X- _ O
from -X- _ O
the -X- _ O
pool -X- _ O
of -X- _ O
99 -X- _ O
negatives -X- _ O
w.r.t -X- _ O
. -X- _ O

To -X- _ O
avoid -X- _ O
imbalanced -X- _ O
class -X- _ O
distribution -X- _ O
, -X- _ O
we -X- _ O
keep -X- _ O
the -X- _ O
ratio -X- _ O
of -X- _ O
positive -X- _ O
and -X- _ O
negative -X- _ O
instances -X- _ O
to -X- _ O
1:1 -X- _ O
in -X- _ O
each -X- _ O
epoch -X- _ B-HyperparameterName
. -X- _ O

We -X- _ O
employ -X- _ O
the -X- _ O
bidirectional -X- _ O
self -X- _ O
- -X- _ O
attention -X- _ O
mask -X- _ O
to -X- _ O
allow -X- _ O
all -X- _ O
the -X- _ O
tokens -X- _ O
to -X- _ O
attend -X- _ O
to -X- _ O
each -X- _ O
other -X- _ O
by -X- _ O
setting -X- _ O
the -X- _ O
mask -X- _ O
matrix -X- _ O
M -X- _ O
in -X- _ O
Eq -X- _ O
. -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
to -X- _ O
all -X- _ O
0s -X- _ O
. -X- _ O

Specifically -X- _ O
, -X- _ O
we -X- _ O
sample -X- _ O
an -X- _ O
answer -X- _ O
Ât -X- _ O
from -X- _ O
the -X- _ O
candidate -X- _ O
pool -X- _ O
and -X- _ O
append -X- _ O
it -X- _ O
to -X- _ O
the -X- _ O
input -X- _ O
sequence -X- _ O
, -X- _ O
and -X- _ O
ask -X- _ O
the -X- _ O
NSP -X- _ O
head -X- _ O
to -X- _ O
distinguish -X- _ O
whether -X- _ O
the -X- _ O
sampled -X- _ O
answer -X- _ O
is -X- _ O
correct -X- _ O
or -X- _ O
not -X- _ O
. -X- _ O

For -X- _ O
training -X- _ O
in -X- _ O
the -X- _ O
discriminative -X- _ O
setting -X- _ O
, -X- _ O
we -X- _ O
transform -X- _ O
the -X- _ O
task -X- _ O
of -X- _ O
selecting -X- _ O
an -X- _ O
answer -X- _ O
into -X- _ O
a -X- _ O
point -X- _ B-TaskName
- -X- _ I-TaskName
wise -X- _ I-TaskName
binary -X- _ I-TaskName
classification -X- _ I-TaskName
problem -X- _ O
. -X- _ O

Discriminative -X- _ O
Setting -X- _ O
. -X- _ O

Below -X- _ O
we -X- _ O
introduce -X- _ O
the -X- _ O
discriminative -X- _ O
and -X- _ O
generative -X- _ O
settings -X- _ O
of -X- _ O
VD -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
. -X- _ O

As -X- _ O
for -X- _ O
NSP -X- _ O
, -X- _ O
instead -X- _ O
of -X- _ O
modeling -X- _ O
the -X- _ O
relationship -X- _ O
between -X- _ O
two -X- _ O
sentences -X- _ O
( -X- _ O
as -X- _ O
in -X- _ O
BERT -X- _ O
) -X- _ O
or -X- _ O
the -X- _ O
matching -X- _ O
of -X- _ O
an -X- _ O
image -X- _ O
- -X- _ O
text -X- _ O
pair -X- _ O
( -X- _ O
as -X- _ O
in -X- _ O
other -X- _ O
visionlanguage -X- _ O
pretraining -X- _ O
models -X- _ O
like -X- _ O
ViLBERT -X- _ B-MethodName
) -X- _ O
, -X- _ O
VDBERT -X- _ B-MethodName
aims -X- _ O
to -X- _ O
predict -X- _ O
whether -X- _ O
the -X- _ O
appended -X- _ O
answer -X- _ O
candidate -X- _ O
Ât -X- _ O
is -X- _ O
correct -X- _ O
or -X- _ O
not -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
joint -X- _ O
understanding -X- _ O
of -X- _ O
the -X- _ O
image -X- _ O
and -X- _ O
dialog -X- _ O
history -X- _ O
: -X- _ O
LN -X- _ O
SP -X- _ O
= -X- _ O
−E(I -X- _ O
, -X- _ O
w)∼D -X- _ O
log -X- _ O
P -X- _ O
( -X- _ O
y|S(I -X- _ O
, -X- _ O
w -X- _ O
) -X- _ O
) -X- _ O
, -X- _ O
( -X- _ O
5 -X- _ O
) -X- _ O
where -X- _ O
y -X- _ O
∈ -X- _ O
{ -X- _ O
0 -X- _ O
, -X- _ O
1 -X- _ O
} -X- _ O
indicates -X- _ O
whether -X- _ O
Ât -X- _ O
is -X- _ O
correct -X- _ O
, -X- _ O
and -X- _ O
S -X- _ O
( -X- _ O
· -X- _ O
) -X- _ O
is -X- _ O
a -X- _ O
binary -X- _ O
classifier -X- _ O
to -X- _ O
predict -X- _ O
the -X- _ O
probability -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
[ -X- _ O
CLS -X- _ O
] -X- _ O
representation -X- _ O
T[CLS -X- _ O
] -X- _ O
at -X- _ O
the -X- _ O
final -X- _ O
layer -X- _ O
. -X- _ O

Following -X- _ O
Zhou -X- _ O
et -X- _ O
al. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
do -X- _ O
not -X- _ O
conduct -X- _ O
similar -X- _ O
masked -X- _ O
object -X- _ O
/ -X- _ O
region -X- _ O
modeling -X- _ O
in -X- _ O
the -X- _ O
image -X- _ O
segment -X- _ O
. -X- _ O

The -X- _ O
model -X- _ O
is -X- _ O
then -X- _ O
required -X- _ O
to -X- _ O
recover -X- _ O
them -X- _ O
based -X- _ O
not -X- _ O
only -X- _ O
on -X- _ O
the -X- _ O
surrounding -X- _ O
tokens -X- _ O
w\m -X- _ O
but -X- _ O
also -X- _ O
on -X- _ O
the -X- _ O
image -X- _ O
I -X- _ O
: -X- _ O
LM -X- _ O
LM -X- _ O
= -X- _ O
−E(I -X- _ O
, -X- _ O
w)∼D -X- _ O
log -X- _ O
P -X- _ O
( -X- _ O
wm -X- _ O
|w\m -X- _ O
, -X- _ O
I -X- _ O
) -X- _ O
, -X- _ O
( -X- _ O
4 -X- _ O
) -X- _ O
where -X- _ O
wm -X- _ O
refers -X- _ O
to -X- _ O
the -X- _ O
masked -X- _ O
token -X- _ O
and -X- _ O
D -X- _ O
denotes -X- _ O
the -X- _ O
training -X- _ O
set -X- _ O
. -X- _ O

[ -X- _ O
MASK -X- _ O
] -X- _ O
. -X- _ O

Similar -X- _ O
to -X- _ O
MLM -X- _ O
in -X- _ O
BERT -X- _ O
, -X- _ O
15 -X- _ O
% -X- _ O
tokens -X- _ O
in -X- _ O
the -X- _ O
text -X- _ O
segment -X- _ O
( -X- _ O
including -X- _ O
special -X- _ O
tokens -X- _ O
like -X- _ O
[ -X- _ O
EOT -X- _ O
] -X- _ O
and -X- _ O
[ -X- _ O
SEP -X- _ O
] -X- _ O
) -X- _ O
are -X- _ O
randomly -X- _ O
masked -X- _ O
out -X- _ O
and -X- _ O
replaced -X- _ O
with -X- _ O
a -X- _ O
special -X- _ O
token -X- _ O

Particularly -X- _ O
, -X- _ O
we -X- _ O
aim -X- _ O
to -X- _ O
capture -X- _ O
dense -X- _ O
interactions -X- _ O
among -X- _ O
both -X- _ O
inter -X- _ O
- -X- _ O
modality -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
image -X- _ O
- -X- _ O
dialog -X- _ O
) -X- _ O
and -X- _ O
intra -X- _ O
- -X- _ O
modality -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
image -X- _ O
- -X- _ O
image -X- _ O
, -X- _ O
dialog -X- _ O
- -X- _ O
dialog -X- _ O
) -X- _ O
. -X- _ O

3.2 -X- _ O
Visually -X- _ O
Grounded -X- _ O
Training -X- _ O
Objectives -X- _ O
We -X- _ O
use -X- _ O
two -X- _ O
visually -X- _ O
grounded -X- _ O
training -X- _ O
objectives -X- _ O
— -X- _ O
masked -X- _ O
language -X- _ O
modeling -X- _ O
( -X- _ O
MLM -X- _ O
) -X- _ O
and -X- _ O
next -X- _ O
sentence -X- _ O
prediction -X- _ O
( -X- _ O
NSP -X- _ O
) -X- _ O
to -X- _ O
train -X- _ O
our -X- _ O
VD -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
. -X- _ O

Then -X- _ O
Al -X- _ O
is -X- _ O
passed -X- _ O
into -X- _ O
a -X- _ O
feedforward -X- _ O
layer -X- _ O
to -X- _ O
compute -X- _ O
Hl -X- _ O
for -X- _ O
the -X- _ O
next -X- _ O
layer -X- _ O
. -X- _ O

Rdh -X- _ O
×dk -X- _ O
are -X- _ O
learnable -X- _ O
weights -X- _ O
for -X- _ O
computing -X- _ O
the -X- _ O
queries -X- _ O
, -X- _ O
keys -X- _ O
, -X- _ O
and -X- _ O
values -X- _ O
respectively -X- _ O
, -X- _ O
and -X- _ O
M -X- _ O
∈ -X- _ O
R|x|×|x| -X- _ O
is -X- _ O
the -X- _ O
self -X- _ O
- -X- _ O
attention -X- _ O
mask -X- _ O
that -X- _ O
determines -X- _ O
whether -X- _ O
tokens -X- _ O
from -X- _ O
two -X- _ O
layers -X- _ O
can -X- _ O
attend -X- _ O
each -X- _ O
other -X- _ O
. -X- _ O

Inside -X- _ O
each -X- _ O
Transformer -X- _ O
block -X- _ O
, -X- _ O
the -X- _ O
previous -X- _ O
layer -X- _ O
’s -X- _ O
output -X- _ O
Hl−1 -X- _ O
∈ -X- _ O
R|x|×dh -X- _ O
is -X- _ O
aggregated -X- _ O
using -X- _ O
the -X- _ O
multi -X- _ O
- -X- _ O
head -X- _ O
selfattention -X- _ O
( -X- _ O
Vaswani -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2017 -X- _ O
): -X- _ O
Q -X- _ O
= -X- _ O
Hl−1 -X- _ O
WlQ -X- _ O
, -X- _ O
K -X- _ O
= -X- _ O
Hl−1 -X- _ O
WlK -X- _ O
, -X- _ O
V -X- _ O
= -X- _ O
Hl−1 -X- _ O
WlV -X- _ O
, -X- _ O
( -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
0 -X- _ O
, -X- _ O
allow -X- _ O
to -X- _ O
attend -X- _ O
, -X- _ O
Mij -X- _ O
= -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
−∞ -X- _ O
, -X- _ O
prevent -X- _ O
from -X- _ O
attending -X- _ O
, -X- _ O
QKT -X- _ O
Al -X- _ O
= -X- _ O
softmax -X- _ O
( -X- _ O
√ -X- _ O
+ -X- _ O
M)V -X- _ O
, -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
dk -X- _ O
where -X- _ O
WlQ -X- _ O
, -X- _ O
WlK -X- _ O
, -X- _ O
WlV -X- _ O
∈ -X- _ O

[ -X- _ O
1 -X- _ O
, -X- _ O
L -X- _ O
] -X- _ O
. -X- _ O

[ -X- _ O
hl1 -X- _ O
, -X- _ O
... -X- _ O
, -X- _ O
hl|x| -X- _ O
] -X- _ O
using -X- _ O
L -X- _ O
- -X- _ O
stacked -X- _ O
Transformer -X- _ O
blocks -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
l -X- _ O
- -X- _ O
th -X- _ O
Transformer -X- _ O
block -X- _ O
is -X- _ O
denoted -X- _ O
as -X- _ O
Hl -X- _ O
= -X- _ O
Transformer(Hl−1 -X- _ O
) -X- _ O
, -X- _ O
l -X- _ O
∈ -X- _ O

Hl -X- _ O
= -X- _ O

and -X- _ O
then -X- _ O
encode -X- _ O
them -X- _ O
into -X- _ O
multiple -X- _ O
levels -X- _ O
of -X- _ O
contextual -X- _ O
representations -X- _ O

[ -X- _ O
e1 -X- _ O
, -X- _ O
... -X- _ O
, -X- _ O
e|x| -X- _ O
] -X- _ O

We -X- _ O
denote -X- _ O
the -X- _ O
embedded -X- _ O
vision -X- _ O
- -X- _ O
language -X- _ O
inputs -X- _ O
as -X- _ O
H0 -X- _ O
= -X- _ O

Transformer -X- _ O
Backbone -X- _ O
. -X- _ O

Finally -X- _ O
, -X- _ O
each -X- _ O
input -X- _ O
token -X- _ O
embedding -X- _ O
is -X- _ O
combined -X- _ O
with -X- _ O
its -X- _ O
position -X- _ O
embedding -X- _ O
and -X- _ O
segment -X- _ O
embedding -X- _ O
( -X- _ O
0 -X- _ O
or -X- _ O
1 -X- _ O
, -X- _ O
indicating -X- _ O
whether -X- _ O
it -X- _ O
is -X- _ O
image -X- _ O
or -X- _ O
text -X- _ O
) -X- _ O
with -X- _ O
layer -X- _ B-HyperparameterName
normalization -X- _ I-HyperparameterName
( -X- _ O
Ba -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
. -X- _ O

To -X- _ O
notify -X- _ O
the -X- _ O
model -X- _ O
for -X- _ O
the -X- _ O
answer -X- _ O
prediction -X- _ O
, -X- _ O
we -X- _ O
further -X- _ O
insert -X- _ O
a -X- _ O
[ -X- _ O
PRED -X- _ O
] -X- _ O
token -X- _ O
between -X- _ O
the -X- _ O
Qt -X- _ O
Ât -X- _ O
pair -X- _ O
. -X- _ O

As -X- _ O
such -X- _ O
, -X- _ O
we -X- _ O
prepare -X- _ O
the -X- _ O
input -X- _ O
sequence -X- _ O
into -X- _ O
the -X- _ O
format -X- _ O
as -X- _ O
x -X- _ O
= -X- _ O
( -X- _ O
[ -X- _ O
CLS -X- _ O
] -X- _ O
, -X- _ O
o1 -X- _ O
, -X- _ O
... -X- _ O
, -X- _ O
ok -X- _ O
, -X- _ O
[ -X- _ O
SEP -X- _ O
] -X- _ O
, -X- _ O
C -X- _ O
, -X- _ O
[ -X- _ O
EOT -X- _ O
] -X- _ O
, -X- _ O
Q1 -X- _ O
A1 -X- _ O
, -X- _ O
[ -X- _ O
EOT -X- _ O
] -X- _ O
, -X- _ O
... -X- _ O
, -X- _ O
Qt -X- _ O
Ât -X- _ O
, -X- _ O
[ -X- _ O
SEP -X- _ O
] -X- _ O
) -X- _ O
. -X- _ O

Moreover -X- _ O
, -X- _ O
to -X- _ O
inject -X- _ O
the -X- _ O
multi -X- _ B-TaskName
- -X- _ I-TaskName
turn -X- _ I-TaskName
dialog -X- _ I-TaskName
structure -X- _ O
into -X- _ O
the -X- _ O
model -X- _ O
, -X- _ O
we -X- _ O
utilize -X- _ O
a -X- _ O
special -X- _ O
token -X- _ O
[ -X- _ O
EOT -X- _ O
] -X- _ O
to -X- _ O
denote -X- _ O
end -X- _ O
of -X- _ O
turn -X- _ O
( -X- _ O
Whang -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
informs -X- _ O
the -X- _ O
model -X- _ O
when -X- _ O
the -X- _ O
dialog -X- _ O
turn -X- _ O
ends -X- _ O
. -X- _ O

Similar -X- _ O
to -X- _ O
BERT -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
special -X- _ O
tokens -X- _ O
like -X- _ O
[ -X- _ O
CLS -X- _ O
] -X- _ O
to -X- _ O
denote -X- _ O
the -X- _ O
beginning -X- _ O
of -X- _ O
the -X- _ O
sequence -X- _ O
, -X- _ O
and -X- _ O
[ -X- _ O
SEP -X- _ O
] -X- _ O
to -X- _ O
separate -X- _ O
the -X- _ O
two -X- _ O
modalities -X- _ O
. -X- _ O

To -X- _ O
feed -X- _ O
both -X- _ O
image -X- _ O
and -X- _ O
text -X- _ O
into -X- _ O
the -X- _ O
Transformer -X- _ O
encoder -X- _ O
, -X- _ O
we -X- _ O
integrate -X- _ O
the -X- _ O
image -X- _ O
objects -X- _ O
with -X- _ O
language -X- _ O
elements -X- _ O
into -X- _ O
a -X- _ O
whole -X- _ O
input -X- _ O
sequence -X- _ O
. -X- _ O

Cross -X- _ O
- -X- _ O
Modality -X- _ O
Encoding -X- _ O
. -X- _ O

We -X- _ O
employ -X- _ O
WordPiece -X- _ O
tokenizer -X- _ O
( -X- _ O
Wu -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
to -X- _ O
split -X- _ O
it -X- _ O
into -X- _ O
a -X- _ O
word -X- _ O
sequence -X- _ O
w -X- _ O
, -X- _ O
where -X- _ O
each -X- _ O
word -X- _ O
is -X- _ O
embedded -X- _ O
with -X- _ O
an -X- _ O
absolute -X- _ O
positional -X- _ O
code -X- _ O
following -X- _ O
Devlin -X- _ O
et -X- _ O
al. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O

We -X- _ O
pack -X- _ O
all -X- _ O
the -X- _ O
textual -X- _ O
elements -X- _ O
( -X- _ O
caption -X- _ O
and -X- _ O
multi -X- _ B-TaskName
- -X- _ I-TaskName
turn -X- _ I-TaskName
dialog -X- _ I-TaskName
) -X- _ O
into -X- _ O
a -X- _ O
long -X- _ O
sequence -X- _ O
. -X- _ O

Language -X- _ O
Features -X- _ O
. -X- _ O

We -X- _ O
extend -X- _ O
pi -X- _ O
with -X- _ O
its -X- _ O
class -X- _ O
i -X- _ O
d -X- _ O
and -X- _ O
confidence -X- _ O
score -X- _ O
for -X- _ O
a -X- _ O
richer -X- _ O
representation -X- _ O
. -X- _ O

Specifically -X- _ O
, -X- _ O
let -X- _ O
( -X- _ O
x1 -X- _ O
, -X- _ O
y1 -X- _ O
) -X- _ O
and -X- _ O
( -X- _ O
x2 -X- _ O
, -X- _ O
y2 -X- _ O
) -X- _ O
be -X- _ O
the -X- _ O
coordinates -X- _ O
of -X- _ O
the -X- _ O
bottom -X- _ O
- -X- _ O
left -X- _ O
and -X- _ O
top -X- _ O
- -X- _ O
right -X- _ O
corner -X- _ O
of -X- _ O
the -X- _ O
i -X- _ O
- -X- _ O
th -X- _ O
object -X- _ O
, -X- _ O
its -X- _ O
location -X- _ O
information -X- _ O
is -X- _ O
encoded -X- _ O
into -X- _ O
a -X- _ O
5 -X- _ O
- -X- _ O
d -X- _ O
vecx1 -X- _ O
y1 -X- _ O
x2 -X- _ O
y2 -X- _ O
( -X- _ O
x2 -X- _ O
−x1 -X- _ O
) -X- _ O
( -X- _ O
y2 -X- _ O
−y1 -X- _ O
) -X- _ O
tor -X- _ O
: -X- _ O
pi -X- _ O
= -X- _ O
( -X- _ O
W -X- _ O
, -X- _ O
H -X- _ O
, -X- _ O
W -X- _ O
, -X- _ O
H -X- _ O
, -X- _ O
) -X- _ O
, -X- _ O
where -X- _ O
WH -X- _ O
W -X- _ O
and -X- _ O
H -X- _ O
respectively -X- _ O
denote -X- _ O
the -X- _ O
width -X- _ O
and -X- _ O
height -X- _ O
of -X- _ O
the -X- _ O
input -X- _ O
image -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
last -X- _ O
element -X- _ O
is -X- _ O
the -X- _ O
relative -X- _ O
area -X- _ O
of -X- _ O
the -X- _ O
object -X- _ O
. -X- _ O

As -X- _ O
there -X- _ O
is -X- _ O
no -X- _ O
natural -X- _ O
orders -X- _ O
among -X- _ O
these -X- _ O
objects -X- _ O
, -X- _ O
we -X- _ O
adopt -X- _ O
normalized -X- _ O
bounding -X- _ O
box -X- _ O
coordinates -X- _ O
as -X- _ O
the -X- _ O
spatial -X- _ O
location -X- _ O
. -X- _ O

Let -X- _ O
OI -X- _ O
= -X- _ O
{ -X- _ O
o1 -X- _ O
, -X- _ O
... -X- _ O
, -X- _ O
ok -X- _ O
} -X- _ O
denote -X- _ O
the -X- _ O
vision -X- _ O
features -X- _ O
for -X- _ O
an -X- _ O
image -X- _ O
I -X- _ O
, -X- _ O
where -X- _ O
each -X- _ O
object -X- _ O
feature -X- _ O
oi -X- _ O
is -X- _ O
a -X- _ O
2048 -X- _ B-HyperparameterValue
- -X- _ O
d -X- _ B-HyperparameterName
Region -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
Interest -X- _ O
( -X- _ O
RoI -X- _ O
) -X- _ O
feature -X- _ O
and -X- _ O
k -X- _ O
is -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
the -X- _ O
detected -X- _ O
objects -X- _ O
( -X- _ O
fixed -X- _ O
to -X- _ O
36 -X- _ O
in -X- _ O
our -X- _ O
setting -X- _ O
) -X- _ O
. -X- _ O

Following -X- _ O
previous -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
employ -X- _ O
Faster -X- _ B-MethodName
R -X- _ I-MethodName
- -X- _ I-MethodName
CNN -X- _ I-MethodName
( -X- _ O
Ren -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
pretrained -X- _ O
on -X- _ O
Visual -X- _ B-DatasetName
Genome -X- _ I-DatasetName
( -X- _ O
Krishna -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
to -X- _ O
extract -X- _ O
the -X- _ O
object -X- _ O
- -X- _ O
level -X- _ O
vision -X- _ O
features -X- _ O
. -X- _ O

3.1 -X- _ O
Vision -X- _ B-MethodName
- -X- _ I-MethodName
Dialog -X- _ I-MethodName
Transformer -X- _ I-MethodName
Encoder -X- _ O
Vision -X- _ O
Features -X- _ O
. -X- _ O

Lastly -X- _ O
, -X- _ O
we -X- _ O
devise -X- _ O
a -X- _ O
ranking -X- _ O
optimization -X- _ O
module -X- _ O
to -X- _ O
further -X- _ O
fine -X- _ O
- -X- _ O
tune -X- _ O
on -X- _ O
the -X- _ O
dense -X- _ O
annotations -X- _ O
( -X- _ O
§ -X- _ O
3.3 -X- _ O
) -X- _ O
. -X- _ O

This -X- _ O
allows -X- _ O
our -X- _ O
unified -X- _ O
model -X- _ O
to -X- _ O
work -X- _ O
in -X- _ O
both -X- _ O
discriminative -X- _ O
and -X- _ O
generative -X- _ O
settings -X- _ O
( -X- _ O
§ -X- _ O
3.2 -X- _ O
) -X- _ O
. -X- _ O

Next -X- _ O
, -X- _ O
we -X- _ O
adopt -X- _ O
visually -X- _ O
grounded -X- _ O
MLM -X- _ O
and -X- _ O
NSP -X- _ O
objectives -X- _ O
to -X- _ O
train -X- _ O
the -X- _ O
model -X- _ O
for -X- _ O
effective -X- _ O
vision -X- _ O
and -X- _ O
dialog -X- _ O
fusion -X- _ O
using -X- _ O
two -X- _ O
types -X- _ O
of -X- _ O
self -X- _ O
- -X- _ O
attention -X- _ O
masks -X- _ O
– -X- _ O
bidirectional -X- _ O
and -X- _ O
seq2seq -X- _ O
. -X- _ O

First -X- _ O
, -X- _ O
we -X- _ O
employ -X- _ O
a -X- _ O
unified -X- _ B-MethodName
vision -X- _ I-MethodName
- -X- _ I-MethodName
dialog -X- _ I-MethodName
Transformer -X- _ I-MethodName
to -X- _ O
encode -X- _ O
both -X- _ O
the -X- _ O
image -X- _ O
and -X- _ O
dialog -X- _ O
history -X- _ O
, -X- _ O
where -X- _ O
we -X- _ O
append -X- _ O
an -X- _ O
answer -X- _ O
candidate -X- _ O
Ât -X- _ O
in -X- _ O
the -X- _ O
input -X- _ O
to -X- _ O
model -X- _ O
their -X- _ O
interactions -X- _ O
in -X- _ O
an -X- _ O
early -X- _ O
fusion -X- _ O
manner -X- _ O
( -X- _ O
§ -X- _ O
3.1 -X- _ O
) -X- _ O
. -X- _ O

Figure -X- _ O
2 -X- _ O
shows -X- _ O
the -X- _ O
overview -X- _ O
of -X- _ O
our -X- _ O
approach -X- _ O
. -X- _ O

In -X- _ O
general -X- _ O
, -X- _ O
there -X- _ O
are -X- _ O
two -X- _ O
types -X- _ O
of -X- _ O
decoder -X- _ O
to -X- _ O
predict -X- _ O
the -X- _ O
answer -X- _ O
: -X- _ O
a -X- _ O
discriminative -X- _ O
decoder -X- _ O
that -X- _ O
ranks -X- _ O
the -X- _ O
answer -X- _ O
candidates -X- _ O
and -X- _ O
is -X- _ O
trained -X- _ O
with -X- _ O
a -X- _ O
cross -X- _ O
entropy -X- _ O
loss -X- _ O
, -X- _ O
or -X- _ O
a -X- _ O
generative -X- _ O
decoder -X- _ O
that -X- _ O
synthesizes -X- _ O
an -X- _ O
answer -X- _ O
and -X- _ O
is -X- _ O
trained -X- _ O
with -X- _ O
a -X- _ O
maximum -X- _ O
log -X- _ O
- -X- _ O
likelihood -X- _ O
loss -X- _ O
. -X- _ O

Given -X- _ O
a -X- _ O
question -X- _ O
Qt -X- _ O
grounded -X- _ O
on -X- _ O
an -X- _ O
image -X- _ O
I -X- _ O
at -X- _ O
t -X- _ O
- -X- _ O
th -X- _ O
turn -X- _ O
, -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
its -X- _ O
dialog -X- _ O
history -X- _ O
formulated -X- _ O
as -X- _ O
Ht -X- _ O
= -X- _ O
{ -X- _ O
C -X- _ O
, -X- _ O
( -X- _ O
Q1 -X- _ O
, -X- _ O
A1 -X- _ O
) -X- _ O
, -X- _ O
... -X- _ O
, -X- _ O
( -X- _ O
Qt−1 -X- _ O
, -X- _ O
At−1 -X- _ O
) -X- _ O
} -X- _ O
( -X- _ O
where -X- _ O
C -X- _ O
denotes -X- _ O
the -X- _ O
image -X- _ O
caption -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
agent -X- _ O
is -X- _ O
asked -X- _ O
to -X- _ O
predict -X- _ O
its -X- _ O
answer -X- _ O
At -X- _ O
by -X- _ O
ranking -X- _ O
a -X- _ O
list -X- _ O
of -X- _ O
100 -X- _ O
answer -X- _ O
candidates -X- _ O
{ -X- _ O
Â1 -X- _ O
t -X- _ O
, -X- _ O
Â2 -X- _ O
t -X- _ O
, -X- _ O
... -X- _ O
, -X- _ O
Â100 -X- _ O
t -X- _ O
} -X- _ O
. -X- _ O

The -X- _ O
VD -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
Model -X- _ O
We -X- _ O
first -X- _ O
formally -X- _ O
describe -X- _ O
the -X- _ O
visual -X- _ B-TaskName
dialog -X- _ I-TaskName
task -X- _ O
. -X- _ O

Our -X- _ O
work -X- _ O
has -X- _ O
two -X- _ O
major -X- _ O
advantages -X- _ O
over -X- _ O
VisDial -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
: -X- _ O
first -X- _ O
, -X- _ O
VDBERT -X- _ B-MethodName
supports -X- _ O
both -X- _ O
discriminative -X- _ O
and -X- _ O
generative -X- _ O
settings -X- _ O
while -X- _ O
theirs -X- _ O
is -X- _ O
restricted -X- _ O
to -X- _ O
only -X- _ O
the -X- _ O
discriminative -X- _ O
setting -X- _ O
; -X- _ O
second -X- _ O
, -X- _ O
we -X- _ O
do -X- _ O
not -X- _ O
require -X- _ O
to -X- _ O
pretrain -X- _ O
on -X- _ O
large -X- _ O
- -X- _ O
scale -X- _ O
external -X- _ O
vision -X- _ O
- -X- _ O
language -X- _ O
datasets -X- _ O
like -X- _ O
theirs -X- _ O
and -X- _ O
still -X- _ O
yield -X- _ O
better -X- _ O
performance -X- _ O
( -X- _ O
§ -X- _ O
5.1 -X- _ O
) -X- _ O
. -X- _ O

Most -X- _ O
closely -X- _ O
related -X- _ O
to -X- _ O
this -X- _ O
paper -X- _ O
is -X- _ O
the -X- _ O
concurrent -X- _ O
work -X- _ O
VisDial -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
by -X- _ O
Murahari -X- _ O
et -X- _ O
al. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
who -X- _ O
also -X- _ O
employ -X- _ O
pretrained -X- _ O
models -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
ViLBERT -X- _ B-MethodName
) -X- _ O
for -X- _ O
visual -X- _ O
dialog -X- _ O
. -X- _ O

Our -X- _ O
model -X- _ O
is -X- _ O
inspired -X- _ O
by -X- _ O
VLP -X- _ B-MethodName
and -X- _ O
specifically -X- _ O
tailored -X- _ O
for -X- _ O
the -X- _ O
visual -X- _ B-TaskName
dialog -X- _ I-TaskName
task -X- _ O
. -X- _ O

Their -X- _ O
model -X- _ O
was -X- _ O
proposed -X- _ O
for -X- _ O
VQA -X- _ B-TaskName
and -X- _ O
image -X- _ B-TaskName
captioning -X- _ I-TaskName
. -X- _ O

More -X- _ O
recently -X- _ O
, -X- _ O
Zhou -X- _ O
et -X- _ O
al. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
proposed -X- _ O
VLP -X- _ B-MethodName
which -X- _ O
also -X- _ O
allows -X- _ O
generation -X- _ O
using -X- _ O
a -X- _ O
unified -X- _ O
Transformer -X- _ O
with -X- _ O
various -X- _ O
self -X- _ O
- -X- _ O
attention -X- _ O
masks -X- _ O
( -X- _ O
Dong -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O

These -X- _ O
models -X- _ O
yield -X- _ O
prominent -X- _ O
improvements -X- _ O
mainly -X- _ O
on -X- _ O
vision -X- _ B-TaskName
- -X- _ I-TaskName
language -X- _ I-TaskName
understanding -X- _ I-TaskName
tasks -X- _ O
like -X- _ O
VQA -X- _ B-TaskName
, -X- _ O
image -X- _ B-TaskName
retrieval -X- _ I-TaskName
( -X- _ O
Young -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
visual -X- _ B-TaskName
reasoning -X- _ I-TaskName
( -X- _ O
Suhr -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Zellers -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O

Our -X- _ O
VD -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
belongs -X- _ O
to -X- _ O
the -X- _ O
second -X- _ O
group -X- _ O
. -X- _ O

They -X- _ O
typically -X- _ O
employ -X- _ O
the -X- _ O
Transformer -X- _ O
encoder -X- _ O
as -X- _ O
the -X- _ O
backbone -X- _ O
with -X- _ O
either -X- _ O
a -X- _ O
two -X- _ O
- -X- _ O
stream -X- _ O
architecture -X- _ O
to -X- _ O
encode -X- _ O
text -X- _ O
and -X- _ O
image -X- _ O
independently -X- _ O
such -X- _ O
as -X- _ O
ViLBERT -X- _ B-MethodName
( -X- _ O
Lu -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
and -X- _ O
LXMERT -X- _ B-MethodName
( -X- _ O
Tan -X- _ O
and -X- _ O
Bansal -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
or -X- _ O
a -X- _ O
single -X- _ O
- -X- _ O
stream -X- _ O
architecture -X- _ O
to -X- _ O
encode -X- _ O
both -X- _ O
text -X- _ O
and -X- _ O
image -X- _ O
together -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
B2T2 -X- _ B-MethodName
( -X- _ O
Alberti -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
Unicoder -X- _ B-MethodName
- -X- _ I-MethodName
VL -X- _ I-MethodName
( -X- _ O
Li -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
VisualBERT -X- _ B-MethodName
( -X- _ O
Li -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
VL -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
( -X- _ O
Su -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
UNITER -X- _ B-MethodName
( -X- _ O
Chen -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O

In -X- _ O
order -X- _ O
to -X- _ O
benefit -X- _ O
from -X- _ O
the -X- _ O
pretraining -X- _ O
, -X- _ O
there -X- _ O
are -X- _ O
many -X- _ O
recent -X- _ O
works -X- _ O
on -X- _ O
extending -X- _ O
BERT -X- _ O
for -X- _ O
vision -X- _ O
and -X- _ O
language -X- _ O
pretraining -X- _ O
. -X- _ O

Pretrained -X- _ O
language -X- _ O
models -X- _ O
like -X- _ O
BERT -X- _ O
( -X- _ O
Devlin -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
have -X- _ O
boosted -X- _ O
performance -X- _ O
greatly -X- _ O
in -X- _ O
a -X- _ O
broad -X- _ O
set -X- _ O
of -X- _ O
NLP -X- _ O
tasks -X- _ O
. -X- _ O

Pretraining -X- _ O
in -X- _ O
Vision -X- _ O
and -X- _ O
Language -X- _ O
. -X- _ O

Regarding -X- _ O
the -X- _ O
architecture -X- _ O
, -X- _ O
our -X- _ O
model -X- _ O
mainly -X- _ O
differs -X- _ O
from -X- _ O
previous -X- _ O
work -X- _ O
in -X- _ O
two -X- _ O
facets -X- _ O
: -X- _ O
first -X- _ O
, -X- _ O
unlike -X- _ O
most -X- _ O
prior -X- _ O
work -X- _ O
that -X- _ O
considers -X- _ O
answer -X- _ O
candidates -X- _ O
only -X- _ O
at -X- _ O
the -X- _ O
final -X- _ O
similarity -X- _ O
computation -X- _ O
layer -X- _ O
, -X- _ O
our -X- _ O
VD -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
integrates -X- _ O
each -X- _ O
answer -X- _ O
candidate -X- _ O
at -X- _ O
the -X- _ O
input -X- _ O
layer -X- _ O
to -X- _ O
enable -X- _ O
its -X- _ O
early -X- _ O
and -X- _ O
deep -X- _ O
fusion -X- _ O
with -X- _ O
other -X- _ O
entities -X- _ O
, -X- _ O
similar -X- _ O
to -X- _ O
Schwartz -X- _ O
et -X- _ O
al. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
; -X- _ O
second -X- _ O
, -X- _ O
existing -X- _ O
models -X- _ O
adopt -X- _ O
an -X- _ O
encoderdecoder -X- _ O
framework -X- _ O
( -X- _ O
Sutskever -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
with -X- _ O
two -X- _ O
types -X- _ O
of -X- _ O
decoder -X- _ O
for -X- _ O
the -X- _ O
discriminative -X- _ O
and -X- _ O
generative -X- _ O
settings -X- _ O
separately -X- _ O
, -X- _ O
while -X- _ O
we -X- _ O
instead -X- _ O
adopt -X- _ O
a -X- _ O
unified -X- _ O
Transformer -X- _ O
encoder -X- _ O
with -X- _ O
two -X- _ O
different -X- _ O
self -X- _ O
- -X- _ O
attention -X- _ O
masks -X- _ O
( -X- _ O
Dong -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
to -X- _ O
seamlessly -X- _ O
support -X- _ O
both -X- _ O
settings -X- _ O
without -X- _ O
extra -X- _ O
decoders -X- _ O
. -X- _ O

However -X- _ O
, -X- _ O
their -X- _ O
models -X- _ O
neglect -X- _ O
the -X- _ O
important -X- _ O
early -X- _ O
interaction -X- _ O
of -X- _ O
the -X- _ O
answer -X- _ O
entity -X- _ O
and -X- _ O
can -X- _ O
not -X- _ O
naturally -X- _ O
leverage -X- _ O
the -X- _ O
pretrained -X- _ O
language -X- _ O
representations -X- _ O
from -X- _ O
BERT -X- _ O
like -X- _ O
ours -X- _ O
. -X- _ O

There -X- _ O
are -X- _ O
recent -X- _ O
works -X- _ O
( -X- _ O
Nguyen -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Agarwal -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
also -X- _ O
applying -X- _ O
the -X- _ O
Transformer -X- _ O
to -X- _ O
model -X- _ O
the -X- _ O
interactions -X- _ O
among -X- _ O
many -X- _ O
entities -X- _ O
. -X- _ O

Similar -X- _ O
to -X- _ O
this -X- _ O
, -X- _ O
Schwartz -X- _ O
et -X- _ O
al. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
proposed -X- _ O
FGA -X- _ B-MethodName
, -X- _ O
a -X- _ O
general -X- _ O
factor -X- _ O
graph -X- _ O
attention -X- _ O
that -X- _ O
can -X- _ O
model -X- _ O
interactions -X- _ O
between -X- _ O
any -X- _ O
two -X- _ O
entities -X- _ O
but -X- _ O
in -X- _ O
a -X- _ O
pairwise -X- _ O
manner -X- _ O
. -X- _ O

Different -X- _ O
from -X- _ O
them -X- _ O
, -X- _ O
we -X- _ O
rely -X- _ O
on -X- _ O
the -X- _ O
selfattention -X- _ O
mechanism -X- _ O
within -X- _ O
a -X- _ O
single -X- _ O
- -X- _ O
stream -X- _ O
Transformer -X- _ O
encoder -X- _ O
to -X- _ O
capture -X- _ O
such -X- _ O
interactions -X- _ O
in -X- _ O
a -X- _ O
unified -X- _ O
manner -X- _ O
and -X- _ O
derive -X- _ O
a -X- _ O
“ -X- _ O
holistic -X- _ O
” -X- _ O
contextualized -X- _ O
representation -X- _ O
for -X- _ O
all -X- _ O
the -X- _ O
entities -X- _ O
. -X- _ O

ReDAN -X- _ B-MethodName
, -X- _ O
proposed -X- _ O
by -X- _ O
Gan -X- _ O
et -X- _ O
al. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
further -X- _ O
explores -X- _ O
the -X- _ O
interactions -X- _ O
between -X- _ O
image -X- _ O
and -X- _ O
dialog -X- _ O
history -X- _ O
via -X- _ O
multi -X- _ O
- -X- _ O
step -X- _ O
reasoning -X- _ O
. -X- _ O

For -X- _ O
example -X- _ O
, -X- _ O
Kang -X- _ O
et -X- _ O
al. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
proposed -X- _ O
DAN -X- _ B-MethodName
, -X- _ O
a -X- _ O
dual -X- _ O
attention -X- _ O
module -X- _ O
to -X- _ O
first -X- _ O
refer -X- _ O
to -X- _ O
relevant -X- _ O
contexts -X- _ O
in -X- _ O
the -X- _ O
dialog -X- _ O
history -X- _ O
, -X- _ O
and -X- _ O
then -X- _ O
find -X- _ O
indicative -X- _ O
image -X- _ O
regions -X- _ O
. -X- _ O

Previous -X- _ O
work -X- _ O
( -X- _ O
Lu -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2017 -X- _ O
; -X- _ O
Seo -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2017 -X- _ O
; -X- _ O
Wu -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Kottur -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Jiang -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Yang -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Guo -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019a -X- _ O
; -X- _ O
Niu -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
focuses -X- _ O
on -X- _ O
developing -X- _ O
a -X- _ O
variety -X- _ O
of -X- _ O
attention -X- _ O
mechanisms -X- _ O
to -X- _ O
model -X- _ O
the -X- _ O
interactions -X- _ O
among -X- _ O
entities -X- _ O
including -X- _ O
image -X- _ O
, -X- _ O
question -X- _ O
, -X- _ O
and -X- _ O
dialog -X- _ O
history -X- _ O
. -X- _ O

It -X- _ O
is -X- _ O
one -X- _ O
of -X- _ O
the -X- _ O
most -X- _ O
challenging -X- _ O
vision -X- _ O
- -X- _ O
language -X- _ O
tasks -X- _ O
that -X- _ O
require -X- _ O
not -X- _ O
only -X- _ O
to -X- _ O
understand -X- _ O
the -X- _ O
image -X- _ O
content -X- _ O
according -X- _ O
to -X- _ O
texts -X- _ O
, -X- _ O
but -X- _ O
also -X- _ O
to -X- _ O
reason -X- _ O
through -X- _ O
the -X- _ O
dialog -X- _ O
history -X- _ O
. -X- _ O

The -X- _ O
Visual -X- _ B-TaskName
Dialog -X- _ I-TaskName
task -X- _ O
has -X- _ O
been -X- _ O
recently -X- _ O
proposed -X- _ O
by -X- _ O
Das -X- _ O
et -X- _ O
al. -X- _ O
( -X- _ O
2017 -X- _ O
) -X- _ O
, -X- _ O
where -X- _ O
a -X- _ O
dialog -X- _ O
agent -X- _ O
needs -X- _ O
to -X- _ O
answer -X- _ O
a -X- _ O
series -X- _ O
of -X- _ O
questions -X- _ O
grounded -X- _ O
by -X- _ O
an -X- _ O
image -X- _ O
. -X- _ O

2 -X- _ O
Related -X- _ O
Work -X- _ O
Visual -X- _ B-TaskName
Dialog -X- _ I-TaskName
. -X- _ O

• -X- _ O
Without -X- _ O
the -X- _ O
need -X- _ O
to -X- _ O
pretrain -X- _ O
on -X- _ O
external -X- _ O
visionlanguage -X- _ O
data -X- _ O
, -X- _ O
our -X- _ O
model -X- _ O
yields -X- _ O
new -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
theart -X- _ O
results -X- _ O
in -X- _ O
discriminative -X- _ O
setting -X- _ O
and -X- _ O
promising -X- _ O
results -X- _ O
in -X- _ O
generative -X- _ O
setting -X- _ O
on -X- _ O
the -X- _ O
visual -X- _ B-TaskName
dialog -X- _ I-TaskName
benchmarks -X- _ O
( -X- _ O
§ -X- _ O
5.1 -X- _ O
) -X- _ O
. -X- _ O

• -X- _ O
We -X- _ O
conduct -X- _ O
extensive -X- _ O
experiments -X- _ O
not -X- _ O
only -X- _ O
to -X- _ O
analyze -X- _ O
how -X- _ O
our -X- _ O
model -X- _ O
performs -X- _ O
with -X- _ O
various -X- _ O
training -X- _ O
aspects -X- _ O
( -X- _ O
§ -X- _ O
5.2 -X- _ O
) -X- _ O
and -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
on -X- _ O
dense -X- _ O
annotations -X- _ O
( -X- _ O
§ -X- _ O
5.3 -X- _ O
) -X- _ O
, -X- _ O
but -X- _ O
also -X- _ O
to -X- _ O
interpret -X- _ O
it -X- _ O
via -X- _ O
attention -X- _ O
visualization -X- _ O
( -X- _ O
§ -X- _ O
5.4 -X- _ O
) -X- _ O
, -X- _ O
shedding -X- _ O
light -X- _ O
on -X- _ O
future -X- _ O
transfer -X- _ O
learning -X- _ O
research -X- _ O
for -X- _ O
VisDial -X- _ B-DatasetName
tasks -X- _ O
. -X- _ O

Besides -X- _ O
, -X- _ O
our -X- _ O
VD -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
is -X- _ O
the -X- _ O
first -X- _ O
unified -X- _ O
model -X- _ O
that -X- _ O
supports -X- _ O
both -X- _ O
discriminative -X- _ O
and -X- _ O
generative -X- _ O
training -X- _ O
settings -X- _ O
without -X- _ O
explicit -X- _ O
decoders -X- _ O
. -X- _ O

We -X- _ O
showcase -X- _ O
that -X- _ O
BERT -X- _ O
can -X- _ O
be -X- _ O
effectively -X- _ O
adapted -X- _ O
to -X- _ O
this -X- _ O
task -X- _ O
with -X- _ O
simple -X- _ O
visually -X- _ O
grounded -X- _ O
training -X- _ O
for -X- _ O
capturing -X- _ O
the -X- _ O
intricate -X- _ O
vision -X- _ O
- -X- _ O
dialog -X- _ O
interactions -X- _ O
. -X- _ O

In -X- _ O
summary -X- _ O
, -X- _ O
we -X- _ O
make -X- _ O
the -X- _ O
following -X- _ O
contributions -X- _ O
: -X- _ O
• -X- _ O
To -X- _ O
the -X- _ O
best -X- _ O
of -X- _ O
our -X- _ O
knowledge -X- _ O
, -X- _ O
our -X- _ O
work -X- _ O
serves -X- _ O
as -X- _ O
one -X- _ O
of -X- _ O
the -X- _ O
first -X- _ O
attempts -X- _ O
to -X- _ O
explore -X- _ O
pretrained -X- _ O
language -X- _ O
models -X- _ O
for -X- _ O
visual -X- _ B-TaskName
dialog -X- _ I-TaskName
. -X- _ O

We -X- _ O
further -X- _ O
fine -X- _ O
- -X- _ O
tune -X- _ O
our -X- _ O
model -X- _ O
on -X- _ O
dense -X- _ O
annotations -X- _ O
that -X- _ O
specify -X- _ O
the -X- _ O
relevance -X- _ O
score -X- _ O
for -X- _ O
each -X- _ O
answer -X- _ O
candidate -X- _ O
with -X- _ O
a -X- _ O
ranking -X- _ O
optimization -X- _ O
module -X- _ O
. -X- _ O

During -X- _ O
inference -X- _ O
, -X- _ O
our -X- _ O
VD -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
either -X- _ O
ranks -X- _ O
the -X- _ O
answer -X- _ O
candidates -X- _ O
according -X- _ O
to -X- _ O
their -X- _ O
NSP -X- _ O
scores -X- _ O
or -X- _ O
generates -X- _ O
the -X- _ O
answer -X- _ O
sequence -X- _ O
by -X- _ O
recursively -X- _ O
applying -X- _ O
the -X- _ O
MLM -X- _ O
operations -X- _ O
. -X- _ O

Instead -X- _ O
of -X- _ O
employing -X- _ O
two -X- _ O
types -X- _ O
of -X- _ O
decoders -X- _ O
like -X- _ O
prior -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
rely -X- _ O
on -X- _ O
a -X- _ O
unified -X- _ O
Transformer -X- _ O
architecture -X- _ O
with -X- _ O
two -X- _ O
different -X- _ O
self -X- _ O
- -X- _ O
attention -X- _ O
masks -X- _ O
( -X- _ O
Dong -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
to -X- _ O
seamlessly -X- _ O
support -X- _ O
both -X- _ O
settings -X- _ O
. -X- _ O

In -X- _ O
the -X- _ O
discriminative -X- _ O
setting -X- _ O
, -X- _ O
the -X- _ O
model -X- _ O
ranks -X- _ O
a -X- _ O
pool -X- _ O
of -X- _ O
answer -X- _ O
candidates -X- _ O
, -X- _ O
whereas -X- _ O
the -X- _ O
generative -X- _ O
setting -X- _ O
additionally -X- _ O
allows -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
generate -X- _ O
the -X- _ O
answers -X- _ O
. -X- _ O

VisDial -X- _ B-DatasetName
models -X- _ O
have -X- _ O
been -X- _ O
trained -X- _ O
in -X- _ O
one -X- _ O
of -X- _ O
two -X- _ O
settings -X- _ O
: -X- _ O
discriminative -X- _ O
or -X- _ O
generative -X- _ O
. -X- _ O

Different -X- _ O
from -X- _ O
the -X- _ O
original -X- _ O
MLM -X- _ O
and -X- _ O
NSP -X- _ O
in -X- _ O
BERT -X- _ O
, -X- _ O
we -X- _ O
additionally -X- _ O
take -X- _ O
the -X- _ O
visual -X- _ O
information -X- _ O
into -X- _ O
account -X- _ O
when -X- _ O
predicting -X- _ O
the -X- _ O
masked -X- _ O
tokens -X- _ O
or -X- _ O
the -X- _ O
next -X- _ O
answer -X- _ O
. -X- _ O

To -X- _ O
effectively -X- _ O
fuse -X- _ O
features -X- _ O
from -X- _ O
the -X- _ O
two -X- _ O
modalities -X- _ O
, -X- _ O
we -X- _ O
make -X- _ O
use -X- _ O
of -X- _ O
two -X- _ O
visually -X- _ O
grounded -X- _ O
training -X- _ O
objectives -X- _ O
– -X- _ O
Masked -X- _ O
Language -X- _ O
Modeling -X- _ O
( -X- _ O
MLM -X- _ O
) -X- _ O
and -X- _ O
Next -X- _ O
Sentence -X- _ O
Prediction -X- _ O
( -X- _ O
NSP -X- _ O
) -X- _ O
. -X- _ O

We -X- _ O
initialize -X- _ O
the -X- _ O
encoder -X- _ O
with -X- _ O
BERT -X- _ O
for -X- _ O
better -X- _ O
leveraging -X- _ O
the -X- _ O
pretrained -X- _ O
language -X- _ O
representations -X- _ O
. -X- _ O

Specifically -X- _ O
, -X- _ O
we -X- _ O
first -X- _ O
encode -X- _ O
the -X- _ O
image -X- _ O
into -X- _ O
a -X- _ O
series -X- _ O
of -X- _ O
detected -X- _ O
objects -X- _ O
and -X- _ O
feed -X- _ O
them -X- _ O
into -X- _ O
a -X- _ O
Transformer -X- _ O
encoder -X- _ O
together -X- _ O
with -X- _ O
the -X- _ O
image -X- _ O
caption -X- _ O
and -X- _ O
multi -X- _ B-TaskName
- -X- _ I-TaskName
turn -X- _ I-TaskName
dialog -X- _ I-TaskName
. -X- _ O

In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
present -X- _ O
VD -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
, -X- _ O
a -X- _ O
novel -X- _ O
unified -X- _ B-MethodName
vision -X- _ I-MethodName
- -X- _ I-MethodName
dialog -X- _ I-MethodName
Transformer -X- _ I-MethodName
framework -X- _ O
for -X- _ O
VisDial -X- _ B-DatasetName
tasks -X- _ O
. -X- _ O

Specifically -X- _ O
, -X- _ O
each -X- _ O
image -X- _ O
in -X- _ O
the -X- _ O
VisDial -X- _ B-DatasetName
dataset -X- _ O
is -X- _ O
associated -X- _ O
with -X- _ O
up -X- _ O
to -X- _ O
10 -X- _ O
dialog -X- _ O
turns -X- _ O
, -X- _ O
which -X- _ O
contain -X- _ O
much -X- _ O
longer -X- _ O
contexts -X- _ O
than -X- _ O
either -X- _ O
VQA -X- _ B-TaskName
or -X- _ O
image -X- _ B-TaskName
captioning -X- _ I-TaskName
. -X- _ O

However -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
still -X- _ O
unclear -X- _ O
how -X- _ O
visual -X- _ B-TaskName
dialog -X- _ I-TaskName
may -X- _ O
benefit -X- _ O
from -X- _ O
such -X- _ O
vision -X- _ O
- -X- _ O
language -X- _ O
pretraining -X- _ O
due -X- _ O
to -X- _ O
its -X- _ O
unique -X- _ O
multiturn -X- _ O
conversational -X- _ O
structure -X- _ O
. -X- _ O

This -X- _ O
has -X- _ O
led -X- _ O
to -X- _ O
compelling -X- _ O
results -X- _ O
in -X- _ O
tasks -X- _ O
such -X- _ O
as -X- _ O
VQA -X- _ B-TaskName
, -X- _ B-TaskName
image -X- _ I-TaskName
captioning -X- _ I-TaskName
, -X- _ O
image -X- _ B-TaskName
retrieval -X- _ I-TaskName
( -X- _ O
Young -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
visual -X- _ B-TaskName
reasoning -X- _ I-TaskName
( -X- _ O
Suhr -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O

They -X- _ O
often -X- _ O
use -X- _ O
self -X- _ O
- -X- _ O
supervised -X- _ O
objectives -X- _ O
to -X- _ O
pretrain -X- _ O
BERT -X- _ O
- -X- _ O
like -X- _ O
models -X- _ O
on -X- _ O
large -X- _ O
- -X- _ O
scale -X- _ O
external -X- _ O
vision -X- _ O
- -X- _ O
language -X- _ O
data -X- _ O
and -X- _ O
then -X- _ O
fine -X- _ O
- -X- _ O
tune -X- _ O
on -X- _ O
downstream -X- _ O
tasks -X- _ O
. -X- _ O

2019 -X- _ O
; -X- _ O
Lu -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Tan -X- _ O
and -X- _ O
Bansal -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Zhou -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O

c -X- _ O
2020 -X- _ O
Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O

Recently -X- _ O
several -X- _ O
emerging -X- _ O
works -X- _ O
have -X- _ O
attempted -X- _ O
to -X- _ O
adapt -X- _ O
BERT -X- _ O
for -X- _ O
multimodal -X- _ B-TaskName
tasks -X- _ O
( -X- _ O
Sun -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
3325 -X- _ O
Proceedings -X- _ O
of -X- _ O
the -X- _ O
2020 -X- _ O
Conference -X- _ O
on -X- _ O
Empirical -X- _ O
Methods -X- _ O
in -X- _ O
Natural -X- _ O
Language -X- _ O
Processing -X- _ O
, -X- _ O
pages -X- _ O
3325–3338 -X- _ O
, -X- _ O
November -X- _ O
16–20 -X- _ O
, -X- _ O
2020 -X- _ O
. -X- _ O

Inspired -X- _ O
by -X- _ O
its -X- _ O
recent -X- _ O
success -X- _ O
in -X- _ O
vision -X- _ O
- -X- _ O
language -X- _ O
pretraining -X- _ O
, -X- _ O
we -X- _ O
further -X- _ O
extend -X- _ O
BERT -X- _ O
to -X- _ O
achieve -X- _ O
simple -X- _ O
yet -X- _ O
effective -X- _ O
fusion -X- _ O
of -X- _ O
vision -X- _ O
and -X- _ O
dialog -X- _ O
contents -X- _ O
in -X- _ O
VisDial -X- _ B-DatasetName
tasks -X- _ O
. -X- _ O

We -X- _ O
employ -X- _ O
the -X- _ O
Transformer -X- _ O
as -X- _ O
the -X- _ O
encoding -X- _ O
backbone -X- _ O
due -X- _ O
to -X- _ O
its -X- _ O
powerful -X- _ O
representation -X- _ O
learning -X- _ O
capability -X- _ O
exhibited -X- _ O
in -X- _ O
pretrained -X- _ O
language -X- _ O
models -X- _ O
like -X- _ O
BERT -X- _ O
( -X- _ O
Devlin -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
way -X- _ O
, -X- _ O
all -X- _ O
the -X- _ O
entities -X- _ O
simultaneously -X- _ O
play -X- _ O
the -X- _ O
role -X- _ O
of -X- _ O
an -X- _ O
“ -X- _ O
information -X- _ O
seeker -X- _ O
” -X- _ O
( -X- _ O
query -X- _ O
) -X- _ O
and -X- _ O
an -X- _ O
“ -X- _ O
information -X- _ O
provider -X- _ O
” -X- _ O
( -X- _ O
key -X- _ O
- -X- _ O
value -X- _ O
) -X- _ O
, -X- _ O
thereby -X- _ O
fully -X- _ O
unleashing -X- _ O
the -X- _ O
potential -X- _ O
of -X- _ O
attention -X- _ O
similar -X- _ O
to -X- _ O
Schwartz -X- _ O
et -X- _ O
al. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O

By -X- _ O
contrast -X- _ O
, -X- _ O
in -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
allow -X- _ O
for -X- _ O
bidirectional -X- _ O
attention -X- _ O
flow -X- _ O
between -X- _ O
all -X- _ O
the -X- _ O
entities -X- _ O
using -X- _ O
a -X- _ O
unified -X- _ O
Transformer -X- _ O
( -X- _ O
Vaswani -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
encoder -X- _ O
, -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
1(c -X- _ O
) -X- _ O
. -X- _ O

In -X- _ O
other -X- _ O
words -X- _ O
, -X- _ O
the -X- _ O
attention -X- _ O
flow -X- _ O
in -X- _ O
these -X- _ O
methods -X- _ O
is -X- _ O
unidirectional -X- _ O
– -X- _ O
from -X- _ O
question -X- _ O
to -X- _ O
the -X- _ O
other -X- _ O
components -X- _ O
( -X- _ O
Figure -X- _ O
1(b -X- _ O
) -X- _ O
) -X- _ O
. -X- _ O

Typically -X- _ O
, -X- _ O
most -X- _ O
of -X- _ O
previous -X- _ O
work -X- _ O
( -X- _ O
Niu -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Gan -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Kang -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
uses -X- _ O
the -X- _ O
question -X- _ O
as -X- _ O
a -X- _ O
query -X- _ O
to -X- _ O
attend -X- _ O
to -X- _ O
relevant -X- _ O
image -X- _ O
regions -X- _ O
and -X- _ O
dialog -X- _ O
history -X- _ O
, -X- _ O
where -X- _ O
their -X- _ O
interactions -X- _ O
are -X- _ O
usually -X- _ O
exploited -X- _ O
to -X- _ O
obtain -X- _ O
better -X- _ O
visual -X- _ O
- -X- _ O
historical -X- _ O
cues -X- _ O
for -X- _ O
predicting -X- _ O
the -X- _ O
answer -X- _ O
. -X- _ O

Compared -X- _ O
to -X- _ O
VQA -X- _ B-TaskName
that -X- _ O
predicts -X- _ O
an -X- _ O
answer -X- _ O
based -X- _ O
only -X- _ O
on -X- _ O
the -X- _ O
question -X- _ O
about -X- _ O
the -X- _ O
image -X- _ O
( -X- _ O
Figure -X- _ O
1(a -X- _ O
) -X- _ O
) -X- _ O
, -X- _ O
VisDial -X- _ B-DatasetName
needs -X- _ O
to -X- _ O
additionally -X- _ O
consider -X- _ O
the -X- _ O
dialog -X- _ O
history -X- _ O
. -X- _ O

ter -X- _ O
fusion -X- _ O
of -X- _ O
vision -X- _ O
and -X- _ O
dialog -X- _ O
contents -X- _ O
. -X- _ O

This -X- _ O
work -X- _ O
was -X- _ O
mainly -X- _ O
done -X- _ O
when -X- _ O
Yue -X- _ O
Wang -X- _ O
was -X- _ O
an -X- _ O
intern -X- _ O
at -X- _ O
Salesforce -X- _ O
Research -X- _ O
Asia -X- _ O
, -X- _ O
Singapore -X- _ O
. -X- _ O

The -X- _ O
primary -X- _ O
research -X- _ O
direction -X- _ O
in -X- _ O
VisDial -X- _ B-DatasetName
has -X- _ O
been -X- _ O
mostly -X- _ O
focusing -X- _ O
on -X- _ O
developing -X- _ O
various -X- _ O
attention -X- _ O
mechanisms -X- _ O
( -X- _ O
Bahdanau -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
for -X- _ O
a -X- _ O
bet -X- _ O
* -X- _ O

Unlike -X- _ O
the -X- _ O
traditional -X- _ O
single -X- _ B-TaskName
- -X- _ I-TaskName
turn -X- _ I-TaskName
Visual -X- _ I-TaskName
Question -X- _ I-TaskName
Answering -X- _ I-TaskName
( -X- _ O
VQA -X- _ B-TaskName
) -X- _ O
( -X- _ O
Antol -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
agent -X- _ O
in -X- _ O
VisDial -X- _ B-DatasetName
requires -X- _ O
to -X- _ O
answer -X- _ O
questions -X- _ O
through -X- _ O
multiple -X- _ O
rounds -X- _ O
of -X- _ O
interactions -X- _ O
together -X- _ O
with -X- _ O
visual -X- _ O
content -X- _ O
understanding -X- _ O
. -X- _ O

Introduction -X- _ O
Visual -X- _ B-TaskName
Dialog -X- _ I-TaskName
( -X- _ O
or -X- _ O
VisDial -X- _ B-DatasetName
) -X- _ O
aims -X- _ O
to -X- _ O
build -X- _ O
an -X- _ O
AI -X- _ O
agent -X- _ O
that -X- _ O
can -X- _ O
answer -X- _ O
a -X- _ O
human -X- _ O
’s -X- _ O
questions -X- _ O
about -X- _ O
visual -X- _ O
content -X- _ O
in -X- _ O
a -X- _ O
natural -X- _ O
conversational -X- _ O
setting -X- _ O
( -X- _ O
Das -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O

Our -X- _ O
code -X- _ O
and -X- _ O
pretrained -X- _ O
models -X- _ O
are -X- _ O
released -X- _ O
at -X- _ O
https -X- _ O
: -X- _ O
//github.com -X- _ O
/ -X- _ O
salesforce -X- _ O
/ -X- _ O
VD -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
. -X- _ O

Without -X- _ O
the -X- _ O
need -X- _ O
of -X- _ O
pretraining -X- _ O
on -X- _ O
external -X- _ O
vision -X- _ O
- -X- _ O
language -X- _ O
data -X- _ O
, -X- _ O
our -X- _ O
model -X- _ O
yields -X- _ O
new -X- _ O
state -X- _ O
of -X- _ O
the -X- _ O
art -X- _ O
, -X- _ O
achieving -X- _ O
the -X- _ O
top -X- _ O
position -X- _ O
in -X- _ O
both -X- _ O
single -X- _ O
- -X- _ O
model -X- _ O
and -X- _ O
ensemble -X- _ O
settings -X- _ O
( -X- _ O
74.54 -X- _ B-MetricValue
and -X- _ O
75.35 -X- _ B-MetricValue
NDCG -X- _ B-MetricName
scores -X- _ O
) -X- _ O
on -X- _ O
the -X- _ O
visual -X- _ B-TaskName
dialog -X- _ I-TaskName
leaderboard -X- _ O
. -X- _ O

More -X- _ O
crucially -X- _ O
, -X- _ O
we -X- _ O
adapt -X- _ O
BERT -X- _ O
for -X- _ O
the -X- _ O
effective -X- _ O
fusion -X- _ O
of -X- _ O
vision -X- _ O
and -X- _ O
dialog -X- _ O
contents -X- _ O
via -X- _ O
visually -X- _ O
grounded -X- _ O
training -X- _ O
. -X- _ O

The -X- _ O
model -X- _ O
is -X- _ O
unified -X- _ O
in -X- _ O
that -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
it -X- _ O
captures -X- _ O
all -X- _ O
the -X- _ O
interactions -X- _ O
between -X- _ O
the -X- _ O
image -X- _ O
and -X- _ O
the -X- _ O
multi -X- _ B-TaskName
- -X- _ I-TaskName
turn -X- _ I-TaskName
dialog -X- _ I-TaskName
using -X- _ O
a -X- _ O
single -X- _ O
- -X- _ O
stream -X- _ O
Transformer -X- _ O
encoder -X- _ O
, -X- _ O
and -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
it -X- _ O
supports -X- _ O
both -X- _ O
answer -X- _ O
ranking -X- _ O
and -X- _ O
answer -X- _ O
generation -X- _ O
seamlessly -X- _ O
through -X- _ O
the -X- _ O
same -X- _ O
architecture -X- _ O
. -X- _ O

By -X- _ O
contrast -X- _ O
, -X- _ O
in -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
VD -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
, -X- _ O
a -X- _ O
simple -X- _ O
yet -X- _ O
effective -X- _ O
framework -X- _ O
of -X- _ O
unified -X- _ B-MethodName
vision -X- _ I-MethodName
- -X- _ I-MethodName
dialog -X- _ I-MethodName
Transformer -X- _ I-MethodName
that -X- _ O
leverages -X- _ O
the -X- _ O
pretrained -X- _ O
BERT -X- _ O
language -X- _ O
models -X- _ O
for -X- _ O
Visual -X- _ B-TaskName
Dialog -X- _ I-TaskName
tasks -X- _ O
. -X- _ O

Prior -X- _ O
work -X- _ O
has -X- _ O
mostly -X- _ O
focused -X- _ O
on -X- _ O
various -X- _ O
attention -X- _ O
mechanisms -X- _ O
to -X- _ O
model -X- _ O
such -X- _ O
intricate -X- _ O
interactions -X- _ O
. -X- _ O

Wang1∗ -X- _ O
, -X- _ O
Shafiq -X- _ O
Joty2 -X- _ O
, -X- _ O
Michael -X- _ O
R. -X- _ O
Lyu1 -X- _ O
, -X- _ O
Irwin -X- _ O
King1 -X- _ O
, -X- _ O
Caiming -X- _ O
Xiong2 -X- _ O
, -X- _ O
and -X- _ O
Steven -X- _ O
C.H. -X- _ O
Hoi2 -X- _ O
1 -X- _ O
Department -X- _ O
of -X- _ O
Computer -X- _ O
Science -X- _ O
and -X- _ O
Engineering -X- _ O
The -X- _ O
Chinese -X- _ O
University -X- _ O
of -X- _ O
Hong -X- _ O
Kong -X- _ O
, -X- _ O
HKSAR -X- _ O
, -X- _ O
China -X- _ O
2 -X- _ O
Salesforce -X- _ O
Research -X- _ O
1 -X- _ O
{ -X- _ O
yuewang,lyu,king}@cse.cuhk.edu.hk -X- _ O
2 -X- _ O
{ -X- _ O
sjoty,cxiong,shoi}@salesforce.com -X- _ O
Abstract -X- _ O
Q -X- _ O
Visual -X- _ B-TaskName
dialog -X- _ I-TaskName
is -X- _ O
a -X- _ O
challenging -X- _ O
vision -X- _ O
- -X- _ O
language -X- _ O
task -X- _ O
, -X- _ O
where -X- _ O
a -X- _ O
dialog -X- _ O
agent -X- _ O
needs -X- _ O
to -X- _ O
answer -X- _ O
a -X- _ O
series -X- _ O
of -X- _ O
questions -X- _ O
through -X- _ O
reasoning -X- _ O
on -X- _ O
the -X- _ O
image -X- _ O
content -X- _ O
and -X- _ O
dialog -X- _ O
history -X- _ O
. -X- _ O

VD -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
: -X- _ O
A -X- _ O
Unified -X- _ B-MethodName
Vision -X- _ I-MethodName
and -X- _ I-MethodName
Dialog -X- _ I-MethodName
Transformer -X- _ I-MethodName
with -X- _ I-MethodName
BERT -X- _ I-MethodName
Yue -X- _ O

