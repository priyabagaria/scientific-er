-DOCSTART- -X- O
Linjing -X- _ O
Li -X- _ O
is -X- _ O
the -X- _ O
corresponding -X- _ O
author -X- _ O
. -X- _ O

This -X- _ O
work -X- _ O
was -X- _ O
supported -X- _ O
in -X- _ O
part -X- _ O
by -X- _ O
the -X- _ O
National -X- _ O
Key -X- _ O
Research -X- _ O
and -X- _ O
Development -X- _ O
Program -X- _ O
of -X- _ O
China -X- _ O
under -X- _ O
Grant -X- _ O
2020AAA0103405 -X- _ O
, -X- _ O
the -X- _ O
National -X- _ O
Natural -X- _ O
Science -X- _ O
Foundation -X- _ O
of -X- _ O
China -X- _ O
under -X- _ O
Grants -X- _ O
71902179 -X- _ O
and -X- _ O
71621002 -X- _ O
. -X- _ O

Acknowledgment -X- _ O

As -X- _ O
to -X- _ O
the -X- _ O
future -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
aim -X- _ O
to -X- _ O
find -X- _ O
out -X- _ O
how -X- _ O
to -X- _ O
decide -X- _ O
the -X- _ O
keywords -X- _ O
in -X- _ O
sentence -X- _ O
pairs -X- _ O
that -X- _ O
determine -X- _ O
their -X- _ O
relationship -X- _ O
. -X- _ O

Experimental -X- _ O
results -X- _ O
validated -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
the -X- _ O
proposed -X- _ O
model -X- _ O
. -X- _ O

These -X- _ O
two -X- _ O
representations -X- _ O
are -X- _ O
then -X- _ O
merged -X- _ O
by -X- _ O
a -X- _ O
feed -X- _ O
- -X- _ O
forward -X- _ O
neural -X- _ O
network -X- _ O
to -X- _ O
predict -X- _ O
the -X- _ O
relationship -X- _ O
label -X- _ O
. -X- _ O

For -X- _ O
a -X- _ O
sentence -X- _ O
pair -X- _ O
, -X- _ O
the -X- _ O
proposed -X- _ O
model -X- _ O
learns -X- _ O
a -X- _ O
knowledgerelation -X- _ O
representation -X- _ O
based -X- _ O
on -X- _ O
paths -X- _ O
of -X- _ O
knowledge -X- _ O
graph -X- _ O
and -X- _ O
a -X- _ O
semantic -X- _ O
- -X- _ O
relation -X- _ O
representation -X- _ O
through -X- _ O
BiLSTM -X- _ B-MethodName
. -X- _ O

The -X- _ O
results -X- _ O
partially -X- _ O
validate -X- _ O
that -X- _ O
parts -X- _ O
of -X- _ O
sentences -X- _ O
are -X- _ O
crucial -X- _ O
in -X- _ O
NLI -X- _ B-TaskName
related -X- _ O
task -X- _ O
. -X- _ O

In -X- _ O
the -X- _ O
experiment -X- _ O
, -X- _ O
parts -X- _ O
of -X- _ O
sentences -X- _ O
are -X- _ O
removed -X- _ O
. -X- _ O

original -X- _ O
p -X- _ O
: -X- _ O
s -X- _ O
: -X- _ O
man -X- _ O
, -X- _ O
p -X- _ O
: -X- _ O
ride -X- _ O
, -X- _ O
o -X- _ O
: -X- _ O
bicycle -X- _ O
h -X- _ O
: -X- _ O
s -X- _ O
: -X- _ O
man -X- _ O
, -X- _ O
p -X- _ O
: -X- _ O
ride -X- _ O
, -X- _ O
o -X- _ O
: -X- _ O
bicycle -X- _ O
unique -X- _ O
p -X- _ O
: -X- _ O
brick -X- _ O
h -X- _ O
: -X- _ O
cement -X- _ O
Ablation -X- _ O
Study -X- _ O
Table -X- _ O
6 -X- _ O
shows -X- _ O
the -X- _ O
results -X- _ O
of -X- _ O
ablation -X- _ O
study -X- _ O
on -X- _ O
SciTail -X- _ B-DatasetName
dataset -X- _ O
. -X- _ O

h -X- _ O
: -X- _ O
The -X- _ O
man -X- _ O
rides -X- _ O
bicycle -X- _ O
up -X- _ O
the -X- _ O
cement -X- _ O
wall -X- _ O
. -X- _ O

4.4 -X- _ O
sentences -X- _ O
p -X- _ O
: -X- _ O
The -X- _ O
man -X- _ O
rides -X- _ O
bicycle -X- _ O
up -X- _ O
the -X- _ O
brick -X- _ O
wall -X- _ O
. -X- _ O

Table -X- _ O
5 -X- _ O
: -X- _ O
Examples -X- _ O
from -X- _ O
BNLI -X- _ B-DatasetName
dataset -X- _ O
. -X- _ O

This -X- _ O
experiment -X- _ O
also -X- _ O
shows -X- _ O
that -X- _ O
the -X- _ O
proposed -X- _ O
model -X- _ O
can -X- _ O
capture -X- _ O
the -X- _ O
background -X- _ O
knowledge -X- _ O
and -X- _ O
utilize -X- _ O
it -X- _ O
to -X- _ O
improve -X- _ O
model -X- _ O
performance -X- _ O
. -X- _ O

As -X- _ O
indicated -X- _ O
by -X- _ O
Table -X- _ O
4 -X- _ O
, -X- _ O
our -X- _ O
model -X- _ O
achieves -X- _ O
the -X- _ O
best -X- _ O
performance -X- _ O
among -X- _ O
all -X- _ O
the -X- _ O
models -X- _ O
. -X- _ O

For -X- _ O
other -X- _ O
datasets -X- _ O
, -X- _ O
we -X- _ O
choose -X- _ O
keywords -X- _ O
among -X- _ O
subjects -X- _ O
, -X- _ O
predicates -X- _ O
, -X- _ O
and -X- _ O
objects -X- _ O
. -X- _ O

We -X- _ O
treat -X- _ O
these -X- _ O
words -X- _ O
as -X- _ O
key -X- _ O
words -X- _ O
, -X- _ O
remove -X- _ O
the -X- _ O
knowledge -X- _ O
composition -X- _ O
layer -X- _ O
, -X- _ O
and -X- _ O
directly -X- _ O
set -X- _ O
the -X- _ O
composed -X- _ O
vector -X- _ O
as -X- _ O
the -X- _ O
relation -X- _ O
vector -X- _ O
of -X- _ O
these -X- _ O
key -X- _ O
words -X- _ O
. -X- _ O

An -X- _ O
example -X- _ O
is -X- _ O
given -X- _ O
in -X- _ O
Table -X- _ O
5 -X- _ O
. -X- _ O

extracted -X- _ O
. -X- _ O

For -X- _ O
dataset -X- _ O
BNLI -X- _ B-DatasetName
, -X- _ O
the -X- _ O
two -X- _ O
different -X- _ O
words -X- _ O
of -X- _ O
sentence -X- _ O
pair -X- _ O
( -X- _ O
p -X- _ O
, -X- _ O
h -X- _ O
) -X- _ O
are -X- _ O
6505 -X- _ O

In -X- _ O
order -X- _ O
to -X- _ O
test -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
our -X- _ O
model -X- _ O
, -X- _ O
we -X- _ O
conduct -X- _ O
a -X- _ O
new -X- _ O
experiment -X- _ O
under -X- _ O
another -X- _ O
setting -X- _ O
, -X- _ O
named -X- _ O
“ -X- _ O
unique -X- _ O
- -X- _ O
word -X- _ O
setting -X- _ O
” -X- _ O
. -X- _ O

Table -X- _ O
4 -X- _ O
: -X- _ O
Performance -X- _ O
of -X- _ O
models -X- _ O
on -X- _ O
BNLI -X- _ B-DatasetName
. -X- _ O

This -X- _ O
is -X- _ O
because -X- _ O
the -X- _ O
subjects -X- _ O
, -X- _ O
predicates -X- _ O
, -X- _ O
and -X- _ O
objects -X- _ O
are -X- _ O
almost -X- _ O
the -X- _ O
same -X- _ O
for -X- _ O
a -X- _ O
sentence -X- _ O
pair -X- _ O
in -X- _ O
BNLI -X- _ B-DatasetName
. -X- _ O

The -X- _ O
performance -X- _ O
difference -X- _ O
between -X- _ O
BNLI -X- _ B-DatasetName
and -X- _ O
SNLI -X- _ B-DatasetName
as -X- _ O
test -X- _ O
set -X- _ O
is -X- _ O
denoted -X- _ O
as -X- _ O
∆. -X- _ O
As -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
4 -X- _ O
, -X- _ O
under -X- _ O
this -X- _ O
setting -X- _ O
, -X- _ O
the -X- _ O
result -X- _ O
of -X- _ O
our -X- _ O
model -X- _ O
, -X- _ O
denoted -X- _ O
as -X- _ O
“ -X- _ O
original -X- _ O
setting -X- _ O
” -X- _ O
, -X- _ O
is -X- _ O
similar -X- _ O
to -X- _ O
that -X- _ O
of -X- _ O
ESIM -X- _ B-MethodName
. -X- _ O

In -X- _ O
practice -X- _ O
, -X- _ O
BNLI -X- _ B-DatasetName
is -X- _ O
used -X- _ O
as -X- _ O
test -X- _ O
set -X- _ O
, -X- _ O
while -X- _ O
training -X- _ O
on -X- _ O
SNLI -X- _ B-DatasetName
, -X- _ O
MultiNLI -X- _ B-DatasetName
, -X- _ O
and -X- _ O
SciTail -X- _ B-DatasetName
. -X- _ O

For -X- _ O
a -X- _ O
sentence -X- _ O
pair -X- _ O
in -X- _ O
BNLI -X- _ B-DatasetName
, -X- _ O
only -X- _ O
one -X- _ O
word -X- _ O
of -X- _ O
hypothesis -X- _ O
h -X- _ O
is -X- _ O
different -X- _ O
with -X- _ O
premise -X- _ O
p. -X- _ O

Table -X- _ O
3 -X- _ O
: -X- _ O
Performance -X- _ O
of -X- _ O
models -X- _ O
on -X- _ O
SciTail -X- _ B-DatasetName
. -X- _ O

The -X- _ O
result -X- _ O
shows -X- _ O
that -X- _ O
the -X- _ O
proposed -X- _ O
model -X- _ O
KGNLI -X- _ B-MethodName
can -X- _ O
capture -X- _ O
external -X- _ O
knowledge -X- _ O
and -X- _ O
use -X- _ O
them -X- _ O
effectively -X- _ O
. -X- _ O

As -X- _ O
SciTail -X- _ B-DatasetName
consists -X- _ O
of -X- _ O
more -X- _ O
factual -X- _ O
sentences -X- _ O
than -X- _ O
SNLI -X- _ B-DatasetName
and -X- _ O
MultiNLI -X- _ B-DatasetName
datasets -X- _ O
( -X- _ O
Tay -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
background -X- _ O
knowledge -X- _ O
plays -X- _ O
a -X- _ O
more -X- _ O
important -X- _ O
role -X- _ O
on -X- _ O
the -X- _ O
inference -X- _ B-TaskName
. -X- _ O

Our -X- _ O
model -X- _ O
achieves -X- _ O
the -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
result -X- _ O
with -X- _ O
large -X- _ O
margin -X- _ O
of -X- _ O
improvement -X- _ O
against -X- _ O
ESIM -X- _ B-MethodName
which -X- _ O
only -X- _ O
considers -X- _ O
semantic -X- _ O
knowledge -X- _ O
. -X- _ O

Table -X- _ O
2 -X- _ O
: -X- _ O
Performance -X- _ O
of -X- _ O
models -X- _ O
on -X- _ O
MultiNLI -X- _ B-DatasetName
. -X- _ O

Model -X- _ O
LSTM -X- _ B-TaskName
Att -X- _ I-TaskName
. -X- _ O

Table -X- _ O
1 -X- _ O
: -X- _ O
Performance -X- _ O
of -X- _ O
models -X- _ O
on -X- _ O
SNLI -X- _ B-DatasetName
. -X- _ O

This -X- _ O
explains -X- _ O
why -X- _ O
our -X- _ O
model -X- _ O
generates -X- _ O
similar -X- _ O
results -X- _ O
with -X- _ O
baselines -X- _ O
. -X- _ O

According -X- _ O
to -X- _ O
( -X- _ O
Glockner -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
inference -X- _ B-TaskName
on -X- _ O
SNLI -X- _ B-DatasetName
dataset -X- _ O
may -X- _ O
not -X- _ O
require -X- _ O
much -X- _ O
knowledge -X- _ O
, -X- _ O
thus -X- _ O
results -X- _ O
are -X- _ O
not -X- _ O
affected -X- _ O
significantly -X- _ O
by -X- _ O
external -X- _ O
knowledge -X- _ O
. -X- _ O

Our -X- _ O
model -X- _ O
gets -X- _ O
the -X- _ O
best -X- _ O
result -X- _ O
. -X- _ O

We -X- _ O
do -X- _ O
not -X- _ O
consider -X- _ O
ensemble -X- _ O
models -X- _ O
in -X- _ O
this -X- _ O
paper -X- _ O
. -X- _ O

4.3 -X- _ O
Results -X- _ O
Table -X- _ O
1 -X- _ O
shows -X- _ O
the -X- _ O
results -X- _ O
on -X- _ O
the -X- _ O
benchmark -X- _ O
SNLI -X- _ B-DatasetName
. -X- _ O

Finally -X- _ O
, -X- _ O
we -X- _ O
stem -X- _ O
the -X- _ O
subjects -X- _ O
, -X- _ O
predicates -X- _ O
, -X- _ O
and -X- _ O
objects -X- _ O
to -X- _ O
match -X- _ O
entities -X- _ O
in -X- _ O
the -X- _ O
knowledge -X- _ O
graph -X- _ O
. -X- _ O

In -X- _ O
both -X- _ O
NP -X- _ O
and -X- _ O
PP -X- _ O
we -X- _ O
search -X- _ O
for -X- _ O
the -X- _ O
first -X- _ O
noun -X- _ O
, -X- _ O
while -X- _ O
in -X- _ O
ADJP -X- _ O
we -X- _ O
just -X- _ O
treat -X- _ O
the -X- _ O
first -X- _ O
adjective -X- _ O
to -X- _ O
be -X- _ O
an -X- _ O
object -X- _ O
. -X- _ O

Objects -X- _ O
are -X- _ O
found -X- _ O
in -X- _ O
three -X- _ O
different -X- _ O
subtrees -X- _ O
, -X- _ O
PP -X- _ O
, -X- _ O
NP -X- _ O
, -X- _ O
and -X- _ O
ADJP -X- _ O
, -X- _ O
which -X- _ O
are -X- _ O
siblings -X- _ O
of -X- _ O
the -X- _ O
VP -X- _ O
subtree -X- _ O
containing -X- _ O
the -X- _ O
predicate -X- _ O
. -X- _ O

Predicates -X- _ O
are -X- _ O
chosen -X- _ O
from -X- _ O
verbs -X- _ O
labeled -X- _ O
as -X- _ O
VB -X- _ O
, -X- _ O
VBD -X- _ O
, -X- _ O
VBG -X- _ O
, -X- _ O
VBN -X- _ O
, -X- _ O
VBP -X- _ O
, -X- _ O
or -X- _ O
VBZ -X- _ O
. -X- _ O

The -X- _ O
deepest -X- _ O
verb -X- _ O
descendent -X- _ O
of -X- _ O
the -X- _ O
VP -X- _ O
subtree -X- _ O
is -X- _ O
considered -X- _ O
as -X- _ O
predicates -X- _ O
. -X- _ O

Subjects -X- _ O
are -X- _ O
selected -X- _ O
from -X- _ O
entities -X- _ O
labeled -X- _ O
as -X- _ O
NN -X- _ O
, -X- _ O
NNP -X- _ O
, -X- _ O
NNPS -X- _ O
, -X- _ O
or -X- _ O
NNS -X- _ O
. -X- _ O

For -X- _ O
subject -X- _ O
, -X- _ O
we -X- _ O
employ -X- _ O
breadth -X- _ O
first -X- _ O
search -X- _ O
to -X- _ O
select -X- _ O
the -X- _ O
first -X- _ O
descendent -X- _ O
of -X- _ O
NP -X- _ O
that -X- _ O
is -X- _ O
a -X- _ O
noun -X- _ O
. -X- _ O

Some -X- _ O
datasets -X- _ O
provide -X- _ O
hand -X- _ O
- -X- _ O
annotated -X- _ O
syntax -X- _ O
trees -X- _ O
, -X- _ O
while -X- _ O
for -X- _ O
others -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
StandfordNLP -X- _ O
( -X- _ O
Qi -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
to -X- _ O
generate -X- _ O
their -X- _ O
syntax -X- _ O
trees -X- _ O
. -X- _ O

To -X- _ O
extract -X- _ O
subjects -X- _ O
, -X- _ O
predicates -X- _ O
, -X- _ O
and -X- _ O
objects -X- _ O
of -X- _ O
sentences -X- _ O
, -X- _ O
we -X- _ O
employ -X- _ O
their -X- _ O
syntax -X- _ O
trees -X- _ O
( -X- _ O
Rusu -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2007 -X- _ O
) -X- _ O
. -X- _ O

We -X- _ O
use -X- _ O
early -X- _ O
stopping -X- _ O
according -X- _ O
to -X- _ O
the -X- _ O
per -X- _ O
- -X- _ O
epoch -X- _ O
accuracy -X- _ O
on -X- _ O
the -X- _ O
validation -X- _ O
set -X- _ O
. -X- _ O

The -X- _ O
optimizer -X- _ B-HyperparameterName
is -X- _ O
Adam -X- _ B-HyperparameterValue
with -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
32 -X- _ B-HyperparameterValue
and -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
0.0004 -X- _ B-HyperparameterValue
. -X- _ O

Dropout -X- _ B-HyperparameterName
is -X- _ O
set -X- _ O
between -X- _ O
layers -X- _ O
to -X- _ O
avoid -X- _ O
overfitting -X- _ O
with -X- _ O
rate -X- _ O
0.5 -X- _ B-HyperparameterValue
. -X- _ O

Dimensions -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
embeddings -X- _ I-HyperparameterName
are -X- _ O
all -X- _ O
set -X- _ O
to -X- _ O
be -X- _ O
300 -X- _ B-HyperparameterValue
. -X- _ O

We -X- _ O
intialize -X- _ O
word -X- _ O
embeddings -X- _ O
by -X- _ O
GloVe -X- _ O
( -X- _ O
Pennington -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
and -X- _ O
entity -X- _ O
embeddings -X- _ O
by -X- _ O
TransE(Bordes -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2013 -X- _ O
) -X- _ O
. -X- _ O

We -X- _ O
limit -X- _ O
the -X- _ O
path -X- _ B-HyperparameterName
length -X- _ I-HyperparameterName
and -X- _ O
the -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
paths -X- _ I-HyperparameterName
both -X- _ O
to -X- _ O
10 -X- _ B-HyperparameterValue
. -X- _ O

4.2 -X- _ O
Implementation -X- _ O
Details -X- _ O
We -X- _ O
use -X- _ O
Concept -X- _ O
Graph -X- _ O
( -X- _ O
Cheng -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2015 -X- _ O
; -X- _ O
Wu -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2012 -X- _ O
) -X- _ O
as -X- _ O
the -X- _ O
external -X- _ O
knowledge -X- _ O
graph -X- _ O
, -X- _ O
as -X- _ O
it -X- _ O
has -X- _ O
the -X- _ O
largest -X- _ O
coverage -X- _ O
on -X- _ O
datasets -X- _ O
we -X- _ O
used -X- _ O
in -X- _ O
this -X- _ O
paper -X- _ O
. -X- _ O

Though -X- _ O
much -X- _ O
simpler -X- _ O
and -X- _ O
smaller -X- _ O
than -X- _ O
the -X- _ O
SNLI -X- _ B-DatasetName
dataset -X- _ O
, -X- _ O
the -X- _ O
performance -X- _ O
on -X- _ O
BNLI -X- _ B-DatasetName
is -X- _ O
substantially -X- _ O
worse -X- _ O
across -X- _ O
models -X- _ O
trained -X- _ O
on -X- _ O
SNLI -X- _ B-DatasetName
( -X- _ O
Glockner -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O

In -X- _ O
BNLI -X- _ B-DatasetName
, -X- _ O
the -X- _ O
premises -X- _ O
are -X- _ O
taken -X- _ O
from -X- _ O
the -X- _ O
SNLI -X- _ B-DatasetName
training -X- _ O
set -X- _ O
, -X- _ O
and -X- _ O
hypotheses -X- _ O
are -X- _ O
generated -X- _ O
by -X- _ O
replacing -X- _ O
a -X- _ O
single -X- _ O
word -X- _ O
within -X- _ O
the -X- _ O
premise -X- _ O
by -X- _ O
a -X- _ O
different -X- _ O
word -X- _ O
. -X- _ O

• -X- _ O
BNLI -X- _ B-DatasetName
is -X- _ O
a -X- _ O
dataset -X- _ O
constructed -X- _ O
based -X- _ O
on -X- _ O
SNLI -X- _ B-DatasetName
( -X- _ O
Glockner -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O

SciTail -X- _ B-DatasetName
is -X- _ O
a -X- _ O
difficult -X- _ O
benchmark -X- _ O
for -X- _ O
NLI -X- _ B-TaskName
( -X- _ O
Tay -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O

It -X- _ O
contains -X- _ O
24k -X- _ O
sentence -X- _ O
pairs -X- _ O
and -X- _ O
only -X- _ O
classifies -X- _ O
sentences -X- _ O
into -X- _ O
two -X- _ O
relationships -X- _ O
: -X- _ O
entailment -X- _ O
and -X- _ O
neutral -X- _ O
. -X- _ O

• -X- _ O
SciTail -X- _ B-DatasetName
is -X- _ O
a -X- _ O
small -X- _ O
- -X- _ O
scale -X- _ O
dataset -X- _ O
constructed -X- _ O
from -X- _ O
multiple -X- _ O
- -X- _ O
choice -X- _ O
science -X- _ O
exams -X- _ O
and -X- _ O
web -X- _ O
sentences -X- _ O
( -X- _ O
Khot -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O

In -X- _ O
MultiNLI -X- _ B-DatasetName
, -X- _ O
the -X- _ O
development -X- _ O
/ -X- _ O
test -X- _ O
sets -X- _ O
whose -X- _ O
genres -X- _ O
appear -X- _ O
in -X- _ O
training -X- _ O
set -X- _ O
are -X- _ O
referred -X- _ O
to -X- _ O
as -X- _ O
“ -X- _ O
matched -X- _ O
” -X- _ O
dataset -X- _ O
, -X- _ O
and -X- _ O
“ -X- _ O
mismatched -X- _ O
” -X- _ O
otherwise -X- _ O
. -X- _ O

• -X- _ O
MultiNLI -X- _ B-DatasetName
Multi -X- _ B-DatasetName
- -X- _ I-DatasetName
Genre -X- _ I-DatasetName
Natural -X- _ I-DatasetName
Language -X- _ I-DatasetName
Inference -X- _ I-DatasetName
( -X- _ O
Williams -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
is -X- _ O
also -X- _ O
a -X- _ O
large -X- _ O
- -X- _ O
scale -X- _ O
corpus -X- _ O
containing -X- _ O
433k -X- _ O
sentence -X- _ O
pairs -X- _ O
. -X- _ O

It -X- _ O
is -X- _ O
the -X- _ O
largest -X- _ O
corpus -X- _ O
for -X- _ O
NLI -X- _ B-TaskName
tasks -X- _ O
, -X- _ O
with -X- _ O
more -X- _ O
than -X- _ O
570k -X- _ O
human -X- _ O
annotated -X- _ O
sentence -X- _ O
pairs -X- _ O
. -X- _ O

SNLI -X- _ B-DatasetName
Stanford -X- _ B-DatasetName
Natural -X- _ I-DatasetName
Language -X- _ I-DatasetName
Inference -X- _ I-DatasetName
( -X- _ O
Bowman -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
is -X- _ O
extracted -X- _ O
from -X- _ O
Flickr30k -X- _ O
corpus -X- _ O
. -X- _ O

4 -X- _ O
Experiments -X- _ O
4.1 -X- _ O
Datasets -X- _ O
We -X- _ O
use -X- _ O
four -X- _ O
widely -X- _ O
adopted -X- _ O
standard -X- _ O
benchmarks -X- _ O
: -X- _ O
SNLI -X- _ B-DatasetName
, -X- _ O
MultiNLI -X- _ B-DatasetName
, -X- _ O
SciTail -X- _ B-DatasetName
, -X- _ O
and -X- _ O
BNLI -X- _ B-DatasetName
. -X- _ O

y -X- _ O
= -X- _ O

The -X- _ O
perceptron -X- _ O
classifier -X- _ O
predict -X- _ O
a -X- _ O
label -X- _ O
y -X- _ O
to -X- _ O
be -X- _ O
entailment -X- _ O
, -X- _ O
contradiction -X- _ O
, -X- _ O
or -X- _ O
neutral -X- _ O
, -X- _ O
i -X- _ O
h -X- _ O

The -X- _ O
label -X- _ O
prediction -X- _ O
layer -X- _ O
is -X- _ O
designed -X- _ O
to -X- _ O
determine -X- _ O
the -X- _ O
overall -X- _ O
logical -X- _ O
relationship -X- _ O
between -X- _ O
two -X- _ O
sentences -X- _ O
. -X- _ O

3.3 -X- _ O
Label -X- _ O
Prediction -X- _ O

The -X- _ O
semantic -X- _ O
relationship -X- _ O
v -X- _ O
s -X- _ O
between -X- _ O
p -X- _ O
and -X- _ O
h -X- _ O
is -X- _ O
, -X- _ O
where -X- _ O
Gs -X- _ O
is -X- _ O
a -X- _ O
feed -X- _ O
- -X- _ O
forward -X- _ O
neural -X- _ O
network -X- _ O
with -X- _ O
ReLU -X- _ O
as -X- _ O
the -X- _ O
activation -X- _ O
function -X- _ O
. -X- _ O

The -X- _ O
resulting -X- _ O
vectors -X- _ O
av -X- _ O
and -X- _ O
bv -X- _ O
are -X- _ O
fed -X- _ O
into -X- _ O
the -X- _ O
pooling -X- _ O
layer -X- _ O
which -X- _ O
computes -X- _ O
both -X- _ O
average -X- _ O
and -X- _ O
max -X- _ O
pooling -X- _ O
for -X- _ O
premise -X- _ O
and -X- _ O
hypothesis -X- _ O
, -X- _ O
m -X- _ O
X -X- _ O
av -X- _ O
, -X- _ O
amax -X- _ O
= -X- _ O
max -X- _ O
avi -X- _ O
, -X- _ O
( -X- _ O
21 -X- _ O
) -X- _ O
, -X- _ O
bmax -X- _ O
= -X- _ O
max -X- _ O
bvj -X- _ O
. -X- _ O

The -X- _ O
composed -X- _ O
vectors -X- _ O
avi -X- _ O
, -X- _ O
bvj -X- _ O
for -X- _ O
premise -X- _ O
and -X- _ O
hypothesis -X- _ O
are -X- _ O
computed -X- _ O
by -X- _ O
BiLSTM -X- _ B-MethodName
, -X- _ O
avi -X- _ O
= -X- _ O
BiLSTM(am -X- _ O
i -X- _ O
) -X- _ O
, -X- _ O
i -X- _ O
= -X- _ O
1 -X- _ O
, -X- _ O
. -X- _ O
. -X- _ O
. -X- _ O

3.2.3 -X- _ O
Semantic -X- _ O
Composition -X- _ O
A -X- _ O
composition -X- _ O
layer -X- _ O
is -X- _ O
employed -X- _ O
to -X- _ O
learn -X- _ O
the -X- _ O
types -X- _ O
of -X- _ O
local -X- _ O
inference -X- _ O
relationship -X- _ O
at -X- _ O
sentence -X- _ O
- -X- _ O
level -X- _ O
. -X- _ O

We -X- _ O
set -X- _ O
it -X- _ O
as -X- _ O
a -X- _ O
one -X- _ O
- -X- _ O
layer -X- _ O
feed -X- _ O
- -X- _ O
forward -X- _ O
neural -X- _ O
network -X- _ O
with -X- _ O
ReLU -X- _ O
as -X- _ O
the -X- _ O
activation -X- _ O
function -X- _ O
. -X- _ O

Local -X- _ O
inference -X- _ O
information -X- _ O
is -X- _ O
then -X- _ O
enhanced -X- _ O
by -X- _ O
computing -X- _ O
difference -X- _ O
and -X- _ O
element -X- _ O
- -X- _ O
wise -X- _ O
product -X- _ O
for -X- _ O
( -X- _ O
as -X- _ O
, -X- _ O
ac -X- _ O
) -X- _ O
and -X- _ O
( -X- _ O
bs -X- _ O
, -X- _ O
bc -X- _ O
) -X- _ O
, -X- _ O
am -X- _ O
= -X- _ O
G([as -X- _ O
; -X- _ O

ik -X- _ O
k=1 -X- _ O

Pn -X- _ O
bsj -X- _ O
, -X- _ O
exp -X- _ O
( -X- _ O
E -X- _ O
) -X- _ O

The -X- _ O
context -X- _ O
vector -X- _ O
bc -X- _ O
that -X- _ O
encoded -X- _ O
relevant -X- _ O
semantics -X- _ O
in -X- _ O
premise -X- _ O
can -X- _ O
be -X- _ O
calculated -X- _ O
in -X- _ O
the -X- _ O
same -X- _ O
way -X- _ O
, -X- _ O
aci -X- _ O
= -X- _ O
bcj -X- _ O
= -X- _ O
n -X- _ O
X -X- _ O
j=1 -X- _ O
m -X- _ O
X -X- _ O
i=1 -X- _ O
exp -X- _ O
( -X- _ O
Eij -X- _ O
) -X- _ O

For -X- _ O
premise -X- _ O
, -X- _ O
the -X- _ O
relevant -X- _ O
semantics -X- _ O
in -X- _ O
hypothesis -X- _ O
is -X- _ O
encoded -X- _ O
into -X- _ O
a -X- _ O
context -X- _ O
vector -X- _ O
ac -X- _ O
based -X- _ O
on -X- _ O
co -X- _ O
- -X- _ O
attention -X- _ O
matrix -X- _ O
E -X- _ O
and -X- _ O
hypothesis -X- _ O
semantic -X- _ O
embedding -X- _ O
b. -X- _ O

Next -X- _ O
, -X- _ O
we -X- _ O
compute -X- _ O
the -X- _ O
local -X- _ O
relevance -X- _ O
information -X- _ O
according -X- _ O
to -X- _ O
the -X- _ O
co -X- _ O
- -X- _ O
attention -X- _ O
E. -X- _ O

For -X- _ O
premise -X- _ O
embedding -X- _ O
asi -X- _ O
and -X- _ O
hypothesis -X- _ O
embedding -X- _ O
bsj -X- _ O
, -X- _ O
their -X- _ O
similarity -X- _ O
is -X- _ O
Eij -X- _ O
= -X- _ O
( -X- _ O
asi -X- _ O
) -X- _ O
T -X- _ O
bsj -X- _ O
, -X- _ O
( -X- _ O
14 -X- _ O
) -X- _ O
all -X- _ O
those -X- _ O
Eij -X- _ O
form -X- _ O
the -X- _ O
co -X- _ O
- -X- _ O
attention -X- _ O
matrix -X- _ O
E -X- _ O
∈ -X- _ O
Rm×n -X- _ O
. -X- _ O

First -X- _ O
, -X- _ O
a -X- _ O
soft -X- _ O
alignment -X- _ O
layer -X- _ O
is -X- _ O
employed -X- _ O
to -X- _ O
compute -X- _ O
the -X- _ O
similarity -X- _ O
between -X- _ O
words -X- _ O
. -X- _ O

No -X- _ O
external -X- _ O
knowledge -X- _ O
is -X- _ O
concerned -X- _ O
in -X- _ O
this -X- _ O
part -X- _ O
. -X- _ O

3.2.2 -X- _ O
Local -X- _ O
Inference -X- _ O
The -X- _ O
computing -X- _ O
of -X- _ O
local -X- _ O
inference -X- _ O
information -X- _ O
between -X- _ O
two -X- _ O
sentences -X- _ O
is -X- _ O
based -X- _ O
on -X- _ O
their -X- _ O
semantic -X- _ O
embeddings -X- _ O
as -X- _ O
and -X- _ O
bs -X- _ O
. -X- _ O


k -X- _ B-HyperparameterName
is -X- _ O
the -X- _ O
embedding -X- _ B-HyperparameterName
dimension -X- _ I-HyperparameterName
, -X- _ O
i -X- _ O
and -X- _ O
j -X- _ O
index -X- _ O
the -X- _ O
position -X- _ O
of -X- _ O
words -X- _ O
in -X- _ O
sentences -X- _ O
, -X- _ O
s -X- _ O
indicates -X- _ O
that -X- _ O
the -X- _ O
embeddings -X- _ O
are -X- _ O
learned -X- _ O
based -X- _ O
on -X- _ O
semantic -X- _ O
. -X- _ O

Denote -X- _ O
as -X- _ O
and -X- _ O
bs -X- _ O
as -X- _ O
embedding -X- _ O
vectors -X- _ O
of -X- _ O
both -X- _ O
premise -X- _ O
and -X- _ O
hypothesis -X- _ O
, -X- _ O
as -X- _ O
= -X- _ O
[ -X- _ O
as1 -X- _ O
, -X- _ O
as2 -X- _ O
, -X- _ O
. -X- _ O
. -X- _ O
. -X- _ O

Semantic -X- _ O
Embedding -X- _ O
We -X- _ O
first -X- _ O
initialize -X- _ O
words -X- _ O
into -X- _ O
embeddings -X- _ O
based -X- _ O
on -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
word -X- _ O
vectors -X- _ O
GloVe -X- _ O
( -X- _ O
Pennington -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
, -X- _ O
then -X- _ O
encode -X- _ O
premise -X- _ O
and -X- _ O
hypothesis -X- _ O
using -X- _ O
bidirectional -X- _ B-MethodName
LSTM -X- _ I-MethodName
( -X- _ O
BiLSTM -X- _ B-MethodName
) -X- _ O
. -X- _ O

, -X- _ O
hn -X- _ O
] -X- _ O
, -X- _ O
where -X- _ O
pi -X- _ O
and -X- _ O
hj -X- _ O
are -X- _ O
words -X- _ O
, -X- _ O
1 -X- _ O
≤ -X- _ O
i -X- _ O
≤ -X- _ O
m -X- _ O
, -X- _ O
1 -X- _ O
≤ -X- _ O
j -X- _ O
≤ -X- _ O
n -X- _ O
, -X- _ O
m -X- _ O
and -X- _ O
n -X- _ O
are -X- _ O
the -X- _ O
lengths -X- _ O
of -X- _ O
premise -X- _ O
p -X- _ O
and -X- _ O
hypothesis -X- _ O
h. -X- _ O
3.2.1 -X- _ O

In -X- _ O
the -X- _ O
following -X- _ O
, -X- _ O
we -X- _ O
denote -X- _ O
sentences -X- _ O
p -X- _ O
and -X- _ O
h -X- _ O
as -X- _ O
p -X- _ O
= -X- _ O

3.2 -X- _ O
Semantic -X- _ O
- -X- _ O
Relation -X- _ O
Representation -X- _ O
To -X- _ O
capture -X- _ O
the -X- _ O
semantic -X- _ O
relationship -X- _ O
between -X- _ O
premise -X- _ O
p -X- _ O
and -X- _ O
hypothesis -X- _ O
h -X- _ O
, -X- _ O
we -X- _ O
follow -X- _ O
the -X- _ O
widely -X- _ O
adopted -X- _ O
framework -X- _ O
to -X- _ O
get -X- _ O
the -X- _ O
relationship -X- _ O
representations -X- _ O
( -X- _ O
Chen -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O

Apart -X- _ O
from -X- _ O
relation -X- _ O
representations -X- _ O
ωSp -X- _ O
, -X- _ O
ωPp -X- _ O
and -X- _ O
ωO -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
consider -X- _ O
the -X- _ O
correlation -X- _ O
among -X- _ O
them -X- _ O
by -X- _ O
using -X- _ O
element -X- _ O
- -X- _ O
wise -X- _ O
product -X- _ O
, -X- _ O
p -X- _ O
; -X- _ O
ωSp -X- _ O
v -X- _ O
k -X- _ O
= -X- _ O
Gk -X- _ O
( -X- _ O
[ -X- _ O
ωSp -X- _ O
; -X- _ O
ωPp -X- _ O
; -X- _ O
ωO -X- _ O
p -X- _ O
ωPp -X- _ O
; -X- _ O
ωO -X- _ O
ωPp -X- _ O
] -X- _ O
) -X- _ O
( -X- _ O
11 -X- _ O
) -X- _ O
where -X- _ O
v -X- _ O
k -X- _ O
is -X- _ O
the -X- _ O
composed -X- _ O
representation -X- _ O
, -X- _ O
and -X- _ O
Gk -X- _ O
is -X- _ O
a -X- _ O
feed -X- _ O
- -X- _ O
forward -X- _ O
neural -X- _ O
network -X- _ O
with -X- _ O
ReLU -X- _ O
as -X- _ O
the -X- _ O
activation -X- _ O
function -X- _ O
. -X- _ O

We -X- _ O
where -X- _ O
ωSp -X- _ O
, -X- _ O
ωPp -X- _ O
and -X- _ O
ωO -X- _ O
set -X- _ O
entity -X- _ O
embeddings -X- _ O
as -X- _ O
the -X- _ O
updated -X- _ O
embeddings -X- _ O
and -X- _ O
relation -X- _ O
embeddings -X- _ O
according -X- _ O
to -X- _ O
TransE. -X- _ O
3.1.4 -X- _ O
Knowledge -X- _ O
Composition -X- _ O
We -X- _ O
use -X- _ O
a -X- _ O
composition -X- _ O
layer -X- _ O
to -X- _ O
merge -X- _ O
the -X- _ O
relationship -X- _ O
of -X- _ O
subject -X- _ O
pair -X- _ O
, -X- _ O
predicate -X- _ O
pair -X- _ O
, -X- _ O
and -X- _ O
object -X- _ O
pair -X- _ O
. -X- _ O

Relations -X- _ O
are -X- _ O
represented -X- _ O
by -X- _ O
the -X- _ O
average -X- _ O
of -X- _ O
the -X- _ O
representations -X- _ O
of -X- _ O
all -X- _ O
paths -X- _ O
N -X- _ O
ωSp -X- _ O
= -X- _ O

We -X- _ O
encode -X- _ O
the -X- _ O
path -X- _ O
sequence -X- _ O
with -X- _ O
BiLSTM -X- _ B-MethodName
. -X- _ O

The -X- _ O
paths -X- _ O
liP -X- _ O
and -X- _ O
liO -X- _ O
of -X- _ O
predicate -X- _ O
and -X- _ O
object -X- _ O
pair -X- _ O
are -X- _ O
defined -X- _ O
in -X- _ O
the -X- _ O
same -X- _ O
way -X- _ O
. -X- _ O

[ -X- _ O
pS -X- _ O
, -X- _ O
r1 -X- _ O
, -X- _ O
e1 -X- _ O
, -X- _ O
r2 -X- _ O
, -X- _ O
e2 -X- _ O
, -X- _ O
. -X- _ O
. -X- _ O
. -X- _ O

Denote -X- _ O
the -X- _ O
i -X- _ O
- -X- _ O
th -X- _ O
path -X- _ O
between -X- _ O
subject -X- _ O
pair -X- _ O
( -X- _ O
pS -X- _ O
, -X- _ O
hS -X- _ O
) -X- _ O
as -X- _ O
liS -X- _ O
= -X- _ O

We -X- _ O
get -X- _ O
the -X- _ O
relationship -X- _ O
representation -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
representation -X- _ O
of -X- _ O
paths -X- _ O
in -X- _ O
the -X- _ O
corresponding -X- _ O
subgraph -X- _ O
. -X- _ O

where -X- _ O
ake -X- _ O
and -X- _ O
akr -X- _ O
are -X- _ O
the -X- _ O
embeddings -X- _ O
of -X- _ O
entity -X- _ O
e -X- _ O
and -X- _ O
relation -X- _ O
r -X- _ O
initialized -X- _ O
by -X- _ O
TransE. -X- _ O
For -X- _ O
hypothesis -X- _ O
, -X- _ O
the -X- _ O
attention -X- _ O
score -X- _ O
is -X- _ O
calculated -X- _ O
in -X- _ O
the -X- _ O
same -X- _ O
way -X- _ O
, -X- _ O
exp -X- _ O
( -X- _ O
W -X- _ O
[ -X- _ O
bke -X- _ O
, -X- _ O
bkr -X- _ O
] -X- _ O
) -X- _ O
. -X- _ O

ϕp -X- _ O
( -X- _ O
e -X- _ O
, -X- _ O
r -X- _ O
) -X- _ O
= -X- _ O

For -X- _ O
premise -X- _ O
, -X- _ O
ϕp -X- _ O
( -X- _ O
e -X- _ O
, -X- _ O
r -X- _ O
) -X- _ O
is -X- _ O
computed -X- _ O
as -X- _ O
exp -X- _ O
( -X- _ O
W -X- _ O
[ -X- _ O
ake -X- _ O
, -X- _ O
akr -X- _ O
] -X- _ O
) -X- _ O
, -X- _ O
k -X- _ O
k -X- _ O
( -X- _ O
e -X- _ O
, -X- _ O
r)∈Sp -X- _ O
exp -X- _ O
( -X- _ O
W -X- _ O
[ -X- _ O
ae -X- _ O
, -X- _ O
ar -X- _ O
] -X- _ O
) -X- _ O

[ -X- _ O
bke -X- _ O
; -X- _ O
bkr -X- _ O
] -X- _ O
) -X- _ O
, -X- _ O
( -X- _ O
4 -X- _ O
) -X- _ O
( -X- _ O
e -X- _ O
, -X- _ O
r)∈Shj -X- _ O
where -X- _ O
aki -X- _ O
and -X- _ O
bkj -X- _ O
are -X- _ O
the -X- _ O
propagated -X- _ O
entity -X- _ O
embedding -X- _ O
, -X- _ O
γ -X- _ O
is -X- _ O
a -X- _ O
tradeoff -X- _ O
parameter -X- _ O
, -X- _ O
and -X- _ O
Spi -X- _ O
represents -X- _ O
the -X- _ O
set -X- _ O
of -X- _ O
all -X- _ O
( -X- _ O
e -X- _ O
, -X- _ O
r -X- _ O
) -X- _ O
pairs -X- _ O
of -X- _ O
pi -X- _ O
, -X- _ O
where -X- _ O
e -X- _ O
is -X- _ O
a -X- _ O
neighobor -X- _ O
of -X- _ O
pi -X- _ O
, -X- _ O
and -X- _ O
r -X- _ O
is -X- _ O
the -X- _ O
relation -X- _ O
between -X- _ O
pi -X- _ O
and -X- _ O
e. -X- _ O
σ -X- _ O
( -X- _ O
· -X- _ O
) -X- _ O
is -X- _ O
the -X- _ O
activation -X- _ O
function -X- _ O
, -X- _ O
W -X- _ O
is -X- _ O
a -X- _ O
transformation -X- _ O
matrix -X- _ O
, -X- _ O
[ -X- _ O
· -X- _ O
; -X- _ O
· -X- _ O
] -X- _ O
denotes -X- _ O
the -X- _ O
concatenation -X- _ O
operator -X- _ O
, -X- _ O
and -X- _ O
ϕp -X- _ O
( -X- _ O
e -X- _ O
, -X- _ O
r -X- _ O
) -X- _ O
is -X- _ O
an -X- _ O
attention -X- _ O
score -X- _ O
over -X- _ O
( -X- _ O
e -X- _ O
, -X- _ O
r -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
calculated -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
embedding -X- _ O
of -X- _ O
the -X- _ O
entity -X- _ O
and -X- _ O
its -X- _ O
neighbors -X- _ O
. -X- _ O

[ -X- _ O
ake -X- _ O
; -X- _ O
akr -X- _ O
] -X- _ O
) -X- _ O
, -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
( -X- _ O
e -X- _ O
, -X- _ O
r)∈Spi -X- _ O
bkj -X- _ O
← -X- _ O
γbkj -X- _ O
+ -X- _ O
( -X- _ O
1 -X- _ O
− -X- _ O
γ -X- _ O
) -X- _ O
X -X- _ O
ϕh -X- _ O
( -X- _ O
e -X- _ O
, -X- _ O
r)σ(W -X- _ O

For -X- _ O
an -X- _ O
entity -X- _ O
, -X- _ O
we -X- _ O
retrieve -X- _ O
all -X- _ O
the -X- _ O
neighboring -X- _ O
relations -X- _ O
of -X- _ O
it -X- _ O
in -X- _ O
the -X- _ O
sub -X- _ O
- -X- _ O
graph -X- _ O
, -X- _ O
and -X- _ O
encode -X- _ O
the -X- _ O
neighboring -X- _ O
knowledge -X- _ O
into -X- _ O
its -X- _ O
embedding -X- _ O
through -X- _ O
the -X- _ O
following -X- _ O
propagation -X- _ O
rule -X- _ O
, -X- _ O
X -X- _ O
aki -X- _ O
← -X- _ O
γaki -X- _ O
+ -X- _ O
( -X- _ O
1 -X- _ O
− -X- _ O
γ -X- _ O
) -X- _ O
ϕp -X- _ O
( -X- _ O
e -X- _ O
, -X- _ O
r)σ(W -X- _ O

( -X- _ O
2 -X- _ O
) -X- _ O
We -X- _ O
then -X- _ O
update -X- _ O
these -X- _ O
embeddings -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
sub -X- _ O
- -X- _ O
graphs -X- _ O
using -X- _ O
graph -X- _ O
neural -X- _ O
network -X- _ O
. -X- _ O

We -X- _ O
initialize -X- _ O
entity -X- _ O
embeddings -X- _ O
based -X- _ O
on -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
vectors -X- _ O
that -X- _ O
are -X- _ O
generated -X- _ O
by -X- _ O
TransE -X- _ O
( -X- _ O
Bordes -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2013 -X- _ O
) -X- _ O
, -X- _ O
aki -X- _ O
= -X- _ O
TransE(pi -X- _ O
) -X- _ O
, -X- _ O
i -X- _ O
∈ -X- _ O
{ -X- _ O
S -X- _ O
, -X- _ O
P -X- _ O
, -X- _ O
O -X- _ O
} -X- _ O
, -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
bkj -X- _ O
= -X- _ O
TransE(hj -X- _ O
) -X- _ O
, -X- _ O
j -X- _ O
∈ -X- _ O
{ -X- _ O
S -X- _ O
, -X- _ O
P -X- _ O
, -X- _ O
O -X- _ O
} -X- _ O
. -X- _ O

, -X- _ O
k -X- _ O
indicates -X- _ O
that -X- _ O
the -X- _ O
embeddings -X- _ O
are -X- _ O
learned -X- _ O
based -X- _ O
on -X- _ O
knowledge -X- _ O
graphs -X- _ O
. -X- _ O

 -X- _ O
k -X- _ O
ink -X- _ O
sub -X- _ O
- -X- _ O
graphs -X- _ O
 -X- _ O
k -X- _ O
k -X- _ O
kfor -X- _ O
entities -X- _ O
k -X- _ O
embedded -X- _ O
vectors -X- _ O
of -X- _ O
p -X- _ O
and -X- _ O
h -X- _ O
as -X- _ O
aS -X- _ O
, -X- _ O
aP -X- _ O
, -X- _ O
aO -X- _ O
and -X- _ O
bS -X- _ O
, -X- _ O
bP -X- _ O
, -X- _ O
bO -X- _ O
, -X- _ O
where -X- _ O
S -X- _ O
, -X- _ O
P -X- _ O
and -X- _ O
O -X- _ O
are -X- _ O
indices -X- _ O
of -X- _ O
subject -X- _ O
, -X- _ O
predicate -X- _ O
, -X- _ O
and -X- _ O
object -X- _ O
as -X- _ O
above -X- _ O

Denote -X- _ O
the -X- _ O
knowledge -X- _ O

First -X- _ O
, -X- _ O
the -X- _ O
knowledge -X- _ O
- -X- _ O
based -X- _ O
embeddings -X- _ O
are -X- _ O
learned -X- _ O
. -X- _ O

3.1.2 -X- _ O
Knowledge -X- _ O
Embedding -X- _ O
With -X- _ O
the -X- _ O
help -X- _ O
of -X- _ O
sub -X- _ O
- -X- _ O
graphs -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
learn -X- _ O
the -X- _ O
knowledge -X- _ O
- -X- _ O
based -X- _ O
relationship -X- _ O
of -X- _ O
sentence -X- _ O
pairs -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
extract -X- _ O
subjects -X- _ O
, -X- _ O
predicates -X- _ O
, -X- _ O
and -X- _ O
objects -X- _ O
of -X- _ O
sentences -X- _ O
based -X- _ O
on -X- _ O
their -X- _ O
syntax -X- _ O
tree -X- _ O
, -X- _ O
consider -X- _ O
paths -X- _ O
with -X- _ O
length -X- _ O
up -X- _ O
to -X- _ O
L -X- _ O
and -X- _ O
limit -X- _ O
the -X- _ O
total -X- _ O
number -X- _ O
of -X- _ O
paths -X- _ O
of -X- _ O
each -X- _ O
sub -X- _ O
- -X- _ O
graph -X- _ O
as -X- _ O
N -X- _ O
. -X- _ O

The -X- _ O
lengths -X- _ O
of -X- _ O
the -X- _ O
first -X- _ O
two -X- _ O
paths -X- _ O
are -X- _ O
5 -X- _ O
, -X- _ O
while -X- _ O
it -X- _ O
is -X- _ O
7 -X- _ O
of -X- _ O
the -X- _ O
last -X- _ O
one -X- _ O
. -X- _ O

sub -X- _ O
- -X- _ O
graph -X- _ O
of -X- _ O
the -X- _ O
object -X- _ O
pair -X- _ O
( -X- _ O
piano -X- _ O
, -X- _ O
music -X- _ O
) -X- _ O
, -X- _ O
“ -X- _ O
piano -X- _ O
- -X- _ O
has -X- _ O
subevent -X- _ O
- -X- _ O
playing -X- _ O
piano -X- _ O
- -X- _ O
causes -X- _ O
- -X- _ O
music -X- _ O
” -X- _ O
, -X- _ O
“ -X- _ O
pianois -X- _ O
a -X- _ O
- -X- _ O
instrument -X- _ O
- -X- _ O
used -X- _ O
for -X- _ O
- -X- _ O
music -X- _ O
” -X- _ O
, -X- _ O
and -X- _ O
“ -X- _ O
piano -X- _ O
- -X- _ O
related -X- _ O
to -X- _ O
- -X- _ O
orchestra -X- _ O
- -X- _ O
related -X- _ O
to -X- _ O
- -X- _ O
classical -X- _ O
- -X- _ O
is -X- _ O
a -X- _ O
- -X- _ O
music -X- _ O
” -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
way -X- _ O
, -X- _ O
we -X- _ O
encode -X- _ O
the -X- _ O
knowledge -X- _ O
into -X- _ O
pooled -X- _ O
embeddings -X- _ O
. -X- _ O

For -X- _ O
entities -X- _ O
“ -X- _ O
piano -X- _ O
” -X- _ O
and -X- _ O
“ -X- _ O
music -X- _ O
” -X- _ O
, -X- _ O
we -X- _ O
first -X- _ O
find -X- _ O
the -X- _ O
paths -X- _ O
between -X- _ O
them -X- _ O
in -X- _ O
the -X- _ O
knowledge -X- _ O
graph -X- _ O
, -X- _ O
and -X- _ O
update -X- _ O
their -X- _ O
embeddings -X- _ O
using -X- _ O
graph -X- _ O
neural -X- _ O
networks -X- _ O
. -X- _ O

Fig -X- _ O
. -X- _ O
3 -X- _ O
shows -X- _ O
three -X- _ O
paths -X- _ O
in -X- _ O
the -X- _ O
6500 -X- _ O

The -X- _ O
sub -X- _ O
- -X- _ O
graphs -X- _ O
for -X- _ O
predicate -X- _ O
pair -X- _ O
( -X- _ O
pP -X- _ O
, -X- _ O
hP -X- _ O
) -X- _ O
and -X- _ O
object -X- _ O
pair -X- _ O
( -X- _ O
pO -X- _ O
, -X- _ O
hO -X- _ O
) -X- _ O
are -X- _ O
constructed -X- _ O
in -X- _ O
the -X- _ O
same -X- _ O
way -X- _ O
. -X- _ O

For -X- _ O
each -X- _ O
sentence -X- _ O
pair -X- _ O
, -X- _ O
the -X- _ O
sub -X- _ O
- -X- _ O
graph -X- _ O
of -X- _ O
background -X- _ O
relationship -X- _ O
for -X- _ O
subject -X- _ O
pair -X- _ O
( -X- _ O
pS -X- _ O
, -X- _ O
hS -X- _ O
) -X- _ O
is -X- _ O
extracted -X- _ O
by -X- _ O
finding -X- _ O
paths -X- _ O
between -X- _ O
entities -X- _ O
that -X- _ O
denote -X- _ O
ps -X- _ O
and -X- _ O
hs -X- _ O
in -X- _ O
the -X- _ O
predetermined -X- _ O
knowledge -X- _ O
graph -X- _ O
KG -X- _ O
with -X- _ O
the -X- _ O
help -X- _ O
of -X- _ O
random -X- _ O
walking -X- _ O
. -X- _ O

The -X- _ O
architecture -X- _ O
of -X- _ O
this -X- _ O
module -X- _ O
is -X- _ O
shown -X- _ O
in -X- _ O
Fig -X- _ O
. -X- _ O
3 -X- _ O
. -X- _ O
3.1.1 -X- _ O
Sub -X- _ O
- -X- _ O
graph -X- _ O
of -X- _ O
background -X- _ O
relationship -X- _ O
In -X- _ O
the -X- _ O
following -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
denote -X- _ O
the -X- _ O
subject -X- _ O
pair -X- _ O
, -X- _ O
predicate -X- _ O
pair -X- _ O
, -X- _ O
and -X- _ O
object -X- _ O
pair -X- _ O
of -X- _ O
p -X- _ O
and -X- _ O
h -X- _ O
as -X- _ O
( -X- _ O
pS -X- _ O
, -X- _ O
hS -X- _ O
) -X- _ O
, -X- _ O
( -X- _ O
pP -X- _ O
, -X- _ O
hP -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
( -X- _ O
pO -X- _ O
, -X- _ O
hO -X- _ O
) -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
assume -X- _ O
that -X- _ O
the -X- _ O
relationship -X- _ O
between -X- _ O
sentences -X- _ O
is -X- _ O
determined -X- _ O
by -X- _ O
the -X- _ O
relationship -X- _ O
of -X- _ O
their -X- _ O
subjects -X- _ O
, -X- _ O
predicates -X- _ O
, -X- _ O
and -X- _ O
objects -X- _ O
. -X- _ O

3.1 -X- _ O
Knowledge -X- _ O
- -X- _ O
Relation -X- _ O
Representation -X- _ O
To -X- _ O
build -X- _ O
the -X- _ O
relationship -X- _ O
between -X- _ O
p -X- _ O
and -X- _ O
h -X- _ O
based -X- _ O
on -X- _ O
background -X- _ O
knowledge -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
novel -X- _ O
knowledge -X- _ O
- -X- _ O
relation -X- _ O
representation -X- _ O
module -X- _ O
. -X- _ O

It -X- _ O
contains -X- _ O
three -X- _ O
major -X- _ O
components -X- _ O
: -X- _ O
knowledge -X- _ O
- -X- _ O
relation -X- _ O
representation -X- _ O
module -X- _ O
, -X- _ O
semantic -X- _ O
- -X- _ O
relation -X- _ O
representation -X- _ O
module -X- _ O
, -X- _ O
and -X- _ O
label -X- _ O
prediction -X- _ O
module -X- _ O
. -X- _ O

Figure -X- _ O
2 -X- _ O
: -X- _ O
The -X- _ O
overall -X- _ O
architecture -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
. -X- _ O

Finally -X- _ O
, -X- _ O
a -X- _ O
multilayer -X- _ O
perceptron -X- _ O
merges -X- _ O
both -X- _ O
knowledge -X- _ O
and -X- _ O
semantic -X- _ O
relationships -X- _ O
and -X- _ O
predicts -X- _ O
the -X- _ O
label -X- _ O
. -X- _ O

The -X- _ O
novel -X- _ O
knowledgerelation -X- _ O
representation -X- _ O
module -X- _ O
builds -X- _ O
the -X- _ O
relationship -X- _ O
between -X- _ O
p -X- _ O
and -X- _ O
h -X- _ O
based -X- _ O
on -X- _ O
background -X- _ O
knowledge -X- _ O
, -X- _ O
while -X- _ O
the -X- _ O
semantic -X- _ O
- -X- _ O
relation -X- _ O
representation -X- _ O
module -X- _ O
captures -X- _ O
sentence -X- _ O
semantic -X- _ O
relationship -X- _ O
. -X- _ O

The -X- _ O
proposed -X- _ O
model -X- _ O
consists -X- _ O
of -X- _ O
three -X- _ O
major -X- _ O
components -X- _ O
, -X- _ O
as -X- _ O
showed -X- _ O
in -X- _ O
Fig -X- _ O
. -X- _ O
2 -X- _ O
. -X- _ O

The -X- _ O
set -X- _ O
of -X- _ O
labels -X- _ O
includes -X- _ O
entailment -X- _ O
( -X- _ O
h -X- _ O
can -X- _ O
be -X- _ O
logically -X- _ O
deduced -X- _ O
from -X- _ O
p -X- _ O
) -X- _ O
, -X- _ O
neutral -X- _ O
( -X- _ O
p -X- _ O
and -X- _ O
h -X- _ O
do -X- _ O
not -X- _ O
have -X- _ O
any -X- _ O
logical -X- _ O
relationship -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
contradiction -X- _ O
( -X- _ O
p -X- _ O
and -X- _ O
h -X- _ O
can -X- _ O
not -X- _ O
be -X- _ O
true -X- _ O
simultaneously -X- _ O
) -X- _ O
. -X- _ O

Given -X- _ O
a -X- _ O
pair -X- _ O
of -X- _ O
sentences -X- _ O
, -X- _ O
premise -X- _ O
p -X- _ O
and -X- _ O
hypothesis -X- _ O
h -X- _ O
, -X- _ O
the -X- _ O
goal -X- _ O
of -X- _ O
NLI -X- _ B-TaskName
is -X- _ O
to -X- _ O
predict -X- _ O
a -X- _ O
label -X- _ O
y -X- _ O
that -X- _ O
indicates -X- _ O
the -X- _ O
logical -X- _ O
relationship -X- _ O
between -X- _ O
sentences -X- _ O
p -X- _ O
and -X- _ O
h. -X- _ O

3 -X- _ O
Methodology -X- _ O

In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
knowledge -X- _ O
graph -X- _ O
is -X- _ O
employed -X- _ O
to -X- _ O
provide -X- _ O
external -X- _ O
background -X- _ O
knowledge -X- _ O
. -X- _ O

There -X- _ O
are -X- _ O
many -X- _ O
open -X- _ O
source -X- _ O
knowledge -X- _ O
graphs -X- _ O
which -X- _ O
can -X- _ O
be -X- _ O
easily -X- _ O
employed -X- _ O
in -X- _ O
a -X- _ O
variety -X- _ O
of -X- _ O
applications -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
WordNet -X- _ O
( -X- _ O
Miller -X- _ O
, -X- _ O
1995 -X- _ O
) -X- _ O
, -X- _ O
Freebase -X- _ O
( -X- _ O
Bollacker -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2008 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
Concept -X- _ O
Graph -X- _ O
( -X- _ O
Cheng -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2015 -X- _ O
; -X- _ O
Wu -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2012 -X- _ O
) -X- _ O
. -X- _ O

Knowledge -X- _ O
is -X- _ O
formatted -X- _ O
as -X- _ O
triples -X- _ O
in -X- _ O
knowledge -X- _ O
graph -X- _ O
, -X- _ O
a -X- _ O
triple -X- _ O
( -X- _ O
h -X- _ O
, -X- _ O
r -X- _ O
, -X- _ O
t -X- _ O
) -X- _ O
indicates -X- _ O
that -X- _ O
head -X- _ O
entity -X- _ O
h -X- _ O
and -X- _ O
tail -X- _ O
entity -X- _ O
t -X- _ O
have -X- _ O
relation -X- _ O
r. -X- _ O

2.3 -X- _ O
Knowledge -X- _ O
Graph -X- _ O
A -X- _ O
knowledge -X- _ O
graph -X- _ O
is -X- _ O
a -X- _ O
large -X- _ O
knowledge -X- _ O
base -X- _ O
storing -X- _ O
relational -X- _ O
knowledge -X- _ O
in -X- _ O
a -X- _ O
graph -X- _ O
structure -X- _ O
. -X- _ O

However -X- _ O
, -X- _ O
it -X- _ O
can -X- _ O
only -X- _ O
deal -X- _ O
with -X- _ O
a -X- _ O
fixed -X- _ O
number -X- _ O
of -X- _ O
types -X- _ O
of -X- _ O
knowledge -X- _ O
, -X- _ O
and -X- _ O
pre -X- _ O
- -X- _ O
assigned -X- _ O
scores -X- _ O
for -X- _ O
relationships -X- _ O
are -X- _ O
needed -X- _ O
before -X- _ O
training -X- _ O
, -X- _ O
which -X- _ O
limits -X- _ O
its -X- _ O
applications -X- _ O
in -X- _ O
practice -X- _ O
. -X- _ O

This -X- _ O
model -X- _ O
incooperates -X- _ O
basic -X- _ O
knowledge -X- _ O
about -X- _ O
synonymy -X- _ O
, -X- _ O
antonymy -X- _ O
, -X- _ O
hypernymy -X- _ O
, -X- _ O
hyponymy -X- _ O
, -X- _ O
and -X- _ O
co -X- _ O
- -X- _ O
hyponyms -X- _ O
to -X- _ O
help -X- _ O
model -X- _ O
soft -X- _ O
- -X- _ O
alignments -X- _ O
between -X- _ O
sentence -X- _ O
pairs -X- _ O
. -X- _ O

To -X- _ O
the -X- _ O
best -X- _ O
of -X- _ O
our -X- _ O
knowledge -X- _ O
, -X- _ O
the -X- _ O
only -X- _ O
neural -X- _ O
model -X- _ O
adopting -X- _ O
external -X- _ O
knowledge -X- _ O
is -X- _ O
KIM -X- _ B-MethodName
( -X- _ O
Chen -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O

Although -X- _ O
these -X- _ O
models -X- _ O
have -X- _ O
achieved -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
results -X- _ O
in -X- _ O
NLI -X- _ O
related -X- _ O
tasks -X- _ O
, -X- _ O
they -X- _ O
only -X- _ O
rely -X- _ O
on -X- _ O
semantic -X- _ O
relationship -X- _ O
learned -X- _ O
from -X- _ O
training -X- _ O
corpus -X- _ O
, -X- _ O
in -X- _ O
other -X- _ O
words -X- _ O
, -X- _ O
no -X- _ O
external -X- _ O
knowledge -X- _ O
is -X- _ O
utilized -X- _ O
explicitly -X- _ O
to -X- _ O
facilitate -X- _ O
inference -X- _ O
. -X- _ O

For -X- _ O
instances -X- _ O
, -X- _ O
ESIM -X- _ B-MethodName
( -X- _ O
Chen -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
considers -X- _ O
recursive -X- _ O
architectures -X- _ O
in -X- _ O
both -X- _ O
local -X- _ O
inference -X- _ O
modeling -X- _ O
and -X- _ O
inference -X- _ O
composition -X- _ O
, -X- _ O
CAFE -X- _ B-MethodName
( -X- _ O
Tay -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
architecture -X- _ O
propagates -X- _ O
compressed -X- _ O
alignment -X- _ O
features -X- _ O
to -X- _ O
upper -X- _ O
layers -X- _ O
to -X- _ O
enhance -X- _ O
representation -X- _ O
learning -X- _ O
, -X- _ O
DMAN -X- _ B-MethodName
( -X- _ O
Pan -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
adopts -X- _ O
reinforcement -X- _ O
learning -X- _ O
with -X- _ O
discourse -X- _ O
markers -X- _ O
to -X- _ O
help -X- _ O
improve -X- _ O
the -X- _ O
performance -X- _ O
. -X- _ O

Various -X- _ O
architectures -X- _ O
have -X- _ O
been -X- _ O
proposed -X- _ O
to -X- _ O
capture -X- _ O
the -X- _ O
interaction -X- _ O
and -X- _ O
soft -X- _ O
alignment -X- _ O
between -X- _ O
sentences -X- _ O
. -X- _ O

( -X- _ O
Williams -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
has -X- _ O
stimulated -X- _ O
research -X- _ O
and -X- _ O
development -X- _ O
of -X- _ O
new -X- _ O
models -X- _ O
based -X- _ O
on -X- _ O
deep -X- _ O
neural -X- _ O
network -X- _ O
. -X- _ O

The -X- _ O
emergence -X- _ O
of -X- _ O
large -X- _ O
- -X- _ O
scale -X- _ O
datasets -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
SNLI -X- _ B-DatasetName
( -X- _ O
Bowman -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
and -X- _ O
MultiNLI -X- _ B-DatasetName

2 -X- _ O
Related -X- _ O
Work -X- _ O
2.1 -X- _ O
Natural -X- _ B-TaskName
Language -X- _ I-TaskName
Inference -X- _ I-TaskName
Traditional -X- _ O
NLI -X- _ B-TaskName
models -X- _ O
are -X- _ O
trained -X- _ O
on -X- _ O
small -X- _ O
- -X- _ O
scale -X- _ O
datasets -X- _ O
, -X- _ O
like -X- _ O
natural -X- _ O
logic -X- _ O
- -X- _ O
based -X- _ O
and -X- _ O
co -X- _ O
- -X- _ O
occurrence -X- _ O
statistics -X- _ O
- -X- _ O
based -X- _ O
models -X- _ O
, -X- _ O
the -X- _ O
former -X- _ O
identifies -X- _ O
inferences -X- _ O
by -X- _ O
lexical -X- _ O
and -X- _ O
syntactic -X- _ O
features -X- _ O
( -X- _ O
MacCartney -X- _ O
and -X- _ O
Manning -X- _ O
, -X- _ O
2008 -X- _ O
) -X- _ O
, -X- _ O
while -X- _ O
the -X- _ O
latter -X- _ O
considers -X- _ O
the -X- _ O
statistical -X- _ O
features -X- _ O
( -X- _ O
Glickman -X- _ O
and -X- _ O
Dagan -X- _ O
, -X- _ O
2005 -X- _ O
) -X- _ O
. -X- _ O

We -X- _ O
further -X- _ O
conduct -X- _ O
ablation -X- _ O
tests -X- _ O
to -X- _ O
validate -X- _ O
the -X- _ O
effectiveness -X- _ O
and -X- _ O
necessity -X- _ O
of -X- _ O
each -X- _ O
component -X- _ O
in -X- _ O
the -X- _ O
proposed -X- _ O
model -X- _ O
. -X- _ O

On -X- _ O
dataset -X- _ O
SciTail -X- _ B-DatasetName
and -X- _ O
BNLI -X- _ B-DatasetName
, -X- _ O
where -X- _ O
knowledge -X- _ O
is -X- _ O
crucial -X- _ O
for -X- _ O
inference -X- _ O
( -X- _ O
Glockner -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
our -X- _ O
model -X- _ O
achieves -X- _ O
large -X- _ O
improvements -X- _ O
against -X- _ O
baselines -X- _ O
. -X- _ O

Our -X- _ O
model -X- _ O
gets -X- _ O
competitive -X- _ O
results -X- _ O
on -X- _ O
all -X- _ O
the -X- _ O
four -X- _ O
datasets -X- _ O
. -X- _ O

In -X- _ O
order -X- _ O
to -X- _ O
evaluate -X- _ O
our -X- _ O
model -X- _ O
, -X- _ O
we -X- _ O
conduct -X- _ O
experiments -X- _ O
on -X- _ O
four -X- _ O
datasets -X- _ O
: -X- _ O
SNLI -X- _ B-DatasetName
, -X- _ O
MultiNLI -X- _ B-DatasetName
, -X- _ O
SciTail -X- _ B-DatasetName
, -X- _ O
and -X- _ O
BNLI -X- _ B-DatasetName
. -X- _ O

Finally -X- _ O
, -X- _ O
KGNLI -X- _ B-MethodName
combines -X- _ O
these -X- _ O
two -X- _ O
representations -X- _ O
and -X- _ O
feed -X- _ O
it -X- _ O
into -X- _ O
a -X- _ O
multilayer -X- _ O
perceptron -X- _ O
to -X- _ O
determine -X- _ O
the -X- _ O
label -X- _ O
of -X- _ O
the -X- _ O
relationship -X- _ O
. -X- _ O

Besides -X- _ O
it -X- _ O
, -X- _ O
KGNLI -X- _ B-MethodName
also -X- _ O
learns -X- _ O
a -X- _ O
semantic -X- _ O
- -X- _ O
relation -X- _ O
representation -X- _ O
between -X- _ O
the -X- _ O
given -X- _ O
sentences -X- _ O
by -X- _ O
Bi -X- _ B-MethodName
- -X- _ I-MethodName
directional -X- _ I-MethodName
Long -X- _ I-MethodName
Short -X- _ I-MethodName
- -X- _ I-MethodName
Term -X- _ I-MethodName
Memory -X- _ I-MethodName
( -X- _ O
BiLSTM -X- _ B-MethodName
) -X- _ O
network -X- _ O
. -X- _ O

the -X- _ O
given -X- _ O
sentence -X- _ O
pair -X- _ O
, -X- _ O
then -X- _ O
learns -X- _ O
a -X- _ O
knowledge -X- _ O
- -X- _ O
relation -X- _ O
representation -X- _ O
based -X- _ O
on -X- _ O
a -X- _ O
predetermined -X- _ O
knowledge -X- _ O
graph -X- _ O
which -X- _ O
contains -X- _ O
these -X- _ O
entities -X- _ O
as -X- _ O
nodes -X- _ O
. -X- _ O

For -X- _ O
the -X- _ O
sentence -X- _ O
pair -X- _ O
in -X- _ O
the -X- _ O
figure -X- _ O
, -X- _ O
their -X- _ O
relationship -X- _ O
largely -X- _ O
depends -X- _ O
on -X- _ O
the -X- _ O
relationship -X- _ O
of -X- _ O
entities -X- _ O
“ -X- _ O
piano -X- _ O
” -X- _ O
and -X- _ O
“ -X- _ O
music -X- _ O
” -X- _ O
, -X- _ O
which -X- _ O
can -X- _ O
be -X- _ O
learned -X- _ O
from -X- _ O
the -X- _ O
paths -X- _ O
in -X- _ O
the -X- _ O
knowledge -X- _ O
graph -X- _ O
. -X- _ O

Knowledge -X- _ O
graphs -X- _ O
can -X- _ O
provide -X- _ O
background -X- _ O
knowledge -X- _ O
for -X- _ O
the -X- _ O
NLI -X- _ B-TaskName
problem -X- _ O
. -X- _ O

To -X- _ O
be -X- _ O
more -X- _ O
specific -X- _ O
, -X- _ O
KGNLI -X- _ B-MethodName
first -X- _ O
extracts -X- _ O
entities -X- _ O
such -X- _ O
as -X- _ O
subjects -X- _ O
, -X- _ O
predicates -X- _ O
, -X- _ O
and -X- _ O
objects -X- _ O
from -X- _ O
This -X- _ O
work -X- _ O
is -X- _ O
licensed -X- _ O
under -X- _ O
a -X- _ O
Creative -X- _ O
Commons -X- _ O
Attribution -X- _ O
4.0 -X- _ O
International -X- _ O
License -X- _ O
. -X- _ O

KGNLI -X- _ B-MethodName
enhances -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
NLI -X- _ B-TaskName
by -X- _ O
introducing -X- _ O
background -X- _ O
knowledge -X- _ O
stored -X- _ O
in -X- _ O
knowledge -X- _ O
graphs -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
Knowledge -X- _ B-MethodName
Graph -X- _ I-MethodName
enhanced -X- _ I-MethodName
Natural -X- _ I-MethodName
Language -X- _ I-MethodName
Inference -X- _ I-MethodName
( -X- _ O
KGNLI -X- _ B-MethodName
) -X- _ O
model -X- _ O
. -X- _ O

How -X- _ O
to -X- _ O
flexibly -X- _ O
incorporate -X- _ O
a -X- _ O
variety -X- _ O
of -X- _ O
different -X- _ O
background -X- _ O
knowledge -X- _ O
in -X- _ O
NLI -X- _ B-TaskName
is -X- _ O
still -X- _ O
a -X- _ O
challenging -X- _ O
task -X- _ O
. -X- _ O

Previous -X- _ O
work -X- _ O
( -X- _ O
Chen -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
shows -X- _ O
that -X- _ O
NLI -X- _ B-TaskName
models -X- _ O
can -X- _ O
benefit -X- _ O
from -X- _ O
leveraging -X- _ O
external -X- _ O
knowledge -X- _ O
. -X- _ O

The -X- _ O
right -X- _ O
part -X- _ O
of -X- _ O
Fig -X- _ O
. -X- _ O
1 -X- _ O
is -X- _ O
a -X- _ O
part -X- _ O
of -X- _ O
a -X- _ O
large -X- _ O
knowledge -X- _ O
graph -X- _ O
, -X- _ O
in -X- _ O
which -X- _ O
paths -X- _ O
between -X- _ O
“ -X- _ O
piano -X- _ O
” -X- _ O
and -X- _ O
“ -X- _ O
music -X- _ O
” -X- _ O
represent -X- _ O
background -X- _ O
knowledge -X- _ O
that -X- _ O
can -X- _ O
be -X- _ O
utilized -X- _ O
to -X- _ O
determine -X- _ O
the -X- _ O
relationship -X- _ O
of -X- _ O
the -X- _ O
sentence -X- _ O
pair -X- _ O
. -X- _ O

However -X- _ O
, -X- _ O
the -X- _ O
latter -X- _ O
is -X- _ O
not -X- _ O
explicitly -X- _ O
expressed -X- _ O
in -X- _ O
the -X- _ O
sentences -X- _ O
per -X- _ O
se -X- _ O
. -X- _ O

For -X- _ O
the -X- _ O
sentences -X- _ O
located -X- _ O
in -X- _ O
the -X- _ O
left -X- _ O
part -X- _ O
of -X- _ O
Fig -X- _ O
. -X- _ O
1 -X- _ O
, -X- _ O
the -X- _ O
logical -X- _ O
relationship -X- _ O
between -X- _ O
the -X- _ O
Premise -X- _ O
and -X- _ O
the -X- _ O
Hypothsis -X- _ O
largely -X- _ O
depends -X- _ O
on -X- _ O
the -X- _ O
relationship -X- _ O
between -X- _ O
“ -X- _ O
piano -X- _ O
” -X- _ O
and -X- _ O
“ -X- _ O
music -X- _ O
” -X- _ O
. -X- _ O

Background -X- _ O
knowledge -X- _ O
can -X- _ O
be -X- _ O
utilized -X- _ O
to -X- _ O
facilitate -X- _ O
inference -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
Fig -X- _ O
. -X- _ O
1 -X- _ O
. -X- _ O

However -X- _ O
, -X- _ O
only -X- _ O
semantic -X- _ O
knowledge -X- _ O
between -X- _ O
premises -X- _ O
and -X- _ O
hypotheses -X- _ O
are -X- _ O
utilized -X- _ O
in -X- _ O
most -X- _ O
of -X- _ O
these -X- _ O
models -X- _ O
. -X- _ O

The -X- _ O
resulting -X- _ O
alignments -X- _ O
and -X- _ O
semantic -X- _ O
representations -X- _ O
of -X- _ O
sentences -X- _ O
are -X- _ O
aggregated -X- _ O
and -X- _ O
fed -X- _ O
into -X- _ O
a -X- _ O
multilayer -X- _ O
feed -X- _ O
- -X- _ O
forward -X- _ O
neural -X- _ O
network -X- _ O
to -X- _ O
judge -X- _ O
logical -X- _ O
relationships -X- _ O
. -X- _ O

They -X- _ O
learn -X- _ O
alignments -X- _ O
according -X- _ O
to -X- _ O
the -X- _ O
attention -X- _ O
between -X- _ O
premises -X- _ O
and -X- _ O
hypotheses -X- _ O
. -X- _ O

Most -X- _ O
of -X- _ O
the -X- _ O
existing -X- _ O
NLI -X- _ B-TaskName
models -X- _ O
are -X- _ O
based -X- _ O
on -X- _ O
cross -X- _ O
sentence -X- _ O
attention -X- _ O
( -X- _ O
Chen -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O

These -X- _ O
datasets -X- _ O
enable -X- _ O
various -X- _ O
deep -X- _ O
learning -X- _ O
models -X- _ O
to -X- _ O
achieve -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
performances -X- _ O
( -X- _ O
Chen -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2017 -X- _ O
; -X- _ O
Chen -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Pan -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Ghaeini -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O

Recent -X- _ O
years -X- _ O
have -X- _ O
witnessed -X- _ O
a -X- _ O
large -X- _ O
improvement -X- _ O
in -X- _ O
NLI -X- _ B-TaskName
models -X- _ O
because -X- _ O
of -X- _ O
the -X- _ O
release -X- _ O
of -X- _ O
several -X- _ O
large -X- _ O
- -X- _ O
scale -X- _ O
corpora -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
SNLI -X- _ B-DatasetName
( -X- _ O
Bowman -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
and -X- _ O
MultiNLI -X- _ B-DatasetName

NLI -X- _ B-TaskName
requires -X- _ O
reasoning -X- _ O
and -X- _ O
inference -X- _ O
abilities -X- _ O
which -X- _ O
are -X- _ O
crucial -X- _ O
for -X- _ O
artificial -X- _ O
intelligence -X- _ O
system -X- _ O
. -X- _ O

NLI -X- _ B-TaskName
aims -X- _ O
to -X- _ O
determine -X- _ O
whether -X- _ O
the -X- _ O
logical -X- _ O
relationship -X- _ O
between -X- _ O
a -X- _ O
premise -X- _ O
p -X- _ O
and -X- _ O
a -X- _ O
hypothesis -X- _ O
h -X- _ O
is -X- _ O
entailment -X- _ O
, -X- _ O
neutral -X- _ O
, -X- _ O
or -X- _ O
contradiction -X- _ O
. -X- _ O

1 -X- _ O
Introduction -X- _ O
Natural -X- _ B-TaskName
Language -X- _ I-TaskName
Inference -X- _ I-TaskName
( -X- _ O
NLI -X- _ B-TaskName
) -X- _ O
is -X- _ O
a -X- _ O
fundamental -X- _ O
yet -X- _ O
challenging -X- _ O
task -X- _ O
for -X- _ O
natural -X- _ B-TaskName
language -X- _ I-TaskName
understanding -X- _ I-TaskName
. -X- _ O

Experiments -X- _ O
on -X- _ O
four -X- _ O
benchmarks -X- _ O
, -X- _ O
SNLI -X- _ B-DatasetName
, -X- _ O
MultiNLI -X- _ B-DatasetName
, -X- _ O
SciTail -X- _ B-DatasetName
, -X- _ O
and -X- _ O
BNLI -X- _ B-DatasetName
, -X- _ O
validate -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
our -X- _ O
model -X- _ O
. -X- _ O

Different -X- _ O
from -X- _ O
previous -X- _ O
methods -X- _ O
, -X- _ O
various -X- _ O
kinds -X- _ O
of -X- _ O
background -X- _ O
knowledge -X- _ O
can -X- _ O
be -X- _ O
flexibly -X- _ O
combined -X- _ O
in -X- _ O
the -X- _ O
proposed -X- _ O
KGNLI -X- _ B-MethodName
model -X- _ O
. -X- _ O

KGNLI -X- _ B-MethodName
model -X- _ O
consists -X- _ O
of -X- _ O
three -X- _ O
components -X- _ O
: -X- _ O
a -X- _ O
semantic -X- _ O
- -X- _ O
relation -X- _ O
representation -X- _ O
module -X- _ O
, -X- _ O
a -X- _ O
knowledge -X- _ O
- -X- _ O
relation -X- _ O
representation -X- _ O
module -X- _ O
, -X- _ O
and -X- _ O
a -X- _ O
label -X- _ O
prediction -X- _ O
module -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
novel -X- _ O
Knowledge -X- _ B-MethodName
Graph -X- _ I-MethodName
- -X- _ I-MethodName
enhanced -X- _ I-MethodName
NLI -X- _ I-MethodName
( -X- _ O
KGNLI -X- _ B-MethodName
) -X- _ O
model -X- _ O
to -X- _ O
leverage -X- _ O
the -X- _ O
usage -X- _ O
of -X- _ O
background -X- _ O
knowledge -X- _ O
stored -X- _ O
in -X- _ O
knowledge -X- _ O
graphs -X- _ O
in -X- _ O
the -X- _ O
field -X- _ O
of -X- _ O
NLI -X- _ B-TaskName
. -X- _ O

The -X- _ O
adoption -X- _ O
of -X- _ O
background -X- _ O
knowledge -X- _ O
is -X- _ O
rarely -X- _ O
seen -X- _ O
or -X- _ O
limited -X- _ O
to -X- _ O
a -X- _ O
few -X- _ O
specific -X- _ O
types -X- _ O
. -X- _ O

Most -X- _ O
of -X- _ O
the -X- _ O
existing -X- _ O
approaches -X- _ O
make -X- _ O
such -X- _ O
inference -X- _ O
based -X- _ O
on -X- _ O
semantic -X- _ O
knowledge -X- _ O
obtained -X- _ O
through -X- _ O
training -X- _ O
corpus -X- _ O
. -X- _ O

It -X- _ O
aims -X- _ O
to -X- _ O
identify -X- _ O
the -X- _ O
logical -X- _ O
relationship -X- _ O
between -X- _ O
two -X- _ O
sentences -X- _ O
. -X- _ O

Knowledge -X- _ O
Graphs -X- _ O

Knowledge -X- _ O
- -X- _ O
Enhanced -X- _ O
Natural -X- _ B-TaskName
Language -X- _ I-TaskName
Inference -X- _ I-TaskName
Based -X- _ O
on -X- _ O

