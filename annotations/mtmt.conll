-DOCSTART- -X- O
γ -X- _ B-HyperparameterName
indicates -X- _ O
consistency -X- _ O
level -X- _ O
between -X- _ O
the -X- _ O
outputs -X- _ O
from -X- _ O
two -X- _ O
teacher -X- _ O
models -X- _ O
, -X- _ O
e.g. -X- _ O
for -X- _ O
two -X- _ O
input -X- _ O
tokens -X- _ O
, -X- _ O
if -X- _ O
the -X- _ O
output -X- _ O
from -X- _ O
entity -X- _ O
similarity -X- _ O
teacher -X- _ O
is -X- _ O
high -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
similarity -X- _ O
level -X- _ O
computed -X- _ O
from -X- _ O
the -X- _ O
outputs -X- _ O
of -X- _ O
the -X- _ O
entity -X- _ O
recognizer -X- _ O
teacher -X- _ O
is -X- _ O
low -X- _ O
, -X- _ O
then -X- _ O
their -X- _ O
consistency -X- _ O
level -X- _ O
is -X- _ O
low -X- _ O
. -X- _ O

And -X- _ O
β -X- _ B-HyperparameterName
is -X- _ O
set -X- _ O
such -X- _ O
that -X- _ O
it -X- _ O
is -X- _ O
high -X- _ O
when -X- _ O
the -X- _ O
output -X- _ O
of -X- _ O
the -X- _ O
entity -X- _ O
similarity -X- _ O
teacher -X- _ O
is -X- _ O
close -X- _ O
to -X- _ O
0 -X- _ O
or -X- _ O
1 -X- _ O
, -X- _ O
and -X- _ O
it -X- _ O
is -X- _ O
low -X- _ O
when -X- _ O
the -X- _ O
output -X- _ O
is -X- _ O
close -X- _ O
to -X- _ O
0.5 -X- _ O
. -X- _ O

The -X- _ O
weights -X- _ O
are -X- _ O
set -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O
α1 -X- _ B-HyperparameterName
( -X- _ O
α2 -X- _ B-HyperparameterName
) -X- _ O
is -X- _ O
an -X- _ O
increasing -X- _ O
function -X- _ O
concerning -X- _ O
the -X- _ O
output -X- _ O
of -X- _ O
the -X- _ O
entity -X- _ O
recognizer -X- _ O
teacher -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
4 -X- _ O
. -X- _ O

T -X- _ O
−sim -X- _ O
( -X- _ O
xT -X- _ O
, -X- _ O
x0 -X- _ O
T -X- _ O
, -X- _ O
i -X- _ O
, -X- _ O
j)∈Dtrain -X- _ O
4.1 -X- _ O
+ -X- _ O
α2 -X- _ B-HyperparameterName
LER -X- _ O
( -X- _ O
x0 -X- _ O
T -X- _ O
, -X- _ O
yS0 -X- _ O
, -X- _ O
j -X- _ O
) -X- _ O
+ -X- _ O
βLBCE -X- _ O
( -X- _ O
t̂T -X- _ O
( -X- _ O
xT -X- _ O
, -X- _ O
x0 -X- _ O
T -X- _ O
, -X- _ O
i -X- _ O
, -X- _ O
j -X- _ O
) -X- _ O
, -X- _ O
t̂S -X- _ O
) -X- _ O
) -X- _ O
where -X- _ O
α1 -X- _ B-HyperparameterName
, -X- _ O
α2 -X- _ B-HyperparameterName
, -X- _ O
β -X- _ B-HyperparameterName
, -X- _ O
and -X- _ O
γ -X- _ B-HyperparameterName
are -X- _ O
weights -X- _ O
in -X- _ O
loss -X- _ O
function -X- _ O
which -X- _ O
are -X- _ O
set -X- _ O
to -X- _ O
make -X- _ O
the -X- _ O
student -X- _ O
model -X- _ O
learns -X- _ O
less -X- _ O
noisy -X- _ O
knowledge -X- _ O
from -X- _ O
teachers -X- _ O
. -X- _ O

− -X- _ O
t̂T -X- _ O
( -X- _ O
xT -X- _ O
, -X- _ O
x0 -X- _ O
T -X- _ O
, -X- _ O
i -X- _ O
, -X- _ O
j)| -X- _ O
4 -X- _ O
Experiment -X- _ O
In -X- _ O
this -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
evaluate -X- _ O
our -X- _ O
multiple -X- _ B-MethodName
- -X- _ I-MethodName
task -X- _ I-MethodName
and -X- _ I-MethodName
multiple -X- _ I-MethodName
- -X- _ I-MethodName
teacher -X- _ I-MethodName
model -X- _ O
for -X- _ O
cross -X- _ B-TaskName
- -X- _ I-TaskName
lingual -X- _ I-TaskName
NER -X- _ I-TaskName
and -X- _ O
compare -X- _ O
our -X- _ O
model -X- _ O
with -X- _ O
a -X- _ O
series -X- _ O
of -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
models -X- _ O
. -X- _ O

, -X- _ O
yS -X- _ O
, -X- _ O
i -X- _ O
) -X- _ O
γ -X- _ O
= -X- _ O
1 -X- _ O
− -X- _ O
|σ(cos(ŷTi -X- _ O
, -X- _ O
ŷT0 -X- _ O
j -X- _ O
) -X- _ O
) -X- _ O

Summering -X- _ O
over -X- _ O
all -X- _ O
the -X- _ O
samples -X- _ O
T -X- _ O
−sim -X- _ O
in -X- _ O
Dtrain -X- _ O
= -X- _ O
{ -X- _ O
( -X- _ O
xT -X- _ O
, -X- _ O
x0 -X- _ O
T -X- _ O
, -X- _ O
i -X- _ O
, -X- _ O
j -X- _ O
) -X- _ O
} -X- _ O
, -X- _ O
the -X- _ O
total -X- _ O
student -X- _ O
model -X- _ O
training -X- _ O
loss -X- _ O
takes -X- _ O
form -X- _ O
, -X- _ O
X -X- _ O
L -X- _ O
= -X- _ O
γ -X- _ B-HyperparameterName
( -X- _ O
α1 -X- _ B-HyperparameterName
LER -X- _ O
( -X- _ O
xT -X- _ O

α -X- _ B-HyperparameterName
( -X- _ I-HyperparameterName
· -X- _ I-HyperparameterName
) -X- _ I-HyperparameterName
= -X- _ O
( -X- _ O
max(ŷTi -X- _ O
) -X- _ O
) -X- _ O
2 -X- _ O
β -X- _ B-HyperparameterName
= -X- _ O
( -X- _ O
2t̂T -X- _ O
( -X- _ O
xT -X- _ O
, -X- _ O
x0 -X- _ O
T -X- _ O
, -X- _ O
i -X- _ O
, -X- _ O
j -X- _ O
) -X- _ O
− -X- _ O

Dtrain -X- _ O
, -X- _ O
the -X- _ O
student -X- _ O
model -X- _ O
transform -X- _ O
them -X- _ O
as -X- _ O
follows -X- _ O
, -X- _ O
1.0 -X- _ O
1.0 -X- _ O
0.8 -X- _ O
0.8 -X- _ O
0.6 -X- _ O
0.6 -X- _ O
0.4 -X- _ O
0.4 -X- _ O
0.2 -X- _ O
0.2 -X- _ O
0.0 -X- _ O
0.0 -X- _ O
0.0 -X- _ O
0.2 -X- _ O
0.4 -X- _ O
0.6 -X- _ O
0.8 -X- _ O
1.0 -X- _ O
( -X- _ O
a -X- _ O
) -X- _ O
0.0 -X- _ O
0.2 -X- _ O
0.4 -X- _ O
0.6 -X- _ O
0.8 -X- _ O
1.0 -X- _ O
( -X- _ O
b -X- _ O
) -X- _ O
Figure -X- _ O
4 -X- _ O
: -X- _ O
Weights -X- _ O
of -X- _ O
loss -X- _ O
. -X- _ O

( -X- _ O
a -X- _ O
) -X- _ O
indicates -X- _ O
the -X- _ O
weight -X- _ O
α -X- _ B-HyperparameterName
( -X- _ I-HyperparameterName
· -X- _ I-HyperparameterName
) -X- _ I-HyperparameterName
of -X- _ O
LER -X- _ O
. -X- _ O

This -X- _ O
work -X- _ O
is -X- _ O
supported -X- _ O
partly -X- _ O
by -X- _ O
the -X- _ O
Fundamental -X- _ O
Research -X- _ O
Funds -X- _ O
for -X- _ O
the -X- _ O
Central -X- _ O
Universities -X- _ O
and -X- _ O
by -X- _ O
the -X- _ O
State -X- _ O
Key -X- _ O
Laboratory -X- _ O
of -X- _ O
Software -X- _ O
Development -X- _ O
Environment -X- _ O
. -X- _ O

Siamese -X- _ O
neural -X- _ O
networks -X- _ O
for -X- _ O
one -X- _ O
- -X- _ O
shot -X- _ O
image -X- _ O
recognition -X- _ O
. -X- _ O

177 -X- _ O

Our -X- _ O
experimental -X- _ O
results -X- _ O
show -X- _ O
that -X- _ O
the -X- _ O
proposed -X- _ O
model -X- _ O
yields -X- _ O
significant -X- _ O
improvements -X- _ O
on -X- _ O
six -X- _ O
target -X- _ O
language -X- _ O
datasets -X- _ O
and -X- _ O
outperforms -X- _ O
the -X- _ O
existing -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
approaches -X- _ O
. -X- _ O

Moreover -X- _ O
, -X- _ O
to -X- _ O
guarantee -X- _ O
the -X- _ O
student -X- _ O
learning -X- _ O
performance -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
propose -X- _ O
a -X- _ O
weighting -X- _ O
strategy -X- _ O
to -X- _ O
take -X- _ O
into -X- _ O
consideration -X- _ O
the -X- _ O
reliability -X- _ O
of -X- _ O
the -X- _ O
teachers -X- _ O
. -X- _ O

The -X- _ O
student -X- _ O
model -X- _ O
learns -X- _ O
two -X- _ O
source -X- _ O
language -X- _ O
patterns -X- _ O
of -X- _ O
entity -X- _ O
recognition -X- _ O
and -X- _ O
entity -X- _ O
similarity -X- _ O
evaluation -X- _ O
. -X- _ O

5 -X- _ O
Conclusion -X- _ O
In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
an -X- _ O
unsupervised -X- _ O
multipletask -X- _ B-MethodName
and -X- _ I-MethodName
multiple -X- _ I-MethodName
- -X- _ I-MethodName
teacher -X- _ I-MethodName
model -X- _ O
for -X- _ O
cross -X- _ B-TaskName
- -X- _ I-TaskName
lingual -X- _ I-TaskName
NER -X- _ I-TaskName
. -X- _ O

The -X- _ O
student -X- _ O
model -X- _ O
learns -X- _ O
less -X- _ O
from -X- _ O
unreasonable -X- _ O
results -X- _ O
, -X- _ O
and -X- _ O
it -X- _ O
can -X- _ O
make -X- _ O
more -X- _ O
accurate -X- _ O
entity -X- _ O
recognition -X- _ O
for -X- _ O
the -X- _ O
target -X- _ O
language -X- _ O
. -X- _ O

The -X- _ O
F1 -X- _ B-MetricName
- -X- _ I-MetricName
score -X- _ I-MetricName
and -X- _ O
similarity -X- _ O
score -X- _ O
of -X- _ O
teachers -X- _ O
are -X- _ O
all -X- _ O
higher -X- _ O
in -X- _ O
the -X- _ O
higher -X- _ O
γ -X- _ B-HyperparameterName
intervals -X- _ O
, -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
6c -X- _ O
. -X- _ O

For -X- _ O
γ -X- _ B-HyperparameterName
analysis -X- _ O
, -X- _ O
we -X- _ O
consider -X- _ O
the -X- _ O
consistency -X- _ O
of -X- _ O
recognition -X- _ O
results -X- _ O
and -X- _ O
similarity -X- _ O
score -X- _ O
by -X- _ O
teachers -X- _ O
. -X- _ O

The -X- _ O
encoder -X- _ O
of -X- _ O
the -X- _ O
student -X- _ O
model -X- _ O
obtains -X- _ O
the -X- _ O
clustering -X- _ O
information -X- _ O
of -X- _ O
the -X- _ O
target -X- _ O
language -X- _ O
with -X- _ O
the -X- _ O
help -X- _ O
of -X- _ O
β -X- _ B-HyperparameterName
. -X- _ O

For -X- _ O
β -X- _ B-HyperparameterName
analysis -X- _ O
, -X- _ O
we -X- _ O
observe -X- _ O
that -X- _ O
F1 -X- _ B-MetricName
- -X- _ I-MetricName
score -X- _ I-MetricName
are -X- _ O
increasing -X- _ O
with -X- _ O
the -X- _ O
entity -X- _ O
similarity -X- _ O
score -X- _ O
from -X- _ O
0.5 -X- _ O
to -X- _ O
both -X- _ O
sides -X- _ O
0 -X- _ O
and -X- _ O
1 -X- _ O
in -X- _ O
Figure -X- _ O
6b -X- _ O
. -X- _ O

Therefore -X- _ O
, -X- _ O
the -X- _ O
student -X- _ O
model -X- _ O
is -X- _ O
better -X- _ O
suited -X- _ O
to -X- _ O
the -X- _ O
target -X- _ O
language -X- _ O
with -X- _ O
learning -X- _ O
fewer -X- _ O
low -X- _ O
- -X- _ O
confidence -X- _ O
misrecognitions -X- _ O
for -X- _ O
the -X- _ O
target -X- _ O
language -X- _ O
. -X- _ O

For -X- _ O
α -X- _ B-HyperparameterName
analysis -X- _ O
, -X- _ O
we -X- _ O
calculate -X- _ O
the -X- _ O
F1 -X- _ B-MetricName
- -X- _ I-MetricName
score -X- _ I-MetricName
in -X- _ O
different -X- _ O
probability -X- _ O
intervals -X- _ O
of -X- _ O
entity -X- _ O
recognizer -X- _ O
teacher -X- _ O
, -X- _ O
we -X- _ O
find -X- _ O
that -X- _ O
the -X- _ O
recognizer -X- _ O
teacher -X- _ O
tends -X- _ O
to -X- _ O
predict -X- _ O
more -X- _ O
correct -X- _ O
in -X- _ O
higher -X- _ O
probability -X- _ O
interval -X- _ O
, -X- _ O
as -X- _ O
illustrated -X- _ O
in -X- _ O
Figure -X- _ O
6a -X- _ O
. -X- _ O

All -X- _ O
of -X- _ O
the -X- _ O
following -X- _ O
experiments -X- _ O
are -X- _ O
conducted -X- _ O
on -X- _ O
Spanish(es -X- _ O
) -X- _ O
data -X- _ O
. -X- _ O

4.7 -X- _ O
Effect -X- _ O
of -X- _ O
Weights -X- _ O
In -X- _ O
this -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
evaluate -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
weight -X- _ O
loss -X- _ O
in -X- _ O
student -X- _ O
learning -X- _ O
from -X- _ O
a -X- _ O
quantitative -X- _ O
perspective -X- _ O
. -X- _ O

This -X- _ O
validates -X- _ O
the -X- _ O
proposed -X- _ O
MTMT -X- _ B-MethodName
model -X- _ O
not -X- _ O
only -X- _ O
transfers -X- _ O
cross -X- _ O
- -X- _ O
lingual -X- _ O
NER -X- _ O
knowledge -X- _ O
from -X- _ O
source -X- _ O
language -X- _ O
, -X- _ O
but -X- _ O
also -X- _ O
learns -X- _ O
the -X- _ O
similarity -X- _ O
knowledge -X- _ O
of -X- _ O
target -X- _ O
language -X- _ O
data -X- _ O
. -X- _ O

We -X- _ O
conjecture -X- _ O
that -X- _ O
the -X- _ O
student -X- _ O
model -X- _ O
captures -X- _ O
similarity -X- _ O
knowledge -X- _ O
from -X- _ O
the -X- _ O
similarity -X- _ O
evaluator -X- _ O
teacher -X- _ O
, -X- _ O
i.e. -X- _ O
the -X- _ O
same -X- _ O
class -X- _ O
of -X- _ O
examples -X- _ O
tend -X- _ O
to -X- _ O
cluster -X- _ O
and -X- _ O
the -X- _ O
different -X- _ O
class -X- _ O
of -X- _ O
examples -X- _ O
tend -X- _ O
to -X- _ O
segregate -X- _ O
in -X- _ O
the -X- _ O
embedding -X- _ O
distribution -X- _ O
. -X- _ O

It -X- _ O
can -X- _ O
be -X- _ O
seen -X- _ O
that -X- _ O
the -X- _ O
embedding -X- _ O
distribution -X- _ O
of -X- _ O
the -X- _ O
student -X- _ O
model -X- _ O
is -X- _ O
close -X- _ O
to -X- _ O
similarity -X- _ O
evaluator -X- _ O
teacher -X- _ O
, -X- _ O
as -X- _ O
illustrated -X- _ O
in -X- _ O
Figure -X- _ O
5 -X- _ O
. -X- _ O

This -X- _ O
section -X- _ O
investigates -X- _ O
the -X- _ O
effect -X- _ O
of -X- _ O
embeddings -X- _ O
of -X- _ O
the -X- _ O
two -X- _ O
different -X- _ O
teacher -X- _ O
models -X- _ O
. -X- _ O

4.6 -X- _ O
Embedding -X- _ O
Distribution -X- _ O

Examples -X- _ O
# -X- _ O
2 -X- _ O
and -X- _ O
# -X- _ O
3 -X- _ O
present -X- _ O
the -X- _ O
same -X- _ O
results -X- _ O
with -X- _ O
different -X- _ O
sentences -X- _ O
. -X- _ O

The -X- _ O
student -X- _ O
learns -X- _ O
from -X- _ O
both -X- _ O
teachers -X- _ O
and -X- _ O
predict -X- _ O
the -X- _ O
correct -X- _ O
label -X- _ O
for -X- _ O
“ -X- _ O
Arévalo -X- _ O
” -X- _ O
. -X- _ O

The -X- _ O
reason -X- _ O
lies -X- _ O
in -X- _ O
that -X- _ O
the -X- _ O
entity -X- _ O
recognizer -X- _ O
teacher -X- _ O
predicts -X- _ O
“ -X- _ O
Viena”(‘Madrid -X- _ O
” -X- _ O
) -X- _ O
as -X- _ O
B -X- _ O
- -X- _ O
LOC -X- _ O
type -X- _ O
correctly -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
similarity -X- _ O
evaluator -X- _ O
teacher -X- _ O
predicts -X- _ O
“ -X- _ O
Viena”(“Madrid -X- _ O
” -X- _ O
) -X- _ O
to -X- _ O
have -X- _ O
a -X- _ O
high -X- _ O
similarity -X- _ O
score(0.7157 -X- _ O
, -X- _ O
0.7156 -X- _ O
) -X- _ O
with -X- _ O
“ -X- _ O
Arévalo -X- _ O
” -X- _ O
. -X- _ O

As -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
6 -X- _ O
, -X- _ O
in -X- _ O
example -X- _ O
# -X- _ O
1 -X- _ O
, -X- _ O
the -X- _ O
entity -X- _ O
recognizer -X- _ O
teacher -X- _ O
fails -X- _ O
to -X- _ O
identify -X- _ O
“ -X- _ O
Arévalo -X- _ O
” -X- _ O
as -X- _ O
B -X- _ O
- -X- _ O
ORG -X- _ O
type -X- _ O
, -X- _ O
while -X- _ O
the -X- _ O
student -X- _ O
model -X- _ O
can -X- _ O
correctly -X- _ O
predict -X- _ O
it -X- _ O
. -X- _ O

Specifically -X- _ O
, -X- _ O
if -X- _ O
there -X- _ O
is -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
tokens -X- _ O
in -X- _ O
which -X- _ O
every -X- _ O
two -X- _ O
of -X- _ O
them -X- _ O
have -X- _ O
a -X- _ O
high -X- _ O
Entity -X- _ O
Similarity -X- _ O
score -X- _ O
, -X- _ O
and -X- _ O
one -X- _ O
of -X- _ O
the -X- _ O
tokens -X- _ O
is -X- _ O
predicted -X- _ O
to -X- _ O
have -X- _ O
a -X- _ O
distinct -X- _ O
label -X- _ O
while -X- _ O
other -X- _ O
tokens -X- _ O
have -X- _ O
identical -X- _ O
labels -X- _ O
, -X- _ O
then -X- _ O
the -X- _ O
one -X- _ O
with -X- _ O
the -X- _ O
distinct -X- _ O
label -X- _ O
is -X- _ O
predicted -X- _ O
wrongly -X- _ O
and -X- _ O
is -X- _ O
corrected -X- _ O
by -X- _ O
the -X- _ O
student -X- _ O
model -X- _ O
to -X- _ O
have -X- _ O
the -X- _ O
label -X- _ O
of -X- _ O
all -X- _ O
other -X- _ O
tokens -X- _ O
. -X- _ O

The -X- _ O
proposed -X- _ O
MTMT -X- _ B-MethodName
model -X- _ O
can -X- _ O
help -X- _ O
to -X- _ O
correct -X- _ O
labels -X- _ O
using -X- _ O
the -X- _ O
Entity -X- _ O
Similarity -X- _ O
defined -X- _ O
in -X- _ O
section -X- _ O
3.2 -X- _ O
. -X- _ O

We -X- _ O
try -X- _ O
to -X- _ O
bring -X- _ O
up -X- _ O
insights -X- _ O
on -X- _ O
why -X- _ O
the -X- _ O
proposed -X- _ O
multiple -X- _ B-MethodName
- -X- _ I-MethodName
task -X- _ I-MethodName
and -X- _ I-MethodName
multiple -X- _ I-MethodName
- -X- _ I-MethodName
teacher -X- _ I-MethodName
model -X- _ O
works -X- _ O
. -X- _ O

4.5 -X- _ O
Case -X- _ O
Study -X- _ O
We -X- _ O
give -X- _ O
a -X- _ O
case -X- _ O
study -X- _ O
to -X- _ O
show -X- _ O
that -X- _ O
the -X- _ O
failed -X- _ O
cases -X- _ O
of -X- _ O
baseline -X- _ O
models -X- _ O
can -X- _ O
be -X- _ O
corrected -X- _ O
by -X- _ O
our -X- _ O
model -X- _ O
. -X- _ O

Without -X- _ O
the -X- _ O
similarity -X- _ O
knowledge -X- _ O
fed -X- _ O
into -X- _ O
the -X- _ O
student -X- _ O
model -X- _ O
, -X- _ O
the -X- _ O
performance -X- _ O
drops -X- _ O
significantly -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
case -X- _ O
, -X- _ O
our -X- _ O
approach -X- _ O
degrades -X- _ O
into -X- _ O
the -X- _ O
single -X- _ O
teacherstudent -X- _ O
learning -X- _ O
model -X- _ O
as -X- _ O
in -X- _ O
TSL -X- _ B-MethodName
( -X- _ O
Wu -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2020a -X- _ O
) -X- _ O
. -X- _ O

1.0 -X- _ O
w -X- _ O
F1 -X- _ O
0.8 -X- _ O
0.6 -X- _ O
0.6 -X- _ O
0.4 -X- _ O
0.4 -X- _ O
0.4 -X- _ O
0.2 -X- _ O
0.2 -X- _ O
0.0 -X- _ O
0.2 -X- _ O
0.4 -X- _ O
0.6 -X- _ O
0.8 -X- _ O
1.0 -X- _ O
0.0 -X- _ O
( -X- _ O
a -X- _ O
) -X- _ O
y -X- _ O
y -X- _ O
' -X- _ O
0.8 -X- _ O
0.6 -X- _ O
0.0 -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
MTMT -X- _ B-MethodName
w/o -X- _ I-MethodName
similarity -X- _ I-MethodName
, -X- _ O
which -X- _ O
removes -X- _ O
the -X- _ O
similarity -X- _ O
teacher -X- _ O
model -X- _ O
. -X- _ O

1.0 -X- _ B-MetricValue
for -X- _ O
Dutch(nl -X- _ O
) -X- _ O
to -X- _ O
0.98 -X- _ B-MetricValue
for -X- _ O
Spanish(es -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
validates -X- _ O
that -X- _ O
weighting -X- _ O
loss -X- _ O
can -X- _ O
bring -X- _ O
more -X- _ O
confident -X- _ O
knowledge -X- _ O
to -X- _ O
the -X- _ O
student -X- _ O
model -X- _ O
. -X- _ O

It -X- _ O
can -X- _ O
be -X- _ O
seen -X- _ O
that -X- _ O
the -X- _ O
performance -X- _ O
decrease -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
F1 -X- _ B-MetricName
- -X- _ I-MetricName
score -X- _ I-MetricName
ranges -X- _ O
from -X- _ O
0.45 -X- _ B-MetricValue

( -X- _ O
2 -X- _ O
) -X- _ O
MTMT -X- _ B-MethodName
w/o -X- _ I-MethodName
weighting -X- _ I-MethodName
, -X- _ O
which -X- _ O
set -X- _ O
the -X- _ O
α -X- _ B-HyperparameterName
( -X- _ I-HyperparameterName
· -X- _ I-HyperparameterName
) -X- _ I-HyperparameterName
, -X- _ O
β -X- _ B-HyperparameterName
and -X- _ O
γ -X- _ B-HyperparameterName
all -X- _ O
to -X- _ O
be -X- _ O
1 -X- _ B-HyperparameterValue
in -X- _ O
the -X- _ O
loss -X- _ O
of -X- _ O
student -X- _ O
learning -X- _ O
. -X- _ O

This -X- _ O
causes -X- _ O
a -X- _ O
performance -X- _ O
drop -X- _ O
across -X- _ O
all -X- _ O
languages -X- _ O
due -X- _ O
to -X- _ O
two -X- _ O
single -X- _ O
teachers -X- _ O
can -X- _ O
not -X- _ O
make -X- _ O
a -X- _ O
difference -X- _ O
with -X- _ O
the -X- _ O
combination -X- _ O
. -X- _ O

That -X- _ O
is -X- _ O
, -X- _ O
the -X- _ O
teacher -X- _ O
model -X- _ O
has -X- _ O
the -X- _ O
same -X- _ O
as -X- _ O
the -X- _ O
neural -X- _ O
network -X- _ O
structure -X- _ O
of -X- _ O
the -X- _ O
student -X- _ O
model -X- _ O
. -X- _ O

176 -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
MTST -X- _ B-MethodName
, -X- _ O
which -X- _ O
combines -X- _ O
the -X- _ O
multiple -X- _ O
- -X- _ O
teacher -X- _ O
to -X- _ O
single -X- _ O
- -X- _ O
teacher -X- _ O
. -X- _ O

Table -X- _ O
5 -X- _ O
presents -X- _ O
the -X- _ O
results -X- _ O
. -X- _ O

4.4 -X- _ O
Ablation -X- _ O
Study -X- _ O
To -X- _ O
demonstrate -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
our -X- _ O
approach -X- _ O
, -X- _ O
we -X- _ O
designed -X- _ O
the -X- _ O
following -X- _ O
ablation -X- _ O
studies -X- _ O
. -X- _ O

( -X- _ O
c -X- _ O
) -X- _ O
Student -X- _ O
. -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
RIKD -X- _ B-MethodName
w/o -X- _ I-MethodName
IKD -X- _ I-MethodName
( -X- _ O
Liang -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
and -X- _ O
Unitrans -X- _ B-MethodName
w/o -X- _ I-MethodName
translation -X- _ I-MethodName
( -X- _ O
Wu -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2020b -X- _ O
) -X- _ O
as -X- _ O
reported -X- _ O
in -X- _ O
their -X- _ O
paper -X- _ O
. -X- _ O

Moreover -X- _ O
, -X- _ O
compared -X- _ O
with -X- _ O
the -X- _ O
latest -X- _ O
model -X- _ O
TOF -X- _ B-MethodName
, -X- _ O
RIKD -X- _ B-MethodName
, -X- _ O
Unitrans -X- _ B-MethodName
, -X- _ O
our -X- _ O
model -X- _ O
requires -X- _ O
much -X- _ O
lower -X- _ O
computational -X- _ O
costs -X- _ O
for -X- _ O
both -X- _ O
translation -X- _ O
and -X- _ O
iterative -X- _ O
knowledge -X- _ O
distillation -X- _ O
, -X- _ O
meanwhile -X- _ O
reaching -X- _ O
superior -X- _ O
performance -X- _ O
. -X- _ O

Note -X- _ O
that -X- _ O
BERT -X- _ B-MethodName
- -X- _ I-MethodName
f -X- _ I-MethodName
performs -X- _ O
better -X- _ O
than -X- _ O
our -X- _ O
model -X- _ O
on -X- _ O
the -X- _ O
Chinese -X- _ O
dataset -X- _ O
due -X- _ O
to -X- _ O
their -X- _ O
re -X- _ O
- -X- _ O
tokenization -X- _ O
of -X- _ O
the -X- _ O
dataset -X- _ O
. -X- _ O

That -X- _ O
demonstrates -X- _ O
the -X- _ O
benefits -X- _ O
of -X- _ O
our -X- _ O
proposed -X- _ O
MTMT -X- _ B-MethodName
model -X- _ O
, -X- _ O
compared -X- _ O
to -X- _ O
direct -X- _ O
model -X- _ O
transfer -X- _ O
( -X- _ O
Wu -X- _ O
and -X- _ O
Dredze -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O

Specifically -X- _ O
, -X- _ O
compared -X- _ O
with -X- _ O
the -X- _ O
remarkable -X- _ O
RIKD -X- _ B-MethodName
, -X- _ O
AdvPicker -X- _ B-MethodName
, -X- _ O
and -X- _ O
Unitrans -X- _ B-MethodName
, -X- _ O
which -X- _ O
also -X- _ O
use -X- _ O
knowledge -X- _ O
distillation -X- _ O
but -X- _ O
ignore -X- _ O
the -X- _ O
entity -X- _ O
similarity -X- _ O
knowledge -X- _ O
, -X- _ O
our -X- _ O
model -X- _ O
obtains -X- _ O
significant -X- _ O
and -X- _ O
consistent -X- _ O
improvements -X- _ O
in -X- _ O
F1 -X- _ B-MetricName
- -X- _ I-MetricName
score -X- _ I-MetricName
ranging -X- _ O
from -X- _ O
0.23 -X- _ B-MetricValue
for -X- _ O
German[de -X- _ O
] -X- _ O
to -X- _ O
6.81 -X- _ B-MetricValue
for -X- _ O
Arabic[ar -X- _ O
] -X- _ O
. -X- _ O

It -X- _ O
can -X- _ O
be -X- _ O
seen -X- _ O
that -X- _ O
our -X- _ O
model -X- _ O
outperforms -X- _ O
the -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
arts -X- _ O
. -X- _ O

TOF -X- _ B-MethodName
( -X- _ O
Zhang -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
transfers -X- _ O
knowledge -X- _ O
from -X- _ O
three -X- _ O
aspects -X- _ O
for -X- _ O
cross -X- _ B-TaskName
- -X- _ I-TaskName
lingual -X- _ I-TaskName
NER -X- _ I-TaskName
. -X- _ O

RIKD -X- _ B-MethodName
( -X- _ O
Liang -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
develops -X- _ O
a -X- _ O
reinforced -X- _ O
iterative -X- _ O
knowledge -X- _ O
distillation -X- _ O
for -X- _ O
cross -X- _ B-TaskName
- -X- _ I-TaskName
lingual -X- _ I-TaskName
NER -X- _ I-TaskName
. -X- _ O

AdvPicker -X- _ B-MethodName
( -X- _ O
Chen -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
proposes -X- _ O
a -X- _ O
adversarial -X- _ O
discriminator -X- _ O
for -X- _ O
cross -X- _ B-TaskName
- -X- _ I-TaskName
lingual -X- _ I-TaskName
NER -X- _ I-TaskName
. -X- _ O

Unitrans -X- _ B-MethodName
( -X- _ O
Wu -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2020b -X- _ O
) -X- _ O
unifies -X- _ O
a -X- _ O
data -X- _ O
transfer -X- _ O
and -X- _ O
model -X- _ O
transfer -X- _ O
for -X- _ O
cross -X- _ B-TaskName
- -X- _ I-TaskName
lingual -X- _ I-TaskName
NER -X- _ I-TaskName
. -X- _ O

TSL -X- _ B-MethodName
( -X- _ O
Wu -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2020c -X- _ O
) -X- _ O
proposes -X- _ O
a -X- _ O
teacher -X- _ O
- -X- _ O
student -X- _ O
learning -X- _ O
model -X- _ O
for -X- _ O
cross -X- _ B-TaskName
- -X- _ I-TaskName
lingual -X- _ I-TaskName
NER -X- _ I-TaskName
. -X- _ O

https://github.com/huggingface/transformers -X- _ O
175 -X- _ O

BERT -X- _ B-MethodName
- -X- _ I-MethodName
f -X- _ I-MethodName
( -X- _ O
Wu -X- _ O
and -X- _ O
Dredze -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
applys -X- _ O
the -X- _ O
mBERT -X- _ B-MethodName
to -X- _ O
cross -X- _ B-TaskName
- -X- _ I-TaskName
lingual -X- _ I-TaskName
NER -X- _ I-TaskName
. -X- _ O

AdvCE -X- _ B-MethodName
( -X- _ O
Keung -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
improves -X- _ O
upon -X- _ O
mBERT -X- _ B-MethodName
via -X- _ O
adversarial -X- _ O
learning -X- _ O
for -X- _ O
cross -X- _ B-TaskName
- -X- _ I-TaskName
lingual -X- _ I-TaskName
NER -X- _ I-TaskName
. -X- _ O

TMP -X- _ B-MethodName
( -X- _ O
Jain -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
leverages -X- _ O
machine -X- _ O
translation -X- _ O
to -X- _ O
improve -X- _ O
annotation -X- _ O
projection -X- _ O
approaches -X- _ O
to -X- _ O
cross -X- _ B-TaskName
- -X- _ I-TaskName
lingual -X- _ I-TaskName
NER -X- _ I-TaskName
. -X- _ O

WS -X- _ B-MethodName
( -X- _ O
Ni -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
presents -X- _ O
two -X- _ O
weakly -X- _ O
supervised -X- _ O
approaches -X- _ O
for -X- _ O
cross -X- _ B-TaskName
- -X- _ I-TaskName
lingual -X- _ I-TaskName
NER -X- _ I-TaskName
. -X- _ O

Wiki -X- _ B-MethodName
( -X- _ O
Tsai -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
introduces -X- _ O
a -X- _ O
language -X- _ O
independent -X- _ O
model -X- _ O
building -X- _ O
on -X- _ O
cross -X- _ B-TaskName
- -X- _ I-TaskName
lingual -X- _ I-TaskName
wikification -X- _ I-TaskName
for -X- _ O
cross -X- _ B-TaskName
- -X- _ I-TaskName
lingual -X- _ I-TaskName
NER -X- _ I-TaskName
. -X- _ O

Moreover -X- _ O
, -X- _ O
we -X- _ O
conduct -X- _ O
each -X- _ O
experiment -X- _ O
5 -X- _ O
times -X- _ O
and -X- _ O
report -X- _ O
the -X- _ O
mean -X- _ O
F1 -X- _ B-MetricName
- -X- _ I-MetricName
score -X- _ I-MetricName
. -X- _ O

Following -X- _ O
( -X- _ O
Tjong -X- _ O
Kim -X- _ O
Sang -X- _ O
, -X- _ O
2002 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
entity -X- _ O
level -X- _ O
F1 -X- _ B-MetricName
- -X- _ I-MetricName
score -X- _ I-MetricName
as -X- _ O
the -X- _ O
evaluation -X- _ O
metric -X- _ O
. -X- _ O

Note -X- _ O
that -X- _ O
if -X- _ O
a -X- _ O
word -X- _ O
is -X- _ O
divided -X- _ O
into -X- _ O
several -X- _ O
subwords -X- _ O
after -X- _ O
tokenization -X- _ O
, -X- _ O
then -X- _ O
only -X- _ O
the -X- _ O
first -X- _ O
subword -X- _ O
is -X- _ O
considered -X- _ O
in -X- _ O
the -X- _ O
loss -X- _ O
function -X- _ O
. -X- _ O

For -X- _ O
knowledge -X- _ O
distillation -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
a -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
of -X- _ O
1e-6 -X- _ B-HyperparameterValue
for -X- _ O
the -X- _ O
student -X- _ O
models -X- _ O
training -X- _ O
. -X- _ O

For -X- _ O
the -X- _ O
training -X- _ O
of -X- _ O
recognition -X- _ O
teacher -X- _ O
model -X- _ O
and -X- _ O
similarity -X- _ O
teacher -X- _ O
model -X- _ O
, -X- _ O
we -X- _ O
set -X- _ O
the -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
to -X- _ O
be -X- _ O
1e-5 -X- _ B-HyperparameterValue
and -X- _ O
5e-6 -X- _ B-HyperparameterValue
separately -X- _ O
. -X- _ O

We -X- _ O
set -X- _ O
the -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
to -X- _ O
be -X- _ O
32 -X- _ B-HyperparameterValue
, -X- _ O
maximum -X- _ B-HyperparameterName
sequence -X- _ I-HyperparameterName
length -X- _ I-HyperparameterName
to -X- _ O
be -X- _ O
128 -X- _ B-HyperparameterValue
, -X- _ O
dropout -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
to -X- _ O
be -X- _ O
0.2 -X- _ B-HyperparameterValue
, -X- _ O
and -X- _ O
we -X- _ O
use -X- _ O
Adam -X- _ B-HyperparameterValue
as -X- _ O
optimizer -X- _ B-HyperparameterName
( -X- _ O
Kingma -X- _ O
and -X- _ O
Ba -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
. -X- _ O

We -X- _ O
do -X- _ O
not -X- _ O
freeze -X- _ O
any -X- _ O
layers -X- _ O
and -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
output -X- _ O
of -X- _ O
the -X- _ O
last -X- _ O
layer -X- _ O
as -X- _ O
our -X- _ O
hidden -X- _ O
feature -X- _ O
vector -X- _ O
. -X- _ O

We -X- _ O
set -X- _ O
our -X- _ O
hyperparameters -X- _ O
empirically -X- _ O
following -X- _ O
( -X- _ O
Wu -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2020c -X- _ O
) -X- _ O
with -X- _ O
some -X- _ O
modifications -X- _ O
. -X- _ O

. -X- _ O

Model -X- _ O
ar -X- _ O
hi -X- _ O
zh -X- _ O
BERT -X- _ O
- -X- _ O
f(Wu -X- _ O
and -X- _ O
Dredze -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
42.30 -X- _ O
67.60 -X- _ O
52.90 -X- _ O
TSL(Wu -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2020a -X- _ O
) -X- _ O
43.12 -X- _ O
69.54 -X- _ O
48.12 -X- _ O
RIKD(Liang -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
45.96 -X- _ O
70.28 -X- _ O
50.40 -X- _ O
MTMT -X- _ O
52.77 -X- _ O
70.76 -X- _ O
52.26 -X- _ O
Table -X- _ O
2 -X- _ O
: -X- _ O
Statistics -X- _ O
of -X- _ O
WikiAnn -X- _ O
. -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
mBERT -X- _ O
model -X- _ O
( -X- _ O
Devlin -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
in -X- _ O
HuggingFace -X- _ O
Transformer1 -X- _ O
, -X- _ O
which -X- _ O
has -X- _ O
12 -X- _ B-HyperparameterValue
Transformer -X- _ B-HyperparameterName
blocks -X- _ I-HyperparameterName
, -X- _ O
12 -X- _ B-HyperparameterValue
attention -X- _ B-HyperparameterName
heads -X- _ I-HyperparameterName
, -X- _ O
and -X- _ O
768 -X- _ B-HyperparameterValue
hidden -X- _ B-HyperparameterName
units -X- _ I-HyperparameterName

All -X- _ O
of -X- _ O
the -X- _ O
feature -X- _ O
encoders -X- _ O
mentioned -X- _ O
in -X- _ O
this -X- _ O
paper -X- _ O
use -X- _ O
174 -X- _ O

4.2 -X- _ O
Implementation -X- _ O
Details -X- _ O
We -X- _ O
use -X- _ O
PyTorch -X- _ O
1.7.1 -X- _ O
to -X- _ O
implement -X- _ O
our -X- _ O
model -X- _ O
. -X- _ O

Table -X- _ O
1 -X- _ O
and -X- _ O
2 -X- _ O
shows -X- _ O
the -X- _ O
statistics -X- _ O
of -X- _ O
all -X- _ O
datasets -X- _ O
. -X- _ O

We -X- _ O
trained -X- _ O
the -X- _ O
model -X- _ O
with -X- _ O
the -X- _ O
labeled -X- _ O
training -X- _ O
set -X- _ O
of -X- _ O
the -X- _ O
source -X- _ O
language -X- _ O
and -X- _ O
evaluated -X- _ O
the -X- _ O
model -X- _ O
on -X- _ O
the -X- _ O
test -X- _ O
set -X- _ O
of -X- _ O
each -X- _ O
target -X- _ O
language -X- _ O
. -X- _ O

In -X- _ O
cross -X- _ B-TaskName
- -X- _ I-TaskName
lingual -X- _ I-TaskName
NER -X- _ I-TaskName
, -X- _ O
the -X- _ O
training -X- _ O
set -X- _ O
without -X- _ O
entity -X- _ O
label -X- _ O
of -X- _ O
the -X- _ O
target -X- _ O
language -X- _ O
is -X- _ O
also -X- _ O
available -X- _ O
when -X- _ O
training -X- _ O
the -X- _ O
model -X- _ O
. -X- _ O

To -X- _ O
imitate -X- _ O
the -X- _ O
zero -X- _ B-TaskName
- -X- _ I-TaskName
resource -X- _ I-TaskName
cross -X- _ I-TaskName
lingual -X- _ I-TaskName
NER -X- _ I-TaskName
case -X- _ O
, -X- _ O
following -X- _ O
( -X- _ O
Wu -X- _ O
and -X- _ O
Dredze -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
used -X- _ O
English -X- _ O
as -X- _ O
the -X- _ O
source -X- _ O
language -X- _ O
and -X- _ O
other -X- _ O
languages -X- _ O
as -X- _ O
the -X- _ O
target -X- _ O
language -X- _ O
. -X- _ O

Following -X- _ O
( -X- _ O
Wu -X- _ O
and -X- _ O
Dredze -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
all -X- _ O
datasets -X- _ O
are -X- _ O
annotated -X- _ O
using -X- _ O
the -X- _ O
BIO -X- _ O
entity -X- _ O
labelling -X- _ O
scheme -X- _ O
. -X- _ O

All -X- _ O
datasets -X- _ O
were -X- _ O
annotated -X- _ O
with -X- _ O
four -X- _ O
entity -X- _ O
types -X- _ O
: -X- _ O
LOC -X- _ O
, -X- _ O
MISC -X- _ O
, -X- _ O
ORG -X- _ O
, -X- _ O
and -X- _ O
PER -X- _ O
. -X- _ O

Each -X- _ O
language -X- _ O
is -X- _ O
divided -X- _ O
into -X- _ O
a -X- _ O
training -X- _ O
set -X- _ O
, -X- _ O
a -X- _ O
development -X- _ O
set -X- _ O
and -X- _ O
a -X- _ O
test -X- _ O
set -X- _ O
. -X- _ O

CoNLL2002 -X- _ B-DatasetName
includes -X- _ O
Spanish -X- _ O
and -X- _ O
Dutch -X- _ O
, -X- _ O
CoNLL2003 -X- _ B-DatasetName
includes -X- _ O
English -X- _ O
and -X- _ O
German -X- _ O
, -X- _ O
and -X- _ O
WikiAnn -X- _ B-DatasetName
includes -X- _ O
English -X- _ O
and -X- _ O
three -X- _ O
non -X- _ O
- -X- _ O
western -X- _ O
languages -X- _ O
: -X- _ O
Arabic -X- _ O
, -X- _ O
Hindi -X- _ O
, -X- _ O
and -X- _ O
Chinese -X- _ O
. -X- _ O

Therefore -X- _ O
, -X- _ O
we -X- _ O
heuristically -X- _ O
devises -X- _ O
the -X- _ O
three -X- _ O
weights -X- _ O
scheduling -X- _ O
as -X- _ O
functions -X- _ O
of -X- _ O
the -X- _ O
inputs -X- _ O
, -X- _ O
Dataset -X- _ O
We -X- _ O
conducted -X- _ O
experiments -X- _ O
on -X- _ O
three -X- _ O
benchmark -X- _ O
datasets -X- _ O
: -X- _ O
CoNLL2002 -X- _ B-DatasetName
( -X- _ O
Tjong -X- _ O
Kim -X- _ O
Sang -X- _ O
, -X- _ O
2002 -X- _ O
) -X- _ O
, -X- _ O
CoNLL2003 -X- _ B-DatasetName
( -X- _ O
Tjong -X- _ O
Kim -X- _ O
Sang -X- _ O
and -X- _ O
De -X- _ O
Meulder -X- _ O
, -X- _ O
2003 -X- _ O
) -X- _ O
and -X- _ O
WikiAnn -X- _ B-DatasetName
( -X- _ O
Pan -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O

We -X- _ O
want -X- _ O
the -X- _ O
student -X- _ O
model -X- _ O
to -X- _ O
learn -X- _ O
from -X- _ O
the -X- _ O
two -X- _ O
teachers -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O
the -X- _ O
higher -X- _ O
the -X- _ O
prediction -X- _ O
of -X- _ O
the -X- _ O
entity -X- _ O
recognizer -X- _ O
teacher -X- _ O
is -X- _ O
( -X- _ O
the -X- _ O
further -X- _ O
away -X- _ O
from -X- _ O
0.5 -X- _ O
the -X- _ O
prediction -X- _ O
of -X- _ O
the -X- _ O
entity -X- _ O
similarity -X- _ O
teacher -X- _ O
is -X- _ O
, -X- _ O
the -X- _ O
higher -X- _ O
the -X- _ O
consistency -X- _ O
level -X- _ O
is -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
more -X- _ O
accurate -X- _ O
the -X- _ O
prediction -X- _ O
is -X- _ O
, -X- _ O
thus -X- _ O
the -X- _ O
more -X- _ O
attention -X- _ O
the -X- _ O
student -X- _ O
model -X- _ O
pays -X- _ O
attention -X- _ O
to -X- _ O
the -X- _ O
input -X- _ O
tokens -X- _ O
, -X- _ O
and -X- _ O
vice -X- _ O
versa -X- _ O
. -X- _ O

Note -X- _ O
that -X- _ O
supervision -X- _ O
information -X- _ O
yS -X- _ O
, -X- _ O
yS0 -X- _ O
, -X- _ O
and -X- _ O
t̂S -X- _ O
are -X- _ O
taught -X- _ O
by -X- _ O
the -X- _ O
three -X- _ O
teacher -X- _ O
models -X- _ O
. -X- _ O

1)2 -X- _ O
Then -X- _ O
for -X- _ O
a -X- _ O
specific -X- _ O
sentence -X- _ O
pair -X- _ O
sample -X- _ O
in -X- _ O
the -X- _ O
target -X- _ O
siamese -X- _ O
dataset -X- _ O
, -X- _ O
the -X- _ O
student -X- _ O
loss -X- _ O
function -X- _ O
has -X- _ O
three -X- _ O
breaches -X- _ O
, -X- _ O
LER -X- _ O
( -X- _ O
xT -X- _ O
, -X- _ O
yS -X- _ O
, -X- _ O
i -X- _ O
) -X- _ O
, -X- _ O
LER -X- _ O
( -X- _ O
x0 -X- _ O
T -X- _ O
, -X- _ O
yS0 -X- _ O
, -X- _ O
j -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
LSIM -X- _ O
( -X- _ O
xT -X- _ O
, -X- _ O
x0 -X- _ O
T -X- _ O
, -X- _ O
i -X- _ O
, -X- _ O
j -X- _ O
, -X- _ O
t̂S -X- _ O
) -X- _ O
. -X- _ O

σ(cos(hT -X- _ O
i -X- _ O
, -X- _ O
h0 -X- _ O
T -X- _ O
j -X- _ O
) -X- _ O
) -X- _ O

ŷT0 -X- _ O
j -X- _ O
= -X- _ O
softmax(W -X- _ O
h0 -X- _ O
T -X- _ O
j -X- _ O
+ -X- _ O
b -X- _ O
) -X- _ O
t̂T -X- _ O
( -X- _ O
xT -X- _ O
, -X- _ O
x0 -X- _ O
T -X- _ O
, -X- _ O
i -X- _ O
, -X- _ O
j -X- _ O
) -X- _ O
= -X- _ O

ŷTi -X- _ O
= -X- _ O
softmax(W -X- _ O
hT -X- _ O
i -X- _ O
+ -X- _ O
b -X- _ O
) -X- _ O
h0 -X- _ O
T -X- _ O
= -X- _ O
mBERT(x0 -X- _ O
T -X- _ O
) -X- _ O

mBERT(xT -X- _ O
) -X- _ O

hT -X- _ O
= -X- _ O

( -X- _ O
b -X- _ O
) -X- _ O
indicates -X- _ O
the -X- _ O
weight -X- _ O
β -X- _ O
of -X- _ O
LBCE -X- _ O
. -X- _ O

Specifically -X- _ O
, -X- _ O
for -X- _ O
a -X- _ O
sentence -X- _ O
pair -X- _ O
T -X- _ O
−sim -X- _ O
( -X- _ O
xT -X- _ O
, -X- _ O
x0 -X- _ O
T -X- _ O
, -X- _ O
i -X- _ O
, -X- _ O
j -X- _ O
) -X- _ O
∈ -X- _ O

The -X- _ O
mBERT -X- _ O
is -X- _ O
also -X- _ O
used -X- _ O
as -X- _ O
an -X- _ O
encoder -X- _ O
for -X- _ O
the -X- _ O
sentence -X- _ O
siamese -X- _ O
pair -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
entity -X- _ O
token -X- _ O
feature -X- _ O
is -X- _ O
queried -X- _ O
from -X- _ O
the -X- _ O
latent -X- _ O
sequence -X- _ O
encoding -X- _ O
representation -X- _ O
. -X- _ O

173 -X- _ O

i -X- _ O
, -X- _ O
j -X- _ O
> -X- _ O
uniformly -X- _ O
sampled -X- _ O
from -X- _ O
the -X- _ O
sentences -X- _ O
therein -X- _ O
. -X- _ O

> -X- _ O
randomly -X- _ O
sample -X- _ O
from -X- _ O
Dtrain -X- _ O
and -X- _ O
the -X- _ O
entity -X- _ O
token -X- _ O
indices -X- _ O
pair -X- _ O
< -X- _ O

T -X- _ O
< -X- _ O
xT -X- _ O
, -X- _ O
xT -X- _ O

Dtrain -X- _ O
= -X- _ O
{ -X- _ O
( -X- _ O
xT -X- _ O
, -X- _ O
x0 -X- _ O
T -X- _ O
, -X- _ O
i -X- _ O
, -X- _ O
j -X- _ O
) -X- _ O
} -X- _ O
, -X- _ O
with -X- _ O
the -X- _ O
sentence -X- _ O
pair -X- _ O
0 -X- _ O

Based -X- _ O
on -X- _ O
the -X- _ O
original -X- _ O
unlabeled -X- _ O
target -X- _ O
senT -X- _ O
tence -X- _ O
training -X- _ O
data -X- _ O
Dtrain -X- _ O
, -X- _ O
we -X- _ O
again -X- _ O
construct -X- _ O
unlabeled -X- _ O
target -X- _ O
- -X- _ O
language -X- _ O
siamese -X- _ O
pairwise -X- _ O
entity -X- _ O
data -X- _ O
T -X- _ O
−sim -X- _ O

To -X- _ O
this -X- _ O
end -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
knowledge -X- _ O
distillation -X- _ O
learning -X- _ O
process -X- _ O
to -X- _ O
train -X- _ O
a -X- _ O
target -X- _ O
language -X- _ O
student -X- _ O
NER -X- _ O
model -X- _ O
with -X- _ O
its -X- _ O
supervisory -X- _ O
signals -X- _ O
mimicked -X- _ O
by -X- _ O
the -X- _ O
entity -X- _ O
type -X- _ O
prediction -X- _ O
probability -X- _ O
by -X- _ O
the -X- _ O
entity -X- _ O
recognizer -X- _ O
teacher -X- _ O
model -X- _ O
and -X- _ O
entity -X- _ O
representation -X- _ O
similarity -X- _ O
target -X- _ O
by -X- _ O
the -X- _ O
entity -X- _ O
siamese -X- _ O
similarity -X- _ O
evaluator -X- _ O
teacher -X- _ O
model -X- _ O
. -X- _ O

3.3 -X- _ O
Teacher -X- _ O
- -X- _ O
student -X- _ O
Distillation -X- _ O
Learning -X- _ O
In -X- _ O
this -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
consider -X- _ O
transferring -X- _ O
the -X- _ O
named -X- _ O
entity -X- _ O
type -X- _ O
and -X- _ O
similarity -X- _ O
knowledge -X- _ O
learned -X- _ O
on -X- _ O
labeled -X- _ O
source -X- _ O
language -X- _ O
corpus -X- _ O
to -X- _ O
unlabeled -X- _ O
target -X- _ O
language -X- _ O
NER -X- _ B-TaskName
task -X- _ O
. -X- _ O

Together -X- _ O
with -X- _ O
entity -X- _ O
recognizer -X- _ O
model -X- _ O
, -X- _ O
this -X- _ O
entity -X- _ O
similarity -X- _ O
evaluator -X- _ O
are -X- _ O
used -X- _ O
as -X- _ O
teachers -X- _ O
in -X- _ O
following -X- _ O
knowledge -X- _ O
distillation -X- _ O
learning -X- _ O
process -X- _ O
, -X- _ O
and -X- _ O
transfer -X- _ O
knowledge -X- _ O
from -X- _ O
source -X- _ O
to -X- _ O
target -X- _ O
lingual -X- _ O
corpus -X- _ O
. -X- _ O

Finally -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
train -X- _ O
the -X- _ O
siamese -X- _ O
entity -X- _ O
similarS−siam -X- _ O
ity -X- _ O
evaluator -X- _ O
on -X- _ O
Dtrain -X- _ O
, -X- _ O
and -X- _ O
evaluate -X- _ O
the -X- _ O
perS−siam -X- _ O
formance -X- _ O
on -X- _ O
test -X- _ O
dataset -X- _ O
Dtest -X- _ O
. -X- _ O

LBCE -X- _ O
( -X- _ O
t -X- _ O
, -X- _ O
t̂ -X- _ O
) -X- _ O
. -X- _ O

The -X- _ O
loss -X- _ O
function -X- _ O
of -X- _ O
the -X- _ O
similarity -X- _ O
prediction -X- _ O
can -X- _ O
be -X- _ O
formulate -X- _ O
as -X- _ O
, -X- _ O
LSIM -X- _ O
( -X- _ O
x -X- _ O
, -X- _ O
x0 -X- _ O
, -X- _ O
i -X- _ O
, -X- _ O
j -X- _ O
, -X- _ O
t -X- _ O
) -X- _ O
= -X- _ O

Larger -X- _ O
t̂ -X- _ O
value -X- _ O
indicates -X- _ O
higher -X- _ O
similarity -X- _ O
between -X- _ O
the -X- _ O
two -X- _ O
queried -X- _ O
entities -X- _ O
tokens -X- _ O
. -X- _ O

[ -X- _ O
σ(−1 -X- _ O
) -X- _ O
, -X- _ O
σ(1 -X- _ O
) -X- _ O
] -X- _ O
denotes -X- _ O
the -X- _ O
predicted -X- _ O
similarity -X- _ O
of -X- _ O
two -X- _ O
queried -X- _ O
tokens -X- _ O
pair -X- _ O
< -X- _ O
xi -X- _ O
, -X- _ O
x0j -X- _ O
> -X- _ O
. -X- _ O

where -X- _ O
cos -X- _ O
is -X- _ O
the -X- _ O
cosine -X- _ O
similarity -X- _ O
metric -X- _ O
function -X- _ O
, -X- _ O
σ -X- _ O
is -X- _ O
the -X- _ O
sigmoid -X- _ O
activation -X- _ O
function -X- _ O
, -X- _ O
t̂ -X- _ O
∈ -X- _ O

Linear -X- _ O
Encoder -X- _ O
structure -X- _ O
could -X- _ O
be -X- _ O
formulated -X- _ O
as -X- _ O
, -X- _ O
CELoss -X- _ O
Similarity -X- _ O
Score -X- _ O
BCELoss -X- _ O
Loss -X- _ O
CELoss -X- _ O
Student -X- _ O
Figure -X- _ O
3 -X- _ O
: -X- _ O
Teacher -X- _ O
- -X- _ O
student -X- _ O
distillation -X- _ O
learning -X- _ O
. -X- _ O

Teacher -X- _ O
Inference -X- _ O
Student -X- _ O
Training -X- _ O
Cos -X- _ O
ŷi -X- _ O
= -X- _ O
softmax(W -X- _ O
hi -X- _ O
+ -X- _ O
b -X- _ O
) -X- _ O
Encoder -X- _ O
Encoder -X- _ O
h -X- _ O
= -X- _ O
mBERT(x -X- _ O
) -X- _ O
h -X- _ O
= -X- _ O
mBERT(x -X- _ O
) -X- _ O
, -X- _ O
h0 -X- _ O
= -X- _ O
mBERT(x0 -X- _ O
) -X- _ O

Similarity -X- _ O
Score -X- _ O
Evaluator -X- _ O
Teacher -X- _ O
Encoder -X- _ O
Encoder -X- _ O
We -X- _ O
train -X- _ O
this -X- _ O
entity -X- _ O
recognition -X- _ O
teacher -X- _ O
model -X- _ O
S -X- _ O
on -X- _ O
the -X- _ O
source -X- _ O
lingual -X- _ O
training -X- _ O
corpus -X- _ O
Dtrain -X- _ O
= -X- _ O
{ -X- _ O
( -X- _ O
x -X- _ O
, -X- _ O
y -X- _ O
) -X- _ O
} -X- _ O
directly -X- _ O
. -X- _ O

Linear -X- _ O
3.2.2 -X- _ O
Siamese -X- _ O
Entity -X- _ O
Similarity -X- _ O
Evaluator -X- _ O
To -X- _ O
leverage -X- _ O
the -X- _ O
entity -X- _ O
similarity -X- _ O
to -X- _ O
boost -X- _ O
the -X- _ O
unsupervised -X- _ O
cross -X- _ B-TaskName
- -X- _ I-TaskName
lingual -X- _ I-TaskName
NER -X- _ I-TaskName
performance -X- _ O
, -X- _ O
we -X- _ O
will -X- _ O
present -X- _ O
our -X- _ O
entity -X- _ O
pairs -X- _ O
construction -X- _ O
method -X- _ O
and -X- _ O
the -X- _ O
siamese -X- _ O
network -X- _ O
model -X- _ O
in -X- _ O
the -X- _ O
following -X- _ O
. -X- _ O

And -X- _ O
the -X- _ O
testing -X- _ O
S−siam -X- _ O
entity -X- _ O
pairs -X- _ O
Dtest -X- _ O
is -X- _ O
constructed -X- _ O
likewisely -X- _ O
. -X- _ O

Dtrain -X- _ O
= -X- _ O
{ -X- _ O
( -X- _ O
x -X- _ O
, -X- _ O
x0 -X- _ O
, -X- _ O
i -X- _ O
, -X- _ O
j -X- _ O
, -X- _ O
t -X- _ O
) -X- _ O
} -X- _ O
where -X- _ O
the -X- _ O
target -X- _ O
t -X- _ O
= -X- _ O
1 -X- _ O
indicates -X- _ O
yi -X- _ O
= -X- _ O
yj0 -X- _ O
, -X- _ O
and -X- _ O
0 -X- _ O
otherwise -X- _ O
. -X- _ O

Dtrain -X- _ O
, -X- _ O
the -X- _ O
siamese -X- _ O
network -X- _ O
could -X- _ O
be -X- _ O
formulated -X- _ O
as -X- _ O
, -X- _ O
Cos -X- _ O
Entity -X- _ O
Similarity -X- _ O
Pairs -X- _ O
Construction -X- _ O
According -X- _ O
to -X- _ O
entity -X- _ O
labels -X- _ O
, -X- _ O
we -X- _ O
randomly -X- _ O
select -X- _ O
sentences -X- _ O
pair -X- _ O
< -X- _ O
x -X- _ O
, -X- _ O
x0 -X- _ O
> -X- _ O
with -X- _ O
their -X- _ O
some -X- _ O
token -X- _ O
pair -X- _ O
< -X- _ O
S -X- _ O
, -X- _ O
xi -X- _ O
, -X- _ O
x0j -X- _ O
> -X- _ O
and -X- _ O
associated -X- _ O
labels -X- _ O
< -X- _ O
yi -X- _ O
, -X- _ O
yj0 -X- _ O
> -X- _ O
in -X- _ O
Dtrain -X- _ O
to -X- _ O
form -X- _ O
the -X- _ O
siamese -X- _ O
supervision -X- _ O
training -X- _ O
dataset -X- _ O
, -X- _ O
S−siam -X- _ O

( -X- _ O
x -X- _ O
, -X- _ O
x0 -X- _ O
, -X- _ O
i -X- _ O
, -X- _ O
j -X- _ O
, -X- _ O
t -X- _ O
) -X- _ O
∈ -X- _ O

More -X- _ O
precisely -X- _ O
, -X- _ O
for -X- _ O
a -X- _ O
specific -X- _ O
entity -X- _ O
pair -X- _ O
S−siam -X- _ O

The -X- _ O
cosine -X- _ O
function -X- _ O
operator -X- _ O
is -X- _ O
added -X- _ O
to -X- _ O
compute -X- _ O
on -X- _ O
the -X- _ O
entity -X- _ O
token -X- _ O
latent -X- _ O
vectors -X- _ O
’ -X- _ O
distance -X- _ O
, -X- _ O
s -X- _ O
to -X- _ O
measure -X- _ O
the -X- _ O
similarity -X- _ O
between -X- _ O
each -X- _ O
siamese -X- _ O
twin -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
fed -X- _ O
into -X- _ O
a -X- _ O
single -X- _ O
sigmoid -X- _ O
output -X- _ O
unit -X- _ O
for -X- _ O
target -X- _ O
t̂ -X- _ O
estimation -X- _ O
. -X- _ O

i -X- _ O
, -X- _ O
j -X- _ O
> -X- _ O
on -X- _ O
the -X- _ O
sequences -X- _ O
representations -X- _ O
. -X- _ O

The -X- _ O
inter -X- _ O
- -X- _ O
entities -X- _ O
similarity -X- _ O
is -X- _ O
measured -X- _ O
on -X- _ O
the -X- _ O
hidden -X- _ O
representations -X- _ O
hi -X- _ O
and -X- _ O
h0j -X- _ O
of -X- _ O
the -X- _ O
tokens -X- _ O
queried -X- _ O
by -X- _ O
the -X- _ O
entity -X- _ O
indices -X- _ O
< -X- _ O

Wherein -X- _ O
h -X- _ O
and -X- _ O
h0 -X- _ O
represent -X- _ O
latent -X- _ O
sequences -X- _ O
encoding -X- _ O
features -X- _ O
derived -X- _ O
by -X- _ O
the -X- _ O
two -X- _ O
symmetric -X- _ O
twins -X- _ O
with -X- _ O
respect -X- _ O
to -X- _ O
input -X- _ O
sentence -X- _ O
x -X- _ O
and -X- _ O
x0 -X- _ O
respectively -X- _ O
. -X- _ O

Our -X- _ O
similarity -X- _ O
backbone -X- _ O
model -X- _ O
is -X- _ O
a -X- _ O
siamese -X- _ O
neural -X- _ O
network -X- _ O
with -X- _ O
mBERT -X- _ O
as -X- _ O
feature -X- _ O
extraction -X- _ O
layer -X- _ O
. -X- _ O

Linear -X- _ O
Siamese -X- _ O
Entity -X- _ O
Similarity -X- _ O
Network -X- _ O

LCE -X- _ O
( -X- _ O
yi -X- _ O
, -X- _ O
ŷi -X- _ O
) -X- _ O
t̂(x -X- _ O
, -X- _ O
x0 -X- _ O
, -X- _ O
i -X- _ O
, -X- _ O
j -X- _ O
) -X- _ O
= -X- _ O
σ(cos(hi -X- _ O
, -X- _ O
h0j -X- _ O
) -X- _ O
) -X- _ O

Dtrain -X- _ O
and -X- _ O
an -X- _ O
entity -X- _ O
token -X- _ O
query -X- _ O
index -X- _ O
i -X- _ O
, -X- _ O
the -X- _ O
loss -X- _ O
function -X- _ O
is -X- _ O
, -X- _ O
LER -X- _ O
( -X- _ O
x -X- _ O
, -X- _ O
y -X- _ O
, -X- _ O
i -X- _ O
) -X- _ O
= -X- _ O

For -X- _ O
some -X- _ O
sentence -X- _ O
sample -X- _ O
( -X- _ O
x -X- _ O
, -X- _ O
y -X- _ O
) -X- _ O
∈ -X- _ O

W -X- _ O
and -X- _ O
b -X- _ O
are -X- _ O
trainable -X- _ O
paramS -X- _ O
eters -X- _ O
. -X- _ O

ŷi -X- _ O
denotes -X- _ O
the -X- _ O
predicted -X- _ O
probability -X- _ O
distribution -X- _ O
for -X- _ O
xi -X- _ O
. -X- _ O

Recognizer -X- _ O
Teacher -X- _ O
Unlabeled -X- _ O
Target -X- _ O
- -X- _ O
Language -X- _ O
Pairwise -X- _ O
Data -X- _ O
where -X- _ O
h -X- _ O
= -X- _ O
{ -X- _ O
hi -X- _ O
} -X- _ O
L -X- _ O
i=1 -X- _ O
and -X- _ O
hi -X- _ O
denotes -X- _ O
the -X- _ O
output -X- _ O
of -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
mBERT -X- _ O
that -X- _ O
corresponds -X- _ O
to -X- _ O
the -X- _ O
input -X- _ O
token -X- _ O
xi -X- _ O
. -X- _ O

The -X- _ O
model -X- _ O
network -X- _ O
172 -X- _ O

And -X- _ O
a -X- _ O
linear -X- _ O
classifier -X- _ O
with -X- _ O
softmax -X- _ O
upon -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
mBERT -X- _ O
output -X- _ O
. -X- _ O

3.2.1 -X- _ O
Entity -X- _ O
Recognizer -X- _ O
Since -X- _ O
the -X- _ O
cross -X- _ O
- -X- _ O
lingual -X- _ O
NER -X- _ O
task -X- _ O
, -X- _ O
we -X- _ O
unitize -X- _ O
multilingual -X- _ O
mBERT -X- _ B-MethodName
( -X- _ O
Wu -X- _ O
and -X- _ O
Dredze -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
as -X- _ O
basic -X- _ O
sequence -X- _ O
feature -X- _ O
extractor -X- _ O
backbone -X- _ O
to -X- _ O
derive -X- _ O
the -X- _ O
sequence -X- _ O
embedding -X- _ O
representation -X- _ O
throughout -X- _ O
this -X- _ O
paper -X- _ O
. -X- _ O

The -X- _ O
following -X- _ O
subsections -X- _ O
will -X- _ O
illustrate -X- _ O
the -X- _ O
two -X- _ O
teacher -X- _ O
models -X- _ O
sequentially -X- _ O
. -X- _ O

Figure -X- _ O
2 -X- _ O
illustrated -X- _ O
the -X- _ O
two -X- _ O
teacher -X- _ O
models -X- _ O
training -X- _ O
. -X- _ O

Our -X- _ O
similarity -X- _ O
evaluator -X- _ O
model -X- _ O
, -X- _ O
inspired -X- _ O
by -X- _ O
siamese -X- _ O
network -X- _ O
( -X- _ O
Koch -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
, -X- _ O
are -X- _ O
able -X- _ O
to -X- _ O
acquires -X- _ O
more -X- _ O
powerful -X- _ O
features -X- _ O
via -X- _ O
capturing -X- _ O
the -X- _ O
invariances -X- _ O
to -X- _ O
transformation -X- _ O
in -X- _ O
the -X- _ O
input -X- _ O
space -X- _ O
. -X- _ O

To -X- _ O
address -X- _ O
this -X- _ O
challenge -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
binary -X- _ O
classifier -X- _ O
called -X- _ O
similarity -X- _ O
evaluator -X- _ O
to -X- _ O
leverage -X- _ O
the -X- _ O
labeled -X- _ O
source -X- _ O
language -X- _ O
data -X- _ O
for -X- _ O
similarity -X- _ O
prediction -X- _ O
. -X- _ O

It -X- _ O
is -X- _ O
a -X- _ O
non -X- _ O
- -X- _ O
trivial -X- _ O
task -X- _ O
since -X- _ O
we -X- _ O
lack -X- _ O
golden -X- _ O
labels -X- _ O
to -X- _ O
help -X- _ O
us -X- _ O
distinguish -X- _ O
target -X- _ O
named -X- _ O
entities -X- _ O
. -X- _ O

We -X- _ O
aim -X- _ O
to -X- _ O
find -X- _ O
entity -X- _ O
similarity -X- _ O
to -X- _ O
help -X- _ O
the -X- _ O
crosslingual -X- _ B-TaskName
NER -X- _ I-TaskName
model -X- _ O
in -X- _ O
the -X- _ O
target -X- _ O
language -X- _ O
. -X- _ O

For -X- _ O
every -X- _ O
two -X- _ O
tokens -X- _ O
, -X- _ O
we -X- _ O
define -X- _ O
Entity -X- _ O
Similarity -X- _ O
Metric -X- _ O
as -X- _ O
a -X- _ O
score -X- _ O
which -X- _ O
is -X- _ O
the -X- _ O
probability -X- _ O
that -X- _ O
two -X- _ O
tokens -X- _ O
belong -X- _ O
to -X- _ O
the -X- _ O
same -X- _ O
entity -X- _ O
type -X- _ O
. -X- _ O

with -X- _ O
Dtrain -X- _ O
and -X- _ O
Dtrain -X- _ O
to -X- _ O
perform -X- _ O
well -X- _ O
on -X- _ O
Dtest -X- _ O
3.2 -X- _ O
Teacher -X- _ O
Models -X- _ O
Here -X- _ O
we -X- _ O
first -X- _ O
consider -X- _ O
the -X- _ O
training -X- _ O
of -X- _ O
two -X- _ O
teacher -X- _ O
models -X- _ O
. -X- _ O

Formally -X- _ O
, -X- _ O
our -X- _ O
goal -X- _ O
is -X- _ O
to -X- _ O
train -X- _ O
a -X- _ O
model -X- _ O
S -X- _ O
T -X- _ O
T -X- _ O
. -X- _ O

In -X- _ O
the -X- _ O
target -X- _ O
language -X- _ O
, -X- _ O
we -X- _ O
denote -X- _ O
the -X- _ O
T -X- _ O
unlabeled -X- _ O
train -X- _ O
data -X- _ O
as -X- _ O
Dtrain -X- _ O
= -X- _ O
{ -X- _ O
x -X- _ O
} -X- _ O
and -X- _ O
the -X- _ O
test -X- _ O
T -X- _ O
data -X- _ O
as -X- _ O
Dtest -X- _ O
. -X- _ O

In -X- _ O
the -X- _ O
source -X- _ O
language -X- _ O
, -X- _ O
we -X- _ O
denote -X- _ O
the -X- _ O
S -X- _ O
labeled -X- _ O
training -X- _ O
data -X- _ O
as -X- _ O
Dtrain -X- _ O
= -X- _ O
{ -X- _ O
( -X- _ O
x -X- _ O
, -X- _ O
y -X- _ O
) -X- _ O
} -X- _ O
and -X- _ O
test -X- _ O
S -X- _ O
data -X- _ O
as -X- _ O
Dtest -X- _ O
. -X- _ O

= -X- _ O
{ -X- _ O
xi -X- _ O
} -X- _ O
L -X- _ O
i=1 -X- _ O
with -X- _ O
L -X- _ O
tokens -X- _ O
, -X- _ O
a -X- _ O
NER -X- _ O
model -X- _ O
produces -X- _ O
a -X- _ O
sequence -X- _ O
of -X- _ O
labels -X- _ O
y -X- _ O
= -X- _ O
{ -X- _ O
yi -X- _ O
} -X- _ O
L -X- _ O
i=1 -X- _ O
, -X- _ O
where -X- _ O
xi -X- _ O
is -X- _ O
the -X- _ O
i -X- _ O
- -X- _ O
th -X- _ O
token -X- _ O
and -X- _ O
yi -X- _ O
is -X- _ O
the -X- _ O
corresponding -X- _ O
label -X- _ O
of -X- _ O
xi -X- _ O
. -X- _ O

To -X- _ O
the -X- _ O
best -X- _ O
of -X- _ O
our -X- _ O
knowledge -X- _ O
, -X- _ O
we -X- _ O
are -X- _ O
the -X- _ O
first -X- _ O
to -X- _ O
learn -X- _ O
the -X- _ O
entity -X- _ O
similarity -X- _ O
by -X- _ O
siamese -X- _ O
network -X- _ O
. -X- _ O

To -X- _ O
handle -X- _ O
this -X- _ O
issue -X- _ O
, -X- _ O
we -X- _ O
reconstruct -X- _ O
the -X- _ O
data -X- _ O
to -X- _ O
pair -X- _ O
format -X- _ O
. -X- _ O

Siamese -X- _ O
network -X- _ O
assumes -X- _ O
the -X- _ O
input -X- _ O
is -X- _ O
a -X- _ O
pair -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
output -X- _ O
is -X- _ O
a -X- _ O
similarity -X- _ O
score -X- _ O
. -X- _ O

However -X- _ O
, -X- _ O
there -X- _ O
is -X- _ O
a -X- _ O
dilemma -X- _ O
to -X- _ O
adapt -X- _ O
the -X- _ O
siamese -X- _ O
network -X- _ O
to -X- _ O
tokenlevel -X- _ B-TaskName
recognition -X- _ I-TaskName
tasks -X- _ O
such -X- _ O
as -X- _ O
NER -X- _ B-TaskName
. -X- _ O

It -X- _ O
has -X- _ O
been -X- _ O
successfully -X- _ O
applied -X- _ O
to -X- _ O
transfer -X- _ O
learning -X- _ O
such -X- _ O
as -X- _ O
one -X- _ O
- -X- _ O
shot -X- _ O
image -X- _ O
recognition -X- _ O
( -X- _ O
Koch -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
, -X- _ O
text -X- _ O
similarity -X- _ O
( -X- _ O
Neculoiu -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
. -X- _ O

Siamese -X- _ O
Network -X- _ O
is -X- _ O
originally -X- _ O
introduced -X- _ O
by -X- _ O
( -X- _ O
Bromley -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
1994 -X- _ O
) -X- _ O
to -X- _ O
treat -X- _ O
signature -X- _ O
verification -X- _ O
as -X- _ O
a -X- _ O
matching -X- _ O
problem -X- _ O
. -X- _ O

We -X- _ O
argue -X- _ O
that -X- _ O
the -X- _ O
student -X- _ O
entity -X- _ O
recognition -X- _ O
task -X- _ O
and -X- _ O
the -X- _ O
student -X- _ O
entity -X- _ O
similarity -X- _ O
evaluation -X- _ O
task -X- _ O
improve -X- _ O
the -X- _ O
representation -X- _ O
learning -X- _ O
of -X- _ O
the -X- _ O
student -X- _ O
encoder -X- _ O
in -X- _ O
the -X- _ O
siamese -X- _ O
structure -X- _ O
. -X- _ O

To -X- _ O
guarantee -X- _ O
the -X- _ O
student -X- _ O
learning -X- _ O
performance -X- _ O
, -X- _ O
we -X- _ O
assign -X- _ O
weights -X- _ O
for -X- _ O
each -X- _ O
supervisory -X- _ O
signal -X- _ O
correspond -X- _ O
to -X- _ O
the -X- _ O
output -X- _ O
confidence -X- _ O
of -X- _ O
teacher -X- _ O
sub -X- _ O
- -X- _ O
models -X- _ O
. -X- _ O

During -X- _ O
the -X- _ O
learning -X- _ O
process -X- _ O
, -X- _ O
the -X- _ O
samples -X- _ O
from -X- _ O
the -X- _ O
target -X- _ O
language -X- _ O
are -X- _ O
fed -X- _ O
into -X- _ O
the -X- _ O
teacher -X- _ O
model -X- _ O
and -X- _ O
the -X- _ O
outputs -X- _ O
are -X- _ O
taken -X- _ O
as -X- _ O
the -X- _ O
supervisory -X- _ O
signal -X- _ O
for -X- _ O
two -X- _ O
tasks -X- _ O
in -X- _ O
the -X- _ O
student -X- _ O
model -X- _ O
. -X- _ O

We -X- _ O
note -X- _ O
that -X- _ O
, -X- _ O
in -X- _ O
this -X- _ O
learning -X- _ O
process -X- _ O
, -X- _ O
such -X- _ O
a -X- _ O
knowledge -X- _ O
distillation -X- _ O
makes -X- _ O
the -X- _ O
student -X- _ O
model -X- _ O
combine -X- _ O
the -X- _ O
advantages -X- _ O
of -X- _ O
both -X- _ O
source -X- _ O
language -X- _ O
patterns -X- _ O
of -X- _ O
entity -X- _ O
recognition -X- _ O
and -X- _ O
entity -X- _ O
similarity -X- _ O
evaluation -X- _ O
. -X- _ O

We -X- _ O
then -X- _ O
present -X- _ O
a -X- _ O
teacher -X- _ O
- -X- _ O
student -X- _ O
distillation -X- _ O
learning -X- _ O
model -X- _ O
to -X- _ O
learn -X- _ O
from -X- _ O
the -X- _ O
two -X- _ O
learned -X- _ O
teacher -X- _ O
models -X- _ O
simultaneously -X- _ O
. -X- _ O

These -X- _ O
two -X- _ O
models -X- _ O
are -X- _ O
two -X- _ O
parallel -X- _ O
tasks -X- _ O
, -X- _ O
wherein -X- _ O
the -X- _ O
entity -X- _ O
recognition -X- _ O
teacher -X- _ O
focuses -X- _ O
on -X- _ O
identifying -X- _ O
the -X- _ O
named -X- _ O
entities -X- _ O
and -X- _ O
the -X- _ O
similarity -X- _ O
evaluator -X- _ O
teacher -X- _ O
is -X- _ O
to -X- _ O
decide -X- _ O
if -X- _ O
two -X- _ O
tokens -X- _ O
are -X- _ O
in -X- _ O
the -X- _ O
same -X- _ O
type -X- _ O
. -X- _ O

In -X- _ O
the -X- _ O
teacher -X- _ O
training -X- _ O
model -X- _ O
, -X- _ O
there -X- _ O
are -X- _ O
two -X- _ O
sub -X- _ O
- -X- _ O
models -X- _ O
, -X- _ O
i.e. -X- _ O
an -X- _ O
entity -X- _ O
recognizer -X- _ O
teacher -X- _ O
and -X- _ O
a -X- _ O
similarity -X- _ O
evaluator -X- _ O
teacher -X- _ O
. -X- _ O

Our -X- _ O
framework -X- _ O
is -X- _ O
consist -X- _ O
of -X- _ O
two -X- _ O
models -X- _ O
: -X- _ O
teacher -X- _ O
training -X- _ O
model -X- _ O
learned -X- _ O
from -X- _ O
the -X- _ O
source -X- _ O
language -X- _ O
and -X- _ O
teacher -X- _ O
- -X- _ O
student -X- _ O
distillation -X- _ O
learning -X- _ O
model -X- _ O
learned -X- _ O
from -X- _ O
the -X- _ O
target -X- _ O
language -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
introduce -X- _ O
our -X- _ O
framework -X- _ O
and -X- _ O
its -X- _ O
detailed -X- _ O
implementation -X- _ O
. -X- _ O

Following -X- _ O
standard -X- _ O
practice -X- _ O
, -X- _ O
we -X- _ O
formulate -X- _ O
crosslingual -X- _ B-TaskName
NER -X- _ I-TaskName
as -X- _ O
a -X- _ O
sequence -X- _ B-TaskName
labeling -X- _ I-TaskName
task -X- _ O
. -X- _ O

In -X- _ O
our -X- _ O
work -X- _ O
, -X- _ O
the -X- _ O
student -X- _ O
model -X- _ O
not -X- _ O
only -X- _ O
learns -X- _ O
the -X- _ O
recognizer -X- _ O
teacher -X- _ O
knowledge -X- _ O
, -X- _ O
but -X- _ O
also -X- _ O
171 -X- _ O

Therefore -X- _ O
, -X- _ O
the -X- _ O
student -X- _ O
model -X- _ O
can -X- _ O
capture -X- _ O
the -X- _ O
extra -X- _ O
knowledge -X- _ O
about -X- _ O
target -X- _ O
languages -X- _ O
. -X- _ O

The -X- _ O
student -X- _ O
model -X- _ O
learns -X- _ O
from -X- _ O
the -X- _ O
soft -X- _ O
label -X- _ O
predicted -X- _ O
by -X- _ O
the -X- _ O
teacher -X- _ O
model -X- _ O
on -X- _ O
unlabeled -X- _ O
target -X- _ O
language -X- _ O
data -X- _ O
. -X- _ O

The -X- _ O
teacher -X- _ O
model -X- _ O
is -X- _ O
trained -X- _ O
on -X- _ O
the -X- _ O
labeled -X- _ O
source -X- _ O
language -X- _ O
. -X- _ O

Knowledge -X- _ O
distillation -X- _ O
based -X- _ O
models -X- _ O
include -X- _ O
a -X- _ O
teacher -X- _ O
model -X- _ O
and -X- _ O
a -X- _ O
student -X- _ O
model -X- _ O
( -X- _ O
Wu -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2020c -X- _ O
) -X- _ O
. -X- _ O

Our -X- _ O
model -X- _ O
achieves -X- _ O
considerable -X- _ O
improvement -X- _ O
by -X- _ O
learning -X- _ O
entity -X- _ O
similarity -X- _ O
in -X- _ O
target -X- _ O
language -X- _ O
data -X- _ O
without -X- _ O
translation -X- _ O
. -X- _ O

For -X- _ O
example -X- _ O
, -X- _ O
( -X- _ O
Wu -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2020b -X- _ O
; -X- _ O
Zhang -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
gain -X- _ O
an -X- _ O
improvement -X- _ O
by -X- _ O
translating -X- _ O
the -X- _ O
labeled -X- _ O
source -X- _ O
language -X- _ O
to -X- _ O
the -X- _ O
target -X- _ O
language -X- _ O
word -X- _ O
- -X- _ O
by -X- _ O
- -X- _ O
word -X- _ O
. -X- _ O

Translation -X- _ O
based -X- _ O
models -X- _ O
generally -X- _ O
generate -X- _ O
pseudo -X- _ O
- -X- _ O
labeled -X- _ O
target -X- _ O
data -X- _ O
to -X- _ O
alleviate -X- _ O
target -X- _ O
data -X- _ O
scarcity -X- _ O
. -X- _ O

The -X- _ O
performance -X- _ O
is -X- _ O
still -X- _ O
weak -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
lack -X- _ O
of -X- _ O
annotations -X- _ O
of -X- _ O
target -X- _ O
languages -X- _ O
. -X- _ O

Moreover -X- _ O
, -X- _ O
some -X- _ O
research -X- _ O
introduces -X- _ O
new -X- _ O
components -X- _ O
on -X- _ O
top -X- _ O
of -X- _ O
the -X- _ O
mBERT -X- _ B-MethodName
by -X- _ O
directly -X- _ O
transferring -X- _ O
the -X- _ O
model -X- _ O
learned -X- _ O
from -X- _ O
the -X- _ O
labeled -X- _ O
source -X- _ O
language -X- _ O
to -X- _ O
that -X- _ O
of -X- _ O
target -X- _ O
languages -X- _ O
( -X- _ O
Keung -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O

Recently -X- _ O
, -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
multilingual -X- _ B-MethodName
language -X- _ I-MethodName
model -X- _ I-MethodName
is -X- _ O
effective -X- _ O
to -X- _ O
address -X- _ O
the -X- _ O
challenge -X- _ O
( -X- _ O
Devlin -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O

Shared -X- _ O
feature -X- _ O
space -X- _ O
based -X- _ O
models -X- _ O
generally -X- _ O
train -X- _ O
a -X- _ O
language -X- _ O
- -X- _ O
independent -X- _ O
encoder -X- _ O
using -X- _ O
source -X- _ O
and -X- _ O
target -X- _ O
language -X- _ O
data -X- _ O
( -X- _ O
Tsai -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
. -X- _ O

The -X- _ O
existing -X- _ O
models -X- _ O
can -X- _ O
be -X- _ O
categorized -X- _ O
to -X- _ O
a -X- _ O
) -X- _ O
Shared -X- _ O
feature -X- _ O
space -X- _ O
based -X- _ O
models -X- _ O
, -X- _ O
b -X- _ O
) -X- _ O
Translation -X- _ O
based -X- _ O
models -X- _ O
, -X- _ O
c -X- _ O
) -X- _ O
Knowledge -X- _ O
distillation -X- _ O
based -X- _ O
models -X- _ O
. -X- _ O

Cross -X- _ B-TaskName
- -X- _ I-TaskName
Lingual -X- _ I-TaskName
NER -X- _ I-TaskName
aims -X- _ O
to -X- _ O
extract -X- _ O
entities -X- _ O
from -X- _ O
a -X- _ O
target -X- _ O
language -X- _ O
but -X- _ O
assumes -X- _ O
only -X- _ O
source -X- _ O
language -X- _ O
is -X- _ O
annotated -X- _ O
. -X- _ O

2 -X- _ O
Related -X- _ O
Work -X- _ O
Our -X- _ O
approach -X- _ O
is -X- _ O
closely -X- _ O
related -X- _ O
to -X- _ O
the -X- _ O
existing -X- _ O
works -X- _ O
on -X- _ O
cross -X- _ B-TaskName
- -X- _ I-TaskName
lingual -X- _ I-TaskName
NER -X- _ I-TaskName
, -X- _ O
knowledge -X- _ O
distillation -X- _ O
, -X- _ O
and -X- _ O
siamese -X- _ O
network -X- _ O
. -X- _ O

• -X- _ O
We -X- _ O
conduct -X- _ O
extensive -X- _ O
experiments -X- _ O
on -X- _ O
7 -X- _ O
languages -X- _ O
compared -X- _ O
with -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
baselines -X- _ O
and -X- _ O
the -X- _ O
results -X- _ O
confirm -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
the -X- _ O
presented -X- _ O
model -X- _ O
. -X- _ O

• -X- _ O
We -X- _ O
present -X- _ O
a -X- _ O
novel -X- _ O
multiple -X- _ B-MethodName
- -X- _ I-MethodName
task -X- _ I-MethodName
and -X- _ I-MethodName
multipleteacher -X- _ I-MethodName
model -X- _ O
that -X- _ O
introduces -X- _ O
an -X- _ O
entity -X- _ O
similarity -X- _ O
evaluator -X- _ O
to -X- _ O
boost -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
student -X- _ O
recognizer -X- _ O
on -X- _ O
target -X- _ O
languages -X- _ O
. -X- _ O

Our -X- _ O
main -X- _ O
contributions -X- _ O
are -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O
• -X- _ O
We -X- _ O
propose -X- _ O
an -X- _ O
unsupervised -X- _ O
knowledge -X- _ O
dis -X- _ O
tillation -X- _ O
framework -X- _ O
for -X- _ O
cross -X- _ B-TaskName
- -X- _ I-TaskName
lingual -X- _ I-TaskName
named -X- _ I-TaskName
entity -X- _ I-TaskName
recognition -X- _ I-TaskName
and -X- _ O
develop -X- _ O
a -X- _ O
teaching -X- _ O
and -X- _ O
learning -X- _ O
procedure -X- _ O
under -X- _ O
this -X- _ O
framework -X- _ O
. -X- _ O

We -X- _ O
validate -X- _ O
the -X- _ O
model -X- _ O
performance -X- _ O
on -X- _ O
the -X- _ O
three -X- _ O
commonly -X- _ O
- -X- _ O
used -X- _ O
datasets -X- _ O
across -X- _ O
7 -X- _ O
languages -X- _ O
and -X- _ O
the -X- _ O
experimental -X- _ O
results -X- _ O
show -X- _ O
the -X- _ O
superiority -X- _ O
of -X- _ O
our -X- _ O
presented -X- _ O
MTMT -X- _ B-MethodName
model -X- _ O
. -X- _ O

In -X- _ O
the -X- _ O
student -X- _ O
model -X- _ O
, -X- _ O
we -X- _ O
then -X- _ O
borrow -X- _ O
the -X- _ O
idea -X- _ O
of -X- _ O
multitask -X- _ O
learning -X- _ O
to -X- _ O
incorporate -X- _ O
a -X- _ O
similarity -X- _ O
evaluation -X- _ O
task -X- _ O
as -X- _ O
an -X- _ O
auxiliary -X- _ O
task -X- _ O
into -X- _ O
the -X- _ O
entity -X- _ O
recognition -X- _ O
classifier -X- _ O
. -X- _ O

Specifically -X- _ O
, -X- _ O
we -X- _ O
first -X- _ O
introduce -X- _ O
the -X- _ O
knowledge -X- _ O
distillation -X- _ O
to -X- _ O
build -X- _ O
entity -X- _ O
recognizer -X- _ O
and -X- _ O
similarity -X- _ O
evaluator -X- _ O
teachers -X- _ O
in -X- _ O
the -X- _ O
source -X- _ O
language -X- _ O
and -X- _ O
transfer -X- _ O
the -X- _ O
learned -X- _ O
patterns -X- _ O
to -X- _ O
the -X- _ O
student -X- _ O
in -X- _ O
the -X- _ O
target -X- _ O
language -X- _ O
. -X- _ O

To -X- _ O
leverage -X- _ O
the -X- _ O
similarity -X- _ O
between -X- _ O
the -X- _ O
tokens -X- _ O
of -X- _ O
the -X- _ O
source -X- _ O
languages -X- _ O
, -X- _ O
we -X- _ O
design -X- _ O
an -X- _ O
multiple -X- _ B-MethodName
- -X- _ I-MethodName
task -X- _ I-MethodName
and -X- _ I-MethodName
multiple -X- _ I-MethodName
- -X- _ I-MethodName
teacher -X- _ I-MethodName
model -X- _ O
( -X- _ O
short -X- _ O
as -X- _ O
MTMT -X- _ B-MethodName
, -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
helps -X- _ O
the -X- _ O
NER -X- _ O
learning -X- _ O
process -X- _ O
on -X- _ O
the -X- _ O
target -X- _ O
languages -X- _ O
. -X- _ O

Then -X- _ O
“ -X- _ O
Arévalo -X- _ O
” -X- _ O
can -X- _ O
be -X- _ O
recognized -X- _ O
correctly -X- _ O
as -X- _ O
LOC -X- _ O
type -X- _ O
under -X- _ O
the -X- _ O
supervisory -X- _ O
signal -X- _ O
using -X- _ O
the -X- _ O
similarity -X- _ O
between -X- _ O
“ -X- _ O
Viena -X- _ O
” -X- _ O
and -X- _ O
“ -X- _ O
Madrid -X- _ O
” -X- _ O
. -X- _ O

Also -X- _ O
, -X- _ O
the -X- _ O
tokens -X- _ O
“ -X- _ O
Viena -X- _ O
” -X- _ O
and -X- _ O
“ -X- _ O
Madrid -X- _ O
” -X- _ O
are -X- _ O
recognized -X- _ O
correctly -X- _ O
as -X- _ O
LOC -X- _ O
type -X- _ O
using -X- _ O
the -X- _ O
same -X- _ O
English -X- _ O
model -X- _ O
mentioned -X- _ O
above -X- _ O
. -X- _ O

" -X- _ O
, -X- _ O
and -X- _ O
“ -X- _ O
Madrid -X- _ O
” -X- _ O
from -X- _ O
sentence -X- _ O
“ -X- _ O
Madrid -X- _ O
, -X- _ O
23 -X- _ O
may -X- _ O
( -X- _ O
EFE -X- _ O
) -X- _ O
. -X- _ O
” -X- _ O
. -X- _ O

In -X- _ O
the -X- _ O
meantime -X- _ O
, -X- _ O
the -X- _ O
token -X- _ O
“ -X- _ O
Arévalo -X- _ O
” -X- _ O
has -X- _ O
high -X- _ O
similarity -X- _ O
scores -X- _ O
with -X- _ O
the -X- _ O
Spanish -X- _ O
tokens -X- _ O
“ -X- _ O
Viena -X- _ O
” -X- _ O
from -X- _ O
sentence -X- _ O
“ -X- _ O
Viena -X- _ O
, -X- _ O
23 -X- _ O
may -X- _ O
( -X- _ O
EFE -X- _ O
) -X- _ O
. -X- _ O

Given -X- _ O
a -X- _ O
Spanish -X- _ O
sentence -X- _ O
“ -X- _ O
Arévalo -X- _ O
( -X- _ O
Avila -X- _ O
) -X- _ O
, -X- _ O
23 -X- _ O
may -X- _ O
( -X- _ O
EFE -X- _ O
) -X- _ O
. -X- _ O
” -X- _ O
, -X- _ O
the -X- _ O
token -X- _ O
“ -X- _ O
Arévalo -X- _ O
” -X- _ O
is -X- _ O
recognized -X- _ O
as -X- _ O
ORG -X- _ O
type -X- _ O
using -X- _ O
the -X- _ O
learned -X- _ O
model -X- _ O
from -X- _ O
the -X- _ O
English -X- _ O
domain -X- _ O
. -X- _ O

Here -X- _ O
we -X- _ O
give -X- _ O
a -X- _ O
concrete -X- _ O
example -X- _ O
to -X- _ O
illustrate -X- _ O
the -X- _ O
importance -X- _ O
of -X- _ O
similarity -X- _ O
between -X- _ O
every -X- _ O
two -X- _ O
tokens -X- _ O
under -X- _ O
the -X- _ O
situation -X- _ O
when -X- _ O
only -X- _ O
the -X- _ O
English -X- _ O
data -X- _ O
is -X- _ O
labeled -X- _ O
. -X- _ O

Due -X- _ O
to -X- _ O
the -X- _ O
distributed -X- _ O
representation -X- _ O
of -X- _ O
natural -X- _ O
languages -X- _ O
, -X- _ O
the -X- _ O
relatedness -X- _ O
among -X- _ O
the -X- _ O
embedding -X- _ O
of -X- _ O
target -X- _ O
languages -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
measured -X- _ O
by -X- _ O
the -X- _ O
similarity -X- _ O
, -X- _ O
can -X- _ O
be -X- _ O
utilized -X- _ O
to -X- _ O
further -X- _ O
boost -X- _ O
the -X- _ O
learned -X- _ O
encoder -X- _ O
and -X- _ O
improve -X- _ O
the -X- _ O
final -X- _ O
NER -X- _ B-TaskName
performance -X- _ O
on -X- _ O
target -X- _ O
languages -X- _ O
. -X- _ O

Although -X- _ O
the -X- _ O
above -X- _ O
- -X- _ O
mentioned -X- _ O
models -X- _ O
solve -X- _ O
the -X- _ O
cross -X- _ B-TaskName
- -X- _ I-TaskName
lingual -X- _ I-TaskName
NER -X- _ I-TaskName
problem -X- _ O
to -X- _ O
some -X- _ O
extent -X- _ O
, -X- _ O
the -X- _ O
auxiliary -X- _ O
tasks -X- _ O
, -X- _ O
as -X- _ O
in -X- _ O
multi -X- _ O
- -X- _ O
task -X- _ O
learning -X- _ O
, -X- _ O
have -X- _ O
not -X- _ O
been -X- _ O
studied -X- _ O
in -X- _ O
this -X- _ O
problem -X- _ O
. -X- _ O

2021 -X- _ O
) -X- _ O
. -X- _ O

Knowledge -X- _ O
distillation -X- _ O
based -X- _ O
models -X- _ O
train -X- _ O
a -X- _ O
student -X- _ O
model -X- _ O
using -X- _ O
soft -X- _ O
labels -X- _ O
of -X- _ O
the -X- _ O
target -X- _ O
language -X- _ O
( -X- _ O
Wu -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2020a -X- _ O
, -X- _ O
b -X- _ O
; -X- _ O
Chen -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Liang -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
170 -X- _ O
Proceedings -X- _ O
of -X- _ O
the -X- _ O
60th -X- _ O
Annual -X- _ O
Meeting -X- _ O
of -X- _ O
the -X- _ O
Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
Volume -X- _ O
1 -X- _ O
: -X- _ O
Long -X- _ O
Papers -X- _ O
, -X- _ O
pages -X- _ O
170 -X- _ O
- -X- _ O
179 -X- _ O
May -X- _ O
22 -X- _ O
- -X- _ O
27 -X- _ O
, -X- _ O
2022 -X- _ O
c -X- _ O
2022 -X- _ O
Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O

( -X- _ O
Mayhew -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2017 -X- _ O
; -X- _ O
Xie -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Wu -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2020b -X- _ O
) -X- _ O
. -X- _ O

Translation -X- _ O
based -X- _ O
models -X- _ O
generate -X- _ O
pseudo -X- _ O
labeled -X- _ O
target -X- _ O
language -X- _ O
data -X- _ O
to -X- _ O
train -X- _ O
the -X- _ O
cross -X- _ B-TaskName
- -X- _ I-TaskName
lingual -X- _ I-TaskName
NER -X- _ I-TaskName
model -X- _ O
, -X- _ O
but -X- _ O
the -X- _ O
noise -X- _ O
from -X- _ O
translation -X- _ O
process -X- _ O
restrains -X- _ O
its -X- _ O
performance -X- _ O
. -X- _ O

Shared -X- _ O
feature -X- _ O
space -X- _ O
based -X- _ O
models -X- _ O
exploit -X- _ O
language -X- _ O
- -X- _ O
independent -X- _ O
features -X- _ O
, -X- _ O
which -X- _ O
lacks -X- _ O
the -X- _ O
domain -X- _ O
- -X- _ O
specific -X- _ O
features -X- _ O
for -X- _ O
the -X- _ O
target -X- _ O
language -X- _ O
( -X- _ O
Tsai -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2016 -X- _ O
; -X- _ O
Wu -X- _ O
and -X- _ O
Dredze -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Keung -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O

Existing -X- _ O
models -X- _ O
can -X- _ O
be -X- _ O
separated -X- _ O
into -X- _ O
three -X- _ O
categories -X- _ O
, -X- _ O
shared -X- _ O
feature -X- _ O
space -X- _ O
based -X- _ O
, -X- _ O
translation -X- _ O
based -X- _ O
and -X- _ O
knowledge -X- _ O
distillation -X- _ O
based -X- _ O
. -X- _ O

Introduction -X- _ O
∗ -X- _ O
NERstu -X- _ O
Many -X- _ O
studies -X- _ O
have -X- _ O
been -X- _ O
done -X- _ O
to -X- _ O
solve -X- _ O
this -X- _ O
crosslingual -X- _ B-TaskName
NER -X- _ I-TaskName
problem -X- _ I-TaskName
. -X- _ O

With -X- _ O
the -X- _ O
help -X- _ O
of -X- _ O
transfer -X- _ O
learning -X- _ O
( -X- _ O
Ruder -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
and -X- _ O
multilingual -X- _ B-MethodName
BERT -X- _ I-MethodName
( -X- _ O
short -X- _ O
as -X- _ O
mBERT -X- _ B-MethodName
) -X- _ O
( -X- _ O
Devlin -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
Corresponding -X- _ O
author -X- _ O
{ -X- _ O
X -X- _ O
, -X- _ O
P}tgt -X- _ O
NER -X- _ B-TaskName

This -X- _ O
situation -X- _ O
is -X- _ O
more -X- _ O
severe -X- _ O
for -X- _ O
zero -X- _ O
- -X- _ O
resource -X- _ O
languages -X- _ O
. -X- _ O

However -X- _ O
, -X- _ O
since -X- _ O
deep -X- _ O
neural -X- _ O
networks -X- _ O
highly -X- _ O
rely -X- _ O
on -X- _ O
a -X- _ O
large -X- _ O
amount -X- _ O
of -X- _ O
labelled -X- _ O
training -X- _ O
data -X- _ O
, -X- _ O
the -X- _ O
annotation -X- _ O
acquiring -X- _ O
process -X- _ O
is -X- _ O
expensive -X- _ O
and -X- _ O
time -X- _ O
consuming -X- _ O
. -X- _ O

The -X- _ O
exploiting -X- _ O
of -X- _ O
deep -X- _ O
neural -X- _ O
networks -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
Bi -X- _ B-MethodName
- -X- _ I-MethodName
LSTM -X- _ I-MethodName
- -X- _ I-MethodName
CRF -X- _ I-MethodName
( -X- _ O
Lample -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
, -X- _ O
Bi -X- _ B-MethodName
- -X- _ I-MethodName
LSTM -X- _ I-MethodName
- -X- _ I-MethodName
CNN -X- _ I-MethodName
( -X- _ O
Chiu -X- _ O
and -X- _ O
Nichols -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
makes -X- _ O
this -X- _ O
task -X- _ O
achieve -X- _ O
significant -X- _ O
performances -X- _ O
. -X- _ O

Named -X- _ B-TaskName
entity -X- _ I-TaskName
recognition -X- _ I-TaskName
, -X- _ O
NER -X- _ B-TaskName
in -X- _ O
short -X- _ O
, -X- _ O
refers -X- _ O
to -X- _ O
identifying -X- _ O
entity -X- _ O
types -X- _ O
, -X- _ O
i.e. -X- _ O
location -X- _ O
, -X- _ O
person -X- _ O
, -X- _ O
organization -X- _ O
, -X- _ O
etc -X- _ O
. -X- _ O
, -X- _ O
in -X- _ O
a -X- _ O
given -X- _ O
sentence -X- _ O
. -X- _ O

2019 -X- _ O
) -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
possible -X- _ O
to -X- _ O
transfer -X- _ O
the -X- _ O
annotated -X- _ O
training -X- _ O
samples -X- _ O
or -X- _ O
trained -X- _ O
models -X- _ O
from -X- _ O
a -X- _ O
rich -X- _ O
- -X- _ O
resource -X- _ O
domain -X- _ O
to -X- _ O
a -X- _ O
zero -X- _ O
- -X- _ O
resource -X- _ O
domain -X- _ O
. -X- _ O

Empirical -X- _ O
studies -X- _ O
on -X- _ O
the -X- _ O
three -X- _ O
datasets -X- _ O
across -X- _ O
7 -X- _ O
different -X- _ O
languages -X- _ O
confirm -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
the -X- _ O
proposed -X- _ O
model -X- _ O
. -X- _ O

Then -X- _ O
, -X- _ O
two -X- _ O
tasks -X- _ O
in -X- _ O
the -X- _ O
student -X- _ O
model -X- _ O
are -X- _ O
supervised -X- _ O
by -X- _ O
these -X- _ O
teachers -X- _ O
simultaneously -X- _ O
. -X- _ O

Specifically -X- _ O
, -X- _ O
an -X- _ O
entity -X- _ O
recognizer -X- _ O
and -X- _ O
a -X- _ O
similarity -X- _ O
evaluator -X- _ O
are -X- _ O
first -X- _ O
trained -X- _ O
in -X- _ O
parallel -X- _ O
as -X- _ O
two -X- _ O
teachers -X- _ O
from -X- _ O
the -X- _ O
source -X- _ O
domain -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
study -X- _ O
, -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
knowledge -X- _ O
distillation -X- _ O
framework -X- _ O
and -X- _ O
multitask -X- _ O
learning -X- _ O
, -X- _ O
we -X- _ O
introduce -X- _ O
the -X- _ O
similarity -X- _ O
metric -X- _ O
model -X- _ O
as -X- _ O
an -X- _ O
auxiliary -X- _ O
task -X- _ O
to -X- _ O
improve -X- _ O
the -X- _ O
cross -X- _ B-TaskName
- -X- _ I-TaskName
lingual -X- _ I-TaskName
NER -X- _ I-TaskName
performance -X- _ O
on -X- _ O
the -X- _ O
target -X- _ O
domain -X- _ O
. -X- _ O

However -X- _ O
, -X- _ O
existing -X- _ O
cross -X- _ O
- -X- _ O
lingual -X- _ O
distillation -X- _ O
models -X- _ O
merely -X- _ O
consider -X- _ O
the -X- _ O
potential -X- _ O
transferability -X- _ O
between -X- _ O
two -X- _ O
identical -X- _ O
single -X- _ O
tasks -X- _ O
across -X- _ O
both -X- _ O
domains -X- _ O
. -X- _ O

Knowledge -X- _ O
distillation -X- _ O
using -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
multilingual -X- _ O
language -X- _ O
models -X- _ O
between -X- _ O
source -X- _ O
and -X- _ O
target -X- _ O
languages -X- _ O
have -X- _ O
shown -X- _ O
their -X- _ O
superiority -X- _ O
in -X- _ O
transfer -X- _ O
. -X- _ O

Abstract -X- _ O
NERstu -X- _ O
training -X- _ O
Cross -X- _ B-TaskName
- -X- _ I-TaskName
lingual -X- _ I-TaskName
named -X- _ I-TaskName
entity -X- _ I-TaskName
recognition -X- _ I-TaskName
task -X- _ O
is -X- _ O
one -X- _ O
of -X- _ O
the -X- _ O
critical -X- _ O
problems -X- _ O
for -X- _ O
evaluating -X- _ O
the -X- _ O
potential -X- _ O
transfer -X- _ O
learning -X- _ O
techniques -X- _ O
on -X- _ O
low -X- _ O
resource -X- _ O
languages -X- _ O
. -X- _ O

SKLSDE -X- _ O
, -X- _ O
School -X- _ O
of -X- _ O
Computer -X- _ O
Science -X- _ O
and -X- _ O
Engineering -X- _ O
, -X- _ O
Beihang -X- _ O
University -X- _ O
, -X- _ O
Beijing -X- _ O
, -X- _ O
China -X- _ O
2 -X- _ O
Hangzhou -X- _ O
Innovation -X- _ O
Institute -X- _ O
, -X- _ O
Beihang -X- _ O
University -X- _ O
, -X- _ O
Hangzhou -X- _ O
, -X- _ O
China -X- _ O
{ -X- _ O
lizhuoranget -X- _ O
, -X- _ O
hucm}@buaa.edu.cn -X- _ O
, -X- _ O
wenyi.qin@hotmail.com -X- _ O
{ -X- _ O
guoxh -X- _ O
, -X- _ O
chenjf -X- _ O
, -X- _ O
zhangrc}@act.buaa.edu.cn -X- _ O

An -X- _ O
Unsupervised -X- _ O
Multiple -X- _ B-MethodName
- -X- _ I-MethodName
Task -X- _ I-MethodName
and -X- _ I-MethodName
Multiple -X- _ I-MethodName
- -X- _ I-MethodName
Teacher -X- _ I-MethodName
Model -X- _ O
for -X- _ O
Cross -X- _ B-TaskName
- -X- _ I-TaskName
lingual -X- _ I-TaskName
Named -X- _ I-TaskName
Entity -X- _ I-TaskName
Recognition -X- _ I-TaskName
Zhuoran -X- _ O
Li1 -X- _ O
, -X- _ O
Chunming -X- _ O
Hu1∗ -X- _ O
, -X- _ O
Xiaohui -X- _ O
Guo2 -X- _ O
Junfan -X- _ O
Chen1 -X- _ O
, -X- _ O
Wenyi -X- _ O
Qin1 -X- _ O
, -X- _ O
Richong -X- _ O
Zhang1 -X- _ O
1 -X- _ O

