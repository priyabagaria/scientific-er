-DOCSTART- -X- O

17 -X- _ O

16 -X- _ O

15 -X- _ O

14 -X- _ O

A.8 -X- _ O
E -X- _ O
XAMPLE -X- _ O
P -X- _ O
REDICTIONS -X- _ O
In -X- _ O
Figures -X- _ O
3 -X- _ O
, -X- _ O
4 -X- _ O
, -X- _ O
5 -X- _ O
, -X- _ O
6 -X- _ O
, -X- _ O
7 -X- _ O
we -X- _ O
show -X- _ O
predictions -X- _ O
by -X- _ O
our -X- _ O
model -X- _ O
that -X- _ O
shows -X- _ O
the -X- _ O
learned -X- _ O
execution -X- _ O
of -X- _ O
various -X- _ O
modules -X- _ O
defined -X- _ O
in -X- _ O
the -X- _ O
paper -X- _ O
. -X- _ O

This -X- _ O
is -X- _ O
exactly -X- _ O
the -X- _ O
same -X- _ O
as -X- _ O
previous -X- _ O
for -X- _ O
find -X- _ O
- -X- _ O
num -X- _ O
module -X- _ O
calls -X- _ O
by -X- _ O
compare -X- _ O
- -X- _ O
num -X- _ O
- -X- _ O
lt -X- _ O
. -X- _ O

3 -X- _ O
. -X- _ O
were -X- _ O
there -X- _ O
fewer -X- _ O
SPAN1 -X- _ O
or -X- _ O
SPAN2 -X- _ O
? -X- _ O

Similar -X- _ O
to -X- _ O
above -X- _ O
, -X- _ O
we -X- _ O
perform -X- _ O
fuzzy -X- _ O
matching -X- _ O
to -X- _ O
find -X- _ O
the -X- _ O
instance -X- _ O
of -X- _ O
EVENT1 -X- _ O
and -X- _ O
EVENT2 -X- _ O
in -X- _ O
the -X- _ O
paragraph -X- _ O
and -X- _ O
assume -X- _ O
that -X- _ O
the -X- _ O
closest -X- _ O
dates -X- _ O
should -X- _ O
be -X- _ O
the -X- _ O
output -X- _ O
of -X- _ O
the -X- _ O
two -X- _ O
find -X- _ O
- -X- _ O
date -X- _ O
module -X- _ O
calls -X- _ O
made -X- _ O
by -X- _ O
the -X- _ O
compare -X- _ O
- -X- _ O
date -X- _ O
- -X- _ O
lt -X- _ O
module -X- _ O
in -X- _ O
the -X- _ O
gold -X- _ O
program -X- _ O
. -X- _ O

2 -X- _ O
. -X- _ O
what -X- _ O
happened -X- _ O
first -X- _ O
EVENT1 -X- _ O
or -X- _ O
EVENT2 -X- _ O
? -X- _ O

We -X- _ O
find -X- _ O
all -X- _ O
instances -X- _ O
of -X- _ O
touchdown -X- _ O
/ -X- _ O
field -X- _ O
goal -X- _ O
in -X- _ O
the -X- _ O
passage -X- _ O
and -X- _ O
assume -X- _ O
that -X- _ O
the -X- _ O
number -X- _ O
appearing -X- _ O
closest -X- _ O
should -X- _ O
be -X- _ O
an -X- _ O
output -X- _ O
of -X- _ O
the -X- _ O
find -X- _ O
- -X- _ O
num -X- _ O
module -X- _ O
. -X- _ O

These -X- _ O
are -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O
1 -X- _ O
. -X- _ O
how -X- _ O
many -X- _ O
yards -X- _ O
was -X- _ O
the -X- _ O
longest -X- _ O
/ -X- _ O
shortest -X- _ O
{ -X- _ O
touchdown -X- _ O
, -X- _ O
field -X- _ O
goal -X- _ O
} -X- _ O
? -X- _ O

As -X- _ O
mentioned -X- _ O
in -X- _ O
Section -X- _ O
4.3 -X- _ O
, -X- _ O
we -X- _ O
heuristically -X- _ O
find -X- _ O
supervision -X- _ O
for -X- _ O
the -X- _ O
output -X- _ O
of -X- _ O
the -X- _ O
find -X- _ O
- -X- _ O
num -X- _ O
and -X- _ O
find -X- _ O
- -X- _ O
date -X- _ O
module -X- _ O
for -X- _ O
a -X- _ O
subset -X- _ O
of -X- _ O
questions -X- _ O
that -X- _ O
already -X- _ O
contain -X- _ O
question -X- _ O
program -X- _ O
supervision -X- _ O
. -X- _ O

A.7 -X- _ O
H -X- _ O
EURISTIC -X- _ O
I -X- _ O
NTERMEDIATE -X- _ O
M -X- _ O
ODULE -X- _ O
O -X- _ O
UTPUT -X- _ O
S -X- _ O
UPERVISION -X- _ O

5 -X- _ O
. -X- _ O
how -X- _ O
many -X- _ O
{ -X- _ O
field -X- _ O
goals -X- _ O
, -X- _ O
touchdowns -X- _ O
, -X- _ O
passes -X- _ O
} -X- _ O
were -X- _ O
scored -X- _ O
SPAN -X- _ O
? -X- _ O
count(filter(find -X- _ O
( -X- _ O
) -X- _ O
) -X- _ O
): -X- _ O
with -X- _ O
find -X- _ O
attention -X- _ O
on -X- _ O
{ -X- _ O
field -X- _ O
goals -X- _ O
, -X- _ O
touchdowns -X- _ O
, -X- _ O
passes -X- _ O
} -X- _ O
and -X- _ O
filter -X- _ O
attention -X- _ O
on -X- _ O
SPAN -X- _ O
. -X- _ O
6 -X- _ O
. -X- _ O
who -X- _ O
{ -X- _ O
kicked -X- _ O
, -X- _ O
caught -X- _ O
, -X- _ O
threw -X- _ O
, -X- _ O
scored -X- _ O
} -X- _ O
SPAN -X- _ O
? -X- _ O
span(relocate(filter(find -X- _ O
( -X- _ O
) -X- _ O
) -X- _ O
) -X- _ O
): -X- _ O
with -X- _ O
relocate -X- _ O
attention -X- _ O
on -X- _ O
{ -X- _ O
kicked -X- _ O
, -X- _ O
caught -X- _ O
, -X- _ O
threw -X- _ O
, -X- _ O
scored -X- _ O
} -X- _ O
, -X- _ O
find -X- _ O
attention -X- _ O
on -X- _ O
{ -X- _ O
touchdown -X- _ O
/ -X- _ O
field -X- _ O
goal -X- _ O
} -X- _ O
, -X- _ O
and -X- _ O
filter -X- _ O
attention -X- _ O
on -X- _ O
all -X- _ O
other -X- _ O
tokens -X- _ O
in -X- _ O
the -X- _ O
SPAN -X- _ O
. -X- _ O
13 -X- _ O

with -X- _ O
find -X- _ O
attention -X- _ O
on -X- _ O
touchdown -X- _ O
/ -X- _ O
field -X- _ O
goal -X- _ O
and -X- _ O
filter -X- _ O
attention -X- _ O
on -X- _ O
all -X- _ O
SPAN -X- _ O
tokens -X- _ O
. -X- _ O

find -X- _ O
- -X- _ O
num(find -X- _ O
- -X- _ O
max -X- _ O
- -X- _ O
num(filter(find -X- _ O
( -X- _ O
) -X- _ O
) -X- _ O
) -X- _ O
): -X- _ O

4 -X- _ O
. -X- _ O
how -X- _ O
many -X- _ O
yards -X- _ O
was -X- _ O
the -X- _ O
longest -X- _ O
{ -X- _ O
touchdown -X- _ O
/ -X- _ O
field -X- _ O
goal -X- _ O
} -X- _ O
SPAN -X- _ O
? -X- _ O

For -X- _ O
shortest -X- _ O
, -X- _ O
the -X- _ O
find -X- _ O
- -X- _ O
min -X- _ O
- -X- _ O
num -X- _ O
module -X- _ O
is -X- _ O
used -X- _ O
. -X- _ O

find -X- _ O
- -X- _ O
num(find -X- _ O
- -X- _ O
max -X- _ O
- -X- _ O
num(find -X- _ O
( -X- _ O
) -X- _ O
) -X- _ O
): -X- _ O
with -X- _ O
find -X- _ O
attention -X- _ O
on -X- _ O
touchdown -X- _ O
/ -X- _ O
field -X- _ O
goal -X- _ O
. -X- _ O

3 -X- _ O
. -X- _ O
how -X- _ O
many -X- _ O
yards -X- _ O
was -X- _ O
the -X- _ O
longest -X- _ O
{ -X- _ O
touchdown -X- _ O
/ -X- _ O
field -X- _ O
goal -X- _ O
} -X- _ O
? -X- _ O

Use -X- _ O
compare -X- _ O
- -X- _ O
num -X- _ O
- -X- _ O
gt -X- _ O
, -X- _ O
if -X- _ O
more -X- _ O
instead -X- _ O
of -X- _ O
fewer -X- _ O
. -X- _ O

2 -X- _ O
. -X- _ O
were -X- _ O
there -X- _ O
fewer -X- _ O
SPAN1 -X- _ O
or -X- _ O
SPAN2 -X- _ O
? -X- _ O
span(compare -X- _ O
- -X- _ O
num -X- _ O
- -X- _ O
lt(find -X- _ O
( -X- _ O
) -X- _ O
, -X- _ O
find -X- _ O
( -X- _ O
) -X- _ O
) -X- _ O
): -X- _ O
with -X- _ O
find -X- _ O
attentions -X- _ O
on -X- _ O
SPAN1 -X- _ O
and -X- _ O
SPAN2 -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O

Use -X- _ O
compare -X- _ O
- -X- _ O
date -X- _ O
- -X- _ O
gt -X- _ O
, -X- _ O
if -X- _ O
second -X- _ O
instead -X- _ O
of -X- _ O
first -X- _ O
. -X- _ O

The -X- _ O
following -X- _ O
patterns -X- _ O
are -X- _ O
used -X- _ O
to -X- _ O
extract -X- _ O
the -X- _ O
question -X- _ O
parse -X- _ O
supervision -X- _ O
for -X- _ O
the -X- _ O
training -X- _ O
data -X- _ O
: -X- _ O
1 -X- _ O
. -X- _ O
what -X- _ O
happened -X- _ O
first -X- _ O
SPAN1 -X- _ O
or -X- _ O
SPAN2 -X- _ O
? -X- _ O
span(compare -X- _ O
- -X- _ O
date -X- _ O
- -X- _ O
lt(find -X- _ O
( -X- _ O
) -X- _ O
, -X- _ O
find -X- _ O
( -X- _ O
) -X- _ O
) -X- _ O
): -X- _ O
with -X- _ O
find -X- _ O
attentions -X- _ O
on -X- _ O
SPAN1 -X- _ O
and -X- _ O
SPAN2 -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O

Since -X- _ O
the -X- _ O
predicted -X- _ O
attention -X- _ O
is -X- _ O
a -X- _ O
normalized -X- _ O
distribution -X- _ O
, -X- _ O
the -X- _ O
objective -X- _ O
increases -X- _ O
the -X- _ O
sum -X- _ O
of -X- _ O
log -X- _ O
- -X- _ O
probabilities -X- _ O
of -X- _ O
the -X- _ O
tokens -X- _ O
in -X- _ O
the -X- _ O
supervision -X- _ O
. -X- _ O

The -X- _ O
loss -X- _ O
against -X- _ O
the -X- _ O
predicted -X- _ O
attention -X- _ O
n -X- _ O
vector -X- _ O
α -X- _ O
is -X- _ O
, -X- _ O
Qloss -X- _ O
= -X- _ O
− -X- _ O
i=1 -X- _ O
αi∗ -X- _ O
log -X- _ O
αi -X- _ O
. -X- _ O

The -X- _ O
question -X- _ O
attention -X- _ O
supervision -X- _ O
is -X- _ O
providedPas -X- _ O
a -X- _ O
mutli -X- _ O
- -X- _ O
hot -X- _ O
vector -X- _ O
α∗ -X- _ O
∈ -X- _ O
{ -X- _ O
0 -X- _ O
, -X- _ O
1}n -X- _ O
. -X- _ O

We -X- _ O
also -X- _ O
add -X- _ O
a -X- _ O
loss -X- _ O
for -X- _ O
the -X- _ O
decoder -X- _ O
to -X- _ O
attend -X- _ O
to -X- _ O
the -X- _ O
tokens -X- _ O
in -X- _ O
the -X- _ O
question -X- _ O
attention -X- _ O
supervision -X- _ O
when -X- _ O
predicting -X- _ O
the -X- _ O
relevant -X- _ O
modules -X- _ O
. -X- _ O

A.6 -X- _ O
AUXILIARY -X- _ O
Q -X- _ O
UESTION -X- _ O
PARSE -X- _ O
S -X- _ O
UPERVISION -X- _ O
For -X- _ O
questions -X- _ O
with -X- _ O
parse -X- _ O
supervision -X- _ O
z∗ -X- _ O
, -X- _ O
we -X- _ O
decouple -X- _ O
the -X- _ O
marginal -X- _ O
likelihood -X- _ O
into -X- _ O
two -X- _ O
maximum -X- _ O
likelihood -X- _ O
objectives -X- _ O
, -X- _ O
p(z∗ -X- _ O
|q -X- _ O
) -X- _ O
and -X- _ O
p(y -X- _ O
∗ -X- _ O
|z∗ -X- _ O
) -X- _ O
. -X- _ O

A -X- _ O
softmax -X- _ O
operation -X- _ O
on -X- _ O
these -X- _ O
scores -X- _ O
gives -X- _ O
the -X- _ O
output -X- _ O
probabilities -X- _ O
. -X- _ O

The -X- _ O
input -X- _ O
paragraph -X- _ O
attention -X- _ O
is -X- _ O
first -X- _ O
scaled -X- _ O
using -X- _ O
[ -X- _ O
1 -X- _ O
, -X- _ O
2 -X- _ O
, -X- _ O
5 -X- _ O
, -X- _ O
10 -X- _ O
] -X- _ O
, -X- _ O
then -X- _ O
a -X- _ O
bidirectional -X- _ O
- -X- _ O
GRU -X- _ O
represents -X- _ O
each -X- _ O
attention -X- _ O
as -X- _ O
a -X- _ O
hidden -X- _ O
vector -X- _ O
, -X- _ O
and -X- _ O
a -X- _ O
single -X- _ B-HyperparameterValue
- -X- _ O
layer -X- _ B-HyperparameterName
feed -X- _ O
- -X- _ O
forward -X- _ O
network -X- _ O
maps -X- _ O
this -X- _ O
to -X- _ O
2 -X- _ O
scores -X- _ O
, -X- _ O
for -X- _ O
span -X- _ O
start -X- _ O
and -X- _ O
end -X- _ O
. -X- _ O

The -X- _ O
span -X- _ O
module -X- _ O
is -X- _ O
implemented -X- _ O
similar -X- _ O
to -X- _ O
the -X- _ O
count -X- _ O
module -X- _ O
. -X- _ O

A.5 -X- _ O
S -X- _ O
PAN -X- _ O
M -X- _ O
ODULE -X- _ O

The -X- _ O
final -X- _ O
feed -X- _ O
- -X- _ O
forward -X- _ O
comprises -X- _ O
of -X- _ O
a -X- _ O
single -X- _ B-HyperparameterValue
- -X- _ O
layer -X- _ B-HyperparameterName
to -X- _ O
map -X- _ O
the -X- _ O
output -X- _ O
of -X- _ O
the -X- _ O
countGRU -X- _ O
into -X- _ O
a -X- _ O
scalar -X- _ O
score -X- _ O
. -X- _ O

The -X- _ O
countGRU -X- _ O
in -X- _ O
the -X- _ O
count -X- _ O
module -X- _ O
( -X- _ O
spanGRU -X- _ O
– -X- _ O
span -X- _ O
module -X- _ O
) -X- _ O
is -X- _ O
a -X- _ O
2 -X- _ B-HyperparameterValue
- -X- _ O
layer -X- _ B-HyperparameterName
, -X- _ O
bi -X- _ O
- -X- _ O
directional -X- _ O
GRU -X- _ O
with -X- _ O
input -X- _ B-HyperparameterName
- -X- _ I-HyperparameterName
dim -X- _ I-HyperparameterName
= -X- _ O
4 -X- _ B-HyperparameterValue
and -X- _ O
output -X- _ B-HyperparameterName
- -X- _ I-HyperparameterName
dim -X- _ I-HyperparameterName
= -X- _ O
20 -X- _ B-HyperparameterValue
. -X- _ O

We -X- _ O
train -X- _ O
the -X- _ O
parameters -X- _ O
of -X- _ O
the -X- _ O
count -X- _ O
module -X- _ O
using -X- _ O
these -X- _ O
generated -X- _ O
instances -X- _ O
using -X- _ O
L2 -X- _ O
-loss -X- _ O
between -X- _ O
the -X- _ O
true -X- _ O
count -X- _ O
value -X- _ O
and -X- _ O
the -X- _ O
predicted -X- _ O
cv -X- _ O
. -X- _ O

We -X- _ O
then -X- _ O
add -X- _ O
0 -X- _ O
- -X- _ O
mean -X- _ O
, -X- _ O
0.01 -X- _ O
- -X- _ O
variance -X- _ O
gaussian -X- _ O
noise -X- _ O
to -X- _ O
all -X- _ O
elements -X- _ O
in -X- _ O
x -X- _ O
and -X- _ O
normalize -X- _ O
to -X- _ O
make -X- _ O
the -X- _ O
normalized -X- _ O
attention -X- _ O
vector -X- _ O
that -X- _ O
can -X- _ O
be -X- _ O
input -X- _ O
to -X- _ O
the -X- _ O
count -X- _ O
module -X- _ O
. -X- _ O

For -X- _ O
all -X- _ O
these -X- _ O
y -X- _ O
spans -X- _ O
in -X- _ O
x -X- _ O
, -X- _ O
we -X- _ O
put -X- _ O
a -X- _ O
value -X- _ O
of -X- _ O
1.0 -X- _ O
and -X- _ O
zeros -X- _ O
everywhere -X- _ O
else -X- _ O
. -X- _ O

We -X- _ O
then -X- _ O
sample -X- _ O
y -X- _ O
span -X- _ O
- -X- _ O
lengths -X- _ O
between -X- _ O
5 -X- _ O
− -X- _ O
15 -X- _ O
and -X- _ O
also -X- _ O
sample -X- _ O
y -X- _ O
non -X- _ O
- -X- _ O
overlapping -X- _ O
span -X- _ O
- -X- _ O
positions -X- _ O
in -X- _ O
the -X- _ O
attention -X- _ O
vector -X- _ O
x. -X- _ O

This -X- _ O
is -X- _ O
generated -X- _ O
by -X- _ O
sampling -X- _ O
m -X- _ O
uniformly -X- _ O
between -X- _ O
200 -X- _ O
− -X- _ O
600 -X- _ O
, -X- _ O
then -X- _ O
sampling -X- _ O
a -X- _ O
count -X- _ O
value -X- _ O
y -X- _ O
uniformly -X- _ O
in -X- _ O
[ -X- _ O
0 -X- _ O
, -X- _ O
9 -X- _ O
] -X- _ O
. -X- _ O

[ -X- _ O
0 -X- _ O
, -X- _ O
9 -X- _ O
] -X- _ O
. -X- _ O

Rm -X- _ O
and -X- _ O
a -X- _ O
count -X- _ O
value -X- _ O
y -X- _ O
∈ -X- _ O

We -X- _ O
generate -X- _ O
synthetic -X- _ O
data -X- _ O
to -X- _ O
pre -X- _ O
- -X- _ O
train -X- _ O
this -X- _ O
module -X- _ O
; -X- _ O
each -X- _ O
instance -X- _ O
is -X- _ O
a -X- _ O
normalized -X- _ O
- -X- _ O
attention -X- _ O
vector -X- _ O
x -X- _ O
= -X- _ O

Rm -X- _ O
X -X- _ O
cv -X- _ O
= -X- _ O
countscores -X- _ O
∈ -X- _ O
R -X- _ O

∈ -X- _ O

 -X- _ O
 -X- _ O
countscores -X- _ O
= -X- _ O
σ -X- _ O
F -X- _ O
F -X- _ O
( -X- _ O
countGRU(Pscaled -X- _ O
) -X- _ O
) -X- _ O

Published -X- _ O
as -X- _ O
a -X- _ O
conference -X- _ O
paper -X- _ O
at -X- _ O
ICLR -X- _ O
2020 -X- _ O
are -X- _ O
summed -X- _ O
to -X- _ O
compute -X- _ O
a -X- _ O
count -X- _ O
value -X- _ O
, -X- _ O
cv -X- _ O
. -X- _ O

These -X- _ O
scores -X- _ O
3 -X- _ O
4 -X- _ O
https://spacy.io/ -X- _ O
https://github.com/scrapinghub/dateparser -X- _ O
12 -X- _ O

A -X- _ O
single -X- _ B-HyperparameterValue
- -X- _ O
layer -X- _ B-HyperparameterName
feed -X- _ O
- -X- _ O
forward -X- _ O
network -X- _ O
maps -X- _ O
this -X- _ O
representation -X- _ O
to -X- _ O
a -X- _ O
soft -X- _ O
0/1 -X- _ O
score -X- _ O
to -X- _ O
indicate -X- _ O
the -X- _ O
presence -X- _ O
of -X- _ O
a -X- _ O
span -X- _ O
surrounding -X- _ O
it -X- _ O
. -X- _ O

A -X- _ O
bidirectional -X- _ O
- -X- _ O
GRU -X- _ O
then -X- _ O
represents -X- _ O
each -X- _ O
token -X- _ O
attention -X- _ O
as -X- _ O
a -X- _ O
hidden -X- _ O
vector -X- _ O
ht -X- _ O
. -X- _ O

The -X- _ O
module -X- _ O
first -X- _ O
scales -X- _ O
the -X- _ O
attention -X- _ O
using -X- _ O
the -X- _ O
values -X- _ O
[ -X- _ O
1 -X- _ O
, -X- _ O
2 -X- _ O
, -X- _ O
5 -X- _ O
, -X- _ O
10 -X- _ O
] -X- _ O
to -X- _ O
convert -X- _ O
it -X- _ O
into -X- _ O
a -X- _ O
matrix -X- _ O
Pscaled -X- _ O
∈ -X- _ O
Rm×4 -X- _ O
. -X- _ O

To -X- _ O
re -X- _ O
- -X- _ O
iterate -X- _ O
, -X- _ O
the -X- _ O
module -X- _ O
gets -X- _ O
as -X- _ O
input -X- _ O
a -X- _ O
paragraph -X- _ O
attention -X- _ O
P -X- _ O
∈ -X- _ O
Rm -X- _ O
. -X- _ O

As -X- _ O
mentioned -X- _ O
in -X- _ O
the -X- _ O
paper -X- _ O
, -X- _ O
training -X- _ O
the -X- _ O
count -X- _ O
module -X- _ O
is -X- _ O
challenging -X- _ O
and -X- _ O
found -X- _ O
that -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
the -X- _ O
parameters -X- _ O
of -X- _ O
the -X- _ O
count -X- _ O
module -X- _ O
helps -X- _ O
. -X- _ O

The -X- _ O
total -X- _ O
number -X- _ O
of -X- _ O
date -X- _ O
- -X- _ O
tokens -X- _ O
is -X- _ O
denoted -X- _ O
by -X- _ O
Dtokens -X- _ O
A.4 -X- _ O
P -X- _ O
RE -X- _ O
- -X- _ O
TRAINING -X- _ O
C -X- _ O
OUNT -X- _ O
M -X- _ O
ODULE -X- _ O

For -X- _ O
example -X- _ O
, -X- _ O
a -X- _ O
date -X- _ O
mention -X- _ O
“ -X- _ O
19th -X- _ O
November -X- _ O
, -X- _ O
1961 -X- _ O
” -X- _ O
would -X- _ O
be -X- _ O
normalized -X- _ O
to -X- _ O
( -X- _ O
19 -X- _ O
, -X- _ O
11 -X- _ O
, -X- _ O
1961 -X- _ O
) -X- _ O
( -X- _ O
day -X- _ O
, -X- _ O
month -X- _ O
, -X- _ O
year -X- _ O
) -X- _ O
. -X- _ O

To -X- _ O
normalize -X- _ O
the -X- _ O
date -X- _ O
mentions -X- _ O
we -X- _ O
use -X- _ O
an -X- _ O
off -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
shelf -X- _ O
date -X- _ O
- -X- _ O
parser4 -X- _ O
. -X- _ O

To -X- _ O
extract -X- _ O
dates -X- _ O
from -X- _ O
the -X- _ O
paragraph -X- _ O
, -X- _ O
we -X- _ O
run -X- _ O
the -X- _ O
spaCy -X- _ O
- -X- _ O
NER3 -X- _ O
and -X- _ O
collect -X- _ O
all -X- _ O
“ -X- _ O
DATE -X- _ O
” -X- _ O
mentions -X- _ O
. -X- _ O

We -X- _ O
do -X- _ O
not -X- _ O
normalize -X- _ O
numbers -X- _ O
based -X- _ O
on -X- _ O
their -X- _ O
units -X- _ O
and -X- _ O
leave -X- _ O
it -X- _ O
for -X- _ O
future -X- _ O
work -X- _ O
. -X- _ O

The -X- _ O
total -X- _ O
number -X- _ O
of -X- _ O
number -X- _ O
- -X- _ O
tokens -X- _ O
in -X- _ O
the -X- _ O
paragraph -X- _ O
is -X- _ O
denoted -X- _ O
by -X- _ O
Ntokens -X- _ O
. -X- _ O

For -X- _ O
example -X- _ O
, -X- _ O
200 -X- _ O
in -X- _ O
“ -X- _ O
200 -X- _ O
women -X- _ O
” -X- _ O
. -X- _ O

For -X- _ O
numbers -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
a -X- _ O
simple -X- _ O
strategy -X- _ O
where -X- _ O
all -X- _ O
tokens -X- _ O
in -X- _ O
the -X- _ O
paragraph -X- _ O
that -X- _ O
can -X- _ O
be -X- _ O
parsed -X- _ O
as -X- _ O
a -X- _ O
number -X- _ O
are -X- _ O
extracted -X- _ O
. -X- _ O

A.3 -X- _ O
N -X- _ O
UMBER -X- _ O
AND -X- _ O
DATE -X- _ O
PARSING -X- _ O
We -X- _ O
pre -X- _ O
- -X- _ O
process -X- _ O
the -X- _ O
paragraphs -X- _ O
to -X- _ O
extract -X- _ O
the -X- _ O
numbers -X- _ O
and -X- _ O
dates -X- _ O
in -X- _ O
them -X- _ O
. -X- _ O

Optmization -X- _ O
is -X- _ O
performed -X- _ O
using -X- _ O
the -X- _ O
Adam -X- _ B-HyperparameterName
algorithm -X- _ O
with -X- _ O
a -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
of -X- _ O
0.001 -X- _ B-HyperparameterValue
or -X- _ O
using -X- _ O
BERT -X- _ O
’s -X- _ O
optimizer -X- _ O
with -X- _ O
a -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
of -X- _ O
1e -X- _ B-HyperparameterValue
− -X- _ I-HyperparameterValue
5 -X- _ I-HyperparameterValue
. -X- _ O

We -X- _ O
use -X- _ O
a -X- _ O
beam -X- _ B-HyperparameterName
- -X- _ I-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
4 -X- _ B-HyperparameterValue
for -X- _ O
the -X- _ O
approximate -X- _ O
maximum -X- _ O
marginal -X- _ O
likelihood -X- _ O
objective -X- _ O
. -X- _ O

As -X- _ O
the -X- _ O
memory -X- _ O
- -X- _ O
state -X- _ O
for -X- _ O
the -X- _ O
zero -X- _ O
- -X- _ O
eth -X- _ O
time -X- _ O
- -X- _ O
step -X- _ O
in -X- _ O
the -X- _ O
decoder -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
last -X- _ O
hidden -X- _ O
- -X- _ O
state -X- _ O
of -X- _ O
the -X- _ O
question -X- _ O
encoder -X- _ O
GRU -X- _ O
, -X- _ O
or -X- _ O
the -X- _ O
[ -X- _ O
CLS -X- _ O
] -X- _ O
embedding -X- _ O
for -X- _ O
the -X- _ O
BERT -X- _ O
- -X- _ O
based -X- _ O
model -X- _ O
. -X- _ O

The -X- _ O
attention -X- _ O
is -X- _ O
computed -X- _ O
as -X- _ O
a -X- _ O
dot -X- _ O
- -X- _ O
product -X- _ O
between -X- _ O
the -X- _ O
decoder -X- _ O
hidden -X- _ O
- -X- _ O
state -X- _ O
and -X- _ O
the -X- _ O
encoders -X- _ O
hidden -X- _ O
states -X- _ O
which -X- _ O
is -X- _ O
normalized -X- _ O
using -X- _ O
the -X- _ O
softmax -X- _ O
operation -X- _ O
. -X- _ O

For -X- _ O
each -X- _ O
module -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
a -X- _ O
100 -X- _ B-HyperparameterValue
- -X- _ O
dimensional -X- _ B-HyperparameterName
embedding -X- _ O
to -X- _ O
present -X- _ O
it -X- _ O
as -X- _ O
an -X- _ O
action -X- _ O
in -X- _ O
the -X- _ O
decoder -X- _ O
’s -X- _ O
input -X- _ O
/ -X- _ O
output -X- _ O
vocabulary -X- _ O
. -X- _ O

The -X- _ O
decoder -X- _ O
for -X- _ O
question -X- _ O
parsing -X- _ O
is -X- _ O
a -X- _ O
single -X- _ B-HyperparameterValue
- -X- _ O
layer -X- _ B-HyperparameterName
, -X- _ O
100 -X- _ B-HyperparameterValue
- -X- _ O
dimensional -X- _ B-HyperparameterName
, -X- _ O
LSTM -X- _ O
. -X- _ O

A.2 -X- _ O
Q -X- _ O
UESTION -X- _ O
PARSER -X- _ O
D -X- _ O
ECODER -X- _ O

We -X- _ O
use -X- _ O
‘ -X- _ O
bert -X- _ O
- -X- _ O
base -X- _ O
- -X- _ O
uncased -X- _ O
‘ -X- _ O
model -X- _ O
for -X- _ O
all -X- _ O
out -X- _ O
experiments -X- _ O
. -X- _ O

We -X- _ O
separate -X- _ O
the -X- _ O
question -X- _ O
and -X- _ O
context -X- _ O
representation -X- _ O
from -X- _ O
the -X- _ O
output -X- _ O
of -X- _ O
BERT -X- _ O
as -X- _ O
Q -X- _ O
and -X- _ O
P -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O

The -X- _ O
question -X- _ O
and -X- _ O
context -X- _ O
tokens -X- _ O
input -X- _ O
to -X- _ O
the -X- _ O
BERT -X- _ O
model -X- _ O
are -X- _ O
sub -X- _ O
- -X- _ O
words -X- _ O
extracted -X- _ O
by -X- _ O
using -X- _ O
BERT -X- _ O
’s -X- _ O
tokenizer -X- _ O
. -X- _ O

Context -X- _ O
[ -X- _ O
SEP -X- _ O
] -X- _ O
. -X- _ O

[ -X- _ O
CLS -X- _ O
] -X- _ O
Question -X- _ O
[ -X- _ O
SEP -X- _ O
] -X- _ O

The -X- _ O
input -X- _ O
to -X- _ O
the -X- _ O
BERT -X- _ O
model -X- _ O
is -X- _ O
the -X- _ O
concatenation -X- _ O
of -X- _ O
the -X- _ O
question -X- _ O
and -X- _ O
paragraph -X- _ O
in -X- _ O
the -X- _ O
following -X- _ O
format -X- _ O
: -X- _ O

BERT -X- _ O
: -X- _ O

The -X- _ O
CNN -X- _ O
uses -X- _ O
filters -X- _ O
of -X- _ O
size=5 -X- _ B-HyperparameterName
and -X- _ O
character -X- _ O
embeddings -X- _ O
of -X- _ O
64 -X- _ B-HyperparameterValue
- -X- _ O
d. -X- _ B-HyperparameterName
The -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
glove -X- _ O
embeddings -X- _ O
are -X- _ O
fixed -X- _ O
, -X- _ O
but -X- _ O
the -X- _ O
character -X- _ O
embeddings -X- _ O
and -X- _ O
the -X- _ O
parameters -X- _ O
for -X- _ O
the -X- _ O
CNN -X- _ O
are -X- _ O
jointly -X- _ O
learned -X- _ O
with -X- _ O
the -X- _ O
rest -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
. -X- _ O

The -X- _ O
token -X- _ O
embeddings -X- _ O
input -X- _ O
to -X- _ O
the -X- _ O
contextual -X- _ O
encoder -X- _ O
are -X- _ O
a -X- _ O
concatenation -X- _ O
of -X- _ O
100 -X- _ B-HyperparameterValue
- -X- _ O
d -X- _ B-HyperparameterName
pre -X- _ O
- -X- _ O
trained -X- _ O
GloVe -X- _ O
embeddings -X- _ O
, -X- _ O
and -X- _ O
200 -X- _ B-HyperparameterValue
- -X- _ O
d -X- _ B-HyperparameterName
embeddings -X- _ O
output -X- _ O
from -X- _ O
a -X- _ O
CNN -X- _ O
over -X- _ O
the -X- _ O
token -X- _ O
’s -X- _ O
characters -X- _ O
. -X- _ O

The -X- _ O
same -X- _ O
GRU -X- _ O
is -X- _ O
used -X- _ O
for -X- _ O
both -X- _ O
, -X- _ O
the -X- _ O
question -X- _ O
and -X- _ O
the -X- _ O
paragraph -X- _ O
. -X- _ O

GRU -X- _ O
: -X- _ O
We -X- _ O
use -X- _ O
a -X- _ O
2 -X- _ B-HyperparameterValue
- -X- _ O
layer -X- _ B-HyperparameterName
, -X- _ O
64 -X- _ B-HyperparameterValue
- -X- _ O
dimensional -X- _ B-HyperparameterName
( -X- _ O
d -X- _ B-HyperparameterName
= -X- _ O
128 -X- _ B-HyperparameterValue
, -X- _ O
effectively -X- _ O
) -X- _ O
, -X- _ O
bi -X- _ O
- -X- _ O
directional -X- _ O
GRU -X- _ O
. -X- _ O

These -X- _ O
embeddings -X- _ O
are -X- _ O
either -X- _ O
produced -X- _ O
using -X- _ O
a -X- _ O
multi -X- _ O
- -X- _ O
layer -X- _ O
GRU -X- _ O
network -X- _ O
that -X- _ O
is -X- _ O
trained -X- _ O
from -X- _ O
scratch -X- _ O
, -X- _ O
or -X- _ O
a -X- _ O
pr -X- _ O
- -X- _ O
trained -X- _ O
BERT -X- _ O
model -X- _ O
that -X- _ O
is -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
during -X- _ O
training -X- _ O
. -X- _ O

A -X- _ O
A -X- _ O
PPENDIX -X- _ O
A.1 -X- _ O
Q -X- _ O
UESTION -X- _ O
AND -X- _ O
PARAGRAPH -X- _ O
E -X- _ O
NCODER -X- _ O
Our -X- _ O
model -X- _ O
represents -X- _ O
the -X- _ O
question -X- _ O
q -X- _ O
as -X- _ O
Q -X- _ O
∈ -X- _ O
Rn×d -X- _ O
and -X- _ O
paragraph -X- _ O
p -X- _ O
as -X- _ O
P -X- _ O
∈ -X- _ O
Rm×d -X- _ O
using -X- _ O
contextualized -X- _ O
token -X- _ O
embeddings -X- _ O
. -X- _ O

N660011924033 -X- _ O
with -X- _ O
the -X- _ O
United -X- _ O
States -X- _ O
Office -X- _ O
Of -X- _ O
Naval -X- _ O
Research -X- _ O
, -X- _ O
an -X- _ O
ONR -X- _ O
award -X- _ O
, -X- _ O
the -X- _ O
LwLL -X- _ O
DARPA -X- _ O
program -X- _ O
, -X- _ O
and -X- _ O
a -X- _ O
grant -X- _ O
from -X- _ O
AI2 -X- _ O
. -X- _ O

This -X- _ O
material -X- _ O
is -X- _ O
based -X- _ O
upon -X- _ O
work -X- _ O
sponsored -X- _ O
in -X- _ O
part -X- _ O
by -X- _ O
the -X- _ O
DARPA -X- _ O
MCS -X- _ O
program -X- _ O
under -X- _ O
Contract -X- _ O
No -X- _ O
. -X- _ O

ACKNOWLEDGMENTS -X- _ O
We -X- _ O
would -X- _ O
like -X- _ O
to -X- _ O
thank -X- _ O
Daniel -X- _ O
Deutsch -X- _ O
and -X- _ O
the -X- _ O
anonymous -X- _ O
reviewers -X- _ O
for -X- _ O
their -X- _ O
helpful -X- _ O
comments -X- _ O
. -X- _ O

Future -X- _ O
research -X- _ O
is -X- _ O
necessary -X- _ O
to -X- _ O
continue -X- _ O
bridging -X- _ O
these -X- _ O
reasoning -X- _ B-TaskName
gaps -X- _ O
. -X- _ O

NMNs -X- _ B-MethodName
provide -X- _ O
interpretability -X- _ O
, -X- _ O
compositionality -X- _ O
, -X- _ O
and -X- _ O
improved -X- _ O
generalizability -X- _ O
, -X- _ O
but -X- _ O
at -X- _ O
the -X- _ O
cost -X- _ O
of -X- _ O
restricted -X- _ O
expressivity -X- _ O
as -X- _ O
compared -X- _ O
to -X- _ O
more -X- _ O
black -X- _ O
box -X- _ O
models -X- _ O
. -X- _ O

While -X- _ O
we -X- _ O
have -X- _ O
demonstrated -X- _ O
marked -X- _ O
success -X- _ O
in -X- _ O
broadening -X- _ O
the -X- _ O
scope -X- _ O
of -X- _ O
neural -X- _ O
modules -X- _ O
and -X- _ O
applying -X- _ O
them -X- _ O
to -X- _ O
open -X- _ O
- -X- _ O
domain -X- _ O
text -X- _ O
, -X- _ O
it -X- _ O
remains -X- _ O
a -X- _ O
significant -X- _ O
challenge -X- _ O
to -X- _ O
extend -X- _ O
these -X- _ O
models -X- _ O
to -X- _ O
the -X- _ O
full -X- _ O
range -X- _ O
of -X- _ O
reasoning -X- _ O
required -X- _ O
even -X- _ O
just -X- _ O
for -X- _ O
the -X- _ O
DROP -X- _ B-DatasetName
dataset -X- _ O
. -X- _ O

Additionally -X- _ O
, -X- _ O
we -X- _ O
show -X- _ O
that -X- _ O
injecting -X- _ O
inductive -X- _ O
bias -X- _ O
using -X- _ O
unsupervised -X- _ O
auxiliary -X- _ O
losses -X- _ O
significantly -X- _ O
helps -X- _ O
learning -X- _ O
. -X- _ O

We -X- _ O
define -X- _ O
probabilistic -X- _ O
modules -X- _ O
that -X- _ O
propagate -X- _ O
uncertainty -X- _ O
about -X- _ O
symbolic -X- _ B-TaskName
reasoning -X- _ I-TaskName
operations -X- _ O
in -X- _ O
a -X- _ O
way -X- _ O
that -X- _ O
is -X- _ O
end -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
end -X- _ O
differentiable -X- _ O
. -X- _ O

We -X- _ O
show -X- _ O
how -X- _ O
to -X- _ O
use -X- _ O
neural -X- _ B-MethodName
module -X- _ I-MethodName
networks -X- _ I-MethodName
to -X- _ O
answer -X- _ B-TaskName
compositional -X- _ I-TaskName
questions -X- _ I-TaskName
requiring -X- _ O
symbolic -X- _ B-TaskName
reasoning -X- _ I-TaskName
against -X- _ O
natural -X- _ O
language -X- _ O
text -X- _ O
. -X- _ O

8 -X- _ O
C -X- _ O
ONCLUSION -X- _ O

Combining -X- _ O
these -X- _ O
black -X- _ O
- -X- _ O
box -X- _ O
operations -X- _ O
with -X- _ O
the -X- _ O
interpretable -X- _ O
modules -X- _ O
that -X- _ O
we -X- _ O
have -X- _ O
presented -X- _ O
is -X- _ O
an -X- _ O
interesting -X- _ O
and -X- _ O
important -X- _ O
challenge -X- _ O
for -X- _ O
future -X- _ O
work -X- _ O
. -X- _ O

Additionally -X- _ O
, -X- _ O
due -X- _ O
to -X- _ O
our -X- _ O
lack -X- _ O
of -X- _ O
supervised -X- _ O
programs -X- _ O
, -X- _ O
training -X- _ O
the -X- _ O
network -X- _ O
to -X- _ O
use -X- _ O
the -X- _ O
interpretable -X- _ O
modules -X- _ O
instead -X- _ O
of -X- _ O
a -X- _ O
black -X- _ O
- -X- _ O
box -X- _ O
shortcut -X- _ O
module -X- _ O
is -X- _ O
challenging -X- _ O
, -X- _ O
further -X- _ O
compounding -X- _ O
the -X- _ O
issue -X- _ O
. -X- _ O

This -X- _ O
also -X- _ O
harms -X- _ O
the -X- _ O
ability -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
use -X- _ O
the -X- _ O
interpretable -X- _ O
modules -X- _ O
even -X- _ O
when -X- _ O
they -X- _ O
would -X- _ O
be -X- _ O
sufficient -X- _ O
to -X- _ O
answer -X- _ O
the -X- _ O
question -X- _ O
. -X- _ O

Allowing -X- _ O
black -X- _ O
- -X- _ O
box -X- _ O
operations -X- _ O
inside -X- _ O
of -X- _ O
a -X- _ O
neural -X- _ B-MethodName
module -X- _ I-MethodName
network -X- _ I-MethodName
significantly -X- _ O
harms -X- _ O
the -X- _ O
interpretability -X- _ O
— -X- _ O
e.g. -X- _ O
, -X- _ O
an -X- _ O
operation -X- _ O
that -X- _ O
directly -X- _ O
answers -X- _ O
a -X- _ O
question -X- _ O
after -X- _ O
an -X- _ O
encoder -X- _ O
, -X- _ O
mimicking -X- _ O
BERT -X- _ O
- -X- _ O
QA -X- _ O
- -X- _ O
style -X- _ O
models -X- _ O
, -X- _ O
encourages -X- _ O
the -X- _ O
encoder -X- _ O
to -X- _ O
perform -X- _ O
complex -X- _ B-TaskName
reasoning -X- _ I-TaskName
in -X- _ O
a -X- _ O
non -X- _ O
- -X- _ O
interpretable -X- _ O
way -X- _ O
. -X- _ O

It -X- _ O
is -X- _ O
not -X- _ O
trivial -X- _ O
to -X- _ O
combine -X- _ O
the -X- _ O
two -X- _ O
approaches -X- _ O
, -X- _ O
however -X- _ O
. -X- _ O

To -X- _ O
solve -X- _ O
both -X- _ O
of -X- _ O
these -X- _ O
classes -X- _ O
of -X- _ O
errors -X- _ O
, -X- _ O
one -X- _ O
could -X- _ O
use -X- _ O
black -X- _ O
- -X- _ O
box -X- _ O
models -X- _ O
, -X- _ O
which -X- _ O
gain -X- _ O
performance -X- _ O
on -X- _ O
some -X- _ O
questions -X- _ O
at -X- _ O
the -X- _ O
expense -X- _ O
of -X- _ O
limited -X- _ O
interpretability -X- _ O
. -X- _ O

Direct -X- _ O
transfer -X- _ O
of -X- _ O
reasoning -X- _ O
capability -X- _ O
in -X- _ O
black -X- _ O
- -X- _ O
box -X- _ O
models -X- _ O
is -X- _ O
not -X- _ O
so -X- _ O
straight -X- _ O
- -X- _ O
forward -X- _ O
. -X- _ O

Published -X- _ O
as -X- _ O
a -X- _ O
conference -X- _ O
paper -X- _ O
at -X- _ O
ICLR -X- _ O
2020 -X- _ O
using -X- _ O
indirect -X- _ O
or -X- _ O
distant -X- _ O
supervision -X- _ O
from -X- _ O
different -X- _ O
tasks -X- _ O
. -X- _ O

This -X- _ O
additionally -X- _ O
opens -X- _ O
up -X- _ O
avenues -X- _ O
for -X- _ O
transfer -X- _ O
learning -X- _ O
where -X- _ O
modules -X- _ O
can -X- _ O
be -X- _ O
independently -X- _ O
trained -X- _ O
9 -X- _ O

For -X- _ O
mistakes -X- _ O
such -X- _ O
as -X- _ O
these -X- _ O
, -X- _ O
our -X- _ O
NMN -X- _ B-MethodName
based -X- _ O
approach -X- _ O
allows -X- _ O
for -X- _ O
identifying -X- _ O
the -X- _ O
cause -X- _ O
of -X- _ O
mistakes -X- _ O
and -X- _ O
supervising -X- _ O
these -X- _ O
modules -X- _ O
using -X- _ O
additional -X- _ O
auxiliary -X- _ O
supervision -X- _ O
that -X- _ O
is -X- _ O
not -X- _ O
possible -X- _ O
in -X- _ O
black -X- _ O
- -X- _ O
box -X- _ O
models -X- _ O
. -X- _ O

For -X- _ O
example -X- _ O
, -X- _ O
incorrect -X- _ O
grounding -X- _ O
by -X- _ O
the -X- _ O
find -X- _ O
module -X- _ O
, -X- _ O
or -X- _ O
incorrect -X- _ O
argument -X- _ O
extraction -X- _ O
by -X- _ O
the -X- _ O
find -X- _ O
- -X- _ O
num -X- _ O
module -X- _ O
. -X- _ O

In -X- _ O
part -X- _ O
due -X- _ O
to -X- _ O
this -X- _ O
training -X- _ O
problem -X- _ O
, -X- _ O
some -X- _ O
other -X- _ O
mistakes -X- _ O
of -X- _ O
our -X- _ O
model -X- _ O
relative -X- _ O
to -X- _ O
MTMSN -X- _ B-MethodName
on -X- _ O
the -X- _ O
full -X- _ O
dataset -X- _ O
are -X- _ O
due -X- _ O
to -X- _ O
incorrect -X- _ O
execution -X- _ O
of -X- _ O
the -X- _ O
intermediate -X- _ O
modules -X- _ O
. -X- _ O

This -X- _ O
is -X- _ O
why -X- _ O
we -X- _ O
focus -X- _ O
on -X- _ O
only -X- _ O
a -X- _ O
subset -X- _ O
of -X- _ O
the -X- _ O
data -X- _ O
when -X- _ O
training -X- _ O
our -X- _ O
model -X- _ O
. -X- _ O

The -X- _ O
modules -X- _ O
in -X- _ O
the -X- _ O
predicted -X- _ O
program -X- _ O
get -X- _ O
updated -X- _ O
to -X- _ O
try -X- _ O
to -X- _ O
perform -X- _ O
the -X- _ O
reasoning -X- _ B-TaskName
anyway -X- _ O
, -X- _ O
which -X- _ O
harms -X- _ O
their -X- _ O
ability -X- _ O
to -X- _ O
execute -X- _ O
their -X- _ O
intended -X- _ O
operations -X- _ O
( -X- _ O
cf -X- _ O
. -X- _ O
§ -X- _ O
2.2 -X- _ O
) -X- _ O
. -X- _ O

It -X- _ O
is -X- _ O
worth -X- _ O
emphasizing -X- _ O
here -X- _ O
what -X- _ O
happens -X- _ O
when -X- _ O
we -X- _ O
try -X- _ O
to -X- _ O
train -X- _ O
our -X- _ O
model -X- _ O
on -X- _ O
these -X- _ O
questions -X- _ O
for -X- _ O
which -X- _ O
our -X- _ O
modules -X- _ O
ca -X- _ O
n’t -X- _ O
express -X- _ O
the -X- _ O
correct -X- _ O
reasoning -X- _ O
. -X- _ O

It -X- _ O
is -X- _ O
not -X- _ O
always -X- _ O
clear -X- _ O
how -X- _ O
to -X- _ O
design -X- _ O
interpretable -X- _ O
modules -X- _ O
for -X- _ O
certain -X- _ O
operations -X- _ O
; -X- _ O
for -X- _ O
example -X- _ O
, -X- _ O
for -X- _ O
the -X- _ O
last -X- _ O
two -X- _ O
cases -X- _ O
above -X- _ O
. -X- _ O

would -X- _ O
require -X- _ O
IE -X- _ O
for -X- _ O
implicit -X- _ O
argument -X- _ O
( -X- _ O
points -X- _ O
scored -X- _ O
by -X- _ O
the -X- _ O
other -X- _ O
team -X- _ O
) -X- _ O
. -X- _ O

would -X- _ O
require -X- _ O
designing -X- _ O
modules -X- _ O
that -X- _ O
considers -X- _ O
some -X- _ O
key -X- _ O
- -X- _ O
value -X- _ O
representation -X- _ O
of -X- _ O
the -X- _ O
paragraph -X- _ O
; -X- _ O
( -X- _ O
c -X- _ O
) -X- _ O
How -X- _ O
many -X- _ O
points -X- _ O
did -X- _ O
the -X- _ O
packers -X- _ O
fall -X- _ O
behind -X- _ O
during -X- _ O
the -X- _ O
game -X- _ O
? -X- _ O

and -X- _ O
In -X- _ O
which -X- _ O
quarter -X- _ O
did -X- _ O
the -X- _ O
teams -X- _ O
both -X- _ O
score -X- _ O
the -X- _ O
same -X- _ O
number -X- _ O
of -X- _ O
points -X- _ O
? -X- _ O

would -X- _ O
require -X- _ O
pruning -X- _ O
passage -X- _ O
spans -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
numerical -X- _ O
comparison -X- _ O
mentioned -X- _ O
in -X- _ O
the -X- _ O
question -X- _ O
; -X- _ O
( -X- _ O
b -X- _ O
) -X- _ O
Which -X- _ O
quarterback -X- _ O
threw -X- _ O
the -X- _ O
most -X- _ O
touchdown -X- _ O
passes -X- _ O
? -X- _ O

and -X- _ O
Which -X- _ O
racial -X- _ O
groups -X- _ O
are -X- _ O
smaller -X- _ O
than -X- _ O
2 -X- _ O
% -X- _ O
? -X- _ O

For -X- _ O
example -X- _ O
, -X- _ O
questions -X- _ O
such -X- _ O
as -X- _ O
( -X- _ O
a -X- _ O
) -X- _ O
How -X- _ O
many -X- _ O
languages -X- _ O
each -X- _ O
had -X- _ O
less -X- _ O
than -X- _ O
115 -X- _ O
, -X- _ O
000 -X- _ O
speakers -X- _ O
in -X- _ O
the -X- _ O
population -X- _ O
? -X- _ O

Manual -X- _ O
analysis -X- _ O
of -X- _ O
predictions -X- _ O
reveals -X- _ O
that -X- _ O
a -X- _ O
significant -X- _ O
majority -X- _ O
of -X- _ O
mistakes -X- _ O
are -X- _ O
due -X- _ O
to -X- _ O
insufficient -X- _ O
reasoning -X- _ O
capability -X- _ O
in -X- _ O
our -X- _ O
model -X- _ O
and -X- _ O
would -X- _ O
require -X- _ O
designing -X- _ O
additional -X- _ O
modules -X- _ O
. -X- _ O

The -X- _ O
resulting -X- _ O
model -X- _ O
achieves -X- _ O
a -X- _ O
score -X- _ O
of -X- _ O
65.4 -X- _ B-MetricValue
F1 -X- _ B-MetricName
on -X- _ O
the -X- _ O
complete -X- _ O
validation -X- _ O
data -X- _ O
of -X- _ O
DROP -X- _ B-DatasetName
, -X- _ O
as -X- _ O
compared -X- _ O
to -X- _ O
MTMSN -X- _ B-MethodName
that -X- _ O
achieves -X- _ O
72.8 -X- _ B-MetricValue
F1 -X- _ B-MetricName
. -X- _ O

7 -X- _ O
F -X- _ O
UTURE -X- _ O
D -X- _ O
IRECTIONS -X- _ O
We -X- _ O
try -X- _ O
a -X- _ O
trivial -X- _ O
extension -X- _ O
to -X- _ O
our -X- _ O
model -X- _ O
by -X- _ O
adding -X- _ O
a -X- _ O
module -X- _ O
that -X- _ O
allows -X- _ O
for -X- _ O
addition -X- _ O
& -X- _ O
subtraction -X- _ O
between -X- _ O
two -X- _ O
paragraph -X- _ O
numbers -X- _ O
. -X- _ O

Concurrently -X- _ O
, -X- _ O
Jiang -X- _ O
& -X- _ O
Bansal -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
apply -X- _ O
NMN -X- _ B-MethodName
to -X- _ O
HotpotQA -X- _ B-DatasetName
( -X- _ O
Yang -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
but -X- _ O
their -X- _ O
model -X- _ O
comprises -X- _ O
of -X- _ O
only -X- _ O
3 -X- _ O
modules -X- _ O
and -X- _ O
is -X- _ O
not -X- _ O
capable -X- _ O
of -X- _ O
performing -X- _ O
symbolic -X- _ B-TaskName
reasoning -X- _ I-TaskName
. -X- _ O

All -X- _ O
these -X- _ O
approaches -X- _ O
perform -X- _ O
reasoning -X- _ B-TaskName
on -X- _ O
synthetic -X- _ O
domains -X- _ O
, -X- _ O
while -X- _ O
our -X- _ O
model -X- _ O
is -X- _ O
applied -X- _ O
to -X- _ O
natural -X- _ O
language -X- _ O
. -X- _ O

Recent -X- _ O
works -X- _ O
( -X- _ O
Gupta -X- _ O
& -X- _ O
Lewis -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Mao -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
also -X- _ O
use -X- _ O
domain -X- _ O
- -X- _ O
knowledge -X- _ O
to -X- _ O
alleviate -X- _ O
issues -X- _ O
in -X- _ O
learning -X- _ O
by -X- _ O
using -X- _ O
curriculum -X- _ O
learning -X- _ O
to -X- _ O
train -X- _ O
the -X- _ O
executor -X- _ O
first -X- _ O
on -X- _ O
simple -X- _ O
questions -X- _ O
for -X- _ O
which -X- _ O
parsing -X- _ O
is -X- _ O
not -X- _ O
an -X- _ O
issue -X- _ O
. -X- _ O

Gupta -X- _ O
& -X- _ O
Lewis -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
propose -X- _ O
a -X- _ O
NMN -X- _ B-MethodName
model -X- _ O
for -X- _ O
QA -X- _ B-TaskName
against -X- _ O
knowledge -X- _ O
graphs -X- _ O
and -X- _ O
learn -X- _ O
execution -X- _ O
for -X- _ O
semantic -X- _ O
operators -X- _ O
from -X- _ O
QA -X- _ O
supervision -X- _ O
alone -X- _ O
. -X- _ O

N2NMNs -X- _ B-MethodName
( -X- _ O
Hu -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
simultaneously -X- _ O
learn -X- _ O
to -X- _ O
parse -X- _ O
and -X- _ O
execute -X- _ O
but -X- _ O
require -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
the -X- _ O
parser -X- _ O
. -X- _ O

For -X- _ O
combining -X- _ O
learned -X- _ O
execution -X- _ O
modules -X- _ O
with -X- _ O
semantic -X- _ O
parsing -X- _ O
, -X- _ O
many -X- _ O
variations -X- _ O
to -X- _ O
NMNs -X- _ B-MethodName
have -X- _ O
been -X- _ O
proposed -X- _ O
; -X- _ O
NMN -X- _ B-MethodName
( -X- _ O
Andreas -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
use -X- _ O
a -X- _ O
PCFG -X- _ O
parser -X- _ O
to -X- _ O
parse -X- _ O
the -X- _ O
question -X- _ O
and -X- _ O
only -X- _ O
learn -X- _ O
module -X- _ O
parameters -X- _ O
. -X- _ O

Our -X- _ O
model -X- _ O
on -X- _ O
the -X- _ O
other -X- _ O
hand -X- _ O
provides -X- _ O
an -X- _ O
interpretable -X- _ O
, -X- _ O
compositional -X- _ O
parse -X- _ O
of -X- _ O
the -X- _ O
question -X- _ O
and -X- _ O
exposes -X- _ O
its -X- _ O
intermediate -X- _ O
reasoning -X- _ O
steps -X- _ O
. -X- _ O

proposed -X- _ O
( -X- _ O
Hu -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Andor -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Kinley -X- _ O
& -X- _ O
Lin -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
but -X- _ O
all -X- _ O
these -X- _ O
models -X- _ O
essentially -X- _ O
perform -X- _ O
a -X- _ O
multiclass -X- _ O
classification -X- _ O
over -X- _ O
pre -X- _ O
- -X- _ O
defined -X- _ O
programs -X- _ O
. -X- _ O

Recently -X- _ O
, -X- _ O
BERT -X- _ O
- -X- _ O
based -X- _ O
models -X- _ O
for -X- _ O
DROP -X- _ B-DatasetName
have -X- _ O
been -X- _ O
been -X- _ O
8 -X- _ O

These -X- _ O
have -X- _ O
also -X- _ O
been -X- _ O
extended -X- _ O
for -X- _ O
QA -X- _ B-TaskName
using -X- _ O
symbolic -X- _ B-TaskName
reasoning -X- _ I-TaskName
against -X- _ O
semi -X- _ O
- -X- _ O
structured -X- _ O
tables -X- _ O
( -X- _ O
Pasupat -X- _ O
& -X- _ O
Liang -X- _ O
, -X- _ O
2015 -X- _ O
; -X- _ O
Krishnamurthy -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2017 -X- _ O
; -X- _ O
Neelakantan -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
. -X- _ O

Approaches -X- _ O
have -X- _ O
used -X- _ O
labeled -X- _ O
logical -X- _ O
- -X- _ O
forms -X- _ O
( -X- _ O
Zelle -X- _ O
& -X- _ O
Mooney -X- _ O
, -X- _ O
1996 -X- _ O
; -X- _ O
Zettlemoyer -X- _ O
& -X- _ O
Collins -X- _ O
, -X- _ O
2005 -X- _ O
) -X- _ O
, -X- _ O
or -X- _ O
weak -X- _ O
QA -X- _ O
supervision -X- _ O
( -X- _ O
Clarke -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2010 -X- _ O
; -X- _ O
Berant -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2013 -X- _ O
; -X- _ O
Reddy -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
to -X- _ O
learn -X- _ O
parsers -X- _ O
to -X- _ O
answer -X- _ O
questions -X- _ O
against -X- _ O
structured -X- _ O
knowledge -X- _ O
bases -X- _ O
. -X- _ O

6 -X- _ O
R -X- _ O
ELATED -X- _ O
W -X- _ O
ORK -X- _ O
Semantic -X- _ O
parsing -X- _ O
techniques -X- _ O
have -X- _ O
been -X- _ O
used -X- _ O
for -X- _ O
a -X- _ O
long -X- _ O
time -X- _ O
for -X- _ O
compositional -X- _ B-TaskName
question -X- _ I-TaskName
understanding -X- _ I-TaskName
. -X- _ O

Such -X- _ O
questions -X- _ O
, -X- _ O
that -X- _ O
require -X- _ O
nested -X- _ O
counting -X- _ O
, -X- _ O
are -X- _ O
out -X- _ O
of -X- _ O
scope -X- _ O
of -X- _ O
our -X- _ O
defined -X- _ O
modules -X- _ O
because -X- _ O
the -X- _ O
model -X- _ O
would -X- _ O
first -X- _ O
need -X- _ O
to -X- _ O
to -X- _ O
count -X- _ O
the -X- _ O
passes -X- _ O
caught -X- _ O
by -X- _ O
each -X- _ O
player -X- _ O
. -X- _ O

is -X- _ O
incorrect -X- _ O
since -X- _ O
the -X- _ O
correct -X- _ O
answer -X- _ O
requires -X- _ O
natural -X- _ O
language -X- _ O
inference -X- _ O
about -X- _ O
the -X- _ O
order -X- _ O
of -X- _ O
events -X- _ O
and -X- _ O
not -X- _ O
symbolic -X- _ O
comparison -X- _ O
between -X- _ O
dates -X- _ O
. -X- _ O

- -X- _ O
relocate(find -X- _ O
- -X- _ O
max -X- _ O
- -X- _ O
num(find -X- _ O
) -X- _ O
) -X- _ O
) -X- _ O
. -X- _ O

3 -X- _ O
. -X- _ O
Who -X- _ O
caught -X- _ O
the -X- _ O
most -X- _ O
touchdown -X- _ O
passes -X- _ O
? -X- _ O

date -X- _ O
- -X- _ O
compare -X- _ O
- -X- _ O
gt(find -X- _ O
, -X- _ O
find -X- _ O
) -X- _ O
) -X- _ O

2 -X- _ O
. -X- _ O
Which -X- _ O
happened -X- _ O
last -X- _ O
, -X- _ O
failed -X- _ O
assassination -X- _ O
attempt -X- _ O
on -X- _ O
Lenin -X- _ O
, -X- _ O
or -X- _ O
the -X- _ O
Red -X- _ O
Terror -X- _ O
? -X- _ O

- -X- _ O
count(find -X- _ O
) -X- _ O
is -X- _ O
incorrect -X- _ O
since -X- _ O
the -X- _ O
correct -X- _ O
answer -X- _ O
requires -X- _ O
a -X- _ O
simple -X- _ O
lookup -X- _ O
from -X- _ O
the -X- _ O
paragraph -X- _ O
. -X- _ O

How -X- _ O
many -X- _ O
touchdown -X- _ O
passes -X- _ O
did -X- _ O
Tom -X- _ O
Brady -X- _ O
throw -X- _ O
in -X- _ O
the -X- _ O
season -X- _ O
? -X- _ O

Here -X- _ O
we -X- _ O
show -X- _ O
few -X- _ O
mistakes -X- _ O
of -X- _ O
the -X- _ O
first -X- _ O
type -X- _ O
that -X- _ O
highlight -X- _ O
the -X- _ O
need -X- _ O
to -X- _ O
parse -X- _ O
the -X- _ O
question -X- _ O
in -X- _ O
a -X- _ O
context -X- _ O
conditional -X- _ O
manner -X- _ O
: -X- _ O
1 -X- _ O
. -X- _ O

Mistakes -X- _ O
by -X- _ O
our -X- _ O
model -X- _ O
can -X- _ O
be -X- _ O
classified -X- _ O
into -X- _ O
two -X- _ O
types -X- _ O
; -X- _ O
incorrect -X- _ O
program -X- _ O
prediction -X- _ O
and -X- _ O
incorrect -X- _ O
execution -X- _ O
. -X- _ O

Incorrect -X- _ O
Program -X- _ O
Predictions -X- _ O
. -X- _ O

This -X- _ O
shows -X- _ O
that -X- _ O
by -X- _ O
explicitly -X- _ O
modeling -X- _ O
compositionality -X- _ O
, -X- _ O
our -X- _ O
model -X- _ O
is -X- _ O
able -X- _ O
to -X- _ O
use -X- _ O
additional -X- _ O
auxiliary -X- _ O
supervision -X- _ O
effectively -X- _ O
and -X- _ O
achieves -X- _ O
improved -X- _ O
model -X- _ O
generalization -X- _ O
. -X- _ O

Figure -X- _ O
2b -X- _ O
shows -X- _ O
that -X- _ O
our -X- _ O
model -X- _ O
significantly -X- _ O
outperforms -X- _ O
MTMSN -X- _ B-MethodName
when -X- _ O
training -X- _ O
using -X- _ O
less -X- _ O
data -X- _ O
, -X- _ O
especially -X- _ O
using -X- _ O
10 -X- _ O
- -X- _ O
25 -X- _ O
% -X- _ O
of -X- _ O
the -X- _ O
available -X- _ O
supervision -X- _ O
. -X- _ O

Effect -X- _ O
of -X- _ O
Training -X- _ O
Data -X- _ O
Size -X- _ O
. -X- _ O

Additionally -X- _ O
, -X- _ O
the -X- _ O
intermediate -X- _ O
module -X- _ O
output -X- _ O
supervision -X- _ O
has -X- _ O
slight -X- _ O
positive -X- _ O
effect -X- _ O
on -X- _ O
the -X- _ O
model -X- _ O
performance -X- _ O
. -X- _ O

The -X- _ O
model -X- _ O
using -X- _ O
BERT -X- _ O
diverges -X- _ O
while -X- _ O
training -X- _ O
without -X- _ O
the -X- _ O
auxiliary -X- _ O
objective -X- _ O
. -X- _ O

Figure -X- _ O
2a -X- _ O
shows -X- _ O
that -X- _ O
the -X- _ O
unsupervised -X- _ O
auxiliary -X- _ O
objective -X- _ O
significantly -X- _ O
improves -X- _ O
model -X- _ O
performance -X- _ O
( -X- _ O
from -X- _ O
57.3 -X- _ B-MetricValue
to -X- _ O
73.1 -X- _ B-MetricValue
F1 -X- _ B-MetricName
) -X- _ O
. -X- _ O

Effect -X- _ O
of -X- _ O
Additional -X- _ O
Supervision -X- _ O
. -X- _ O

We -X- _ O
believe -X- _ O
this -X- _ O
is -X- _ O
because -X- _ O
feedback -X- _ O
from -X- _ O
count -X- _ O
questions -X- _ O
is -X- _ O
weak -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
the -X- _ O
model -X- _ O
only -X- _ O
gets -X- _ O
feedback -X- _ O
about -X- _ O
the -X- _ O
count -X- _ O
value -X- _ O
and -X- _ O
not -X- _ O
what -X- _ O
the -X- _ O
underlying -X- _ O
set -X- _ O
is -X- _ O
; -X- _ O
and -X- _ O
because -X- _ O
it -X- _ O
was -X- _ O
challenging -X- _ O
to -X- _ O
define -X- _ O
a -X- _ O
categorical -X- _ O
count -X- _ O
distribution -X- _ O
given -X- _ O
a -X- _ O
passage -X- _ O
attention -X- _ O
distribution -X- _ O
— -X- _ O
finding -X- _ O
a -X- _ O
better -X- _ O
way -X- _ O
to -X- _ O
parameterize -X- _ O
this -X- _ O
function -X- _ O
is -X- _ O
an -X- _ O
interesting -X- _ O
problem -X- _ O
for -X- _ O
future -X- _ O
work -X- _ O
. -X- _ O

Even -X- _ O
after -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
the -X- _ O
count -X- _ O
module -X- _ O
using -X- _ O
synthetic -X- _ O
data -X- _ O
, -X- _ O
training -X- _ O
it -X- _ O
is -X- _ O
particularly -X- _ O
unstable -X- _ O
. -X- _ O

Our -X- _ O
model -X- _ O
outperforms -X- _ O
MTMSN -X- _ B-MethodName
on -X- _ O
majority -X- _ O
of -X- _ O
question -X- _ O
types -X- _ O
but -X- _ O
struggles -X- _ O
with -X- _ O
counting -X- _ O
questions -X- _ O
; -X- _ O
it -X- _ O
outperforms -X- _ O
MTMSN -X- _ B-MethodName
on -X- _ O
only -X- _ O
some -X- _ O
of -X- _ O
the -X- _ O
runs -X- _ O
. -X- _ O

Table -X- _ O
2b -X- _ O
shows -X- _ O
the -X- _ O
performance -X- _ O
for -X- _ O
different -X- _ O
question -X- _ O
types -X- _ O
as -X- _ O
identified -X- _ O
by -X- _ O
our -X- _ O
heuristic -X- _ O
labeling -X- _ O
. -X- _ O

Performance -X- _ O
by -X- _ O
Question -X- _ O
Type -X- _ O
. -X- _ O

Additionally -X- _ O
, -X- _ O
this -X- _ O
shows -X- _ O
that -X- _ O
structured -X- _ O
models -X- _ O
still -X- _ O
benefit -X- _ O
when -X- _ O
used -X- _ O
over -X- _ O
representations -X- _ O
from -X- _ O
large -X- _ O
pretrained -X- _ O
- -X- _ O
LMs -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
BERT -X- _ O
. -X- _ O

reasoning -X- _ B-TaskName
over -X- _ O
natural -X- _ O
language -X- _ O
text -X- _ O
. -X- _ O

This -X- _ O
shows -X- _ O
the -X- _ O
efficacy -X- _ O
of -X- _ O
our -X- _ O
proposed -X- _ O
model -X- _ O
in -X- _ O
understanding -X- _ O
complex -X- _ O
compositional -X- _ O
questions -X- _ O
and -X- _ O
performing -X- _ O
multi -X- _ O
- -X- _ O
step -X- _ O
2 -X- _ O
Our -X- _ O
code -X- _ O
is -X- _ O
available -X- _ O
at -X- _ O
https://github.com/nitishgupta/nmn-drop -X- _ O
7 -X- _ O

Using -X- _ O
BERT -X- _ O
representations -X- _ O
, -X- _ O
our -X- _ O
model -X- _ O
’s -X- _ O
performance -X- _ O
increases -X- _ O
to -X- _ O
77.4 -X- _ B-MetricValue
F1 -X- _ B-MetricName
and -X- _ O
outperforms -X- _ O
SoTA -X- _ O
models -X- _ O
that -X- _ O
use -X- _ O
BERT -X- _ O
representations -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
MTMSN -X- _ B-MethodName
( -X- _ O
76.5 -X- _ B-MetricValue
F1 -X- _ B-MetricName
) -X- _ O
. -X- _ O

Our -X- _ O
model -X- _ O
achieves -X- _ O
an -X- _ O
F1 -X- _ B-MetricName
score -X- _ O
of -X- _ O
73.1 -X- _ B-MetricValue
( -X- _ O
w/ -X- _ O
GRU -X- _ O
) -X- _ O
and -X- _ O
significantly -X- _ O
outperforms -X- _ O
NAQANet -X- _ B-MethodName
( -X- _ O
62.1 -X- _ B-MetricValue
F1 -X- _ B-MetricName
) -X- _ O
. -X- _ O

Table -X- _ O
2a -X- _ O
compares -X- _ O
our -X- _ O
model -X- _ O
’s -X- _ O
performance -X- _ O
to -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
models -X- _ O
on -X- _ O
our -X- _ O
full -X- _ O
test -X- _ O
set -X- _ O
. -X- _ O

Overall -X- _ O
. -X- _ O

All -X- _ O
results -X- _ O
are -X- _ O
reported -X- _ O
as -X- _ O
an -X- _ O
average -X- _ O
of -X- _ O
4 -X- _ O
model -X- _ O
runs -X- _ O
. -X- _ O

The -X- _ O
hyperparameters -X- _ O
used -X- _ O
for -X- _ O
our -X- _ O
model -X- _ O
are -X- _ O
described -X- _ O
in -X- _ O
the -X- _ O
appendix -X- _ O
. -X- _ O

2 -X- _ O

We -X- _ O
implement -X- _ O
our -X- _ O
model -X- _ O
using -X- _ O
AllenNLP -X- _ O
( -X- _ O
Gardner -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O

5.2 -X- _ O
R -X- _ O
ESULTS -X- _ O
We -X- _ O
compare -X- _ O
to -X- _ O
publicly -X- _ O
available -X- _ O
best -X- _ O
performing -X- _ O
models -X- _ O
: -X- _ O
NAQANet -X- _ B-MethodName
( -X- _ O
Dua -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
NABERT+ -X- _ B-MethodName
( -X- _ O
Kinley -X- _ O
& -X- _ O
Lin -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
TAG -X- _ B-MethodName
- -X- _ I-MethodName
NABERT+ -X- _ I-MethodName
( -X- _ O
Avia -X- _ O
Efrat -X- _ O
& -X- _ O
Shoham -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
MTMSN -X- _ B-MethodName
( -X- _ O
Hu -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
all -X- _ O
trained -X- _ O
on -X- _ O
the -X- _ O
same -X- _ O
data -X- _ O
as -X- _ O
our -X- _ O
model -X- _ O
. -X- _ O

We -X- _ O
use -X- _ O
curriculum -X- _ O
learning -X- _ O
( -X- _ O
Bengio -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2009 -X- _ O
) -X- _ O
where -X- _ O
the -X- _ O
model -X- _ O
is -X- _ O
trained -X- _ O
only -X- _ O
on -X- _ O
heuristically -X- _ O
- -X- _ O
supervised -X- _ O
non -X- _ O
- -X- _ O
count -X- _ O
questions -X- _ O
for -X- _ O
the -X- _ O
first -X- _ O
5 -X- _ B-HyperparameterValue
epochs -X- _ B-HyperparameterName
. -X- _ O

Auxiliary -X- _ O
Supervision -X- _ O
Out -X- _ O
of -X- _ O
the -X- _ O
20 -X- _ O
, -X- _ O
000 -X- _ O
training -X- _ O
questions -X- _ O
, -X- _ O
we -X- _ O
provide -X- _ O
question -X- _ O
program -X- _ O
supervision -X- _ O
for -X- _ O
10 -X- _ O
% -X- _ O
( -X- _ O
2000 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
intermediate -X- _ O
module -X- _ O
output -X- _ O
supervision -X- _ O
for -X- _ O
5 -X- _ O
% -X- _ O
( -X- _ O
1000 -X- _ O
) -X- _ O
of -X- _ O
training -X- _ O
questions -X- _ O
. -X- _ O

Extract -X- _ O
- -X- _ O
Argument -X- _ O
e.g. -X- _ O
Who -X- _ O
threw -X- _ O
the -X- _ O
longest -X- _ O
touchdown -X- _ O
pass -X- _ O
in -X- _ O
the -X- _ O
first -X- _ O
quarter -X- _ O
? -X- _ O

Count -X- _ O
e.g. -X- _ O
How -X- _ O
many -X- _ O
touchdowns -X- _ O
did -X- _ O
the -X- _ O
Vikings -X- _ O
score -X- _ O
in -X- _ O
the -X- _ O
first -X- _ O
half -X- _ O
? -X- _ O

Extract -X- _ O
- -X- _ O
Number -X- _ O
e.g. -X- _ O
How -X- _ O
many -X- _ O
yards -X- _ O
was -X- _ O
Kasay -X- _ O
’s -X- _ O
shortest -X- _ O
field -X- _ O
goal -X- _ O
during -X- _ O
the -X- _ O
second -X- _ O
half -X- _ O
? -X- _ O

Number -X- _ O
- -X- _ O
Compare -X- _ O
e.g. -X- _ O
Were -X- _ O
there -X- _ O
more -X- _ O
of -X- _ O
cultivators -X- _ O
or -X- _ O
main -X- _ O
agricultural -X- _ O
labourers -X- _ O
in -X- _ O
Sweden -X- _ O
? -X- _ O

Date -X- _ O
- -X- _ O
Difference -X- _ O
e.g. -X- _ O
How -X- _ O
many -X- _ O
years -X- _ O
after -X- _ O
his -X- _ O
attempted -X- _ O
assassination -X- _ O
was -X- _ O
James -X- _ O
II -X- _ O
coronated -X- _ O
? -X- _ O

Based -X- _ O
on -X- _ O
the -X- _ O
manual -X- _ O
analysis -X- _ O
we -X- _ O
classify -X- _ O
these -X- _ O
questions -X- _ O
into -X- _ O
different -X- _ O
categories -X- _ O
, -X- _ O
which -X- _ O
are -X- _ O
: -X- _ O
Date -X- _ O
- -X- _ O
Compare -X- _ O
e.g. -X- _ O
What -X- _ O
happened -X- _ O
last -X- _ O
, -X- _ O
commission -X- _ O
being -X- _ O
granted -X- _ O
to -X- _ O
Robert -X- _ O
or -X- _ O
death -X- _ O
of -X- _ O
his -X- _ O
cousin -X- _ O
? -X- _ O

We -X- _ O
make -X- _ O
our -X- _ O
subset -X- _ O
and -X- _ O
splits -X- _ O
available -X- _ O
publicly -X- _ O
with -X- _ O
the -X- _ O
code -X- _ O
. -X- _ O

Though -X- _ O
this -X- _ O
is -X- _ O
a -X- _ O
subset -X- _ O
of -X- _ O
the -X- _ O
full -X- _ O
DROP -X- _ B-DatasetName
dataset -X- _ O
it -X- _ O
is -X- _ O
still -X- _ O
a -X- _ O
significantly -X- _ O
- -X- _ O
sized -X- _ O
dataset -X- _ O
that -X- _ O
allows -X- _ O
drawing -X- _ O
meaningful -X- _ O
conclusions -X- _ O
. -X- _ O

Since -X- _ O
the -X- _ O
DROP -X- _ B-DatasetName
test -X- _ O
set -X- _ O
is -X- _ O
hidden -X- _ O
, -X- _ O
this -X- _ O
test -X- _ O
set -X- _ O
is -X- _ O
extracted -X- _ O
from -X- _ O
the -X- _ O
validation -X- _ O
data -X- _ O
. -X- _ O

The -X- _ O
dataset -X- _ O
we -X- _ O
construct -X- _ O
contains -X- _ O
20 -X- _ O
, -X- _ O
000 -X- _ O
questions -X- _ O
for -X- _ O
training -X- _ O
/ -X- _ O
validation -X- _ O
, -X- _ O
and -X- _ O
1800 -X- _ O
questions -X- _ O
for -X- _ O
testing -X- _ O
( -X- _ O
25 -X- _ O
% -X- _ O
of -X- _ O
DROP -X- _ B-DatasetName
) -X- _ O
. -X- _ O

These -X- _ O
n -X- _ O
- -X- _ O
grams -X- _ O
were -X- _ O
selected -X- _ O
by -X- _ O
performing -X- _ O
manual -X- _ O
analysis -X- _ O
on -X- _ O
a -X- _ O
small -X- _ O
set -X- _ O
of -X- _ O
questions -X- _ O
. -X- _ O

Our -X- _ O
model -X- _ O
possesses -X- _ O
diverse -X- _ O
but -X- _ O
limited -X- _ O
reasoning -X- _ B-TaskName
capability -X- _ O
; -X- _ O
hence -X- _ O
, -X- _ O
we -X- _ O
try -X- _ O
to -X- _ O
automatically -X- _ O
extract -X- _ O
questions -X- _ O
in -X- _ O
the -X- _ O
scope -X- _ O
of -X- _ O
our -X- _ O
model -X- _ O
based -X- _ O
on -X- _ O
their -X- _ O
first -X- _ O
n -X- _ O
- -X- _ O
gram -X- _ O
. -X- _ O

5 -X- _ O
E -X- _ O
XPERIMENTS -X- _ O
5.1 -X- _ O
DATASET -X- _ O
We -X- _ O
perform -X- _ O
experiments -X- _ O
on -X- _ O
a -X- _ O
portion -X- _ O
of -X- _ O
the -X- _ O
recently -X- _ O
released -X- _ O
DROP -X- _ B-DatasetName
dataset -X- _ O
( -X- _ O
Dua -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
to -X- _ O
the -X- _ O
best -X- _ O
of -X- _ O
our -X- _ O
knowledge -X- _ O
is -X- _ O
the -X- _ O
only -X- _ O
dataset -X- _ O
that -X- _ O
requires -X- _ O
the -X- _ O
kind -X- _ O
of -X- _ O
compositional -X- _ B-TaskName
and -X- _ I-TaskName
symbolic -X- _ I-TaskName
reasoning -X- _ I-TaskName
that -X- _ O
our -X- _ O
model -X- _ O
aims -X- _ O
to -X- _ O
solve -X- _ O
. -X- _ O

We -X- _ O
follow -X- _ O
the -X- _ O
same -X- _ O
procedure -X- _ O
for -X- _ O
a -X- _ O
few -X- _ O
other -X- _ O
question -X- _ O
types -X- _ O
involving -X- _ O
dates -X- _ O
and -X- _ O
numbers -X- _ O
; -X- _ O
see -X- _ O
§ -X- _ O
A.7 -X- _ O
for -X- _ O
details -X- _ O
. -X- _ O

We -X- _ O
supervise -X- _ O
this -X- _ O
as -X- _ O
a -X- _ O
multi -X- _ O
- -X- _ O
hot -X- _ O
vector -X- _ O
N -X- _ O
∗ -X- _ O
and -X- _ O
use -X- _ O
an -X- _ O
auxiliary -X- _ O
loss -X- _ O
, -X- _ O
similar -X- _ O
to -X- _ O
question -X- _ O
- -X- _ O
attention -X- _ O
loss -X- _ O
, -X- _ O
against -X- _ O
the -X- _ O
output -X- _ O
distribution -X- _ O
N -X- _ O
of -X- _ O
find -X- _ O
- -X- _ O
num -X- _ O
. -X- _ O

For -X- _ O
questions -X- _ O
like -X- _ O
“ -X- _ O
how -X- _ O
many -X- _ O
yards -X- _ O
was -X- _ O
the -X- _ O
longest -X- _ O
/ -X- _ O
shortest -X- _ O
touchdown -X- _ O
? -X- _ O
” -X- _ O
, -X- _ O
we -X- _ O
identify -X- _ O
all -X- _ O
instances -X- _ O
of -X- _ O
the -X- _ O
token -X- _ O
“ -X- _ O
touchdown -X- _ O
” -X- _ O
in -X- _ O
the -X- _ O
paragraph -X- _ O
and -X- _ O
assume -X- _ O
the -X- _ O
closest -X- _ O
number -X- _ O
to -X- _ O
it -X- _ O
should -X- _ O
be -X- _ O
an -X- _ O
output -X- _ O
of -X- _ O
the -X- _ O
find -X- _ O
- -X- _ O
num -X- _ O
module -X- _ O
. -X- _ O

We -X- _ O
provide -X- _ O
heuristically -X- _ O
- -X- _ O
obtained -X- _ O
noisy -X- _ O
supervision -X- _ O
for -X- _ O
the -X- _ O
output -X- _ O
of -X- _ O
the -X- _ O
find -X- _ O
- -X- _ O
num -X- _ O
and -X- _ O
find -X- _ O
- -X- _ O
date -X- _ O
modules -X- _ O
for -X- _ O
a -X- _ O
subset -X- _ O
of -X- _ O
the -X- _ O
questions -X- _ O
( -X- _ O
5 -X- _ O
% -X- _ O
) -X- _ O
for -X- _ O
which -X- _ O
we -X- _ O
also -X- _ O
provide -X- _ O
question -X- _ O
program -X- _ O
supervision -X- _ O
. -X- _ O

Such -X- _ O
feedback -X- _ O
biases -X- _ O
the -X- _ O
model -X- _ O
in -X- _ O
predicting -X- _ O
incorrect -X- _ O
values -X- _ O
for -X- _ O
intermediate -X- _ O
modules -X- _ O
( -X- _ O
only -X- _ O
the -X- _ O
shortest -X- _ O
goal -X- _ O
instead -X- _ O
of -X- _ O
all -X- _ O
in -X- _ O
find -X- _ O
- -X- _ O
num -X- _ O
) -X- _ O
which -X- _ O
in -X- _ O
turn -X- _ O
hurts -X- _ O
model -X- _ O
generalization -X- _ O
. -X- _ O

The -X- _ O
model -X- _ O
only -X- _ O
gets -X- _ O
feedback -X- _ O
for -X- _ O
how -X- _ O
long -X- _ O
the -X- _ O
shortest -X- _ O
goal -X- _ O
is -X- _ O
, -X- _ O
but -X- _ O
not -X- _ O
for -X- _ O
other -X- _ O
goals -X- _ O
. -X- _ O

Consider -X- _ O
the -X- _ O
question -X- _ O
, -X- _ O
“ -X- _ O
how -X- _ O
many -X- _ O
yards -X- _ O
was -X- _ O
the -X- _ O
shortest -X- _ O
goal -X- _ O
? -X- _ O
” -X- _ O
. -X- _ O

Intermediate -X- _ O
Module -X- _ O
Output -X- _ O
Supervision -X- _ O
. -X- _ O

For -X- _ O
example -X- _ O
, -X- _ O
for -X- _ O
program -X- _ O
find -X- _ O
- -X- _ O
num(find -X- _ O
- -X- _ O
max -X- _ O
- -X- _ O
num(find -X- _ O
( -X- _ O
) -X- _ O
) -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
provide -X- _ O
supervision -X- _ O
for -X- _ O
question -X- _ O
tokens -X- _ O
to -X- _ O
attend -X- _ O
to -X- _ O
when -X- _ O
predicting -X- _ O
the -X- _ O
find -X- _ O
module -X- _ O
. -X- _ O

Published -X- _ O
as -X- _ O
a -X- _ O
conference -X- _ O
paper -X- _ O
at -X- _ O
ICLR -X- _ O
2020 -X- _ O
of -X- _ O
the -X- _ O
questions -X- _ O
; -X- _ O
see -X- _ O
§ -X- _ O
A.6 -X- _ O
) -X- _ O
. -X- _ O

In -X- _ O
order -X- _ O
to -X- _ O
bootstrap -X- _ O
the -X- _ O
parser -X- _ O
, -X- _ O
we -X- _ O
analyze -X- _ O
some -X- _ O
questions -X- _ O
manually -X- _ O
and -X- _ O
come -X- _ O
up -X- _ O
with -X- _ O
a -X- _ O
few -X- _ O
heuristic -X- _ O
patterns -X- _ O
to -X- _ O
get -X- _ O
program -X- _ O
and -X- _ O
corresponding -X- _ O
question -X- _ O
attention -X- _ O
supervision -X- _ O
( -X- _ O
for -X- _ O
modules -X- _ O
that -X- _ O
require -X- _ O
it -X- _ O
) -X- _ O
for -X- _ O
a -X- _ O
subset -X- _ O
of -X- _ O
the -X- _ O
training -X- _ O
data -X- _ O
( -X- _ O
10 -X- _ O
% -X- _ O
6 -X- _ O

For -X- _ O
DROP -X- _ B-DatasetName
, -X- _ O
we -X- _ O
have -X- _ O
no -X- _ O
such -X- _ O
external -X- _ O
supervision -X- _ O
. -X- _ O

For -X- _ O
example -X- _ O
, -X- _ O
even -X- _ O
though -X- _ O
the -X- _ O
questions -X- _ O
in -X- _ O
CLEVR -X- _ B-DatasetName
are -X- _ O
programmatically -X- _ O
generated -X- _ O
, -X- _ O
Hu -X- _ O
et -X- _ O
al. -X- _ O
( -X- _ O
2017 -X- _ O
) -X- _ O
needed -X- _ O
to -X- _ O
pre -X- _ O
- -X- _ O
train -X- _ O
their -X- _ O
parser -X- _ O
using -X- _ O
external -X- _ O
supervision -X- _ O
for -X- _ O
all -X- _ O
questions -X- _ O
. -X- _ O

Learning -X- _ O
to -X- _ O
parse -X- _ O
questions -X- _ O
in -X- _ O
a -X- _ O
noisy -X- _ O
feedback -X- _ O
environment -X- _ O
is -X- _ O
very -X- _ O
challenging -X- _ O
. -X- _ O

AND -X- _ O
I -X- _ O
NTERMEDIATE -X- _ O
M -X- _ O
ODULE -X- _ O
O -X- _ O
UTPUT -X- _ O
S -X- _ O
UPERVISION -X- _ O
Question -X- _ O
Parse -X- _ O
Supervision -X- _ O
. -X- _ O

4.2 -X- _ O
Q -X- _ O
UESTION -X- _ O
PARSE -X- _ O

Hloss -X- _ O
+ -X- _ O
Hloss -X- _ O
+ -X- _ O
Hloss -X- _ O
. -X- _ O

n -X- _ O
d -X- _ O
r -X- _ O
The -X- _ O
final -X- _ O
auxiliary -X- _ O
loss -X- _ O
is -X- _ O
Hloss -X- _ O
= -X- _ O

We -X- _ O
compute -X- _ O
a -X- _ O
similar -X- _ O
loss -X- _ O
for -X- _ O
the -X- _ O
date -X- _ O
- -X- _ O
attention -X- _ O
map -X- _ O
Adate -X- _ O
( -X- _ O
Hloss -X- _ O
) -X- _ O
and -X- _ O
the -X- _ O
relocate -X- _ O
- -X- _ O
map -X- _ O
R -X- _ O
( -X- _ O
Hloss -X- _ O
) -X- _ O
. -X- _ O

r -X- _ O

Anum -X- _ O
ij -X- _ O
 -X- _ O
j=0 -X- _ O
d -X- _ O

 -X- _ O
NX -X- _ O
1nj -X- _ O
∈[i±W -X- _ O
] -X- _ O

The -X- _ O
objective -X- _ O
for -X- _ O
the -X- _ O
find -X- _ O
- -X- _ O
num -X- _ O
is -X- _ O
n -X- _ O
Hloss -X- _ O
= -X- _ O
− -X- _ O
m -X- _ O
X -X- _ O
i=1 -X- _ O
log -X- _ O
tokens -X- _ O

For -X- _ O
any -X- _ O
token -X- _ O
, -X- _ O
the -X- _ O
objective -X- _ O
increases -X- _ O
the -X- _ O
sum -X- _ O
of -X- _ O
the -X- _ O
attention -X- _ O
probabilities -X- _ O
for -X- _ O
output -X- _ O
tokens -X- _ O
that -X- _ O
appear -X- _ O
within -X- _ O
a -X- _ O
window -X- _ O
W -X- _ O
= -X- _ O
10 -X- _ O
, -X- _ O
letting -X- _ O
the -X- _ O
model -X- _ O
distribute -X- _ O
the -X- _ O
mass -X- _ O
within -X- _ O
that -X- _ O
window -X- _ O
however -X- _ O
it -X- _ O
likes -X- _ O
. -X- _ O

We -X- _ O
introduce -X- _ O
an -X- _ O
auxiliary -X- _ O
objective -X- _ O
to -X- _ O
induce -X- _ O
the -X- _ O
idea -X- _ O
that -X- _ O
the -X- _ O
arguments -X- _ O
of -X- _ O
a -X- _ O
mention -X- _ O
should -X- _ O
appear -X- _ O
near -X- _ O
it -X- _ O
. -X- _ O

In -X- _ O
our -X- _ O
initial -X- _ O
experiments -X- _ O
we -X- _ O
found -X- _ O
that -X- _ O
these -X- _ O
modules -X- _ O
would -X- _ O
often -X- _ O
spuriously -X- _ O
predict -X- _ O
a -X- _ O
high -X- _ O
attention -X- _ O
score -X- _ O
for -X- _ O
output -X- _ O
tokens -X- _ O
that -X- _ O
appear -X- _ O
far -X- _ O
away -X- _ O
from -X- _ O
their -X- _ O
corresponding -X- _ O
inputs -X- _ O
. -X- _ O

4.1 -X- _ O
U -X- _ O
NSUPERVISED -X- _ O
AUXILIARY -X- _ O
L -X- _ O
OSS -X- _ O
FOR -X- _ O
IE -X- _ O
The -X- _ O
find -X- _ O
- -X- _ O
num -X- _ O
, -X- _ O
find -X- _ O
- -X- _ O
date -X- _ O
, -X- _ O
and -X- _ O
relocate -X- _ O
modules -X- _ O
perform -X- _ O
information -X- _ O
extraction -X- _ O
by -X- _ O
finding -X- _ O
relevant -X- _ O
arguments -X- _ O
for -X- _ O
entities -X- _ O
and -X- _ O
events -X- _ O
mentioned -X- _ O
in -X- _ O
the -X- _ O
context -X- _ O
. -X- _ O

To -X- _ O
overcome -X- _ O
issues -X- _ O
in -X- _ O
learning -X- _ O
, -X- _ O
( -X- _ O
a -X- _ O
) -X- _ O
we -X- _ O
introduce -X- _ O
an -X- _ O
unsupervised -X- _ O
auxiliary -X- _ O
loss -X- _ O
to -X- _ O
provide -X- _ O
an -X- _ O
inductive -X- _ O
bias -X- _ O
to -X- _ O
the -X- _ O
execution -X- _ O
of -X- _ O
find -X- _ O
- -X- _ O
num -X- _ O
, -X- _ O
find -X- _ O
- -X- _ O
date -X- _ O
, -X- _ O
and -X- _ O
relocate -X- _ O
modules -X- _ O
( -X- _ O
§ -X- _ O
4.1 -X- _ O
) -X- _ O
; -X- _ O
and -X- _ O
( -X- _ O
b -X- _ O
) -X- _ O
provide -X- _ O
heuristically -X- _ O
- -X- _ O
obtained -X- _ O
supervision -X- _ O
for -X- _ O
question -X- _ O
program -X- _ O
and -X- _ O
intermediate -X- _ O
module -X- _ O
output -X- _ O
( -X- _ O
§ -X- _ O
4.2 -X- _ O
) -X- _ O
for -X- _ O
a -X- _ O
subset -X- _ O
of -X- _ O
questions -X- _ O
( -X- _ O
5–10 -X- _ O
% -X- _ O
) -X- _ O
. -X- _ O

4 -X- _ O
AUXILIARY -X- _ O
S -X- _ O
UPERVISION -X- _ O
As -X- _ O
mentioned -X- _ O
in -X- _ O
§ -X- _ O
2.2 -X- _ O
, -X- _ O
jointly -X- _ O
learning -X- _ O
the -X- _ O
parameters -X- _ O
of -X- _ O
the -X- _ O
parser -X- _ O
and -X- _ O
the -X- _ O
modules -X- _ O
using -X- _ O
only -X- _ O
endtask -X- _ O
QA -X- _ O
supervision -X- _ O
is -X- _ O
extremely -X- _ O
challenging -X- _ O
. -X- _ O

This -X- _ O
module -X- _ O
is -X- _ O
implemented -X- _ O
similar -X- _ O
to -X- _ O
the -X- _ O
count -X- _ O
module -X- _ O
( -X- _ O
see -X- _ O
§ -X- _ O
A.5 -X- _ O
) -X- _ O
. -X- _ O

The -X- _ O
module -X- _ O
outputs -X- _ O
two -X- _ O
probability -X- _ O
distributions -X- _ O
, -X- _ O
Ps -X- _ O
and -X- _ O
Pe -X- _ O
∈ -X- _ O
Rm -X- _ O
, -X- _ O
denoting -X- _ O
the -X- _ O
probability -X- _ O
of -X- _ O
a -X- _ O
token -X- _ O
being -X- _ O
the -X- _ O
start -X- _ O
and -X- _ O
end -X- _ O
of -X- _ O
a -X- _ O
span -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O

This -X- _ O
module -X- _ O
is -X- _ O
used -X- _ O
to -X- _ O
convert -X- _ O
a -X- _ O
paragraph -X- _ O
attention -X- _ O
into -X- _ O
a -X- _ O
contiguous -X- _ O
answer -X- _ O
span -X- _ O
and -X- _ O
only -X- _ O
appears -X- _ O
as -X- _ O
the -X- _ O
outermost -X- _ O
module -X- _ O
in -X- _ O
a -X- _ O
program -X- _ O
. -X- _ O

→ -X- _ O
S -X- _ O

span(P -X- _ O
) -X- _ O

By -X- _ O
picking -X- _ O
the -X- _ O
set -X- _ O
size -X- _ O
n -X- _ B-HyperparameterName
= -X- _ O
3 -X- _ B-HyperparameterValue
as -X- _ O
a -X- _ O
hyperparameter -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
analytically -X- _ O
( -X- _ O
and -X- _ O
differentiably -X- _ O
) -X- _ O
convert -X- _ O
the -X- _ O
expected -X- _ O
distribution -X- _ O
over -X- _ O
number -X- _ O
tokens -X- _ O
, -X- _ O
T -X- _ O
, -X- _ O
into -X- _ O
a -X- _ O
distribution -X- _ O
over -X- _ O
the -X- _ O
maximum -X- _ O
value -X- _ O
T -X- _ O
max -X- _ O
. -X- _ O

The -X- _ O
probability -X- _ O
that -X- _ O
Nj -X- _ O
is -X- _ O
the -X- _ O
largest -X- _ O
number -X- _ O
in -X- _ O
this -X- _ O
set -X- _ O
is -X- _ O
p(x -X- _ O
≤ -X- _ O
Nj -X- _ O
) -X- _ O
n -X- _ O
− -X- _ O
p(x -X- _ O
≤ -X- _ O
Nj−1 -X- _ O
) -X- _ O
n -X- _ O
i.e. -X- _ O
all -X- _ O
numbers -X- _ O
in -X- _ O
S -X- _ O
are -X- _ O
less -X- _ O
than -X- _ O
or -X- _ O
equal -X- _ O
to -X- _ O
Nj -X- _ O
, -X- _ O
and -X- _ O
at -X- _ O
least -X- _ O
one -X- _ O
number -X- _ O
is -X- _ O
Nj -X- _ O
. -X- _ O

Say -X- _ O
we -X- _ O
sample -X- _ O
a -X- _ O
set -X- _ O
S -X- _ O
( -X- _ O
size -X- _ O
n -X- _ O
) -X- _ O
of -X- _ O
numbers -X- _ O
from -X- _ O
this -X- _ O
distribution -X- _ O
. -X- _ O

Computing -X- _ O
T -X- _ O
max -X- _ O
: -X- _ O
Consider -X- _ O
a -X- _ O
distribution -X- _ O
over -X- _ O
numbers -X- _ O
N -X- _ O
, -X- _ O
sorted -X- _ O
in -X- _ O
an -X- _ O
increasing -X- _ O
order -X- _ O
. -X- _ O

Pi -X- _ O
· -X- _ O
Anum -X- _ O
ij -X- _ O
. -X- _ O

To -X- _ O
compute -X- _ O
the -X- _ O
new -X- _ O
attention -X- _ O
value -X- _ O
for -X- _ O
token -X- _ O
i -X- _ O
, -X- _ O
we -X- _ O
re -X- _ O
- -X- _ O
weight -X- _ O
this -X- _ O
Tjmax -X- _ O
/ -X- _ O
Tj -X- _ O
and -X- _ O
marginalize -X- _ O
across -X- _ O
the -X- _ O
number -X- _ O
tokens -X- _ O
to -X- _ O
get -X- _ O
the -X- _ O
new -X- _ O
token -X- _ O
contribution -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
P -X- _ O
ratio -X- _ O
max -X- _ O
T -X- _ O
attention -X- _ O
value -X- _ O
: -X- _ O
P̄i -X- _ O
= -X- _ O
j -X- _ O
j -X- _ O
/Tj -X- _ O
· -X- _ O

The -X- _ O
contribution -X- _ O
from -X- _ O
the -X- _ O
i -X- _ O
- -X- _ O
th -X- _ O
paragraph -X- _ O
token -X- _ O
to -X- _ O
the -X- _ O
j -X- _ O
- -X- _ O
th -X- _ O
number -X- _ O
token -X- _ O
, -X- _ O
Tj -X- _ O
, -X- _ O
was -X- _ O
Pi -X- _ O
· -X- _ O
Anum -X- _ O
ij -X- _ O
. -X- _ O

We -X- _ O
then -X- _ O
re -X- _ O
- -X- _ O
distribute -X- _ O
this -X- _ O
distribution -X- _ O
back -X- _ O
to -X- _ O
the -X- _ O
original -X- _ O
passage -X- _ O
tokens -X- _ O
associated -X- _ O
with -X- _ O
those -X- _ O
numbers -X- _ O
. -X- _ O

We -X- _ O
first -X- _ O
compute -X- _ O
an -X- _ O
expected -X- _ O
number -X- _ O
token -X- _ O
distribution -X- _ O
T -X- _ O
using -X- _ O
find -X- _ O
- -X- _ O
num -X- _ O
, -X- _ O
then -X- _ O
use -X- _ O
this -X- _ O
to -X- _ O
compute -X- _ O
the -X- _ O
expected -X- _ O
probability -X- _ O
that -X- _ O
each -X- _ O
number -X- _ O
token -X- _ O
is -X- _ O
the -X- _ O
one -X- _ O
with -X- _ O
the -X- _ O
maximum -X- _ O
value -X- _ O
, -X- _ O
T -X- _ O
max -X- _ O
∈ -X- _ O
RNtokens -X- _ O
( -X- _ O
explained -X- _ O
below -X- _ O
) -X- _ O
. -X- _ O

Given -X- _ O
a -X- _ O
passage -X- _ O
attention -X- _ O
attending -X- _ O
to -X- _ O
multiple -X- _ O
spans -X- _ O
, -X- _ O
this -X- _ O
module -X- _ O
outputs -X- _ O
an -X- _ O
attention -X- _ O
for -X- _ O
the -X- _ O
span -X- _ O
associated -X- _ O
with -X- _ O
the -X- _ O
largest -X- _ O
( -X- _ O
or -X- _ O
smallest -X- _ O
) -X- _ O
number -X- _ O
. -X- _ O

find -X- _ O
- -X- _ O
max -X- _ O
- -X- _ O
num(P -X- _ O
) -X- _ O
→ -X- _ O
P -X- _ O
, -X- _ O
find -X- _ O
- -X- _ O
min -X- _ O
- -X- _ O
num(P -X- _ O
) -X- _ O
→ -X- _ O
P -X- _ O

i -X- _ O
, -X- _ O
j -X- _ O
1(di -X- _ O
−dj -X- _ O
= -X- _ O
td -X- _ O
) -X- _ O
D1i -X- _ O
D2j -X- _ O
. -X- _ O

The -X- _ O
probability -X- _ O
of -X- _ O
the -X- _ O
difference -X- _ O
being -X- _ O
td -X- _ O
is -X- _ O
computed -X- _ O
by -X- _ O
marginalizing -X- _ O
over -X- _ O
the -X- _ O
joint -X- _ O
P -X- _ O
probability -X- _ O
for -X- _ O
the -X- _ O
dates -X- _ O
that -X- _ O
yield -X- _ O
this -X- _ O
value -X- _ O
, -X- _ O
as -X- _ O
p(td -X- _ O
) -X- _ O
= -X- _ O

Published -X- _ O
as -X- _ O
a -X- _ O
conference -X- _ O
paper -X- _ O
at -X- _ O
ICLR -X- _ O
2020 -X- _ O
D1 -X- _ O
and -X- _ O
D2 -X- _ O
. -X- _ O

The -X- _ O
module -X- _ O
internally -X- _ O
calls -X- _ O
the -X- _ O
find -X- _ O
- -X- _ O
date -X- _ O
module -X- _ O
to -X- _ O
get -X- _ O
a -X- _ O
date -X- _ O
distribution -X- _ O
for -X- _ O
the -X- _ O
two -X- _ O
paragraph -X- _ O
attentions -X- _ O
, -X- _ O
5 -X- _ O

time -X- _ O
- -X- _ O
diff(P1 -X- _ O
, -X- _ O
P2 -X- _ O
) -X- _ O
→ -X- _ O
TD -X- _ O
The -X- _ O
module -X- _ O
outputs -X- _ O
the -X- _ O
difference -X- _ O
between -X- _ O
the -X- _ O
dates -X- _ O
associated -X- _ O
with -X- _ O
the -X- _ O
two -X- _ O
paragraph -X- _ O
attentions -X- _ O
as -X- _ O
a -X- _ O
distribution -X- _ O
over -X- _ O
all -X- _ O
possible -X- _ O
difference -X- _ O
values -X- _ O
. -X- _ O

We -X- _ O
similarly -X- _ O
include -X- _ O
the -X- _ O
comparison -X- _ O
modules -X- _ O
compare -X- _ O
- -X- _ O
num -X- _ O
- -X- _ O
gt -X- _ O
, -X- _ O
compare -X- _ O
- -X- _ O
date -X- _ O
- -X- _ O
lt -X- _ O
, -X- _ O
and -X- _ O
compare -X- _ O
- -X- _ O
date -X- _ O
- -X- _ O
gt -X- _ O
, -X- _ O
defined -X- _ O
in -X- _ O
an -X- _ O
essentially -X- _ O
identical -X- _ O
manner -X- _ O
, -X- _ O
but -X- _ O
for -X- _ O
greater -X- _ O
- -X- _ O
than -X- _ O
and -X- _ O
for -X- _ O
dates -X- _ O
. -X- _ O

When -X- _ O
the -X- _ O
the -X- _ O
predicted -X- _ O
number -X- _ O
distributions -X- _ O
are -X- _ O
peaky -X- _ O
, -X- _ O
p(N1 -X- _ O
< -X- _ O
N2 -X- _ O
) -X- _ O
or -X- _ O
p(N2 -X- _ O
< -X- _ O
N1 -X- _ O
) -X- _ O
is -X- _ O
close -X- _ O
to -X- _ O
1 -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
output -X- _ O
is -X- _ O
either -X- _ O
P1 -X- _ O
or -X- _ O
P2 -X- _ O
. -X- _ O

P1 -X- _ O
+ -X- _ O
p(N2 -X- _ O
< -X- _ O
N1 -X- _ O
) -X- _ O
∗ -X- _ O
P2 -X- _ O
. -X- _ O

The -X- _ O
final -X- _ O
output -X- _ O
is -X- _ O
, -X- _ O
Pout -X- _ O
= -X- _ O
p(N1 -X- _ O
< -X- _ O
N2 -X- _ O
) -X- _ O
∗ -X- _ O

i -X- _ O
2 -X- _ O
2 -X- _ O
j -X- _ O
i -X- _ O
1 -X- _ O
j -X- _ O

1N -X- _ O
i -X- _ O
< -X- _ O
N -X- _ O
j -X- _ O
N2i -X- _ O
N1j -X- _ O
1 -X- _ O

N1i -X- _ O
N2j -X- _ O
p(N2 -X- _ O
< -X- _ O
N1 -X- _ O
) -X- _ O
= -X- _ O

1N -X- _ O
i -X- _ O
< -X- _ O
N -X- _ O
j -X- _ O

The -X- _ O
boolean -X- _ O
values -X- _ O
are -X- _ O
computed -X- _ O
by -X- _ O
marginalizing -X- _ O
the -X- _ O
relevant -X- _ O
joint -X- _ O
probabilities -X- _ O
: -X- _ O
XX -X- _ O
XX -X- _ O
p(N1 -X- _ O
< -X- _ O
N2 -X- _ O
) -X- _ O
= -X- _ O

It -X- _ O
then -X- _ O
computes -X- _ O
two -X- _ O
soft -X- _ O
boolean -X- _ O
values -X- _ O
, -X- _ O
p(N1 -X- _ O
< -X- _ O
N2 -X- _ O
) -X- _ O
and -X- _ O
p(N2 -X- _ O
< -X- _ O
N1 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
outputs -X- _ O
a -X- _ O
weighted -X- _ O
sum -X- _ O
of -X- _ O
the -X- _ O
input -X- _ O
paragraph -X- _ O
attentions -X- _ O
. -X- _ O

This -X- _ O
module -X- _ O
internally -X- _ O
calls -X- _ O
the -X- _ O
find -X- _ O
- -X- _ O
num -X- _ O
module -X- _ O
to -X- _ O
get -X- _ O
a -X- _ O
number -X- _ O
distribution -X- _ O
for -X- _ O
each -X- _ O
of -X- _ O
the -X- _ O
input -X- _ O
paragraph -X- _ O
attentions -X- _ O
, -X- _ O
N1 -X- _ O
and -X- _ O
N2 -X- _ O
. -X- _ O

For -X- _ O
example -X- _ O
, -X- _ O
to -X- _ O
find -X- _ O
the -X- _ O
city -X- _ O
with -X- _ O
fewer -X- _ O
people -X- _ O
, -X- _ O
cityA -X- _ O
or -X- _ O
cityB -X- _ O
, -X- _ O
the -X- _ O
module -X- _ O
would -X- _ O
output -X- _ O
a -X- _ O
linear -X- _ O
combination -X- _ O
of -X- _ O
the -X- _ O
two -X- _ O
input -X- _ O
attentions -X- _ O
weighted -X- _ O
by -X- _ O
which -X- _ O
city -X- _ O
was -X- _ O
associated -X- _ O
with -X- _ O
a -X- _ O
lower -X- _ O
number -X- _ O
. -X- _ O

This -X- _ O
module -X- _ O
performs -X- _ O
a -X- _ O
soft -X- _ O
less -X- _ O
- -X- _ O
than -X- _ O
operation -X- _ O
between -X- _ O
two -X- _ O
passage -X- _ O
distributions -X- _ O
. -X- _ O

→ -X- _ O
P -X- _ O

compare -X- _ O
- -X- _ O
num -X- _ O
- -X- _ O
lt(P1 -X- _ O
, -X- _ O
P2 -X- _ O
) -X- _ O

Pretraining -X- _ O
this -X- _ O
module -X- _ O
by -X- _ O
generating -X- _ O
synthetic -X- _ O
data -X- _ O
of -X- _ O
attention -X- _ O
and -X- _ O
count -X- _ O
values -X- _ O
helps -X- _ O
( -X- _ O
see -X- _ O
§ -X- _ O
A.4 -X- _ O
) -X- _ O
. -X- _ O

[ -X- _ O
0 -X- _ O
, -X- _ O
9 -X- _ O
] -X- _ O
. -X- _ O

∀c -X- _ O
∈ -X- _ O

We -X- _ O
hypothesize -X- _ O
that -X- _ O
the -X- _ O
output -X- _ O
count -X- _ O
value -X- _ O
is -X- _ O
normally -X- _ O
distributed -X- _ O
with -X- _ O
cv -X- _ O
as -X- _ O
mean -X- _ O
, -X- _ O
and -X- _ O
a -X- _ O
constant -X- _ O
variance -X- _ O
v -X- _ O
= -X- _ O
0.5 -X- _ O
, -X- _ O
and -X- _ O
compute -X- _ O
a -X- _ O
categorical -X- _ O
distribution -X- _ O
2 -X- _ O
over -X- _ O
the -X- _ O
supported -X- _ O
count -X- _ O
values -X- _ O
, -X- _ O
as -X- _ O
p(c -X- _ O
) -X- _ O
∝ -X- _ O
exp(−(c−cv -X- _ O
) -X- _ O
/2v2 -X- _ O
) -X- _ O

R. -X- _ O

∈ -X- _ O

These -X- _ O
scores -X- _ O
are -X- _ O
summed -X- _ O
to -X- _ O
compute -X- _ O
a -X- _ O
count -X- _ O
value -X- _ O
, -X- _ O
cv -X- _ O
= -X- _ O
σ -X- _ O
( -X- _ O
F -X- _ O
F -X- _ O
( -X- _ O
countGRU(Pscaled -X- _ O
) -X- _ O
) -X- _ O
) -X- _ O

A -X- _ O
single -X- _ O
- -X- _ O
layer -X- _ O
feed -X- _ O
- -X- _ O
forward -X- _ O
network -X- _ O
maps -X- _ O
this -X- _ O
representation -X- _ O
to -X- _ O
a -X- _ O
soft -X- _ O
0/1 -X- _ O
score -X- _ O
to -X- _ O
indicate -X- _ O
P -X- _ O
the -X- _ O
presence -X- _ O
of -X- _ O
a -X- _ O
span -X- _ O
surrounding -X- _ O
it -X- _ O
. -X- _ O

A -X- _ O
bidirectional -X- _ O
- -X- _ O
GRU -X- _ O
then -X- _ O
represents -X- _ O
each -X- _ O
token -X- _ O
attention -X- _ O
as -X- _ O
a -X- _ O
hidden -X- _ O
vector -X- _ O
ht -X- _ O
. -X- _ O

The -X- _ O
module -X- _ O
first -X- _ O
scales -X- _ O
the -X- _ O
attention -X- _ O
using -X- _ O
the -X- _ O
values -X- _ O
[ -X- _ O
1 -X- _ O
, -X- _ O
2 -X- _ O
, -X- _ O
5 -X- _ O
, -X- _ O
10 -X- _ O
] -X- _ O
to -X- _ O
convert -X- _ O
it -X- _ O
into -X- _ O
a -X- _ O
matrix -X- _ O
Pscaled -X- _ O
∈ -X- _ O
Rm×4 -X- _ O
. -X- _ O

For -X- _ O
example -X- _ O
, -X- _ O
if -X- _ O
an -X- _ O
attention -X- _ O
vector -X- _ O
is -X- _ O
[ -X- _ O
0 -X- _ O
, -X- _ O
0 -X- _ O
, -X- _ O
0.3 -X- _ O
, -X- _ O
0.3 -X- _ O
, -X- _ O
0 -X- _ O
, -X- _ O
0.4 -X- _ O
] -X- _ O
, -X- _ O
the -X- _ O
count -X- _ O
module -X- _ O
should -X- _ O
produce -X- _ O
an -X- _ O
output -X- _ O
of -X- _ O
2 -X- _ O
. -X- _ O

The -X- _ O
idea -X- _ O
is -X- _ O
to -X- _ O
learn -X- _ O
a -X- _ O
module -X- _ O
that -X- _ O
detects -X- _ O
contiguous -X- _ O
spans -X- _ O
of -X- _ O
attention -X- _ O
values -X- _ O
and -X- _ O
counts -X- _ O
each -X- _ O
as -X- _ O
one -X- _ O
. -X- _ O

This -X- _ O
module -X- _ O
is -X- _ O
used -X- _ O
to -X- _ O
count -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
attended -X- _ O
paragraph -X- _ O
spans -X- _ O
. -X- _ O

count(P -X- _ O
) -X- _ O
→ -X- _ O
C -X- _ O

The -X- _ O
corresponding -X- _ O
learnable -X- _ O
parameter -X- _ O
matrix -X- _ O
is -X- _ O
Wdate -X- _ O
∈ -X- _ O
Rd×d -X- _ O
. -X- _ O

find -X- _ O
- -X- _ O
date(P -X- _ O
) -X- _ O
→ -X- _ O
D -X- _ O
follows -X- _ O
the -X- _ O
same -X- _ O
process -X- _ O
as -X- _ O
above -X- _ O
to -X- _ O
compute -X- _ O
a -X- _ O
distribution -X- _ O
over -X- _ O
dates -X- _ O
for -X- _ O
the -X- _ O
input -X- _ O
paragraph -X- _ O
attention -X- _ O
. -X- _ O

For -X- _ O
example -X- _ O
, -X- _ O
if -X- _ O
the -X- _ O
values -X- _ O
of -X- _ O
the -X- _ O
number -X- _ O
- -X- _ O
tokens -X- _ O
are -X- _ O
[ -X- _ O
2 -X- _ O
, -X- _ O
2 -X- _ O
, -X- _ O
3 -X- _ O
, -X- _ O
4 -X- _ O
] -X- _ O
and -X- _ O
T -X- _ O
= -X- _ O
[ -X- _ O
0.1 -X- _ O
, -X- _ O
0.4 -X- _ O
, -X- _ O
0.3 -X- _ O
, -X- _ O
0.2 -X- _ O
] -X- _ O
, -X- _ O
the -X- _ O
output -X- _ O
will -X- _ O
be -X- _ O
a -X- _ O
distribution -X- _ O
over -X- _ O
{ -X- _ O
2 -X- _ O
, -X- _ O
3 -X- _ O
, -X- _ O
4 -X- _ O
} -X- _ O
with -X- _ O
N -X- _ O
= -X- _ O
[ -X- _ O
0.5 -X- _ O
, -X- _ O
0.3 -X- _ O
, -X- _ O
0.2 -X- _ O
] -X- _ O
. -X- _ O

We -X- _ O
compute -X- _ O
an -X- _ O
expected -X- _ O
distribution -X- _ O
over -X- _ O
the -X- _ O
number -X- _ O
tokens -X- _ O
num -X- _ O
T -X- _ O
= -X- _ O
P -X- _ O
· -X- _ O
A -X- _ O
and -X- _ O
aggregate -X- _ O
the -X- _ O
probabilities -X- _ O
for -X- _ O
number -X- _ O
- -X- _ O
tokens -X- _ O
with -X- _ O
the -X- _ O
same -X- _ O
value -X- _ O
to -X- _ O
i -X- _ O
i -X- _ O
: -X- _ O
i -X- _ O
compute -X- _ O
the -X- _ O
output -X- _ O
distribution -X- _ O
N -X- _ O
. -X- _ O

i -X- _ O
: -X- _ O
) -X- _ O
. -X- _ O

AP -X- _ O
i -X- _ O
: -X- _ O
= -X- _ O
softmax(S -X- _ O

Wnum -X- _ O
Pnj -X- _ O
: -X- _ O
, -X- _ O
where -X- _ O
nj -X- _ O
is -X- _ O
the -X- _ O
index -X- _ O
of -X- _ O
the -X- _ O
j -X- _ O
- -X- _ O
th -X- _ O
number -X- _ O
token -X- _ O
and -X- _ O
Wnum -X- _ O
∈ -X- _ O
Rd×d -X- _ O
is -X- _ O
a -X- _ O
learnable -X- _ O
paramenum -X- _ O
num -X- _ O
ter -X- _ O
. -X- _ O

Rm×Ntokens -X- _ O
as -X- _ O
, -X- _ O
Snum -X- _ O
i -X- _ O
, -X- _ O
j -X- _ O
= -X- _ O
PTi -X- _ O
: -X- _ O

We -X- _ O
first -X- _ O
compute -X- _ O
a -X- _ O
token -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
number -X- _ O
similarity -X- _ O
matrix -X- _ O
Snum -X- _ O
∈ -X- _ O

Rm×Ntokens -X- _ O
whose -X- _ O
i -X- _ O
- -X- _ O
th -X- _ O
row -X- _ O
is -X- _ O
probability -X- _ O
distribution -X- _ O
over -X- _ O
number -X- _ O
- -X- _ O
containing -X- _ O
tokens -X- _ O
for -X- _ O
the -X- _ O
i -X- _ O
- -X- _ O
th -X- _ O
paragraph -X- _ O
token -X- _ O
. -X- _ O

We -X- _ O
use -X- _ O
a -X- _ O
paragraph -X- _ O
token -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
number -X- _ O
- -X- _ O
token -X- _ O
attention -X- _ O
map -X- _ O
Anum -X- _ O
∈ -X- _ O

This -X- _ O
module -X- _ O
finds -X- _ O
a -X- _ O
number -X- _ O
distribution -X- _ O
associated -X- _ O
with -X- _ O
the -X- _ O
input -X- _ O
paragraph -X- _ O
attention -X- _ O
. -X- _ O

i -X- _ O
Pi -X- _ O
· -X- _ O
Ri -X- _ O
: -X- _ O
find -X- _ O
- -X- _ O
num(P -X- _ O
) -X- _ O
→ -X- _ O
N -X- _ O

The -X- _ O
output -X- _ O
P -X- _ O
attention -X- _ O
is -X- _ O
a -X- _ O
weighted -X- _ O
sum -X- _ O
of -X- _ O
the -X- _ O
rows -X- _ O
R -X- _ O
weighted -X- _ O
by -X- _ O
the -X- _ O
input -X- _ O
paragraph -X- _ O
attention -X- _ O
, -X- _ O
Prelocated -X- _ O
= -X- _ O

Each -X- _ O
row -X- _ O
of -X- _ O
R -X- _ O
is -X- _ O
also -X- _ O
normalized -X- _ O
using -X- _ O
the -X- _ O
softmax -X- _ O
operation -X- _ O
. -X- _ O

Qi -X- _ O
: -X- _ O
∈ -X- _ O
Rd -X- _ O
, -X- _ O
and -X- _ O
wrelocate -X- _ O
∈ -X- _ O
R3d -X- _ O
is -X- _ O
a -X- _ O
learnable -X- _ O
parameter -X- _ O
vector -X- _ O
. -X- _ O

Pj -X- _ O
: -X- _ O
] -X- _ O
, -X- _ O
where -X- _ O
q -X- _ O
= -X- _ O
i -X- _ O
Qi -X- _ O
· -X- _ O

Pj -X- _ O
: -X- _ O
; -X- _ O
( -X- _ O
q -X- _ O
+ -X- _ O
Pi -X- _ O
: -X- _ O
) -X- _ O
◦ -X- _ O

wrelocate -X- _ O
T -X- _ O
[ -X- _ O
( -X- _ O
q -X- _ O
+ -X- _ O
Pi -X- _ O
: -X- _ O
) -X- _ O
; -X- _ O

We -X- _ O
first -X- _ O
compute -X- _ O
a -X- _ O
paragraph -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
paragraph -X- _ O
attention -X- _ O
matrix -X- _ O
R -X- _ O
∈PRm×m -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
question -X- _ O
, -X- _ O
as -X- _ O
Rij -X- _ O
= -X- _ O

This -X- _ O
module -X- _ O
re -X- _ O
- -X- _ O
attends -X- _ O
to -X- _ O
the -X- _ O
paragraph -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
question -X- _ O
and -X- _ O
is -X- _ O
used -X- _ O
to -X- _ O
find -X- _ O
the -X- _ O
arguments -X- _ O
for -X- _ O
paragraph -X- _ O
spans -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
shifting -X- _ O
the -X- _ O
attention -X- _ O
from -X- _ O
“ -X- _ O
field -X- _ O
goals -X- _ O
” -X- _ O
to -X- _ O
“ -X- _ O
who -X- _ O
kicked -X- _ O
” -X- _ O
them -X- _ O
) -X- _ O
. -X- _ O

relocate(Q -X- _ O
, -X- _ O
P -X- _ O
) -X- _ O
→ -X- _ O
P -X- _ O

The -X- _ O
output -X- _ O
is -X- _ O
a -X- _ O
normalized -X- _ O
masked -X- _ O
input -X- _ O
paragraph -X- _ O
attention -X- _ O
, -X- _ O
Pfiltered -X- _ O
= -X- _ O
normalize(M -X- _ O
◦ -X- _ O
P -X- _ O
) -X- _ O
. -X- _ O

Qi -X- _ O
: -X- _ O
∈ -X- _ O
R -X- _ O
, -X- _ O
is -X- _ O
a -X- _ O
weighted -X- _ O
sum -X- _ O
of -X- _ O
question -X- _ O
- -X- _ O
token -X- _ O
embeddings -X- _ O
, -X- _ O
wfilter -X- _ O
∈ -X- _ O
R -X- _ O
is -X- _ O
a -X- _ O
learnable -X- _ O
parameter -X- _ O
vector -X- _ O
, -X- _ O
and -X- _ O
σ -X- _ O
is -X- _ O
the -X- _ O
sigmoid -X- _ O
non -X- _ O
- -X- _ O
linearity -X- _ O
function -X- _ O
. -X- _ O

Here -X- _ O
q -X- _ O
= -X- _ O
i -X- _ O
Qi -X- _ O
· -X- _ O

P -X- _ O
score -X- _ O
for -X- _ O
thed -X- _ O
j -X- _ O
- -X- _ O
th -X- _ O
paragraph -X- _ O
token -X- _ O
computed -X- _ O
as -X- _ O
Mj -X- _ O
= -X- _ O
σ(wfilter -X- _ O
[ -X- _ O
q -X- _ O
; -X- _ O
PTj -X- _ O
: -X- _ O
; -X- _ O
q -X- _ O
◦ -X- _ O
3d -X- _ O

We -X- _ O
compute -X- _ O
a -X- _ O
locally -X- _ O
- -X- _ O
normalized -X- _ O
paragraph -X- _ O
- -X- _ O
token -X- _ O
mask -X- _ O
M -X- _ O
∈ -X- _ O
Rm -X- _ O
where -X- _ O
Mj -X- _ O
T -X- _ O
is -X- _ O
the -X- _ O
masking -X- _ O
Pj -X- _ O
: -X- _ O
] -X- _ O
) -X- _ O
. -X- _ O

Published -X- _ O
as -X- _ O
a -X- _ O
conference -X- _ O
paper -X- _ O
at -X- _ O
ICLR -X- _ O
2020 -X- _ O
quarter -X- _ O
” -X- _ O
in -X- _ O
Fig -X- _ O
. -X- _ O
1 -X- _ O
) -X- _ O
. -X- _ O

This -X- _ O
module -X- _ O
masks -X- _ O
the -X- _ O
input -X- _ O
paragraph -X- _ O
attention -X- _ O
conditioned -X- _ O
on -X- _ O
the -X- _ O
question -X- _ O
, -X- _ O
selecting -X- _ O
a -X- _ O
subset -X- _ O
of -X- _ O
the -X- _ O
attended -X- _ O
paragraph -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
selecting -X- _ O
fields -X- _ O
goals -X- _ O
“ -X- _ O
in -X- _ O
the -X- _ O
second -X- _ O
1 -X- _ O
We -X- _ O
extract -X- _ O
numbers -X- _ O
and -X- _ O
dates -X- _ O
as -X- _ O
a -X- _ O
pre -X- _ O
- -X- _ O
processing -X- _ O
step -X- _ O
explained -X- _ O
in -X- _ O
the -X- _ O
Appendix -X- _ O
( -X- _ O
§ -X- _ O
A.3 -X- _ O
) -X- _ O
4 -X- _ O

filter(Q -X- _ O
, -X- _ O
P -X- _ O
) -X- _ O
→ -X- _ O
P -X- _ O

Sij -X- _ O
= -X- _ O
wf -X- _ O
T -X- _ O
[ -X- _ O
Qi -X- _ O
: -X- _ O
; -X- _ O
Pj -X- _ O
: -X- _ O
; -X- _ O
Qi -X- _ O
: -X- _ O
◦ -X- _ O
Pj -X- _ O
: -X- _ O
] -X- _ O
, -X- _ O
where -X- _ O
wf -X- _ O
∈ -X- _ O
R3d -X- _ O
is -X- _ O
a -X- _ O
learnable -X- _ O
parameter -X- _ O
vector -X- _ O
of -X- _ O
this -X- _ O
module -X- _ O
, -X- _ O
[ -X- _ O
; -X- _ O
] -X- _ O
denotes -X- _ O
the -X- _ O
concatenation -X- _ O
operation -X- _ O
, -X- _ O
and -X- _ O
◦ -X- _ O
is -X- _ O
elementwise -X- _ O
multiplication -X- _ O
. -X- _ O

Here -X- _ O
Sij -X- _ O
is -X- _ O
the -X- _ O
similarity -X- _ O
between -X- _ O
the -X- _ O
contextual -X- _ O
embeddings -X- _ O
of -X- _ O
the -X- _ O
i -X- _ O
- -X- _ O
th -X- _ O
question -X- _ O
token -X- _ O
and -X- _ O
the -X- _ O
j -X- _ O
- -X- _ O
th -X- _ O
paragraph -X- _ O
token -X- _ O
computed -X- _ O
as -X- _ O
, -X- _ O

A -X- _ O
is -X- _ O
computed -X- _ O
by -X- _ O
normalizing -X- _ O
( -X- _ O
using -X- _ O
softmax -X- _ O
) -X- _ O
the -X- _ O
rows -X- _ O
of -X- _ O
a -X- _ O
question -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
paragraph -X- _ O
similarity -X- _ O
matrix -X- _ O
S -X- _ O
∈ -X- _ O
Rn×m -X- _ O
. -X- _ O

Ai -X- _ O
: -X- _ O
∈ -X- _ O
Rm -X- _ O
. -X- _ O

The -X- _ O
output -X- _ O
is -X- _ O
an -X- _ O
expected -X- _ O
paragraph -X- _ O
attention -X- _ O
; -X- _ O
a -X- _ O
weighted -X- _ O
- -X- _ O
sum -X- _ O
of -X- _ O
the -X- _ O
rows -X- _ O
of -X- _ O
A -X- _ O
, -X- _ O
weighed -X- _ O
by -X- _ O
the -X- _ O
P -X- _ O
input -X- _ O
question -X- _ O
attention -X- _ O
, -X- _ O
P -X- _ O
= -X- _ O
i -X- _ O
Qi -X- _ O
· -X- _ O

We -X- _ O
use -X- _ O
a -X- _ O
question -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
paragraph -X- _ O
attention -X- _ O
matrix -X- _ O
A -X- _ O
∈ -X- _ O
Rn×m -X- _ O
whose -X- _ O
i -X- _ O
- -X- _ O
th -X- _ O
row -X- _ O
is -X- _ O
the -X- _ O
distribution -X- _ O
of -X- _ O
similarity -X- _ O
over -X- _ O
the -X- _ O
paragraph -X- _ O
tokens -X- _ O
for -X- _ O
the -X- _ O
i -X- _ O
- -X- _ O
th -X- _ O
question -X- _ O
token -X- _ O
. -X- _ O

This -X- _ O
module -X- _ O
is -X- _ O
used -X- _ O
to -X- _ O
ground -X- _ O
attended -X- _ O
question -X- _ O
tokens -X- _ O
to -X- _ O
similar -X- _ O
tokens -X- _ O
in -X- _ O
the -X- _ O
paragraph -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
“ -X- _ O
field -X- _ O
goal -X- _ O
” -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
) -X- _ O
. -X- _ O

→ -X- _ O
P -X- _ O

find(Q -X- _ O
) -X- _ O

The -X- _ O
question -X- _ O
attention -X- _ O
computed -X- _ O
by -X- _ O
the -X- _ O
decoder -X- _ O
during -X- _ O
the -X- _ O
timestep -X- _ O
the -X- _ O
module -X- _ O
was -X- _ O
produced -X- _ O
is -X- _ O
also -X- _ O
available -X- _ O
to -X- _ O
the -X- _ O
module -X- _ O
as -X- _ O
a -X- _ O
side -X- _ O
argument -X- _ O
, -X- _ O
as -X- _ O
described -X- _ O
in -X- _ O
§ -X- _ O
2.1 -X- _ O
. -X- _ O

A -X- _ B-TaskName
NSWERING -X- _ I-TaskName
The -X- _ O
question -X- _ O
and -X- _ O
paragraph -X- _ O
contextualized -X- _ O
embeddings -X- _ O
( -X- _ O
Q -X- _ O
and -X- _ O
P -X- _ O
) -X- _ O
are -X- _ O
available -X- _ O
as -X- _ O
global -X- _ O
variables -X- _ O
to -X- _ O
all -X- _ O
modules -X- _ O
in -X- _ O
the -X- _ O
program -X- _ O
. -X- _ O

3.2 -X- _ O
N -X- _ O
EURAL -X- _ O
M -X- _ O
ODULES -X- _ O
FOR -X- _ O
Q -X- _ B-TaskName
UESTION -X- _ I-TaskName

• -X- _ O
Span -X- _ O
( -X- _ O
S -X- _ O
): -X- _ O
span -X- _ O
- -X- _ O
type -X- _ O
answers -X- _ O
as -X- _ O
two -X- _ O
probability -X- _ O
values -X- _ O
( -X- _ O
start -X- _ O
/ -X- _ O
end -X- _ O
) -X- _ O
for -X- _ O
each -X- _ O
paragraph -X- _ O
token -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
consider -X- _ O
differences -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
years -X- _ O
. -X- _ O

• -X- _ O
Time -X- _ O
Delta -X- _ O
( -X- _ O
TD -X- _ O
): -X- _ O
a -X- _ O
value -X- _ O
amongst -X- _ O
all -X- _ O
possible -X- _ O
unique -X- _ O
differences -X- _ O
between -X- _ O
dates -X- _ O
in -X- _ O
the -X- _ O
paragraph -X- _ O
. -X- _ O

1 -X- _ O
• -X- _ O
Count -X- _ O
Number -X- _ O
( -X- _ O
C -X- _ O
): -X- _ O
count -X- _ O
value -X- _ O
as -X- _ O
a -X- _ O
distribution -X- _ O
over -X- _ O
the -X- _ O
supported -X- _ O
count -X- _ O
values -X- _ O
( -X- _ O
0 -X- _ O
− -X- _ O
9 -X- _ O
) -X- _ O
. -X- _ O

• -X- _ O
Number -X- _ O
( -X- _ O
N -X- _ O
) -X- _ O
and -X- _ O
Date -X- _ O
( -X- _ O
D -X- _ O
): -X- _ O
soft -X- _ O
subset -X- _ O
of -X- _ O
unique -X- _ O
numbers -X- _ O
and -X- _ O
dates -X- _ O
from -X- _ O
the -X- _ O
passage -X- _ O
. -X- _ O

• -X- _ O
Question -X- _ O
( -X- _ O
Q -X- _ O
) -X- _ O
and -X- _ O
Paragraph -X- _ O
( -X- _ O
P -X- _ O
) -X- _ O
attentions -X- _ O
: -X- _ O
soft -X- _ O
subsets -X- _ O
of -X- _ O
relevant -X- _ O
tokens -X- _ O
in -X- _ O
the -X- _ O
text -X- _ O
. -X- _ O

Each -X- _ O
data -X- _ O
type -X- _ O
represents -X- _ O
its -X- _ O
underlying -X- _ O
value -X- _ O
as -X- _ O
a -X- _ O
normalized -X- _ O
distribution -X- _ O
over -X- _ O
the -X- _ O
relevant -X- _ O
support -X- _ O
. -X- _ O

The -X- _ O
modules -X- _ O
operate -X- _ O
over -X- _ O
the -X- _ O
following -X- _ O
data -X- _ O
types -X- _ O
. -X- _ O

3.1 -X- _ O
DATA -X- _ O
T -X- _ O
YPES -X- _ O

Table -X- _ O
1 -X- _ O
gives -X- _ O
an -X- _ O
overview -X- _ O
of -X- _ O
representative -X- _ O
modules -X- _ O
and -X- _ O
§ -X- _ O
3.2 -X- _ O
describes -X- _ O
them -X- _ O
in -X- _ O
detail -X- _ O
. -X- _ O

One -X- _ O
of -X- _ O
the -X- _ O
main -X- _ O
contributions -X- _ O
of -X- _ O
our -X- _ O
work -X- _ O
is -X- _ O
introducing -X- _ O
differentiable -X- _ O
modules -X- _ O
that -X- _ O
perform -X- _ O
reasoning -X- _ B-TaskName
over -X- _ O
text -X- _ O
and -X- _ O
symbols -X- _ O
in -X- _ O
a -X- _ O
probabilistic -X- _ O
manner -X- _ O
. -X- _ O

Since -X- _ O
the -X- _ O
module -X- _ O
parameters -X- _ O
will -X- _ O
be -X- _ O
learned -X- _ O
jointly -X- _ O
with -X- _ O
the -X- _ O
rest -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
, -X- _ O
we -X- _ O
would -X- _ O
like -X- _ O
the -X- _ O
modules -X- _ O
to -X- _ O
maintain -X- _ O
uncertainties -X- _ O
about -X- _ O
their -X- _ O
decisions -X- _ O
and -X- _ O
propagate -X- _ O
them -X- _ O
through -X- _ O
the -X- _ O
decision -X- _ O
making -X- _ O
layers -X- _ O
via -X- _ O
end -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
end -X- _ O
differentiability -X- _ O
. -X- _ O

We -X- _ O
identify -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
tasks -X- _ O
that -X- _ O
need -X- _ O
to -X- _ O
be -X- _ O
performed -X- _ O
to -X- _ O
support -X- _ O
diverse -X- _ O
enough -X- _ O
reasoning -X- _ B-TaskName
capabilities -X- _ O
over -X- _ O
text -X- _ O
, -X- _ O
numbers -X- _ O
, -X- _ O
and -X- _ O
dates -X- _ O
, -X- _ O
and -X- _ O
define -X- _ O
modules -X- _ O
accordingly -X- _ O
. -X- _ O

Published -X- _ O
as -X- _ O
a -X- _ O
conference -X- _ O
paper -X- _ O
at -X- _ O
ICLR -X- _ O
2020 -X- _ O
3 -X- _ O
M -X- _ O
ODULES -X- _ O
FOR -X- _ O
R -X- _ O
EASONING -X- _ O
OVER -X- _ O
T -X- _ O
EXT -X- _ O
Modules -X- _ O
are -X- _ O
designed -X- _ O
to -X- _ O
perform -X- _ O
basic -X- _ O
independent -X- _ B-TaskName
reasoning -X- _ I-TaskName
tasks -X- _ O
and -X- _ O
form -X- _ O
the -X- _ O
basis -X- _ O
of -X- _ O
the -X- _ O
compositional -X- _ B-TaskName
reasoning -X- _ I-TaskName
that -X- _ O
the -X- _ O
model -X- _ O
is -X- _ O
capable -X- _ O
of -X- _ O
. -X- _ O

3 -X- _ O

On -X- _ O
the -X- _ O
next -X- _ O
iteration -X- _ O
, -X- _ O
incorrect -X- _ O
program -X- _ O
execution -X- _ O
would -X- _ O
provide -X- _ O
the -X- _ O
wrong -X- _ O
feedback -X- _ O
to -X- _ O
the -X- _ O
question -X- _ O
parser -X- _ O
and -X- _ O
lead -X- _ O
to -X- _ O
its -X- _ O
incorrect -X- _ O
training -X- _ O
, -X- _ O
and -X- _ O
learning -X- _ O
fails -X- _ O
. -X- _ O

E.g. -X- _ O
, -X- _ O
if -X- _ O
the -X- _ O
parser -X- _ O
predicts -X- _ O
the -X- _ O
program -X- _ O
relocate(find -X- _ O
( -X- _ O
) -X- _ O
) -X- _ O
for -X- _ O
the -X- _ O
question -X- _ O
in -X- _ O
Fig -X- _ O
. -X- _ O
1 -X- _ O
, -X- _ O
then -X- _ O
the -X- _ O
associated -X- _ O
modules -X- _ O
would -X- _ O
be -X- _ O
incorrectly -X- _ O
trained -X- _ O
to -X- _ O
predict -X- _ O
the -X- _ O
gold -X- _ O
answer -X- _ O
. -X- _ O

Additionally -X- _ O
, -X- _ O
joint -X- _ O
learning -X- _ O
is -X- _ O
challenging -X- _ O
as -X- _ O
prediction -X- _ O
errors -X- _ O
from -X- _ O
one -X- _ O
component -X- _ O
lead -X- _ O
to -X- _ O
incorrect -X- _ O
training -X- _ O
of -X- _ O
the -X- _ O
other -X- _ O
. -X- _ O

Jointly -X- _ O
training -X- _ O
the -X- _ O
parser -X- _ O
and -X- _ O
executor -X- _ O
increases -X- _ O
the -X- _ O
latent -X- _ O
choices -X- _ O
available -X- _ O
to -X- _ O
the -X- _ O
model -X- _ O
by -X- _ O
many -X- _ O
folds -X- _ O
while -X- _ O
the -X- _ O
only -X- _ O
supervision -X- _ O
available -X- _ O
is -X- _ O
the -X- _ O
gold -X- _ O
answer -X- _ O
. -X- _ O

Joint -X- _ O
Learning -X- _ O
. -X- _ O

Differentiable -X- _ O
modules -X- _ O
that -X- _ O
propagate -X- _ O
uncertainties -X- _ O
in -X- _ O
intermediate -X- _ O
decisions -X- _ O
help -X- _ O
here -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
attention -X- _ O
on -X- _ O
pixels -X- _ O
in -X- _ O
CLEVR -X- _ B-DatasetName
, -X- _ O
but -X- _ O
do -X- _ O
not -X- _ O
fully -X- _ O
solve -X- _ O
the -X- _ O
learning -X- _ O
challenges -X- _ O
. -X- _ O

The -X- _ O
absence -X- _ O
of -X- _ O
any -X- _ O
direct -X- _ O
feedback -X- _ O
to -X- _ O
the -X- _ O
intermediate -X- _ O
modules -X- _ O
complicates -X- _ O
learning -X- _ O
since -X- _ O
the -X- _ O
errors -X- _ O
of -X- _ O
one -X- _ O
module -X- _ O
would -X- _ O
be -X- _ O
passed -X- _ O
on -X- _ O
to -X- _ O
the -X- _ O
next -X- _ O
. -X- _ O

The -X- _ O
output -X- _ O
of -X- _ O
each -X- _ O
intermediate -X- _ O
module -X- _ O
in -X- _ O
the -X- _ O
program -X- _ O
is -X- _ O
a -X- _ O
latent -X- _ O
decision -X- _ O
by -X- _ O
the -X- _ O
model -X- _ O
since -X- _ O
the -X- _ O
only -X- _ O
feedback -X- _ O
available -X- _ O
is -X- _ O
for -X- _ O
the -X- _ O
final -X- _ O
output -X- _ O
of -X- _ O
the -X- _ O
program -X- _ O
. -X- _ O

Program -X- _ O
Executor -X- _ O
. -X- _ O

Additionally -X- _ O
, -X- _ O
many -X- _ O
incorrect -X- _ O
programs -X- _ O
can -X- _ O
yield -X- _ O
the -X- _ O
same -X- _ O
correct -X- _ O
answer -X- _ O
thus -X- _ O
training -X- _ O
the -X- _ O
question -X- _ O
parser -X- _ O
to -X- _ O
highly -X- _ O
score -X- _ O
incorrect -X- _ O
interpretations -X- _ O
. -X- _ O

This -X- _ O
is -X- _ O
challenging -X- _ O
since -X- _ O
the -X- _ O
questions -X- _ O
are -X- _ O
not -X- _ O
generated -X- _ O
from -X- _ O
a -X- _ O
small -X- _ O
fixed -X- _ O
grammar -X- _ O
( -X- _ O
unlike -X- _ O
CLEVR -X- _ B-DatasetName
) -X- _ O
, -X- _ O
involve -X- _ O
lexical -X- _ O
variability -X- _ O
, -X- _ O
and -X- _ O
have -X- _ O
no -X- _ O
program -X- _ O
supervision -X- _ O
. -X- _ O

Our -X- _ O
model -X- _ O
needs -X- _ O
to -X- _ O
parse -X- _ O
free -X- _ O
- -X- _ O
form -X- _ O
real -X- _ O
- -X- _ O
world -X- _ O
questions -X- _ O
into -X- _ O
the -X- _ O
correct -X- _ O
program -X- _ O
structure -X- _ O
and -X- _ O
identify -X- _ O
its -X- _ O
arguments -X- _ O
( -X- _ O
e.g. -X- _ O
” -X- _ O
who -X- _ O
kicked -X- _ O
” -X- _ O
, -X- _ O
” -X- _ O
field -X- _ O
goal -X- _ O
” -X- _ O
, -X- _ O
etc -X- _ O
. -X- _ O
) -X- _ O
. -X- _ O

Question -X- _ O
Parser -X- _ O
. -X- _ O

Each -X- _ O
of -X- _ O
them -X- _ O
is -X- _ O
challenging -X- _ O
to -X- _ O
learn -X- _ O
in -X- _ O
its -X- _ O
own -X- _ O
right -X- _ O
and -X- _ O
joint -X- _ O
training -X- _ O
further -X- _ O
exacerbates -X- _ O
the -X- _ O
situation -X- _ O
. -X- _ O

As -X- _ O
mentioned -X- _ O
above -X- _ O
, -X- _ O
the -X- _ O
question -X- _ O
parser -X- _ O
and -X- _ O
the -X- _ O
program -X- _ O
executor -X- _ O
both -X- _ O
contain -X- _ O
learnable -X- _ O
parameters -X- _ O
. -X- _ O

2.2 -X- _ O
L -X- _ O
EARNING -X- _ O
C -X- _ O
HALLENGES -X- _ O
IN -X- _ O
NMN -X- _ B-MethodName
FOR -X- _ O
T -X- _ O
EXT -X- _ O

Since -X- _ O
the -X- _ O
space -X- _ O
of -X- _ O
all -X- _ O
programs -X- _ O
is -X- _ O
intractable -X- _ O
, -X- _ O
we -X- _ O
run -X- _ O
beam -X- _ O
search -X- _ O
to -X- _ O
enumerate -X- _ O
top -X- _ O
- -X- _ O
K -X- _ O
programs -X- _ O
and -X- _ O
maximize -X- _ O
the -X- _ O
approximate -X- _ O
marginal -X- _ O
- -X- _ O
likelihood -X- _ O
. -X- _ O

Combined -X- _ O
with -X- _ O
the -X- _ O
likelihood -X- _ O
of -X- _ O
the -X- _ O
program -X- _ O
under -X- _ O
the -X- _ O
question -X- _ O
- -X- _ O
parser -X- _ O
model -X- _ O
p(z|q -X- _ O
) -X- _ O
, -X- _ O
Pwe -X- _ O
can -X- _ O
maximize -X- _ O
the -X- _ O
marginal -X- _ O
likelihood -X- _ O
of -X- _ O
the -X- _ O
answer -X- _ O
by -X- _ O
enumerating -X- _ O
all -X- _ O
possible -X- _ O
programs -X- _ O
; -X- _ O
J -X- _ O
= -X- _ O
z -X- _ O
p(y -X- _ O
∗ -X- _ O
|z)p(z|q -X- _ O
) -X- _ O
. -X- _ O

We -X- _ O
define -X- _ O
our -X- _ O
model -X- _ O
probabilistically -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
for -X- _ O
any -X- _ O
given -X- _ O
program -X- _ O
z -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
compute -X- _ O
the -X- _ O
likelihood -X- _ O
of -X- _ O
the -X- _ O
gold -X- _ O
- -X- _ O
answer -X- _ O
p(y -X- _ O
∗ -X- _ O
|z -X- _ O
) -X- _ O
. -X- _ O

Learning -X- _ O
. -X- _ O

See -X- _ O
§ -X- _ O
A.2 -X- _ O
for -X- _ O
details -X- _ O
. -X- _ O

The -X- _ O
output -X- _ O
of -X- _ O
the -X- _ O
decoder -X- _ O
is -X- _ O
a -X- _ O
linearized -X- _ O
abstract -X- _ O
syntax -X- _ O
tree -X- _ O
( -X- _ O
in -X- _ O
an -X- _ O
in -X- _ O
- -X- _ O
order -X- _ O
traversal -X- _ O
) -X- _ O
. -X- _ O

For -X- _ O
example -X- _ O
, -X- _ O
if -X- _ O
a -X- _ O
module -X- _ O
f1 -X- _ O
inputs -X- _ O
a -X- _ O
number -X- _ O
, -X- _ O
and -X- _ O
f2 -X- _ O
outputs -X- _ O
a -X- _ O
date -X- _ O
, -X- _ O
then -X- _ O
f1 -X- _ O
( -X- _ O
f2 -X- _ O
) -X- _ O
is -X- _ O
invalid -X- _ O
and -X- _ O
would -X- _ O
not -X- _ O
be -X- _ O
explored -X- _ O
while -X- _ O
decoding -X- _ O
. -X- _ O

For -X- _ O
example -X- _ O
, -X- _ O
if -X- _ O
a -X- _ O
module -X- _ O
f1 -X- _ O
inputs -X- _ O
a -X- _ O
number -X- _ O
, -X- _ O
and -X- _ O
f2 -X- _ O
outputs -X- _ O
a -X- _ O
date -X- _ O
, -X- _ O
then -X- _ O
f1 -X- _ O
( -X- _ O
f2 -X- _ O
) -X- _ O
is -X- _ O
invalid -X- _ O
and -X- _ O
would -X- _ O
not -X- _ O
be -X- _ O
explored -X- _ O
while -X- _ O
decoding -X- _ O
. -X- _ O

This -X- _ O
ensures -X- _ O
that -X- _ O
the -X- _ O
decoder -X- _ O
always -X- _ O
produces -X- _ O
well -X- _ O
- -X- _ O
typed -X- _ O
programs -X- _ O
. -X- _ O

In -X- _ O
our -X- _ O
model -X- _ O
, -X- _ O
the -X- _ O
data -X- _ O
types -X- _ O
of -X- _ O
the -X- _ O
inputs -X- _ O
and -X- _ O
output -X- _ O
of -X- _ O
modules -X- _ O
automatically -X- _ O
induce -X- _ O
a -X- _ O
typeconstrained -X- _ O
grammar -X- _ O
which -X- _ O
lends -X- _ O
itself -X- _ O
to -X- _ O
top -X- _ O
- -X- _ O
down -X- _ O
grammar -X- _ O
- -X- _ O
constrained -X- _ O
decoding -X- _ O
as -X- _ O
performed -X- _ O
by -X- _ O
Krishnamurthy -X- _ O
et -X- _ O
al. -X- _ O
( -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O

This -X- _ O
lets -X- _ O
the -X- _ O
modules -X- _ O
have -X- _ O
access -X- _ O
to -X- _ O
question -X- _ O
information -X- _ O
without -X- _ O
making -X- _ O
hard -X- _ O
decisions -X- _ O
about -X- _ O
which -X- _ O
question -X- _ O
words -X- _ O
to -X- _ O
put -X- _ O
into -X- _ O
the -X- _ O
program -X- _ O
. -X- _ O

Similar -X- _ O
to -X- _ O
N2NMN -X- _ B-MethodName
( -X- _ O
Hu -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
, -X- _ O
at -X- _ O
each -X- _ O
timestep -X- _ O
of -X- _ O
decoding -X- _ O
, -X- _ O
the -X- _ O
attention -X- _ O
that -X- _ O
the -X- _ O
parser -X- _ O
puts -X- _ O
on -X- _ O
the -X- _ O
question -X- _ O
is -X- _ O
available -X- _ O
as -X- _ O
a -X- _ O
side -X- _ O
argument -X- _ O
to -X- _ O
the -X- _ O
module -X- _ O
produced -X- _ O
at -X- _ O
that -X- _ O
timestep -X- _ O
during -X- _ O
execution -X- _ O
. -X- _ O

We -X- _ O
use -X- _ O
an -X- _ O
encoder -X- _ O
- -X- _ O
decoder -X- _ O
model -X- _ O
with -X- _ O
attention -X- _ O
to -X- _ O
map -X- _ O
the -X- _ O
question -X- _ O
into -X- _ O
an -X- _ O
executable -X- _ O
program -X- _ O
. -X- _ O

Question -X- _ O
Parser -X- _ O
. -X- _ O

Appendix -X- _ O
§ -X- _ O
A.1 -X- _ O
contains -X- _ O
details -X- _ O
about -X- _ O
how -X- _ O
these -X- _ O
contextual -X- _ O
embeddings -X- _ O
are -X- _ O
produced -X- _ O
. -X- _ O

Here -X- _ O
n -X- _ O
and -X- _ O
m -X- _ O
are -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
tokens -X- _ O
in -X- _ O
the -X- _ O
question -X- _ O
and -X- _ O
the -X- _ O
paragraph -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O

These -X- _ O
are -X- _ O
outputs -X- _ O
of -X- _ O
either -X- _ O
the -X- _ O
same -X- _ O
bidirectional -X- _ O
- -X- _ O
GRU -X- _ O
or -X- _ O
a -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
BERT -X- _ O
( -X- _ O
Devlin -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
model -X- _ O
. -X- _ O

Our -X- _ O
model -X- _ O
represents -X- _ O
the -X- _ O
question -X- _ O
q -X- _ O
as -X- _ O
Q -X- _ O
∈ -X- _ O
Rn×d -X- _ O
and -X- _ O
the -X- _ O
context -X- _ O
paragraph -X- _ O
p -X- _ O
as -X- _ O
P -X- _ O
∈ -X- _ O
Rm×d -X- _ O
using -X- _ O
contextualized -X- _ O
token -X- _ O
embeddings -X- _ O
. -X- _ O

Contextual -X- _ O
Token -X- _ O
Representations -X- _ O
. -X- _ O

We -X- _ O
describe -X- _ O
these -X- _ O
modules -X- _ O
and -X- _ O
the -X- _ O
data -X- _ O
types -X- _ O
in -X- _ O
§ -X- _ O
3 -X- _ O
. -X- _ O

To -X- _ O
perform -X- _ O
natural -X- _ B-TaskName
language -X- _ I-TaskName
and -X- _ I-TaskName
symbolic -X- _ I-TaskName
reasoning -X- _ I-TaskName
over -X- _ O
different -X- _ O
types -X- _ O
of -X- _ O
information -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
text -X- _ O
, -X- _ O
numbers -X- _ O
, -X- _ O
and -X- _ O
dates -X- _ O
, -X- _ O
we -X- _ O
define -X- _ O
a -X- _ O
diverse -X- _ O
set -X- _ O
of -X- _ O
differentiable -X- _ O
modules -X- _ O
to -X- _ O
operate -X- _ O
over -X- _ O
these -X- _ O
different -X- _ O
data -X- _ O
types -X- _ O
. -X- _ O

Published -X- _ O
as -X- _ O
a -X- _ O
conference -X- _ O
paper -X- _ O
at -X- _ O
ICLR -X- _ O
2020 -X- _ O
2.1 -X- _ O
C -X- _ O
OMPONENTS -X- _ O
OF -X- _ O
A -X- _ O
NMN -X- _ O
FOR -X- _ O
T -X- _ O
EXT -X- _ O
Modules -X- _ O
. -X- _ O

2 -X- _ O

For -X- _ O
example -X- _ O
, -X- _ O
the -X- _ O
find -X- _ O
module -X- _ O
should -X- _ O
ground -X- _ O
the -X- _ O
question -X- _ O
span -X- _ O
“ -X- _ O
field -X- _ O
goal -X- _ O
” -X- _ O
to -X- _ O
its -X- _ O
various -X- _ O
occurrences -X- _ O
in -X- _ O
the -X- _ O
paragraph -X- _ O
; -X- _ O
the -X- _ O
module -X- _ O
find -X- _ O
- -X- _ O
max -X- _ O
- -X- _ O
num -X- _ O
should -X- _ O
output -X- _ O
the -X- _ O
span -X- _ O
amongst -X- _ O
its -X- _ O
input -X- _ O
that -X- _ O
is -X- _ O
associated -X- _ O
with -X- _ O
the -X- _ O
largest -X- _ O
length -X- _ O
; -X- _ O
and -X- _ O
finally -X- _ O
, -X- _ O
the -X- _ O
relocate -X- _ O
module -X- _ O
should -X- _ O
find -X- _ O
“ -X- _ O
who -X- _ O
kicked -X- _ O
” -X- _ O
the -X- _ O
field -X- _ O
goal -X- _ O
corresponding -X- _ O
to -X- _ O
its -X- _ O
input -X- _ O
span -X- _ O
. -X- _ O

These -X- _ O
programs -X- _ O
capture -X- _ O
the -X- _ O
abstract -X- _ O
compositional -X- _ O
reasoning -X- _ O
structure -X- _ O
required -X- _ O
to -X- _ O
answer -X- _ O
the -X- _ O
question -X- _ O
correctly -X- _ O
and -X- _ O
are -X- _ O
composed -X- _ O
of -X- _ O
learnable -X- _ O
modules -X- _ O
designed -X- _ O
to -X- _ O
solve -X- _ O
sufficiently -X- _ O
independent -X- _ O
reasoning -X- _ B-TaskName
tasks -X- _ O
. -X- _ O

A -X- _ O
NMN -X- _ B-MethodName
would -X- _ O
parse -X- _ O
such -X- _ O
a -X- _ O
question -X- _ O
into -X- _ O
an -X- _ O
executable -X- _ O
program -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
relocate(find -X- _ O
- -X- _ O
max -X- _ O
- -X- _ O
num(filter(find -X- _ O
( -X- _ O
) -X- _ O
) -X- _ O
) -X- _ O
) -X- _ O
, -X- _ O
whose -X- _ O
execution -X- _ O
against -X- _ O
the -X- _ O
given -X- _ O
paragraph -X- _ O
yields -X- _ O
the -X- _ O
correct -X- _ O
answer -X- _ O
. -X- _ O

Neural -X- _ B-MethodName
module -X- _ I-MethodName
networks -X- _ I-MethodName
( -X- _ O
NMN -X- _ B-MethodName
) -X- _ O
capture -X- _ O
this -X- _ O
intuition -X- _ O
naturally -X- _ O
, -X- _ O
which -X- _ O
makes -X- _ O
them -X- _ O
a -X- _ O
good -X- _ O
fit -X- _ O
to -X- _ O
solve -X- _ O
reasoning -X- _ B-TaskName
problems -X- _ I-TaskName
like -X- _ O
these -X- _ O
. -X- _ O

We -X- _ O
would -X- _ O
like -X- _ O
to -X- _ O
develop -X- _ O
machine -X- _ O
reading -X- _ O
models -X- _ O
that -X- _ O
are -X- _ O
capable -X- _ O
of -X- _ O
understanding -X- _ O
the -X- _ O
context -X- _ O
and -X- _ O
the -X- _ O
compositional -X- _ O
semantics -X- _ O
of -X- _ O
such -X- _ O
complex -X- _ O
questions -X- _ O
in -X- _ O
order -X- _ O
to -X- _ O
provide -X- _ O
the -X- _ O
correct -X- _ O
answer -X- _ O
, -X- _ O
ideally -X- _ O
while -X- _ O
also -X- _ O
explaining -X- _ O
the -X- _ O
reasoning -X- _ O
that -X- _ O
led -X- _ O
to -X- _ O
that -X- _ O
answer -X- _ O
. -X- _ O

Multiple -X- _ O
reasoning -X- _ O
steps -X- _ O
are -X- _ O
needed -X- _ O
to -X- _ O
answer -X- _ O
such -X- _ O
a -X- _ O
question -X- _ O
: -X- _ O
find -X- _ O
all -X- _ O
instances -X- _ O
of -X- _ O
“ -X- _ O
field -X- _ O
goal -X- _ O
” -X- _ O
in -X- _ O
the -X- _ O
paragraph -X- _ O
, -X- _ O
select -X- _ O
the -X- _ O
ones -X- _ O
“ -X- _ O
in -X- _ O
the -X- _ O
second -X- _ O
quarter -X- _ O
” -X- _ O
, -X- _ O
find -X- _ O
their -X- _ O
lengths -X- _ O
, -X- _ O
compute -X- _ O
the -X- _ O
“ -X- _ O
longest -X- _ O
” -X- _ O
of -X- _ O
them -X- _ O
, -X- _ O
and -X- _ O
then -X- _ O
find -X- _ O
“ -X- _ O
who -X- _ O
kicked -X- _ O
” -X- _ O
it -X- _ O
. -X- _ O

in -X- _ O
Figure -X- _ O
1 -X- _ O
. -X- _ O

2 -X- _ O
N -X- _ B-MethodName
EURAL -X- _ I-MethodName
M -X- _ I-MethodName
ODULE -X- _ I-MethodName
N -X- _ I-MethodName
ETWORKS -X- _ I-MethodName
Consider -X- _ O
the -X- _ O
question -X- _ O
“ -X- _ O
Who -X- _ O
kicked -X- _ O
the -X- _ O
longest -X- _ O
field -X- _ O
goal -X- _ O
in -X- _ O
the -X- _ O
second -X- _ O
quarter -X- _ O
? -X- _ O
” -X- _ O

We -X- _ O
conclude -X- _ O
with -X- _ O
a -X- _ O
discussion -X- _ O
of -X- _ O
the -X- _ O
challenges -X- _ O
of -X- _ O
pushing -X- _ O
NMNs -X- _ B-MethodName
to -X- _ O
the -X- _ O
entire -X- _ O
DROP -X- _ B-DatasetName
dataset -X- _ O
, -X- _ O
where -X- _ O
some -X- _ O
questions -X- _ O
require -X- _ O
reasoning -X- _ O
that -X- _ O
is -X- _ O
hard -X- _ O
to -X- _ O
design -X- _ O
modules -X- _ O
for -X- _ O
. -X- _ O

We -X- _ O
show -X- _ O
that -X- _ O
our -X- _ O
model -X- _ O
, -X- _ O
which -X- _ O
has -X- _ O
interpretable -X- _ O
intermediate -X- _ O
outputs -X- _ O
by -X- _ O
design -X- _ O
, -X- _ O
significantly -X- _ O
outperforms -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
black -X- _ O
box -X- _ O
models -X- _ O
on -X- _ O
this -X- _ O
dataset -X- _ O
. -X- _ O

This -X- _ O
is -X- _ O
a -X- _ O
significantly -X- _ O
- -X- _ O
sized -X- _ O
subset -X- _ O
that -X- _ O
poses -X- _ O
a -X- _ O
wide -X- _ O
variety -X- _ O
of -X- _ O
reasoning -X- _ O
challenges -X- _ O
and -X- _ O
allows -X- _ O
for -X- _ O
controlled -X- _ O
development -X- _ O
and -X- _ O
testing -X- _ O
of -X- _ O
models -X- _ O
. -X- _ O

We -X- _ O
experiment -X- _ O
on -X- _ O
21,800 -X- _ O
questions -X- _ O
from -X- _ O
the -X- _ O
recently -X- _ O
proposed -X- _ O
DROP -X- _ B-DatasetName
dataset -X- _ O
( -X- _ O
Dua -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
that -X- _ O
are -X- _ O
heuristically -X- _ O
chosen -X- _ O
based -X- _ O
on -X- _ O
their -X- _ O
first -X- _ O
n -X- _ O
- -X- _ O
gram -X- _ O
such -X- _ O
that -X- _ O
they -X- _ O
are -X- _ O
covered -X- _ O
by -X- _ O
our -X- _ O
designed -X- _ O
modules -X- _ O
. -X- _ O

Additionally -X- _ O
, -X- _ O
we -X- _ O
show -X- _ O
that -X- _ O
providing -X- _ O
heuristically -X- _ O
- -X- _ O
obtained -X- _ O
supervision -X- _ O
for -X- _ O
question -X- _ O
programs -X- _ O
and -X- _ O
outputs -X- _ O
for -X- _ O
intermediate -X- _ O
modules -X- _ O
in -X- _ O
a -X- _ O
program -X- _ O
( -X- _ O
§ -X- _ O
4.2 -X- _ O
) -X- _ O
for -X- _ O
a -X- _ O
small -X- _ O
subset -X- _ O
of -X- _ O
the -X- _ O
training -X- _ O
data -X- _ O
( -X- _ O
5–10 -X- _ O
% -X- _ O
) -X- _ O
is -X- _ O
sufficient -X- _ O
for -X- _ O
accurate -X- _ O
learning -X- _ O
. -X- _ O

Specifically -X- _ O
, -X- _ O
we -X- _ O
introduce -X- _ O
an -X- _ O
unsupervised -X- _ O
objective -X- _ O
that -X- _ O
provides -X- _ O
an -X- _ O
inductive -X- _ O
bias -X- _ O
to -X- _ O
perform -X- _ O
accurate -X- _ O
information -X- _ O
extraction -X- _ O
from -X- _ O
the -X- _ O
context -X- _ O
( -X- _ O
§ -X- _ O
4.1 -X- _ O
) -X- _ O
. -X- _ O

Secondly -X- _ O
, -X- _ O
we -X- _ O
show -X- _ O
that -X- _ O
the -X- _ O
challenges -X- _ O
arising -X- _ O
in -X- _ O
learning -X- _ O
from -X- _ O
end -X- _ O
- -X- _ O
task -X- _ O
QA -X- _ O
supervision -X- _ O
can -X- _ O
be -X- _ O
alleviated -X- _ O
with -X- _ O
an -X- _ O
auxiliary -X- _ O
loss -X- _ O
over -X- _ O
the -X- _ O
intermediate -X- _ O
latent -X- _ O
decisions -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
. -X- _ O

The -X- _ O
modules -X- _ O
we -X- _ O
define -X- _ O
are -X- _ O
probabilistic -X- _ O
and -X- _ O
differentiable -X- _ O
, -X- _ O
which -X- _ O
lets -X- _ O
us -X- _ O
maintain -X- _ O
uncertainty -X- _ O
about -X- _ O
intermediate -X- _ O
decisions -X- _ O
and -X- _ O
train -X- _ O
the -X- _ O
entire -X- _ O
model -X- _ O
via -X- _ O
end -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
end -X- _ O
differentiability -X- _ O
. -X- _ O

We -X- _ O
introduce -X- _ O
neural -X- _ O
modules -X- _ O
to -X- _ O
perform -X- _ O
reasoning -X- _ O
over -X- _ O
text -X- _ O
using -X- _ O
distributed -X- _ O
representations -X- _ O
, -X- _ O
and -X- _ O
perform -X- _ O
symbolic -X- _ B-TaskName
reasoning -X- _ I-TaskName
, -X- _ O
such -X- _ O
as -X- _ O
arithmetic -X- _ B-TaskName
, -X- _ O
sorting -X- _ B-TaskName
, -X- _ O
comparisons -X- _ B-TaskName
, -X- _ O
and -X- _ O
counting -X- _ B-TaskName
( -X- _ O
§ -X- _ O
3 -X- _ O
) -X- _ O
. -X- _ O

Our -X- _ O
contributions -X- _ O
are -X- _ O
two -X- _ O
- -X- _ O
fold -X- _ O
: -X- _ O
Firstly -X- _ O
, -X- _ O
we -X- _ O
extend -X- _ O
NMNs -X- _ B-MethodName
to -X- _ O
answer -X- _ O
compositional -X- _ O
questions -X- _ O
against -X- _ O
a -X- _ O
paragraph -X- _ O
of -X- _ O
text -X- _ O
as -X- _ O
context -X- _ O
. -X- _ O

Jointly -X- _ O
learning -X- _ O
the -X- _ O
parser -X- _ O
and -X- _ O
executor -X- _ O
using -X- _ O
only -X- _ O
QA -X- _ O
supervision -X- _ O
is -X- _ O
also -X- _ O
extremely -X- _ O
challenging -X- _ O
( -X- _ O
§ -X- _ O
2.2 -X- _ O
) -X- _ O
. -X- _ O

the -X- _ O
ambiguity -X- _ O
and -X- _ O
variability -X- _ O
of -X- _ O
real -X- _ O
- -X- _ O
world -X- _ O
text -X- _ O
while -X- _ O
performing -X- _ O
a -X- _ O
diverse -X- _ O
range -X- _ O
of -X- _ O
reasoning -X- _ B-TaskName
. -X- _ O

Published -X- _ O
as -X- _ O
a -X- _ O
conference -X- _ O
paper -X- _ O
at -X- _ O
ICLR -X- _ O
2020 -X- _ O
Figure -X- _ O
1 -X- _ O
: -X- _ O
Model -X- _ O
Overview -X- _ O
: -X- _ O
Given -X- _ O
a -X- _ O
question -X- _ O
, -X- _ O
our -X- _ O
model -X- _ O
parses -X- _ O
it -X- _ O
into -X- _ O
a -X- _ O
program -X- _ O
composed -X- _ O
of -X- _ O
neural -X- _ O
modules -X- _ O
. -X- _ O

We -X- _ O
find -X- _ O
, -X- _ O
however -X- _ O
, -X- _ O
that -X- _ O
it -X- _ O
is -X- _ O
non -X- _ O
- -X- _ O
trivial -X- _ O
to -X- _ O
extend -X- _ O
NMNs -X- _ B-MethodName
for -X- _ O
answering -X- _ O
non -X- _ O
- -X- _ O
synthetic -X- _ O
questions -X- _ O
against -X- _ O
open -X- _ O
- -X- _ O
domain -X- _ O
text -X- _ O
, -X- _ O
where -X- _ O
a -X- _ O
model -X- _ O
needs -X- _ O
to -X- _ O
deal -X- _ O
with -X- _ O
∗ -X- _ O
Work -X- _ O
done -X- _ O
while -X- _ O
at -X- _ O
Allen -X- _ O
Institute -X- _ O
for -X- _ O
AI -X- _ O
. -X- _ O
1 -X- _ O

NMNs -X- _ B-MethodName
perform -X- _ O
well -X- _ O
on -X- _ O
synthetic -X- _ B-TaskName
visual -X- _ I-TaskName
question -X- _ I-TaskName
answering -X- _ I-TaskName
( -X- _ O
VQA -X- _ B-TaskName
) -X- _ O
domains -X- _ O
such -X- _ O
as -X- _ O
CLEVR -X- _ B-DatasetName
( -X- _ O
Johnson -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
and -X- _ O
it -X- _ O
is -X- _ O
appealing -X- _ O
to -X- _ O
apply -X- _ O
them -X- _ O
to -X- _ O
answer -X- _ O
questions -X- _ O
over -X- _ O
text -X- _ O
due -X- _ O
to -X- _ O
their -X- _ O
interpretable -X- _ O
, -X- _ O
modular -X- _ O
, -X- _ O
and -X- _ O
inherently -X- _ O
compositional -X- _ O
nature -X- _ O
. -X- _ O

These -X- _ O
modules -X- _ O
are -X- _ O
designed -X- _ O
to -X- _ O
perform -X- _ O
basic -X- _ O
reasoning -X- _ B-TaskName
tasks -X- _ O
and -X- _ O
can -X- _ O
be -X- _ O
composed -X- _ O
to -X- _ O
perform -X- _ O
complex -X- _ O
reasoning -X- _ B-TaskName
over -X- _ O
unstructured -X- _ O
knowledge -X- _ O
. -X- _ O

Neural -X- _ B-MethodName
module -X- _ I-MethodName
networks -X- _ I-MethodName
( -X- _ O
NMNs -X- _ B-MethodName
; -X- _ O
Andreas -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
extend -X- _ O
semantic -X- _ O
parsers -X- _ O
by -X- _ O
making -X- _ O
the -X- _ O
program -X- _ O
executor -X- _ O
a -X- _ O
learned -X- _ O
function -X- _ O
composed -X- _ O
of -X- _ O
neural -X- _ O
network -X- _ O
modules -X- _ O
. -X- _ O

Semantic -X- _ O
parsing -X- _ O
techniques -X- _ O
, -X- _ O
which -X- _ O
map -X- _ O
natural -X- _ O
language -X- _ O
utterances -X- _ O
to -X- _ O
executable -X- _ O
programs -X- _ O
, -X- _ O
have -X- _ O
been -X- _ O
used -X- _ O
for -X- _ O
compositional -X- _ B-TaskName
question -X- _ I-TaskName
understanding -X- _ I-TaskName
for -X- _ O
a -X- _ O
long -X- _ O
time -X- _ O
( -X- _ O
Zelle -X- _ O
& -X- _ O
Mooney -X- _ O
, -X- _ O
1996 -X- _ O
; -X- _ O
Zettlemoyer -X- _ O
& -X- _ O
Collins -X- _ O
, -X- _ O
2005 -X- _ O
; -X- _ O
Liang -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2011 -X- _ O
) -X- _ O
, -X- _ O
but -X- _ O
have -X- _ O
been -X- _ O
limited -X- _ O
to -X- _ O
answering -X- _ O
questions -X- _ O
against -X- _ O
structured -X- _ O
and -X- _ O
semi -X- _ O
- -X- _ O
structured -X- _ O
knowledge -X- _ O
sources -X- _ O
. -X- _ O

for -X- _ O
the -X- _ O
field -X- _ O
goals -X- _ O
and -X- _ O
touchdowns -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
perform -X- _ O
symbolic -X- _ B-TaskName
reasoning -X- _ I-TaskName
( -X- _ O
eg -X- _ O
. -X- _ O
counting -X- _ O
, -X- _ O
sorting -X- _ O
, -X- _ O
etc -X- _ O
. -X- _ O
) -X- _ O
. -X- _ O

Consider -X- _ O
the -X- _ O
question -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
; -X- _ O
a -X- _ O
model -X- _ O
needs -X- _ O
to -X- _ O
understand -X- _ O
the -X- _ O
compositional -X- _ O
reasoning -X- _ O
structure -X- _ O
of -X- _ O
the -X- _ O
questions -X- _ O
, -X- _ O
perform -X- _ O
accurate -X- _ O
information -X- _ O
extraction -X- _ O
from -X- _ O
the -X- _ O
passage -X- _ O
( -X- _ O
eg -X- _ O
. -X- _ O
extract -X- _ O
lengths -X- _ O
, -X- _ O
kickers -X- _ O
, -X- _ O
etc -X- _ O
. -X- _ O

Answering -X- _ O
complex -X- _ O
compositional -X- _ O
questions -X- _ O
against -X- _ O
text -X- _ O
is -X- _ O
challenging -X- _ O
since -X- _ O
it -X- _ O
requires -X- _ O
a -X- _ O
comprehensive -X- _ O
understanding -X- _ O
of -X- _ O
both -X- _ O
the -X- _ O
question -X- _ O
semantics -X- _ O
and -X- _ O
the -X- _ O
text -X- _ O
against -X- _ O
which -X- _ O
the -X- _ O
question -X- _ O
needs -X- _ O
to -X- _ O
be -X- _ O
answered -X- _ O
. -X- _ O

Recent -X- _ O
models -X- _ O
have -X- _ O
performed -X- _ O
well -X- _ O
on -X- _ O
certain -X- _ O
QA -X- _ O
datasets -X- _ O
, -X- _ O
sometimes -X- _ O
rivaling -X- _ O
humans -X- _ O
( -X- _ O
Zhang -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
but -X- _ O
it -X- _ O
has -X- _ O
become -X- _ O
increasingly -X- _ O
clear -X- _ O
that -X- _ O
they -X- _ O
primarily -X- _ O
exploit -X- _ O
surface -X- _ O
level -X- _ O
lexical -X- _ O
cues -X- _ O
( -X- _ O
Jia -X- _ O
& -X- _ O
Liang -X- _ O
, -X- _ O
2017 -X- _ O
; -X- _ O
Feng -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
and -X- _ O
compositional -X- _ B-TaskName
QA -X- _ I-TaskName
still -X- _ O
remains -X- _ O
a -X- _ O
challenge -X- _ O
. -X- _ O

Being -X- _ O
formalism -X- _ O
- -X- _ O
free -X- _ O
and -X- _ O
close -X- _ O
to -X- _ O
an -X- _ O
end -X- _ O
- -X- _ O
user -X- _ O
task -X- _ O
, -X- _ O
QA -X- _ B-TaskName
is -X- _ O
increasingly -X- _ O
becoming -X- _ O
a -X- _ O
proxy -X- _ O
for -X- _ O
gauging -X- _ O
a -X- _ O
model -X- _ O
’s -X- _ O
natural -X- _ O
language -X- _ O
understanding -X- _ O
capability -X- _ O
( -X- _ O
He -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2015 -X- _ O
; -X- _ O
Talmor -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O

I -X- _ O
NTRODUCTION -X- _ O

1 -X- _ O

Our -X- _ O
proposed -X- _ O
model -X- _ O
significantly -X- _ O
outperforms -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
models -X- _ O
on -X- _ O
a -X- _ O
subset -X- _ O
of -X- _ O
the -X- _ O
DROP -X- _ B-DatasetName
dataset -X- _ O
that -X- _ O
poses -X- _ O
a -X- _ O
variety -X- _ O
of -X- _ O
reasoning -X- _ O
challenges -X- _ O
that -X- _ O
are -X- _ O
covered -X- _ O
by -X- _ O
our -X- _ O
modules -X- _ O
. -X- _ O

Additionally -X- _ O
, -X- _ O
we -X- _ O
show -X- _ O
that -X- _ O
a -X- _ O
limited -X- _ O
amount -X- _ O
of -X- _ O
heuristically -X- _ O
- -X- _ O
obtained -X- _ O
question -X- _ O
program -X- _ O
and -X- _ O
intermediate -X- _ O
module -X- _ O
output -X- _ O
supervision -X- _ O
provides -X- _ O
sufficient -X- _ O
inductive -X- _ O
bias -X- _ O
for -X- _ O
accurate -X- _ O
learning -X- _ O
. -X- _ O

We -X- _ O
extend -X- _ O
NMNs -X- _ B-MethodName
by -X- _ O
: -X- _ O
( -X- _ O
a -X- _ O
) -X- _ O
introducing -X- _ O
modules -X- _ O
that -X- _ O
reason -X- _ O
over -X- _ O
a -X- _ O
paragraph -X- _ O
of -X- _ O
text -X- _ O
, -X- _ O
performing -X- _ O
symbolic -X- _ O
reasoning -X- _ O
( -X- _ O
such -X- _ O
as -X- _ O
arithmetic -X- _ O
, -X- _ O
sorting -X- _ O
, -X- _ O
counting -X- _ O
) -X- _ O
over -X- _ O
numbers -X- _ O
and -X- _ O
dates -X- _ O
in -X- _ O
a -X- _ O
probabilistic -X- _ O
and -X- _ O
differentiable -X- _ O
manner -X- _ O
; -X- _ O
and -X- _ O
( -X- _ O
b -X- _ O
) -X- _ O
proposing -X- _ O
an -X- _ O
unsupervised -X- _ O
auxiliary -X- _ O
loss -X- _ O
to -X- _ O
help -X- _ O
extract -X- _ O
arguments -X- _ O
associated -X- _ O
with -X- _ O
the -X- _ O
events -X- _ O
in -X- _ O
text -X- _ O
. -X- _ O

However -X- _ O
, -X- _ O
we -X- _ O
find -X- _ O
that -X- _ O
it -X- _ O
is -X- _ O
challenging -X- _ O
to -X- _ O
learn -X- _ O
these -X- _ O
models -X- _ O
for -X- _ O
non -X- _ O
- -X- _ O
synthetic -X- _ O
questions -X- _ O
on -X- _ O
open -X- _ O
- -X- _ O
domain -X- _ O
text -X- _ O
, -X- _ O
where -X- _ O
a -X- _ O
model -X- _ O
needs -X- _ O
to -X- _ O
deal -X- _ O
with -X- _ O
the -X- _ O
diversity -X- _ O
of -X- _ O
natural -X- _ O
language -X- _ O
and -X- _ O
perform -X- _ O
a -X- _ O
broader -X- _ O
range -X- _ O
of -X- _ O
reasoning -X- _ O
. -X- _ O

Neural -X- _ B-MethodName
module -X- _ I-MethodName
networks -X- _ I-MethodName
( -X- _ O
NMNs -X- _ B-MethodName
) -X- _ O
learn -X- _ O
to -X- _ O
parse -X- _ O
such -X- _ O
questions -X- _ O
as -X- _ O
executable -X- _ O
programs -X- _ O
composed -X- _ O
of -X- _ O
learnable -X- _ O
modules -X- _ O
, -X- _ O
performing -X- _ O
well -X- _ O
on -X- _ O
synthetic -X- _ O
visual -X- _ O
QA -X- _ O
domains -X- _ O
. -X- _ O

[ -X- _ O
cs -X- _ O
. -X- _ O
CL -X- _ O
] -X- _ O
15 -X- _ O
Feb -X- _ O
2020 -X- _ O
Nitish -X- _ O
Gupta1 -X- _ O
, -X- _ O
Kevin -X- _ O
Lin2∗ -X- _ O
, -X- _ O
Dan -X- _ O
Roth1 -X- _ O
, -X- _ O
Sameer -X- _ O
Singh3 -X- _ O
& -X- _ O
Matt -X- _ O
Gardner4 -X- _ O
{ -X- _ O
nitishg,danroth}@seas.upenn.edu -X- _ O
, -X- _ O
kevinlin@eecs.berkeley.edu -X- _ O
, -X- _ O
sameer@uci.edu -X- _ O
, -X- _ O
mattg@allenai.org -X- _ O
1 -X- _ O
University -X- _ O
of -X- _ O
Pennsylvania -X- _ O
, -X- _ O
Philadelphia -X- _ O
, -X- _ O
2 -X- _ O
University -X- _ O
of -X- _ O
California -X- _ O
, -X- _ O
Berkeley -X- _ O
, -X- _ O
3 -X- _ O
University -X- _ O
of -X- _ O
California -X- _ O
, -X- _ O
Irvine -X- _ O
, -X- _ O
4 -X- _ O
Allen -X- _ O
Institute -X- _ O
for -X- _ O
AI -X- _ O
A -X- _ O
BSTRACT -X- _ O
Answering -X- _ O
compositional -X- _ O
questions -X- _ O
that -X- _ O
require -X- _ O
multiple -X- _ O
steps -X- _ O
of -X- _ O
reasoning -X- _ O
against -X- _ O
text -X- _ O
is -X- _ O
challenging -X- _ O
, -X- _ O
especially -X- _ O
when -X- _ O
they -X- _ O
involve -X- _ O
discrete -X- _ O
, -X- _ O
symbolic -X- _ O
operations -X- _ O
. -X- _ O

Published -X- _ O
as -X- _ O
a -X- _ O
conference -X- _ O
paper -X- _ O
at -X- _ O
ICLR -X- _ O
2020 -X- _ O
N -X- _ B-MethodName
EURAL -X- _ I-MethodName
M -X- _ I-MethodName
ODULE -X- _ I-MethodName
N -X- _ I-MethodName
ETWORKS -X- _ I-MethodName
FOR -X- _ I-MethodName
R -X- _ I-MethodName
EASONING -X- _ I-MethodName
OVER -X- _ I-MethodName
T -X- _ I-MethodName
EXT -X- _ I-MethodName
arXiv:1912.04971v2 -X- _ O

