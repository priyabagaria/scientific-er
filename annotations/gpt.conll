-DOCSTART- -X- O
References -X- _ O
[ -X- _ O
1 -X- _ O
] -X- _ O
S. -X- _ O
Arora -X- _ O
, -X- _ O
Y. -X- _ O
Liang -X- _ O
, -X- _ O
and -X- _ O
T. -X- _ O
Ma -X- _ O
. -X- _ O

We -X- _ O
hope -X- _ O
that -X- _ O
this -X- _ O
will -X- _ O
help -X- _ O
enable -X- _ O
new -X- _ O
research -X- _ O
into -X- _ O
unsupervised -X- _ O
learning -X- _ O
, -X- _ O
for -X- _ O
both -X- _ O
natural -X- _ O
language -X- _ O
understanding -X- _ O
and -X- _ O
other -X- _ O
domains -X- _ O
, -X- _ O
further -X- _ O
improving -X- _ O
our -X- _ O
understanding -X- _ O
of -X- _ O
how -X- _ O
and -X- _ O
when -X- _ O
unsupervised -X- _ O
learning -X- _ O
works -X- _ O
. -X- _ O

Our -X- _ O
work -X- _ O
suggests -X- _ O
that -X- _ O
achieving -X- _ O
significant -X- _ O
performance -X- _ O
gains -X- _ O
is -X- _ O
indeed -X- _ O
possible -X- _ O
, -X- _ O
and -X- _ O
offers -X- _ O
hints -X- _ O
as -X- _ O
to -X- _ O
what -X- _ O
models -X- _ O
( -X- _ O
Transformers -X- _ O
) -X- _ O
and -X- _ O
data -X- _ O
sets -X- _ O
( -X- _ O
text -X- _ O
with -X- _ O
long -X- _ O
range -X- _ O
dependencies -X- _ O
) -X- _ O
work -X- _ O
best -X- _ O
with -X- _ O
this -X- _ O
approach -X- _ O
. -X- _ O

Using -X- _ O
unsupervised -X- _ O
( -X- _ O
pre-)training -X- _ O
to -X- _ O
boost -X- _ O
performance -X- _ O
on -X- _ O
discriminative -X- _ O
tasks -X- _ O
has -X- _ O
long -X- _ O
been -X- _ O
an -X- _ O
important -X- _ O
goal -X- _ O
of -X- _ O
Machine -X- _ O
Learning -X- _ O
research -X- _ O
. -X- _ O

By -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
on -X- _ O
a -X- _ O
diverse -X- _ O
corpus -X- _ O
with -X- _ O
long -X- _ O
stretches -X- _ O
of -X- _ O
contiguous -X- _ O
text -X- _ O
our -X- _ O
model -X- _ O
acquires -X- _ O
significant -X- _ O
world -X- _ O
knowledge -X- _ O
and -X- _ O
ability -X- _ O
to -X- _ O
process -X- _ O
long -X- _ O
- -X- _ O
range -X- _ O
dependencies -X- _ O
which -X- _ O
are -X- _ O
then -X- _ O
successfully -X- _ O
transferred -X- _ O
to -X- _ O
solving -X- _ O
discriminative -X- _ O
tasks -X- _ O
such -X- _ O
as -X- _ O
question -X- _ B-TaskName
answering -X- _ I-TaskName
, -X- _ O
semantic -X- _ B-TaskName
similarity -X- _ I-TaskName
assessment -X- _ O
, -X- _ O
entailment -X- _ B-TaskName
determination -X- _ I-TaskName
, -X- _ O
and -X- _ O
text -X- _ B-TaskName
classification -X- _ I-TaskName
, -X- _ O
improving -X- _ O
the -X- _ O
state -X- _ O
of -X- _ O
the -X- _ O
art -X- _ O
on -X- _ O
9 -X- _ O
of -X- _ O
the -X- _ O
12 -X- _ O
datasets -X- _ O
we -X- _ O
study -X- _ O
. -X- _ O

6 -X- _ O
Conclusion -X- _ O
We -X- _ O
introduced -X- _ O
a -X- _ O
framework -X- _ O
for -X- _ O
achieving -X- _ O
strong -X- _ O
natural -X- _ B-TaskName
language -X- _ I-TaskName
understanding -X- _ I-TaskName
with -X- _ O
a -X- _ O
single -X- _ O
task -X- _ O
- -X- _ O
agnostic -X- _ O
model -X- _ O
through -X- _ O
generative -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
and -X- _ O
discriminative -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
. -X- _ O

We -X- _ O
observe -X- _ O
that -X- _ O
the -X- _ O
lack -X- _ O
of -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
hurts -X- _ O
performance -X- _ B-MetricName
across -X- _ O
all -X- _ O
the -X- _ O
tasks -X- _ O
, -X- _ O
resulting -X- _ O
in -X- _ O
a -X- _ O
14.8 -X- _ B-MetricValue
% -X- _ I-MetricValue
decrease -X- _ O
compared -X- _ O
to -X- _ O
our -X- _ O
full -X- _ O
model -X- _ O
. -X- _ O

We -X- _ O
observe -X- _ O
a -X- _ O
5.6 -X- _ B-MetricValue
average -X- _ B-MetricName
score -X- _ I-MetricName
drop -X- _ O
when -X- _ O
using -X- _ O
the -X- _ O
LSTM -X- _ B-MethodName
instead -X- _ O
of -X- _ O
the -X- _ O
Transformer -X- _ B-MethodName
. -X- _ O

The -X- _ O
LSTM -X- _ B-MethodName
only -X- _ O
outperforms -X- _ O
the -X- _ O
Transformer -X- _ B-MethodName
on -X- _ O
one -X- _ O
dataset -X- _ O
– -X- _ O
MRPC -X- _ B-DatasetName
. -X- _ O

Second -X- _ O
, -X- _ O
we -X- _ O
analyze -X- _ O
the -X- _ O
effect -X- _ O
of -X- _ O
the -X- _ O
Transformer -X- _ O
by -X- _ O
comparing -X- _ O
it -X- _ O
with -X- _ O
a -X- _ O
single -X- _ O
layer -X- _ O
2048 -X- _ O
unit -X- _ O
LSTM -X- _ B-MethodName
using -X- _ O
the -X- _ O
same -X- _ O
framework -X- _ O
. -X- _ O

Overall -X- _ O
, -X- _ O
the -X- _ O
trend -X- _ O
suggests -X- _ O
that -X- _ O
larger -X- _ O
datasets -X- _ O
benefit -X- _ O
from -X- _ O
the -X- _ O
auxiliary -X- _ O
objective -X- _ O
but -X- _ O
smaller -X- _ O
datasets -X- _ O
do -X- _ O
not -X- _ O
. -X- _ O

We -X- _ O
observe -X- _ O
that -X- _ O
the -X- _ O
auxiliary -X- _ O
objective -X- _ O
helps -X- _ O
on -X- _ O
the -X- _ O
NLI -X- _ B-TaskName
tasks -X- _ O
and -X- _ O
QQP -X- _ B-DatasetName
. -X- _ O

First -X- _ O
, -X- _ O
we -X- _ O
examine -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
our -X- _ O
method -X- _ O
without -X- _ O
the -X- _ O
auxiliary -X- _ O
LM -X- _ O
objective -X- _ O
during -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
. -X- _ O

Ablation -X- _ O
studies -X- _ O
We -X- _ O
perform -X- _ O
three -X- _ O
different -X- _ O
ablation -X- _ O
studies -X- _ O
( -X- _ O
Table -X- _ O
5 -X- _ O
) -X- _ O
. -X- _ O

For -X- _ O
DPRD -X- _ B-DatasetName
[ -X- _ O
46 -X- _ O
] -X- _ O
( -X- _ O
winograd -X- _ B-TaskName
schemas -X- _ I-TaskName
) -X- _ O
, -X- _ O
we -X- _ O
replace -X- _ O
the -X- _ O
definite -X- _ O
pronoun -X- _ O
with -X- _ O
the -X- _ O
two -X- _ O
possible -X- _ O
referrents -X- _ O
and -X- _ O
predict -X- _ O
the -X- _ O
resolution -X- _ O
that -X- _ O
the -X- _ O
generative -X- _ O
model -X- _ O
assigns -X- _ O
higher -X- _ O
average -X- _ O
token -X- _ O
log -X- _ O
- -X- _ O
probability -X- _ O
to -X- _ O
the -X- _ O
rest -X- _ O
of -X- _ O
the -X- _ O
sequence -X- _ O
after -X- _ O
the -X- _ O
substitution -X- _ O
. -X- _ O

For -X- _ O
RACE -X- _ B-DatasetName
( -X- _ O
question -X- _ B-TaskName
answering -X- _ I-TaskName
) -X- _ O
, -X- _ O
we -X- _ O
pick -X- _ O
the -X- _ O
answer -X- _ O
the -X- _ O
generative -X- _ O
model -X- _ O
assigns -X- _ O
the -X- _ O
highest -X- _ O
average -X- _ O
token -X- _ O
log -X- _ O
- -X- _ O
probability -X- _ O
when -X- _ O
conditioned -X- _ O
on -X- _ O
the -X- _ O
document -X- _ O
and -X- _ O
question -X- _ O
. -X- _ O

For -X- _ O
SST-2 -X- _ B-DatasetName
( -X- _ O
sentiment -X- _ B-TaskName
analysis -X- _ I-TaskName
) -X- _ O
, -X- _ O
we -X- _ O
append -X- _ O
the -X- _ O
token -X- _ O
very -X- _ O
to -X- _ O
each -X- _ O
example -X- _ O
and -X- _ O
restrict -X- _ O
the -X- _ O
language -X- _ O
model -X- _ O
’s -X- _ O
output -X- _ O
distribution -X- _ O
to -X- _ O
only -X- _ O
the -X- _ O
words -X- _ O
positive -X- _ O
and -X- _ O
negative -X- _ O
and -X- _ O
guess -X- _ O
the -X- _ O
token -X- _ O
it -X- _ O
assigns -X- _ O
higher -X- _ O
probability -X- _ O
to -X- _ O
as -X- _ O
the -X- _ O
prediction -X- _ O
. -X- _ O

For -X- _ O
CoLA -X- _ B-DatasetName
( -X- _ O
linguistic -X- _ B-TaskName
acceptability -X- _ I-TaskName
) -X- _ O
, -X- _ O
examples -X- _ O
are -X- _ O
scored -X- _ O
as -X- _ O
the -X- _ O
average -X- _ O
token -X- _ O
log -X- _ O
- -X- _ O
probability -X- _ O
the -X- _ O
generative -X- _ O
model -X- _ O
assigns -X- _ O
and -X- _ O
predictions -X- _ O
are -X- _ O
made -X- _ O
by -X- _ O
thresholding -X- _ O
. -X- _ O

We -X- _ O
also -X- _ O
observe -X- _ O
the -X- _ O
LSTM -X- _ B-MethodName
exhibits -X- _ O
higher -X- _ O
variance -X- _ O
in -X- _ O
its -X- _ O
zero -X- _ O
- -X- _ O
shot -X- _ O
performance -X- _ O
suggesting -X- _ O
that -X- _ O
the -X- _ O
inductive -X- _ O
bias -X- _ O
of -X- _ O
the -X- _ O
Transformer -X- _ O
architecture -X- _ O
assists -X- _ O
in -X- _ O
transfer -X- _ O
. -X- _ O

We -X- _ O
observe -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
these -X- _ O
heuristics -X- _ O
is -X- _ O
stable -X- _ O
and -X- _ O
steadily -X- _ O
increases -X- _ O
over -X- _ O
training -X- _ O
suggesting -X- _ O
that -X- _ O
generative -X- _ O
pretraining -X- _ O
supports -X- _ O
the -X- _ O
learning -X- _ O
of -X- _ O
a -X- _ O
wide -X- _ O
variety -X- _ O
of -X- _ O
task -X- _ O
relevant -X- _ O
functionality -X- _ O
. -X- _ O

We -X- _ O
visualize -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
these -X- _ O
heuristic -X- _ O
solutions -X- _ O
over -X- _ O
the -X- _ O
course -X- _ O
of -X- _ O
generative -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
in -X- _ O
Fig -X- _ O
2(right -X- _ O
) -X- _ O
. -X- _ O

We -X- _ O
designed -X- _ O
a -X- _ O
series -X- _ O
of -X- _ O
heuristic -X- _ O
solutions -X- _ O
that -X- _ O
use -X- _ O
the -X- _ O
underlying -X- _ O
generative -X- _ O
model -X- _ O
to -X- _ O
perform -X- _ O
tasks -X- _ O
without -X- _ O
supervised -X- _ O
finetuning -X- _ O
. -X- _ O

Score -X- _ O
CoLA -X- _ B-DatasetName
( -X- _ O
mc -X- _ B-MetricName
) -X- _ O
SST2 -X- _ B-DatasetName
( -X- _ O
acc -X- _ B-MetricName
) -X- _ O
MRPC -X- _ B-DatasetName
( -X- _ O
F1 -X- _ B-MetricName
) -X- _ O
STSB -X- _ B-DatasetName
( -X- _ O
pc -X- _ B-MetricName
) -X- _ O
QQP -X- _ B-DatasetName
( -X- _ O
F1 -X- _ B-MetricName
) -X- _ O
MNLI -X- _ B-DatasetName
( -X- _ O
acc -X- _ B-MetricName
) -X- _ O
QNLI -X- _ B-DatasetName
( -X- _ O
acc -X- _ B-MetricName
) -X- _ O
RTE -X- _ B-DatasetName
( -X- _ O
acc -X- _ B-MetricName
) -X- _ O
Transformer -X- _ B-MethodName
w/ -X- _ I-MethodName
aux -X- _ I-MethodName
LM -X- _ I-MethodName
( -X- _ O
full -X- _ O
) -X- _ O
74.7 -X- _ O
45.4 -X- _ O
91.3 -X- _ O
82.3 -X- _ O
82.0 -X- _ O
70.3 -X- _ O
81.8 -X- _ O
88.1 -X- _ O
56.0 -X- _ O
Transformer -X- _ B-MethodName
w/o -X- _ I-MethodName
pre -X- _ I-MethodName
- -X- _ I-MethodName
training -X- _ I-MethodName
Transformer -X- _ B-MethodName
w/o -X- _ I-MethodName
aux -X- _ I-MethodName
LM -X- _ I-MethodName
LSTM -X- _ B-MethodName
w/ -X- _ I-MethodName
aux -X- _ I-MethodName
LM -X- _ I-MethodName
59.9 -X- _ O
75.0 -X- _ O
69.1 -X- _ O
18.9 -X- _ O
47.9 -X- _ O
30.3 -X- _ O
84.0 -X- _ O
92.0 -X- _ O
90.5 -X- _ O
79.4 -X- _ O
84.9 -X- _ O
83.2 -X- _ O
30.9 -X- _ O
83.2 -X- _ O
71.8 -X- _ O
65.5 -X- _ O
69.8 -X- _ O
68.1 -X- _ O
75.7 -X- _ O
81.1 -X- _ O
73.7 -X- _ O
71.2 -X- _ O
86.9 -X- _ O
81.1 -X- _ O
53.8 -X- _ O
54.4 -X- _ O
54.6 -X- _ O
attentional -X- _ O
memory -X- _ O
of -X- _ O
the -X- _ O
transformer -X- _ O
assists -X- _ O
in -X- _ O
transfer -X- _ O
compared -X- _ O
to -X- _ O
LSTMs -X- _ B-MethodName
. -X- _ O

( -X- _ O
mc= -X- _ B-MetricName
Mathews -X- _ B-MetricName
correlation -X- _ I-MetricName
, -X- _ O
acc -X- _ B-MetricName
= -X- _ O
Accuracy -X- _ B-MetricName
, -X- _ O
pc -X- _ B-MetricName
= -X- _ O
Pearson -X- _ B-MetricName
correlation -X- _ I-MetricName
) -X- _ O
Method -X- _ O
Avg -X- _ O
. -X- _ O

Avg -X- _ O
. -X- _ O
score -X- _ O
is -X- _ O
a -X- _ O
unweighted -X- _ O
average -X- _ O
of -X- _ O
all -X- _ O
the -X- _ O
results -X- _ O
. -X- _ O

Table -X- _ O
5 -X- _ O
: -X- _ O
Analysis -X- _ O
of -X- _ O
various -X- _ O
model -X- _ O
ablations -X- _ O
on -X- _ O
different -X- _ O
tasks -X- _ O
. -X- _ O

A -X- _ O
hypothesis -X- _ O
is -X- _ O
that -X- _ O
the -X- _ O
underlying -X- _ O
generative -X- _ O
model -X- _ O
learns -X- _ O
to -X- _ O
perform -X- _ O
many -X- _ O
of -X- _ O
the -X- _ O
tasks -X- _ O
we -X- _ O
evaluate -X- _ O
on -X- _ O
in -X- _ O
order -X- _ O
to -X- _ O
improve -X- _ O
its -X- _ O
language -X- _ O
modeling -X- _ O
capability -X- _ O
and -X- _ O
that -X- _ O
the -X- _ O
more -X- _ O
structured -X- _ O
7 -X- _ O

Zero -X- _ O
- -X- _ O
shot -X- _ O
Behaviors -X- _ O
We -X- _ O
’d -X- _ O
like -X- _ O
to -X- _ O
better -X- _ O
understand -X- _ O
why -X- _ O
language -X- _ O
model -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
of -X- _ O
transformers -X- _ O
is -X- _ O
effective -X- _ O
. -X- _ O

Performance -X- _ O
per -X- _ O
task -X- _ O
is -X- _ O
normalized -X- _ O
between -X- _ O
a -X- _ O
random -X- _ O
guess -X- _ O
baseline -X- _ O
and -X- _ O
the -X- _ O
current -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
with -X- _ O
a -X- _ O
single -X- _ O
model -X- _ O
. -X- _ O

Plot -X- _ O
showing -X- _ O
the -X- _ O
evolution -X- _ O
of -X- _ O
zero -X- _ O
- -X- _ O
shot -X- _ O
performance -X- _ O
on -X- _ O
different -X- _ O
tasks -X- _ O
as -X- _ O
a -X- _ O
function -X- _ O
of -X- _ O
LM -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
updates -X- _ O
. -X- _ O

( -X- _ O
right -X- _ O
) -X- _ O

Figure -X- _ O
2 -X- _ O
: -X- _ O
( -X- _ O
left -X- _ O
) -X- _ O
Effect -X- _ O
of -X- _ O
transferring -X- _ O
increasing -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
layers -X- _ I-HyperparameterName
from -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
language -X- _ O
model -X- _ O
on -X- _ O
RACE -X- _ B-DatasetName
and -X- _ O
MultiNLI -X- _ B-DatasetName
. -X- _ O

This -X- _ O
indicates -X- _ O
that -X- _ O
each -X- _ O
layer -X- _ O
in -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
model -X- _ O
contains -X- _ O
useful -X- _ O
functionality -X- _ O
for -X- _ O
solving -X- _ O
target -X- _ O
tasks -X- _ O
. -X- _ O

We -X- _ O
observe -X- _ O
the -X- _ O
standard -X- _ O
result -X- _ O
that -X- _ O
transferring -X- _ O
embeddings -X- _ O
improves -X- _ O
performance -X- _ O
and -X- _ O
that -X- _ O
each -X- _ O
transformer -X- _ O
layer -X- _ O
provides -X- _ O
further -X- _ O
benefits -X- _ O
up -X- _ O
to -X- _ O
9 -X- _ B-MetricValue
% -X- _ I-MetricValue
for -X- _ O
full -X- _ O
transfer -X- _ O
on -X- _ O
MultiNLI -X- _ B-DatasetName
. -X- _ O

Figure -X- _ O
2(left -X- _ O
) -X- _ O
illustrates -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
our -X- _ O
approach -X- _ O
on -X- _ O
MultiNLI -X- _ B-DatasetName
and -X- _ O
RACE -X- _ B-DatasetName
as -X- _ O
a -X- _ O
function -X- _ O
of -X- _ O
the -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
layers -X- _ I-HyperparameterName
transferred -X- _ O
. -X- _ O

5 -X- _ O
Analysis -X- _ O
Impact -X- _ O
of -X- _ O
number -X- _ O
of -X- _ O
layers -X- _ O
transferred -X- _ O
We -X- _ O
observed -X- _ O
the -X- _ O
impact -X- _ O
of -X- _ O
transferring -X- _ O
a -X- _ O
variable -X- _ O
number -X- _ O
of -X- _ O
layers -X- _ O
from -X- _ O
unsupervised -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
to -X- _ O
the -X- _ O
supervised -X- _ O
target -X- _ O
task -X- _ O
. -X- _ O

Our -X- _ O
results -X- _ O
also -X- _ O
indicate -X- _ O
that -X- _ O
our -X- _ O
approach -X- _ O
works -X- _ O
well -X- _ O
across -X- _ O
datasets -X- _ O
of -X- _ O
different -X- _ O
sizes -X- _ O
, -X- _ O
from -X- _ O
smaller -X- _ O
datasets -X- _ O
such -X- _ O
as -X- _ O
STS -X- _ B-DatasetName
- -X- _ I-DatasetName
B -X- _ I-DatasetName
( -X- _ O
≈5.7k -X- _ O
training -X- _ O
examples -X- _ O
) -X- _ O
– -X- _ O
to -X- _ O
the -X- _ O
largest -X- _ O
one -X- _ O
– -X- _ O
SNLI -X- _ B-DatasetName
( -X- _ O
≈550k -X- _ O
training -X- _ O
examples -X- _ O
) -X- _ O
. -X- _ O

[ -X- _ O
60 -X- _ O
] -X- _ O
GLUE -X- _ B-DatasetName
81.0 -X- _ O
Single -X- _ B-MethodName
- -X- _ I-MethodName
task -X- _ I-MethodName
BiLSTM -X- _ I-MethodName
+ -X- _ I-MethodName
ELMo -X- _ I-MethodName
+ -X- _ I-MethodName
Attn -X- _ I-MethodName
[ -X- _ O
64 -X- _ O
] -X- _ O
Multi -X- _ B-MethodName
- -X- _ I-MethodName
task -X- _ I-MethodName
BiLSTM -X- _ I-MethodName
+ -X- _ I-MethodName
ELMo -X- _ I-MethodName
+ -X- _ I-MethodName
Attn -X- _ I-MethodName
[ -X- _ O
64 -X- _ O
] -X- _ O
35.0 -X- _ O
18.9 -X- _ O
90.2 -X- _ O
91.6 -X- _ O
80.2 -X- _ O
83.5 -X- _ O
55.5 -X- _ O
72.8 -X- _ O
66.1 -X- _ O
63.3 -X- _ O
64.8 -X- _ O
68.9 -X- _ O
Finetuned -X- _ B-MethodName
Transformer -X- _ I-MethodName
LM -X- _ I-MethodName
( -X- _ O
ours -X- _ O
) -X- _ O
45.4 -X- _ O
91.3 -X- _ O
82.3 -X- _ O
82.0 -X- _ O
70.3 -X- _ O
72.8 -X- _ O
Overall -X- _ O
, -X- _ O
our -X- _ O
approach -X- _ O
achieves -X- _ O
new -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
results -X- _ O
in -X- _ O
9 -X- _ O
out -X- _ O
of -X- _ O
the -X- _ O
12 -X- _ O
datasets -X- _ O
we -X- _ O
evaluate -X- _ O
on -X- _ O
, -X- _ O
outperforming -X- _ O
ensembles -X- _ O
in -X- _ O
many -X- _ O
cases -X- _ O
. -X- _ O

[ -X- _ O
16 -X- _ O
] -X- _ O
93.2 -X- _ O
TF -X- _ B-MethodName
- -X- _ I-MethodName
KLD -X- _ I-MethodName
[ -X- _ O
23 -X- _ O
] -X- _ O
86.0 -X- _ O
ECNU -X- _ B-MethodName
( -X- _ O
mixed -X- _ O
ensemble -X- _ O
) -X- _ O

Sparse -X- _ B-MethodName
byte -X- _ I-MethodName
mLSTM -X- _ I-MethodName

Method -X- _ O
Classification -X- _ B-TaskName
Semantic -X- _ B-TaskName
Similarity -X- _ I-TaskName
CoLA -X- _ B-DatasetName
( -X- _ O
mc -X- _ B-MetricName
) -X- _ O
SST2 -X- _ B-DatasetName
( -X- _ O
acc -X- _ B-MetricName
) -X- _ O
MRPC -X- _ B-DatasetName
( -X- _ O
F1 -X- _ B-MetricName
) -X- _ O
STSB -X- _ B-DatasetName
( -X- _ O
pc -X- _ B-MetricName
) -X- _ O
QQP -X- _ B-DatasetName
( -X- _ O
F1 -X- _ B-MetricName
) -X- _ O

( -X- _ O
mc= -X- _ B-MetricName
Mathews -X- _ B-MetricName
correlation -X- _ I-MetricName
, -X- _ O
acc -X- _ B-MetricName
= -X- _ O
Accuracy -X- _ B-MetricName
, -X- _ O
pc -X- _ B-MetricName
= -X- _ O
Pearson -X- _ B-MetricName
correlation -X- _ I-MetricName
) -X- _ O

All -X- _ O
task -X- _ O
evaluations -X- _ O
in -X- _ O
this -X- _ O
table -X- _ O
were -X- _ O
done -X- _ O
using -X- _ O
the -X- _ O
GLUE -X- _ B-DatasetName
benchmark -X- _ O
. -X- _ O

Table -X- _ O
4 -X- _ O
: -X- _ O
Semantic -X- _ B-TaskName
similarity -X- _ I-TaskName
and -X- _ O
classification -X- _ B-TaskName
results -X- _ O
, -X- _ O
comparing -X- _ O
our -X- _ O
model -X- _ O
with -X- _ O
current -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
theart -X- _ O
methods -X- _ O
. -X- _ O

We -X- _ O
also -X- _ O
achieve -X- _ O
an -X- _ O
overall -X- _ O
score -X- _ O
of -X- _ O
72.8 -X- _ B-MetricValue
on -X- _ O
the -X- _ O
GLUE -X- _ B-DatasetName
benchmark -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
significantly -X- _ O
better -X- _ O
than -X- _ O
the -X- _ O
previous -X- _ O
best -X- _ O
of -X- _ O
68.9 -X- _ B-MetricValue
. -X- _ O
6 -X- _ O

The -X- _ O
model -X- _ O
also -X- _ O
achieves -X- _ O
91.3 -X- _ B-MetricValue
% -X- _ I-MetricValue
accuracy -X- _ B-MetricName
on -X- _ O
SST-2 -X- _ B-DatasetName
, -X- _ O
which -X- _ O
is -X- _ O
competitive -X- _ O
with -X- _ O
the -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
results -X- _ O
. -X- _ O

Our -X- _ O
model -X- _ O
obtains -X- _ O
an -X- _ O
score -X- _ O
of -X- _ O
45.4 -X- _ B-MetricValue
on -X- _ O
CoLA -X- _ B-DatasetName
, -X- _ O
which -X- _ O
is -X- _ O
an -X- _ O
especially -X- _ O
big -X- _ O
jump -X- _ O
over -X- _ O
the -X- _ O
previous -X- _ O
best -X- _ O
result -X- _ O
of -X- _ O
35.0 -X- _ B-MetricValue
, -X- _ O
showcasing -X- _ O
the -X- _ O
innate -X- _ O
linguistic -X- _ O
bias -X- _ O
learned -X- _ O
by -X- _ O
our -X- _ O
model -X- _ O
. -X- _ O

The -X- _ O
Stanford -X- _ B-DatasetName
Sentiment -X- _ I-DatasetName
Treebank -X- _ I-DatasetName
( -X- _ O
SST-2 -X- _ B-DatasetName
) -X- _ O
[ -X- _ O
54 -X- _ O
] -X- _ O
, -X- _ O
on -X- _ O
the -X- _ O
other -X- _ O
hand -X- _ O
, -X- _ O
is -X- _ O
a -X- _ O
standard -X- _ O
binary -X- _ B-TaskName
classification -X- _ I-TaskName
task -X- _ O
. -X- _ O

[ -X- _ O
65 -X- _ O
] -X- _ O
contains -X- _ O
expert -X- _ O
judgements -X- _ O
on -X- _ O
whether -X- _ O
a -X- _ O
sentence -X- _ O
is -X- _ O
grammatical -X- _ O
or -X- _ O
not -X- _ O
, -X- _ O
and -X- _ O
tests -X- _ O
the -X- _ O
innate -X- _ O
linguistic -X- _ O
bias -X- _ O
of -X- _ O
trained -X- _ O
models -X- _ O
. -X- _ O

The -X- _ O
Corpus -X- _ B-DatasetName
of -X- _ I-DatasetName
Linguistic -X- _ I-DatasetName
Acceptability -X- _ I-DatasetName
( -X- _ O
CoLA -X- _ B-DatasetName
) -X- _ O

Finally -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
evaluate -X- _ O
on -X- _ O
two -X- _ O
different -X- _ O
text -X- _ B-TaskName
classification -X- _ I-TaskName
tasks -X- _ O
. -X- _ O

Classification -X- _ B-TaskName

+ -X- _ O
Attn -X- _ O
. -X- _ O

The -X- _ O
performance -X- _ O
delta -X- _ O
on -X- _ O
QQP -X- _ B-DatasetName
is -X- _ O
significant -X- _ O
, -X- _ O
with -X- _ O
a -X- _ O
4.2 -X- _ B-MetricValue
% -X- _ I-MetricValue
absolute -X- _ O
improvement -X- _ B-MetricName
over -X- _ O
Single -X- _ B-MethodName
- -X- _ I-MethodName
task -X- _ I-MethodName
BiLSTM -X- _ I-MethodName
+ -X- _ I-MethodName
ELMo -X- _ I-MethodName

We -X- _ O
obtain -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
results -X- _ O
on -X- _ O
two -X- _ O
of -X- _ O
the -X- _ O
three -X- _ O
semantic -X- _ O
similarity -X- _ O
tasks -X- _ O
( -X- _ O
Table -X- _ O
4 -X- _ O
) -X- _ O
with -X- _ O
a -X- _ O
1 -X- _ B-MetricValue
point -X- _ I-MetricValue
absolute -X- _ O
gain -X- _ B-MetricName
on -X- _ O
STS -X- _ B-DatasetName
- -X- _ I-DatasetName
B. -X- _ I-DatasetName

[ -X- _ O
6 -X- _ O
] -X- _ O
. -X- _ O

[ -X- _ O
14 -X- _ O
] -X- _ O
( -X- _ O
collected -X- _ O
from -X- _ O
news -X- _ O
sources -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
Quora -X- _ B-DatasetName
Question -X- _ I-DatasetName
Pairs -X- _ I-DatasetName
( -X- _ O
QQP -X- _ B-DatasetName
) -X- _ O
dataset -X- _ O
[ -X- _ O
9 -X- _ O
] -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
Semantic -X- _ B-DatasetName
Textual -X- _ I-DatasetName
Similarity -X- _ I-DatasetName
benchmark -X- _ I-DatasetName
( -X- _ O
STS -X- _ B-DatasetName
- -X- _ I-DatasetName
B -X- _ I-DatasetName
) -X- _ O

We -X- _ O
use -X- _ O
three -X- _ O
datasets -X- _ O
for -X- _ O
this -X- _ O
task -X- _ O
– -X- _ O
the -X- _ O
Microsoft -X- _ B-DatasetName
Paraphrase -X- _ I-DatasetName
corpus -X- _ I-DatasetName
( -X- _ O
MRPC -X- _ B-DatasetName
) -X- _ O

The -X- _ O
challenges -X- _ O
lie -X- _ O
in -X- _ O
recognizing -X- _ O
rephrasing -X- _ O
of -X- _ O
concepts -X- _ O
, -X- _ O
understanding -X- _ O
negation -X- _ O
, -X- _ O
and -X- _ O
handling -X- _ O
syntactic -X- _ O
ambiguity -X- _ O
. -X- _ O

Semantic -X- _ B-TaskName
Similarity -X- _ I-TaskName
Semantic -X- _ B-TaskName
similarity -X- _ I-TaskName
( -X- _ O
or -X- _ O
paraphrase -X- _ B-TaskName
detection -X- _ I-TaskName
) -X- _ O
tasks -X- _ O
involve -X- _ O
predicting -X- _ O
whether -X- _ O
two -X- _ O
sentences -X- _ O
are -X- _ O
semantically -X- _ O
equivalent -X- _ O
or -X- _ O
not -X- _ O
. -X- _ O

This -X- _ O
demonstrates -X- _ O
the -X- _ O
ability -X- _ O
of -X- _ O
our -X- _ O
model -X- _ O
to -X- _ O
handle -X- _ O
long -X- _ O
- -X- _ O
range -X- _ O
contexts -X- _ O
effectively -X- _ O
. -X- _ O

On -X- _ O
these -X- _ O
tasks -X- _ O
, -X- _ O
our -X- _ O
model -X- _ O
again -X- _ O
outperforms -X- _ O
the -X- _ O
previous -X- _ O
best -X- _ O
results -X- _ O
by -X- _ O
significant -X- _ O
margins -X- _ O
- -X- _ O
up -X- _ O
to -X- _ O
8.9 -X- _ B-MetricValue
% -X- _ I-MetricValue
on -X- _ O
Story -X- _ B-DatasetName
Cloze -X- _ I-DatasetName
, -X- _ O
and -X- _ O
5.7 -X- _ B-MetricValue
% -X- _ I-MetricValue
overall -X- _ O
on -X- _ O
RACE -X- _ B-DatasetName
. -X- _ O

In -X- _ O
addition -X- _ O
, -X- _ O
we -X- _ O
evaluate -X- _ O
on -X- _ O
the -X- _ O
Story -X- _ B-DatasetName
Cloze -X- _ I-DatasetName
Test -X- _ O
[ -X- _ O
40 -X- _ O
] -X- _ O
, -X- _ O
which -X- _ O
involves -X- _ O
selecting -X- _ O
the -X- _ O
correct -X- _ O
ending -X- _ O
to -X- _ O
multi -X- _ O
- -X- _ O
sentence -X- _ O
stories -X- _ O
from -X- _ O
two -X- _ O
options -X- _ O
. -X- _ O

This -X- _ O
corpus -X- _ O
has -X- _ O
been -X- _ O
shown -X- _ O
to -X- _ O
contain -X- _ O
more -X- _ O
reasoning -X- _ O
type -X- _ O
questions -X- _ O
that -X- _ O
other -X- _ O
datasets -X- _ O
like -X- _ O
CNN -X- _ B-DatasetName
[ -X- _ O
19 -X- _ O
] -X- _ O
or -X- _ O
SQuaD -X- _ B-DatasetName
[ -X- _ O
47 -X- _ O
] -X- _ O
, -X- _ O
providing -X- _ O
the -X- _ O
perfect -X- _ O
evaluation -X- _ O
for -X- _ O
our -X- _ O
model -X- _ O
which -X- _ O
is -X- _ O
trained -X- _ O
to -X- _ O
handle -X- _ O
long -X- _ O
- -X- _ O
range -X- _ O
contexts -X- _ O
. -X- _ O

We -X- _ O
use -X- _ O
the -X- _ O
recently -X- _ O
released -X- _ O
RACE -X- _ B-DatasetName
dataset -X- _ O
[ -X- _ O
30 -X- _ O
] -X- _ O
, -X- _ O
consisting -X- _ O
of -X- _ O
English -X- _ O
passages -X- _ O
with -X- _ O
associated -X- _ O
questions -X- _ O
from -X- _ O
middle -X- _ O
and -X- _ O
high -X- _ O
school -X- _ O
exams -X- _ O
. -X- _ O

Question -X- _ B-TaskName
answering -X- _ I-TaskName
and -X- _ O
commonsense -X- _ B-TaskName
reasoning -X- _ I-TaskName
Another -X- _ O
task -X- _ O
that -X- _ O
requires -X- _ O
aspects -X- _ O
of -X- _ O
single -X- _ O
and -X- _ O
multi -X- _ B-TaskName
- -X- _ I-TaskName
sentence -X- _ I-TaskName
reasoning -X- _ I-TaskName
is -X- _ O
question -X- _ B-TaskName
answering -X- _ I-TaskName
. -X- _ O

[ -X- _ O
67 -X- _ O
] -X- _ O
( -X- _ O
9x -X- _ O
) -X- _ O
BiAttention -X- _ B-MethodName
MRU -X- _ I-MethodName
[ -X- _ O
59 -X- _ O
] -X- _ O
( -X- _ O
9x -X- _ O
) -X- _ O
55.6 -X- _ O
60.2 -X- _ O
49.4 -X- _ O
50.3 -X- _ O
51.2 -X- _ O
53.3 -X- _ O
86.5 -X- _ O
62.9 -X- _ O
57.4 -X- _ O
59.0 -X- _ O
Finetuned -X- _ B-MethodName
Transformer -X- _ I-MethodName
LM -X- _ I-MethodName
( -X- _ O
ours -X- _ O
) -X- _ O

Method -X- _ O
Story -X- _ B-DatasetName
Cloze -X- _ I-DatasetName
RACE -X- _ B-DatasetName
- -X- _ I-DatasetName
m -X- _ I-DatasetName
RACE -X- _ B-DatasetName
- -X- _ I-DatasetName
h -X- _ I-DatasetName
RACE -X- _ B-DatasetName
val -X- _ B-MethodName
- -X- _ I-MethodName
LS -X- _ I-MethodName
- -X- _ I-MethodName
skip -X- _ I-MethodName
[ -X- _ O
55 -X- _ O
] -X- _ O
Hidden -X- _ B-MethodName
Coherence -X- _ I-MethodName
Model -X- _ O
[ -X- _ O
7 -X- _ O
] -X- _ O
76.5 -X- _ O
77.6 -X- _ O
Dynamic -X- _ B-MethodName
Fusion -X- _ I-MethodName
Net -X- _ I-MethodName

[ -X- _ O
58 -X- _ O
] -X- _ O
78.7 -X- _ O
77.9 -X- _ O
88.5 -X- _ O
83.3 -X- _ O
GenSen -X- _ B-MethodName
[ -X- _ O
64 -X- _ O
] -X- _ O
Multi -X- _ B-MethodName
- -X- _ I-MethodName
task -X- _ I-MethodName
BiLSTM -X- _ I-MethodName
+ -X- _ I-MethodName
Attn -X- _ I-MethodName
[ -X- _ O
64 -X- _ O
] -X- _ O
71.4 -X- _ O
72.2 -X- _ O
71.3 -X- _ O
72.1 -X- _ O
82.3 -X- _ O
82.1 -X- _ O
59.2 -X- _ O
61.7 -X- _ O
Finetuned -X- _ B-MethodName
Transformer -X- _ I-MethodName
LM -X- _ I-MethodName
( -X- _ O
ours -X- _ O
) -X- _ O
82.1 -X- _ O
81.4 -X- _ O
89.9 -X- _ O
88.3 -X- _ O
88.1 -X- _ O
56.0 -X- _ O
Table -X- _ O
3 -X- _ O
: -X- _ O
Results -X- _ O
on -X- _ O
question -X- _ B-TaskName
answering -X- _ I-TaskName
and -X- _ O
commonsense -X- _ B-TaskName
reasoning -X- _ I-TaskName
, -X- _ O
comparing -X- _ O
our -X- _ O
model -X- _ O
with -X- _ O
current -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
methods -X- _ O
.. -X- _ O
9x -X- _ O
means -X- _ O
an -X- _ O
ensemble -X- _ O
of -X- _ O
9 -X- _ O
models -X- _ O
. -X- _ O

Stochastic -X- _ B-MethodName
Answer -X- _ I-MethodName
Network -X- _ I-MethodName
[ -X- _ O
35 -X- _ O
] -X- _ O
( -X- _ O
3x -X- _ O
) -X- _ O
80.2 -X- _ O
80.6 -X- _ O
79.0 -X- _ O
80.1 -X- _ O
89.3 -X- _ O
89.3 -X- _ O
CAFE -X- _ B-MethodName

[ -X- _ O
58 -X- _ O
] -X- _ O
( -X- _ O
5x -X- _ O
) -X- _ O

RTE -X- _ B-DatasetName
ESIM -X- _ B-MethodName
+ -X- _ I-MethodName
ELMo -X- _ I-MethodName
[ -X- _ O
44 -X- _ O
] -X- _ O
( -X- _ O
5x -X- _ O
) -X- _ O
CAFE -X- _ B-MethodName

Method -X- _ O
MNLI -X- _ B-DatasetName
- -X- _ I-DatasetName
m -X- _ I-DatasetName
MNLI -X- _ B-DatasetName
- -X- _ I-DatasetName
mm -X- _ I-DatasetName
SNLI -X- _ B-DatasetName
SciTail -X- _ B-DatasetName
QNLI -X- _ B-DatasetName

All -X- _ O
datasets -X- _ O
use -X- _ O
accuracy -X- _ O
as -X- _ O
the -X- _ O
evaluation -X- _ O
metric -X- _ O
. -X- _ O

5x -X- _ O
indicates -X- _ O
an -X- _ O
ensemble -X- _ O
of -X- _ O
5 -X- _ O
models -X- _ O
. -X- _ O

Table -X- _ O
2 -X- _ O
: -X- _ O
Experimental -X- _ O
results -X- _ O
on -X- _ O
natural -X- _ B-TaskName
language -X- _ I-TaskName
inference -X- _ I-TaskName
tasks -X- _ O
, -X- _ O
comparing -X- _ O
our -X- _ O
model -X- _ O
with -X- _ O
current -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
methods -X- _ O
. -X- _ O

2 -X- _ O
3 -X- _ O
https://ftfy.readthedocs.io/en/latest/ -X- _ O
https://spacy.io/ -X- _ O
5 -X- _ O

Given -X- _ O
the -X- _ O
strong -X- _ O
performance -X- _ O
of -X- _ O
our -X- _ O
approach -X- _ O
on -X- _ O
larger -X- _ O
NLI -X- _ B-TaskName
datasets -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
likely -X- _ O
our -X- _ O
model -X- _ O
will -X- _ O
benefit -X- _ O
from -X- _ O
multi -X- _ O
- -X- _ O
task -X- _ O
training -X- _ O
as -X- _ O
well -X- _ O
but -X- _ O
we -X- _ O
have -X- _ O
not -X- _ O
explored -X- _ O
this -X- _ O
currently -X- _ O
. -X- _ O

On -X- _ O
RTE -X- _ B-DatasetName
, -X- _ O
one -X- _ O
of -X- _ O
the -X- _ O
smaller -X- _ O
datasets -X- _ O
we -X- _ O
evaluate -X- _ O
on -X- _ O
( -X- _ O
2490 -X- _ O
examples -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
achieve -X- _ O
an -X- _ O
accuracy -X- _ B-MetricName
of -X- _ O
56 -X- _ B-MetricValue
% -X- _ I-MetricValue
, -X- _ O
which -X- _ O
is -X- _ O
below -X- _ O
the -X- _ O
61.7 -X- _ B-MetricValue
% -X- _ I-MetricValue
reported -X- _ O
by -X- _ O
a -X- _ O
multi -X- _ B-MethodName
- -X- _ I-MethodName
task -X- _ I-MethodName
biLSTM -X- _ I-MethodName
model -X- _ O
. -X- _ O

This -X- _ O
demonstrates -X- _ O
our -X- _ O
model -X- _ O
’s -X- _ O
ability -X- _ O
to -X- _ O
better -X- _ O
reason -X- _ O
over -X- _ O
multiple -X- _ O
sentences -X- _ O
, -X- _ O
and -X- _ O
handle -X- _ O
aspects -X- _ O
of -X- _ O
linguistic -X- _ O
ambiguity -X- _ O
. -X- _ O

Our -X- _ O
method -X- _ O
significantly -X- _ O
outperforms -X- _ O
the -X- _ O
baselines -X- _ O
on -X- _ O
four -X- _ O
of -X- _ O
the -X- _ O
five -X- _ O
datasets -X- _ O
, -X- _ O
achieving -X- _ O
absolute -X- _ O
improvements -X- _ O
of -X- _ O
upto -X- _ O
1.5 -X- _ B-MetricValue
% -X- _ I-MetricValue
on -X- _ O
MNLI -X- _ B-DatasetName
, -X- _ O
5 -X- _ B-MetricValue
% -X- _ I-MetricValue
on -X- _ O
SciTail -X- _ B-DatasetName
, -X- _ O
5.8 -X- _ B-MetricValue
% -X- _ I-MetricValue
on -X- _ O
QNLI -X- _ B-DatasetName
and -X- _ O
0.6 -X- _ B-MetricValue
% -X- _ I-MetricValue
on -X- _ O
SNLI -X- _ B-DatasetName
over -X- _ O
the -X- _ O
previous -X- _ O
best -X- _ O
results -X- _ O
. -X- _ O

Table -X- _ O
2 -X- _ O
details -X- _ O
various -X- _ O
results -X- _ O
on -X- _ O
the -X- _ O
different -X- _ O
NLI -X- _ O
tasks -X- _ O
for -X- _ O
our -X- _ O
model -X- _ O
and -X- _ O
previous -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
approaches -X- _ O
. -X- _ O

We -X- _ O
evaluate -X- _ O
on -X- _ O
five -X- _ O
datasets -X- _ O
with -X- _ O
diverse -X- _ O
sources -X- _ O
, -X- _ O
including -X- _ O
image -X- _ O
captions -X- _ O
( -X- _ O
SNLI -X- _ B-DatasetName
) -X- _ O
, -X- _ O
transcribed -X- _ O
speech -X- _ O
, -X- _ O
popular -X- _ O
fiction -X- _ O
, -X- _ O
and -X- _ O
government -X- _ O
reports -X- _ O
( -X- _ O
MNLI -X- _ B-DatasetName
) -X- _ O
, -X- _ O
Wikipedia -X- _ O
articles -X- _ O
( -X- _ O
QNLI -X- _ B-DatasetName
) -X- _ O
, -X- _ O
science -X- _ O
exams -X- _ O
( -X- _ O
SciTail -X- _ B-DatasetName
) -X- _ O
or -X- _ O
news -X- _ O
articles -X- _ O
( -X- _ O
RTE -X- _ B-DatasetName
) -X- _ O
. -X- _ O

Although -X- _ O
there -X- _ O
has -X- _ O
been -X- _ O
a -X- _ O
lot -X- _ O
of -X- _ O
recent -X- _ O
interest -X- _ O
[ -X- _ O
58 -X- _ O
, -X- _ O
35 -X- _ O
, -X- _ O
44 -X- _ O
] -X- _ O
, -X- _ O
the -X- _ O
task -X- _ O
remains -X- _ O
challenging -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
presence -X- _ O
of -X- _ O
a -X- _ O
wide -X- _ O
variety -X- _ O
of -X- _ O
phenomena -X- _ O
like -X- _ O
lexical -X- _ B-TaskName
entailment -X- _ I-TaskName
, -X- _ O
coreference -X- _ O
, -X- _ O
and -X- _ O
lexical -X- _ O
and -X- _ O
syntactic -X- _ O
ambiguity -X- _ O
. -X- _ O

Natural -X- _ B-TaskName
Language -X- _ I-TaskName
Inference -X- _ I-TaskName
The -X- _ O
task -X- _ O
of -X- _ O
natural -X- _ B-TaskName
language -X- _ I-TaskName
inference -X- _ I-TaskName
( -X- _ O
NLI -X- _ B-TaskName
) -X- _ O
, -X- _ O
also -X- _ O
known -X- _ O
as -X- _ O
recognizing -X- _ O
textual -X- _ B-TaskName
entailment -X- _ I-TaskName
, -X- _ O
involves -X- _ O
reading -X- _ O
a -X- _ O
pair -X- _ O
of -X- _ O
sentences -X- _ O
and -X- _ O
judging -X- _ O
the -X- _ O
relationship -X- _ O
between -X- _ O
them -X- _ O
from -X- _ O
one -X- _ O
of -X- _ O
entailment -X- _ O
, -X- _ O
contradiction -X- _ O
or -X- _ O
neutral -X- _ O
. -X- _ O

Figure -X- _ O
1 -X- _ O
provides -X- _ O
an -X- _ O
overview -X- _ O
of -X- _ O
all -X- _ O
the -X- _ O
tasks -X- _ O
and -X- _ O
datasets -X- _ O
. -X- _ O

Some -X- _ O
of -X- _ O
these -X- _ O
tasks -X- _ O
are -X- _ O
available -X- _ O
as -X- _ O
part -X- _ O
of -X- _ O
the -X- _ O
recently -X- _ O
released -X- _ O
GLUE -X- _ B-DatasetName
multi -X- _ I-DatasetName
- -X- _ I-DatasetName
task -X- _ I-DatasetName
benchmark -X- _ O
[ -X- _ O
64 -X- _ O
] -X- _ O
, -X- _ O
which -X- _ O
we -X- _ O
make -X- _ O
use -X- _ O
of -X- _ O
. -X- _ O

4.2 -X- _ O
Supervised -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
We -X- _ O
perform -X- _ O
experiments -X- _ O
on -X- _ O
a -X- _ O
variety -X- _ O
of -X- _ O
supervised -X- _ O
tasks -X- _ O
including -X- _ O
natural -X- _ B-TaskName
language -X- _ I-TaskName
inference -X- _ I-TaskName
, -X- _ O
question -X- _ B-TaskName
answering -X- _ I-TaskName
, -X- _ O
semantic -X- _ B-TaskName
similarity -X- _ I-TaskName
, -X- _ O
and -X- _ O
text -X- _ B-TaskName
classification -X- _ I-TaskName
. -X- _ O

λ -X- _ B-HyperparameterName
was -X- _ O
set -X- _ O
to -X- _ O
0.5 -X- _ B-HyperparameterValue
. -X- _ O

We -X- _ O
use -X- _ O
a -X- _ O
linear -X- _ B-HyperparameterValue
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
decay -X- _ I-HyperparameterName
schedule -X- _ I-HyperparameterName
with -X- _ O
warmup -X- _ B-HyperparameterName
over -X- _ O
0.2 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
of -X- _ O
training -X- _ O
. -X- _ O

Our -X- _ O
model -X- _ O
finetunes -X- _ O
quickly -X- _ O
and -X- _ O
3 -X- _ B-HyperparameterValue
epochs -X- _ B-HyperparameterName
of -X- _ O
training -X- _ O
was -X- _ O
sufficient -X- _ O
for -X- _ O
most -X- _ O
cases -X- _ O
. -X- _ O

For -X- _ O
most -X- _ O
tasks -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
a -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
of -X- _ O
6.25e-5 -X- _ B-HyperparameterValue
and -X- _ O
a -X- _ O
batchsize -X- _ B-HyperparameterName
of -X- _ O
32 -X- _ B-HyperparameterValue
. -X- _ O

We -X- _ O
add -X- _ O
dropout -X- _ B-HyperparameterName
to -X- _ O
the -X- _ O
classifier -X- _ O
with -X- _ O
a -X- _ O
rate -X- _ B-HyperparameterName
of -X- _ O
0.1 -X- _ B-HyperparameterValue
. -X- _ O

We -X- _ O
use -X- _ O
the -X- _ O
ftfy -X- _ O
library2 -X- _ O
to -X- _ O
clean -X- _ O
the -X- _ O
raw -X- _ O
text -X- _ O
in -X- _ O
BooksCorpus -X- _ B-DatasetName
, -X- _ O
standardize -X- _ O
some -X- _ O
punctuation -X- _ O
and -X- _ O
whitespace -X- _ O
, -X- _ O
and -X- _ O
use -X- _ O
the -X- _ O
spaCy -X- _ O
tokenizer.3 -X- _ O
Fine -X- _ O
- -X- _ O
tuning -X- _ O
details -X- _ O
Unless -X- _ O
specified -X- _ O
, -X- _ O
we -X- _ O
reuse -X- _ O
the -X- _ O
hyperparameter -X- _ O
settings -X- _ O
from -X- _ O
unsupervised -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
. -X- _ O

We -X- _ O
used -X- _ O
learned -X- _ O
position -X- _ O
embeddings -X- _ O
instead -X- _ O
of -X- _ O
the -X- _ O
sinusoidal -X- _ O
version -X- _ O
proposed -X- _ O
in -X- _ O
the -X- _ O
original -X- _ O
work -X- _ O
. -X- _ O

[ -X- _ O
18 -X- _ O
] -X- _ O
. -X- _ O

For -X- _ O
the -X- _ O
activation -X- _ O
function -X- _ O
, -X- _ O
we -X- _ O
used -X- _ O
the -X- _ O
Gaussian -X- _ O
Error -X- _ O
Linear -X- _ O
Unit -X- _ O
( -X- _ O
GELU -X- _ O
) -X- _ O

We -X- _ O
also -X- _ O
employed -X- _ O
a -X- _ O
modified -X- _ O
version -X- _ O
of -X- _ O
L2 -X- _ O
regularization -X- _ O
proposed -X- _ O
in -X- _ O
[ -X- _ O
37 -X- _ O
] -X- _ O
, -X- _ O
with -X- _ O
w -X- _ B-HyperparameterName
= -X- _ O
0.01 -X- _ B-HyperparameterValue
on -X- _ O
all -X- _ O
non -X- _ O
bias -X- _ O
or -X- _ O
gain -X- _ O
weights -X- _ O
. -X- _ O

We -X- _ O
used -X- _ O
a -X- _ O
bytepair -X- _ O
encoding -X- _ O
( -X- _ O
BPE -X- _ O
) -X- _ O
vocabulary -X- _ O
with -X- _ O
40,000 -X- _ O
merges -X- _ O
[ -X- _ O
53 -X- _ O
] -X- _ O
and -X- _ O
residual -X- _ O
, -X- _ O
embedding -X- _ O
, -X- _ O
and -X- _ O
attention -X- _ O
dropouts -X- _ O
with -X- _ O
a -X- _ O
rate -X- _ O
of -X- _ O
0.1 -X- _ O
for -X- _ O
regularization -X- _ O
. -X- _ O

Since -X- _ O
layernorm -X- _ O
[ -X- _ O
2 -X- _ O
] -X- _ O
is -X- _ O
used -X- _ O
extensively -X- _ O
throughout -X- _ O
the -X- _ O
model -X- _ O
, -X- _ O
a -X- _ O
simple -X- _ O
weight -X- _ O
initialization -X- _ O
of -X- _ O
N -X- _ B-HyperparameterName
( -X- _ O
0 -X- _ B-HyperparameterValue
, -X- _ I-HyperparameterValue
0.02 -X- _ I-HyperparameterValue
) -X- _ O
was -X- _ O
sufficient -X- _ O
. -X- _ O

We -X- _ O
train -X- _ O
for -X- _ O
100 -X- _ B-HyperparameterValue
epochs -X- _ B-HyperparameterName
on -X- _ O
minibatches -X- _ B-HyperparameterName
of -X- _ O
64 -X- _ B-HyperparameterValue
randomly -X- _ B-HyperparameterValue
sampled -X- _ I-HyperparameterValue
, -X- _ O
contiguous -X- _ O
sequences -X- _ O
of -X- _ O
512 -X- _ B-HyperparameterValue
tokens -X- _ B-HyperparameterName
. -X- _ O

The -X- _ O
learning -X- _ O
rate -X- _ O
was -X- _ O
increased -X- _ O
linearly -X- _ O
from -X- _ O
zero -X- _ O
over -X- _ O
the -X- _ O
first -X- _ O
2000 -X- _ O
updates -X- _ O
and -X- _ O
annealed -X- _ O
to -X- _ O
0 -X- _ O
using -X- _ O
a -X- _ O
cosine -X- _ O
schedule -X- _ O
. -X- _ O

We -X- _ O
used -X- _ O
the -X- _ O
Adam -X- _ O
optimization -X- _ O
scheme -X- _ O
[ -X- _ O
27 -X- _ O
] -X- _ O
with -X- _ O
a -X- _ O
max -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
of -X- _ O
2.5e-4 -X- _ B-HyperparameterValue
. -X- _ O

For -X- _ O
the -X- _ O
position -X- _ O
- -X- _ O
wise -X- _ O
feed -X- _ O
- -X- _ O
forward -X- _ O
networks -X- _ O
, -X- _ O
we -X- _ O
used -X- _ O
3072 -X- _ B-HyperparameterValue
dimensional -X- _ I-HyperparameterValue
inner -X- _ B-HyperparameterName
states -X- _ I-HyperparameterName
. -X- _ O

We -X- _ O
trained -X- _ O
a -X- _ O
12 -X- _ B-HyperparameterValue
- -X- _ O
layer -X- _ B-HyperparameterName
decoder -X- _ O
- -X- _ O
only -X- _ O
transformer -X- _ O
with -X- _ O
masked -X- _ O
self -X- _ O
- -X- _ O
attention -X- _ O
heads -X- _ O
( -X- _ O
768 -X- _ B-HyperparameterValue
dimensional -X- _ B-HyperparameterName
states -X- _ I-HyperparameterName
and -X- _ O
12 -X- _ B-HyperparameterValue
attention -X- _ B-HyperparameterName
heads -X- _ I-HyperparameterName
) -X- _ O
. -X- _ O

Model -X- _ O
specifications -X- _ O
Our -X- _ O
model -X- _ O
largely -X- _ O
follows -X- _ O
the -X- _ O
original -X- _ O
transformer -X- _ O
work -X- _ O
[ -X- _ O
62 -X- _ O
] -X- _ O
. -X- _ O

Our -X- _ O
language -X- _ O
model -X- _ O
achieves -X- _ O
a -X- _ O
very -X- _ O
low -X- _ O
token -X- _ O
level -X- _ O
perplexity -X- _ B-MetricName
of -X- _ O
18.4 -X- _ B-MetricValue
on -X- _ O
this -X- _ O
corpus -X- _ O
. -X- _ O

[ -X- _ O
54 -X- _ O
] -X- _ O
, -X- _ O
CoLA -X- _ B-DatasetName
[ -X- _ O
65 -X- _ O
] -X- _ O
but -X- _ O
is -X- _ O
shuffled -X- _ O
at -X- _ O
a -X- _ O
sentence -X- _ O
level -X- _ O
- -X- _ O
destroying -X- _ O
long -X- _ O
- -X- _ O
range -X- _ O
structure -X- _ O
. -X- _ O

[ -X- _ O
66 -X- _ O
] -X- _ O
, -X- _ O
Question -X- _ B-DatasetName
NLI -X- _ I-DatasetName
[ -X- _ O
64 -X- _ O
] -X- _ O
, -X- _ O
RTE -X- _ B-DatasetName
[ -X- _ O
4 -X- _ O
] -X- _ O
, -X- _ O
SciTail -X- _ B-DatasetName
[ -X- _ O
25 -X- _ O
] -X- _ O
RACE -X- _ B-DatasetName
[ -X- _ O
30 -X- _ O
] -X- _ O
, -X- _ O
Story -X- _ B-DatasetName
Cloze -X- _ I-DatasetName
[ -X- _ O
40 -X- _ O
] -X- _ O
MSR -X- _ B-DatasetName
Paraphrase -X- _ I-DatasetName
Corpus -X- _ I-DatasetName
[ -X- _ O
14 -X- _ O
] -X- _ O
, -X- _ O
Quora -X- _ B-DatasetName
Question -X- _ I-DatasetName
Pairs -X- _ I-DatasetName
[ -X- _ O
9 -X- _ O
] -X- _ O
, -X- _ O
STS -X- _ B-DatasetName
Benchmark -X- _ O
[ -X- _ O
6 -X- _ O
] -X- _ O
Stanford -X- _ B-DatasetName
Sentiment -X- _ I-DatasetName
Treebank-2 -X- _ I-DatasetName

[ -X- _ O
5 -X- _ O
] -X- _ O
, -X- _ O
MultiNLI -X- _ B-DatasetName

Task -X- _ O
Natural -X- _ B-TaskName
language -X- _ I-TaskName
inference -X- _ I-TaskName
Question -X- _ B-TaskName
Answering -X- _ I-TaskName
Sentence -X- _ B-TaskName
similarity -X- _ I-TaskName
Classification -X- _ B-TaskName
Datasets -X- _ O
SNLI -X- _ B-DatasetName

Table -X- _ O
1 -X- _ O
: -X- _ O
A -X- _ O
list -X- _ O
of -X- _ O
the -X- _ O
different -X- _ O
tasks -X- _ O
and -X- _ O
datasets -X- _ O
used -X- _ O
in -X- _ O
our -X- _ O
experiments -X- _ O
. -X- _ O

An -X- _ O
alternative -X- _ O
dataset -X- _ O
, -X- _ O
the -X- _ O
1B -X- _ B-TaskName
Word -X- _ I-TaskName
Benchmark -X- _ I-TaskName
, -X- _ O
which -X- _ O
is -X- _ O
used -X- _ O
by -X- _ O
a -X- _ O
similar -X- _ O
approach -X- _ O
, -X- _ O
ELMo -X- _ B-TaskName
[ -X- _ O
44 -X- _ O
] -X- _ O
, -X- _ O
is -X- _ O
approximately -X- _ O
the -X- _ O
same -X- _ O
size -X- _ O
4 -X- _ O

Crucially -X- _ O
, -X- _ O
it -X- _ O
contains -X- _ O
long -X- _ O
stretches -X- _ O
of -X- _ O
contiguous -X- _ O
text -X- _ O
, -X- _ O
which -X- _ O
allows -X- _ O
the -X- _ O
generative -X- _ O
model -X- _ O
to -X- _ O
learn -X- _ O
to -X- _ O
condition -X- _ O
on -X- _ O
long -X- _ O
- -X- _ O
range -X- _ O
information -X- _ O
. -X- _ O

It -X- _ O
contains -X- _ O
over -X- _ O
7,000 -X- _ O
unique -X- _ O
unpublished -X- _ O
books -X- _ O
from -X- _ O
a -X- _ O
variety -X- _ O
of -X- _ O
genres -X- _ O
including -X- _ O
Adventure -X- _ O
, -X- _ O
Fantasy -X- _ O
, -X- _ O
and -X- _ O
Romance -X- _ O
. -X- _ O

4 -X- _ O
Experiments -X- _ O
4.1 -X- _ O
Setup -X- _ O
Unsupervised -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
We -X- _ O
use -X- _ O
the -X- _ O
BooksCorpus -X- _ B-DatasetName
dataset -X- _ O
[ -X- _ O
71 -X- _ O
] -X- _ O
for -X- _ O
training -X- _ O
the -X- _ O
language -X- _ O
model -X- _ O
. -X- _ O

Each -X- _ O
of -X- _ O
these -X- _ O
sequences -X- _ O
are -X- _ O
processed -X- _ O
independently -X- _ O
with -X- _ O
our -X- _ O
model -X- _ O
and -X- _ O
then -X- _ O
normalized -X- _ O
via -X- _ O
a -X- _ O
softmax -X- _ O
layer -X- _ O
to -X- _ O
produce -X- _ O
an -X- _ O
output -X- _ O
distribution -X- _ O
over -X- _ O
possible -X- _ O
answers -X- _ O
. -X- _ O

We -X- _ O
concatenate -X- _ O
the -X- _ O
document -X- _ O
context -X- _ O
and -X- _ O
question -X- _ O
with -X- _ O
each -X- _ O
possible -X- _ O
answer -X- _ O
, -X- _ O
adding -X- _ O
a -X- _ O
delimiter -X- _ O
token -X- _ O
in -X- _ O
between -X- _ O
to -X- _ O
get -X- _ O
[ -X- _ O
z -X- _ O
; -X- _ O
q -X- _ O
; -X- _ O
$ -X- _ O
; -X- _ O
ak -X- _ O
] -X- _ O
. -X- _ O

Question -X- _ B-TaskName
Answering -X- _ I-TaskName
and -X- _ O
Commonsense -X- _ B-TaskName
Reasoning -X- _ I-TaskName
For -X- _ O
these -X- _ O
tasks -X- _ O
, -X- _ O
we -X- _ O
are -X- _ O
given -X- _ O
a -X- _ O
context -X- _ O
document -X- _ O
z -X- _ O
, -X- _ O
a -X- _ O
question -X- _ O
q -X- _ O
, -X- _ O
and -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
possible -X- _ O
answers -X- _ O
{ -X- _ O
ak -X- _ O
} -X- _ O
. -X- _ O

hm -X- _ O
l -X- _ O
which -X- _ O
are -X- _ O
added -X- _ O
element -X- _ O
- -X- _ O
wise -X- _ O
before -X- _ O
being -X- _ O
fed -X- _ O
into -X- _ O
the -X- _ O
linear -X- _ O
output -X- _ O
layer -X- _ O
. -X- _ O

To -X- _ O
reflect -X- _ O
this -X- _ O
, -X- _ O
we -X- _ O
modify -X- _ O
the -X- _ O
input -X- _ O
sequence -X- _ O
to -X- _ O
contain -X- _ O
both -X- _ O
possible -X- _ O
sentence -X- _ O
orderings -X- _ O
( -X- _ O
with -X- _ O
a -X- _ O
delimiter -X- _ O
in -X- _ O
between -X- _ O
) -X- _ O
and -X- _ O
process -X- _ O
each -X- _ O
independently -X- _ O
to -X- _ O
produce -X- _ O
two -X- _ O
sequence -X- _ O
representations -X- _ O

Similarity -X- _ B-TaskName
For -X- _ O
similarity -X- _ B-TaskName
tasks -X- _ O
, -X- _ O
there -X- _ O
is -X- _ O
no -X- _ O
inherent -X- _ O
ordering -X- _ O
of -X- _ O
the -X- _ O
two -X- _ O
sentences -X- _ O
being -X- _ O
compared -X- _ O
. -X- _ O

Textual -X- _ B-TaskName
entailment -X- _ I-TaskName
For -X- _ O
entailment -X- _ B-TaskName
tasks -X- _ O
, -X- _ O
we -X- _ O
concatenate -X- _ O
the -X- _ O
premise -X- _ O
p -X- _ O
and -X- _ O
hypothesis -X- _ O
h -X- _ O
token -X- _ O
sequences -X- _ O
, -X- _ O
with -X- _ O
a -X- _ O
delimiter -X- _ O
token -X- _ O
( -X- _ O
$ -X- _ O
) -X- _ O
in -X- _ O
between -X- _ O
. -X- _ O

All -X- _ O
transformations -X- _ O
include -X- _ O
adding -X- _ O
randomly -X- _ O
initialized -X- _ O
start -X- _ O
and -X- _ O
end -X- _ O
tokens -X- _ O
( -X- _ O
hsi -X- _ O
, -X- _ O
hei -X- _ O
) -X- _ O
. -X- _ O

We -X- _ O
provide -X- _ O
a -X- _ O
brief -X- _ O
description -X- _ O
of -X- _ O
these -X- _ O
input -X- _ O
transformations -X- _ O
below -X- _ O
and -X- _ O
Figure -X- _ O
1 -X- _ O
provides -X- _ O
a -X- _ O
visual -X- _ O
illustration -X- _ O
. -X- _ O

These -X- _ O
input -X- _ O
transformations -X- _ O
allow -X- _ O
us -X- _ O
to -X- _ O
avoid -X- _ O
making -X- _ O
extensive -X- _ O
changes -X- _ O
to -X- _ O
the -X- _ O
architecture -X- _ O
across -X- _ O
tasks -X- _ O
. -X- _ O

Instead -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
a -X- _ O
traversal -X- _ O
- -X- _ O
style -X- _ O
approach -X- _ O
[ -X- _ O
52 -X- _ O
] -X- _ O
, -X- _ O
where -X- _ O
we -X- _ O
convert -X- _ O
structured -X- _ O
inputs -X- _ O
into -X- _ O
an -X- _ O
ordered -X- _ O
sequence -X- _ O
that -X- _ O
our -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
model -X- _ O
can -X- _ O
process -X- _ O
. -X- _ O

Such -X- _ O
an -X- _ O
approach -X- _ O
re -X- _ O
- -X- _ O
introduces -X- _ O
a -X- _ O
significant -X- _ O
amount -X- _ O
of -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
customization -X- _ O
and -X- _ O
does -X- _ O
not -X- _ O
use -X- _ O
transfer -X- _ B-TaskName
learning -X- _ I-TaskName
for -X- _ O
these -X- _ O
additional -X- _ O
architectural -X- _ O
components -X- _ O
. -X- _ O

Previous -X- _ O
work -X- _ O
proposed -X- _ O
learning -X- _ O
task -X- _ O
specific -X- _ O
architectures -X- _ O
on -X- _ O
top -X- _ O
of -X- _ O
transferred -X- _ O
representations -X- _ O
[ -X- _ O
44 -X- _ O
] -X- _ O
. -X- _ O

Since -X- _ O
our -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
model -X- _ O
was -X- _ O
trained -X- _ O
on -X- _ O
contiguous -X- _ O
sequences -X- _ O
of -X- _ O
text -X- _ O
, -X- _ O
we -X- _ O
require -X- _ O
some -X- _ O
modifications -X- _ O
to -X- _ O
apply -X- _ O
it -X- _ O
to -X- _ O
these -X- _ O
tasks -X- _ O
. -X- _ O

Certain -X- _ O
other -X- _ O
tasks -X- _ O
, -X- _ O
like -X- _ O
question -X- _ B-TaskName
answering -X- _ I-TaskName
or -X- _ O
textual -X- _ B-TaskName
entailment -X- _ I-TaskName
, -X- _ O
have -X- _ O
structured -X- _ O
inputs -X- _ O
such -X- _ O
as -X- _ O
ordered -X- _ O
sentence -X- _ O
pairs -X- _ O
, -X- _ O
or -X- _ O
triplets -X- _ O
of -X- _ O
document -X- _ O
, -X- _ O
question -X- _ O
, -X- _ O
and -X- _ O
answers -X- _ O
. -X- _ O

3.3 -X- _ O
Task -X- _ O
- -X- _ O
specific -X- _ O
input -X- _ O
transformations -X- _ O
For -X- _ O
some -X- _ O
tasks -X- _ O
, -X- _ O
like -X- _ O
text -X- _ B-TaskName
classification -X- _ I-TaskName
, -X- _ O
we -X- _ O
can -X- _ O
directly -X- _ O
fine -X- _ O
- -X- _ O
tune -X- _ O
our -X- _ O
model -X- _ O
as -X- _ O
described -X- _ O
above -X- _ O
. -X- _ O

We -X- _ O
convert -X- _ O
all -X- _ O
structured -X- _ O
inputs -X- _ O
into -X- _ O
token -X- _ O
sequences -X- _ O
to -X- _ O
be -X- _ O
processed -X- _ O
by -X- _ O
our -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
model -X- _ O
, -X- _ O
followed -X- _ O
by -X- _ O
a -X- _ O
linear+softmax -X- _ O
layer -X- _ O
. -X- _ O

( -X- _ O
right -X- _ O
) -X- _ O
Input -X- _ O
transformations -X- _ O
for -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
on -X- _ O
different -X- _ O
tasks -X- _ O
. -X- _ O

Figure -X- _ O
1 -X- _ O
: -X- _ O
( -X- _ O
left -X- _ O
) -X- _ O
Transformer -X- _ O
architecture -X- _ O
and -X- _ O
training -X- _ O
objectives -X- _ O
used -X- _ O
in -X- _ O
this -X- _ O
work -X- _ O
. -X- _ O

3 -X- _ O

L2 -X- _ O
( -X- _ O
C -X- _ O
) -X- _ O
+ -X- _ O
λ -X- _ O
∗ -X- _ O
L1 -X- _ O
( -X- _ O
C -X- _ O
) -X- _ O
( -X- _ O
5 -X- _ O
) -X- _ O
Overall -X- _ O
, -X- _ O
the -X- _ O
only -X- _ O
extra -X- _ O
parameters -X- _ O
we -X- _ O
require -X- _ O
during -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
are -X- _ O
Wy -X- _ O
, -X- _ O
and -X- _ O
embeddings -X- _ O
for -X- _ O
delimiter -X- _ O
tokens -X- _ O
( -X- _ O
described -X- _ O
below -X- _ O
in -X- _ O
Section -X- _ O
3.3 -X- _ O
) -X- _ O
. -X- _ O

Specifically -X- _ O
, -X- _ O
we -X- _ O
optimize -X- _ O
the -X- _ O
following -X- _ O
objective -X- _ O
( -X- _ O
with -X- _ O
weight -X- _ O
λ -X- _ O
): -X- _ O
L3 -X- _ O
( -X- _ O
C -X- _ O
) -X- _ O
= -X- _ O

This -X- _ O
is -X- _ O
in -X- _ O
line -X- _ O
with -X- _ O
prior -X- _ O
work -X- _ O
[ -X- _ O
50 -X- _ O
, -X- _ O
43 -X- _ O
] -X- _ O
, -X- _ O
who -X- _ O
also -X- _ O
observed -X- _ O
improved -X- _ O
performance -X- _ O
with -X- _ O
such -X- _ O
an -X- _ O
auxiliary -X- _ O
objective -X- _ O
. -X- _ O

( -X- _ O
4 -X- _ O
) -X- _ O
( -X- _ O
x -X- _ O
, -X- _ O
y -X- _ O
) -X- _ O
We -X- _ O
additionally -X- _ O
found -X- _ O
that -X- _ O
including -X- _ O
language -X- _ B-TaskName
modeling -X- _ I-TaskName
as -X- _ O
an -X- _ O
auxiliary -X- _ O
objective -X- _ O
to -X- _ O
the -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
helped -X- _ O
learning -X- _ O
by -X- _ O
( -X- _ O
a -X- _ O
) -X- _ O
improving -X- _ O
generalization -X- _ O
of -X- _ O
the -X- _ O
supervised -X- _ O
model -X- _ O
, -X- _ O
and -X- _ O
( -X- _ O
b -X- _ O
) -X- _ O
accelerating -X- _ O
convergence -X- _ O
. -X- _ O

, -X- _ O
xm -X- _ O
) -X- _ O
. -X- _ O

This -X- _ O
gives -X- _ O
us -X- _ O
the -X- _ O
following -X- _ O
objective -X- _ O
to -X- _ O
maximize -X- _ O
: -X- _ O
X -X- _ O
L2 -X- _ O
( -X- _ O
C -X- _ O
) -X- _ O
= -X- _ O
log -X- _ O
P -X- _ O
( -X- _ O
y|x1 -X- _ O
, -X- _ O
. -X- _ O
. -X- _ O
. -X- _ O

softmax(hm -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
l -X- _ O
Wy -X- _ O
) -X- _ O
. -X- _ O

, -X- _ O
xm -X- _ O
) -X- _ O
= -X- _ O

The -X- _ O
inputs -X- _ O
are -X- _ O
passed -X- _ O
through -X- _ O
our -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
model -X- _ O
to -X- _ O
obtain -X- _ O
the -X- _ O
final -X- _ O
transformer -X- _ B-MethodName
block -X- _ O
’s -X- _ O
activation -X- _ O
hm -X- _ O
l -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
then -X- _ O
fed -X- _ O
into -X- _ O
an -X- _ O
added -X- _ O
linear -X- _ O
output -X- _ O
layer -X- _ O
with -X- _ O
parameters -X- _ O
Wy -X- _ O
to -X- _ O
predict -X- _ O
y -X- _ O
: -X- _ O
P -X- _ O
( -X- _ O
y|x1 -X- _ O
, -X- _ O
. -X- _ O
. -X- _ O
. -X- _ O

, -X- _ O
xm -X- _ O
, -X- _ O
along -X- _ O
with -X- _ O
a -X- _ O
label -X- _ O
y. -X- _ O

We -X- _ O
assume -X- _ O
a -X- _ O
labeled -X- _ O
dataset -X- _ O
C -X- _ O
, -X- _ O
where -X- _ O
each -X- _ O
instance -X- _ O
consists -X- _ O
of -X- _ O
a -X- _ O
sequence -X- _ O
of -X- _ O
input -X- _ O
tokens -X- _ O
, -X- _ O
x1 -X- _ O
, -X- _ O
. -X- _ O
. -X- _ O
. -X- _ O

3.2 -X- _ O
Supervised -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
After -X- _ O
training -X- _ O
the -X- _ O
model -X- _ O
with -X- _ O
the -X- _ O
objective -X- _ O
in -X- _ O
Eq -X- _ O
. -X- _ O
1 -X- _ O
, -X- _ O
we -X- _ O
adapt -X- _ O
the -X- _ O
parameters -X- _ O
to -X- _ O
the -X- _ O
supervised -X- _ O
target -X- _ O
task -X- _ O
. -X- _ O

, -X- _ O
u−1 -X- _ O
) -X- _ O
is -X- _ O
the -X- _ O
context -X- _ O
vector -X- _ O
of -X- _ O
tokens -X- _ O
, -X- _ O
n -X- _ B-HyperparameterName
is -X- _ O
the -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
layers -X- _ I-HyperparameterName
, -X- _ O
We -X- _ O
is -X- _ O
the -X- _ O
token -X- _ O
embedding -X- _ O
matrix -X- _ O
, -X- _ O
and -X- _ O
Wp -X- _ O
is -X- _ O
the -X- _ O
position -X- _ O
embedding -X- _ O
matrix -X- _ O
. -X- _ O

softmax(hn -X- _ O
WeT -X- _ O
) -X- _ O
where -X- _ O
U -X- _ O
= -X- _ O
( -X- _ O
u−k -X- _ O
, -X- _ O
. -X- _ O
. -X- _ O
. -X- _ O

[ -X- _ O
1 -X- _ O
, -X- _ O
n -X- _ O
] -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
P -X- _ O
( -X- _ O
u -X- _ O
) -X- _ O
= -X- _ O

∈ -X- _ O

transformer_block(hl−1 -X- _ O
) -X- _ O
∀i -X- _ O

+ -X- _ O
Wp -X- _ O
hl -X- _ O
= -X- _ O

This -X- _ O
model -X- _ O
applies -X- _ O
a -X- _ O
multi -X- _ O
- -X- _ O
headed -X- _ O
self -X- _ O
- -X- _ O
attention -X- _ O
operation -X- _ O
over -X- _ O
the -X- _ O
input -X- _ O
context -X- _ O
tokens -X- _ O
followed -X- _ O
by -X- _ O
position -X- _ O
- -X- _ O
wise -X- _ O
feedforward -X- _ O
layers -X- _ O
to -X- _ O
produce -X- _ O
an -X- _ O
output -X- _ O
distribution -X- _ O
over -X- _ O
target -X- _ O
tokens -X- _ O
: -X- _ O
h0 -X- _ O
= -X- _ O
U -X- _ O
We -X- _ O

In -X- _ O
our -X- _ O
experiments -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
a -X- _ O
multi -X- _ B-MethodName
- -X- _ I-MethodName
layer -X- _ I-MethodName
Transformer -X- _ I-MethodName
decoder -X- _ I-MethodName
[ -X- _ O
34 -X- _ O
] -X- _ O
for -X- _ O
the -X- _ O
language -X- _ O
model -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
a -X- _ O
variant -X- _ O
of -X- _ O
the -X- _ O
transformer -X- _ B-MethodName
[ -X- _ O
62 -X- _ O
] -X- _ O
. -X- _ O

These -X- _ O
parameters -X- _ O
are -X- _ O
trained -X- _ O
using -X- _ O
stochastic -X- _ O
gradient -X- _ O
descent -X- _ O
[ -X- _ O
51 -X- _ O
] -X- _ O
. -X- _ O

, -X- _ O
ui−1 -X- _ O
; -X- _ O
Θ -X- _ O
) -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
i -X- _ O
where -X- _ O
k -X- _ B-HyperparameterName
is -X- _ O
the -X- _ O
size -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
the -X- _ I-HyperparameterName
context -X- _ I-HyperparameterName
window -X- _ I-HyperparameterName
, -X- _ O
and -X- _ O
the -X- _ O
conditional -X- _ O
probability -X- _ O
P -X- _ O
is -X- _ O
modeled -X- _ O
using -X- _ O
a -X- _ O
neural -X- _ O
network -X- _ O
with -X- _ O
parameters -X- _ O
Θ. -X- _ O

, -X- _ O
un -X- _ O
} -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
a -X- _ O
standard -X- _ O
language -X- _ O
modeling -X- _ O
objective -X- _ O
to -X- _ O
maximize -X- _ O
the -X- _ O
following -X- _ O
likelihood -X- _ O
: -X- _ O
X -X- _ O
L1 -X- _ O
( -X- _ O
U -X- _ O
) -X- _ O
= -X- _ O
log -X- _ O
P -X- _ O
( -X- _ O
ui -X- _ O
|ui−k -X- _ O
, -X- _ O
. -X- _ O
. -X- _ O
. -X- _ O

3.1 -X- _ O
Unsupervised -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
Given -X- _ O
an -X- _ O
unsupervised -X- _ O
corpus -X- _ O
of -X- _ O
tokens -X- _ O
U -X- _ O
= -X- _ O
{ -X- _ O
u1 -X- _ O
, -X- _ O
. -X- _ O
. -X- _ O
. -X- _ O

This -X- _ O
is -X- _ O
followed -X- _ O
by -X- _ O
a -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
stage -X- _ O
, -X- _ O
where -X- _ O
we -X- _ O
adapt -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
a -X- _ O
discriminative -X- _ O
task -X- _ O
with -X- _ O
labeled -X- _ O
data -X- _ O
. -X- _ O

The -X- _ O
first -X- _ O
stage -X- _ O
is -X- _ O
learning -X- _ O
a -X- _ O
high -X- _ O
- -X- _ O
capacity -X- _ O
language -X- _ O
model -X- _ O
on -X- _ O
a -X- _ O
large -X- _ O
corpus -X- _ O
of -X- _ O
text -X- _ O
. -X- _ O

3 -X- _ O
Framework -X- _ O
Our -X- _ O
training -X- _ O
procedure -X- _ O
consists -X- _ O
of -X- _ O
two -X- _ O
stages -X- _ O
. -X- _ O

Our -X- _ O
experiments -X- _ O
also -X- _ O
use -X- _ O
an -X- _ O
auxiliary -X- _ O
objective -X- _ O
, -X- _ O
but -X- _ O
as -X- _ O
we -X- _ O
show -X- _ O
, -X- _ O
unsupervised -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
already -X- _ O
learns -X- _ O
several -X- _ O
linguistic -X- _ O
aspects -X- _ O
relevant -X- _ O
to -X- _ O
target -X- _ O
tasks -X- _ O
. -X- _ O

More -X- _ O
recently -X- _ O
, -X- _ O
Rei -X- _ O
[ -X- _ O
50 -X- _ O
] -X- _ O
added -X- _ O
an -X- _ O
auxiliary -X- _ O
language -X- _ B-TaskName
modeling -X- _ I-TaskName
objective -X- _ O
to -X- _ O
their -X- _ O
target -X- _ O
task -X- _ O
objective -X- _ O
and -X- _ O
demonstrated -X- _ O
performance -X- _ O
gains -X- _ O
on -X- _ O
sequence -X- _ B-TaskName
labeling -X- _ I-TaskName
tasks -X- _ O
. -X- _ O

Early -X- _ O
work -X- _ O
by -X- _ O
Collobert -X- _ O
and -X- _ O
Weston -X- _ O
[ -X- _ O
10 -X- _ O
] -X- _ O
used -X- _ O
a -X- _ O
wide -X- _ O
variety -X- _ O
of -X- _ O
auxiliary -X- _ O
NLP -X- _ B-TaskName
tasks -X- _ O
such -X- _ O
as -X- _ O
POS -X- _ B-TaskName
tagging -X- _ I-TaskName
, -X- _ O
chunking -X- _ B-TaskName
, -X- _ O
named -X- _ B-TaskName
entity -X- _ I-TaskName
recognition -X- _ I-TaskName
, -X- _ O
and -X- _ O
language -X- _ B-TaskName
modeling -X- _ I-TaskName
to -X- _ O
improve -X- _ O
semantic -X- _ B-TaskName
role -X- _ I-TaskName
labeling -X- _ I-TaskName
. -X- _ O

Auxiliary -X- _ O
training -X- _ O
objectives -X- _ O
Adding -X- _ O
auxiliary -X- _ O
unsupervised -X- _ O
training -X- _ O
objectives -X- _ O
is -X- _ O
an -X- _ O
alternative -X- _ O
form -X- _ O
of -X- _ O
semi -X- _ O
- -X- _ O
supervised -X- _ O
learning -X- _ O
. -X- _ O

This -X- _ O
involves -X- _ O
a -X- _ O
substantial -X- _ O
amount -X- _ O
of -X- _ O
new -X- _ O
parameters -X- _ O
for -X- _ O
each -X- _ O
separate -X- _ O
target -X- _ O
task -X- _ O
, -X- _ O
whereas -X- _ O
we -X- _ O
require -X- _ O
minimal -X- _ O
changes -X- _ O
to -X- _ O
our -X- _ O
model -X- _ O
architecture -X- _ O
during -X- _ O
transfer -X- _ O
. -X- _ O

pre -X- _ O
- -X- _ O
trained -X- _ O
language -X- _ O
or -X- _ O
machine -X- _ B-TaskName
translation -X- _ I-TaskName
model -X- _ O
as -X- _ O
auxiliary -X- _ O
features -X- _ O
while -X- _ O
training -X- _ O
a -X- _ O
supervised -X- _ O
model -X- _ O
on -X- _ O
the -X- _ O
target -X- _ O
task -X- _ O
. -X- _ O

Other -X- _ O
approaches -X- _ O
[ -X- _ O
43 -X- _ O
, -X- _ O
44 -X- _ O
, -X- _ O
38 -X- _ O
] -X- _ O
use -X- _ O
hidden -X- _ O
representations -X- _ O
from -X- _ O
a -X- _ O
2 -X- _ O

Further -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
demonstrate -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
our -X- _ O
model -X- _ O
on -X- _ O
a -X- _ O
wider -X- _ O
range -X- _ O
of -X- _ O
tasks -X- _ O
including -X- _ O
natural -X- _ B-TaskName
language -X- _ I-TaskName
inference -X- _ I-TaskName
, -X- _ O
paraphrase -X- _ B-TaskName
detection -X- _ I-TaskName
and -X- _ O
story -X- _ B-TaskName
completion -X- _ I-TaskName
. -X- _ O

In -X- _ O
contrast -X- _ O
, -X- _ O
our -X- _ O
choice -X- _ O
of -X- _ O
transformer -X- _ O
networks -X- _ O
allows -X- _ O
us -X- _ O
to -X- _ O
capture -X- _ O
longerrange -X- _ O
linguistic -X- _ O
structure -X- _ O
, -X- _ O
as -X- _ O
demonstrated -X- _ O
in -X- _ O
our -X- _ O
experiments -X- _ O
. -X- _ O

However -X- _ O
, -X- _ O
although -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
phase -X- _ O
helps -X- _ O
capture -X- _ O
some -X- _ O
linguistic -X- _ O
information -X- _ O
, -X- _ O
their -X- _ O
usage -X- _ O
of -X- _ O
LSTM -X- _ B-MethodName
models -X- _ O
restricts -X- _ O
their -X- _ O
prediction -X- _ O
ability -X- _ O
to -X- _ O
a -X- _ O
short -X- _ O
range -X- _ O
. -X- _ O

Dai -X- _ O
et -X- _ O
al. -X- _ O
[ -X- _ O
13 -X- _ O
] -X- _ O
and -X- _ O
Howard -X- _ O
and -X- _ O
Ruder -X- _ O
[ -X- _ O
21 -X- _ O
] -X- _ O
follow -X- _ O
this -X- _ O
method -X- _ O
to -X- _ O
improve -X- _ O
text -X- _ B-TaskName
classification -X- _ I-TaskName
. -X- _ O

The -X- _ O
closest -X- _ O
line -X- _ O
of -X- _ O
work -X- _ O
to -X- _ O
ours -X- _ O
involves -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
a -X- _ O
neural -X- _ O
network -X- _ O
using -X- _ O
a -X- _ O
language -X- _ O
modeling -X- _ O
objective -X- _ O
and -X- _ O
then -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
it -X- _ O
on -X- _ O
a -X- _ O
target -X- _ O
task -X- _ O
with -X- _ O
supervision -X- _ O
. -X- _ O

In -X- _ O
recent -X- _ O
work -X- _ O
, -X- _ O
the -X- _ O
method -X- _ O
has -X- _ O
been -X- _ O
used -X- _ O
to -X- _ O
help -X- _ O
train -X- _ O
deep -X- _ O
neural -X- _ O
networks -X- _ O
on -X- _ O
various -X- _ O
tasks -X- _ O
like -X- _ O
image -X- _ B-TaskName
classification -X- _ I-TaskName
[ -X- _ O
69 -X- _ O
] -X- _ O
, -X- _ O
speech -X- _ B-TaskName
recognition -X- _ I-TaskName
[ -X- _ O
68 -X- _ O
] -X- _ O
, -X- _ O
entity -X- _ B-TaskName
disambiguation -X- _ I-TaskName
[ -X- _ O
17 -X- _ O
] -X- _ O
and -X- _ O
machine -X- _ B-TaskName
translation -X- _ I-TaskName
[ -X- _ O
48 -X- _ O
] -X- _ O
. -X- _ O

Subsequent -X- _ O
research -X- _ O
[ -X- _ O
15 -X- _ O
] -X- _ O
demonstrated -X- _ O
that -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
acts -X- _ O
as -X- _ O
a -X- _ O
regularization -X- _ O
scheme -X- _ O
, -X- _ O
enabling -X- _ O
better -X- _ O
generalization -X- _ O
in -X- _ O
deep -X- _ O
neural -X- _ O
networks -X- _ O
. -X- _ O

Early -X- _ O
works -X- _ O
explored -X- _ O
the -X- _ O
use -X- _ O
of -X- _ O
the -X- _ O
technique -X- _ O
in -X- _ O
image -X- _ B-TaskName
classification -X- _ I-TaskName
[ -X- _ O
20 -X- _ O
, -X- _ O
49 -X- _ O
, -X- _ O
63 -X- _ O
] -X- _ O
and -X- _ O
regression -X- _ B-TaskName
tasks -X- _ O
[ -X- _ O
3 -X- _ O
] -X- _ O
. -X- _ O

Unsupervised -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
Unsupervised -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
is -X- _ O
a -X- _ O
special -X- _ O
case -X- _ O
of -X- _ O
semi -X- _ O
- -X- _ O
supervised -X- _ O
learning -X- _ O
where -X- _ O
the -X- _ O
goal -X- _ O
is -X- _ O
to -X- _ O
find -X- _ O
a -X- _ O
good -X- _ O
initialization -X- _ O
point -X- _ O
instead -X- _ O
of -X- _ O
modifying -X- _ O
the -X- _ O
supervised -X- _ O
learning -X- _ O
objective -X- _ O
. -X- _ O

Phrase -X- _ O
- -X- _ O
level -X- _ O
or -X- _ O
sentence -X- _ O
- -X- _ O
level -X- _ O
embeddings -X- _ O
, -X- _ O
which -X- _ O
can -X- _ O
be -X- _ O
trained -X- _ O
using -X- _ O
an -X- _ O
unlabeled -X- _ O
corpus -X- _ O
, -X- _ O
have -X- _ O
been -X- _ O
used -X- _ O
to -X- _ O
encode -X- _ O
text -X- _ O
into -X- _ O
suitable -X- _ O
vector -X- _ O
representations -X- _ O
for -X- _ O
various -X- _ O
target -X- _ O
tasks -X- _ O
[ -X- _ O
28 -X- _ O
, -X- _ O
32 -X- _ O
, -X- _ O
1 -X- _ O
, -X- _ O
36 -X- _ O
, -X- _ O
22 -X- _ O
, -X- _ O
12 -X- _ O
, -X- _ O
56 -X- _ O
, -X- _ O
31 -X- _ O
] -X- _ O
. -X- _ O

Recent -X- _ O
approaches -X- _ O
have -X- _ O
investigated -X- _ O
learning -X- _ O
and -X- _ O
utilizing -X- _ O
more -X- _ O
than -X- _ O
word -X- _ O
- -X- _ O
level -X- _ O
semantics -X- _ O
from -X- _ O
unlabeled -X- _ O
data -X- _ O
. -X- _ O

These -X- _ O
approaches -X- _ O
, -X- _ O
however -X- _ O
, -X- _ O
mainly -X- _ O
transfer -X- _ O
word -X- _ O
- -X- _ O
level -X- _ O
information -X- _ O
, -X- _ O
whereas -X- _ O
we -X- _ O
aim -X- _ O
to -X- _ O
capture -X- _ O
higher -X- _ O
- -X- _ O
level -X- _ O
semantics -X- _ O
. -X- _ O

Over -X- _ O
the -X- _ O
last -X- _ O
few -X- _ O
years -X- _ O
, -X- _ O
researchers -X- _ O
have -X- _ O
demonstrated -X- _ O
the -X- _ O
benefits -X- _ O
of -X- _ O
using -X- _ O
word -X- _ O
embeddings -X- _ O
[ -X- _ O
11 -X- _ O
, -X- _ O
39 -X- _ O
, -X- _ O
42 -X- _ O
] -X- _ O
, -X- _ O
which -X- _ O
are -X- _ O
trained -X- _ O
on -X- _ O
unlabeled -X- _ O
corpora -X- _ O
, -X- _ O
to -X- _ O
improve -X- _ O
performance -X- _ O
on -X- _ O
a -X- _ O
variety -X- _ O
of -X- _ O
tasks -X- _ O
[ -X- _ O
8 -X- _ O
, -X- _ O
11 -X- _ O
, -X- _ O
26 -X- _ O
, -X- _ O
45 -X- _ O
] -X- _ O
. -X- _ O

The -X- _ O
earliest -X- _ O
approaches -X- _ O
used -X- _ O
unlabeled -X- _ O
data -X- _ O
to -X- _ O
compute -X- _ O
word -X- _ O
- -X- _ O
level -X- _ O
or -X- _ O
phrase -X- _ O
- -X- _ O
level -X- _ O
statistics -X- _ O
, -X- _ O
which -X- _ O
were -X- _ O
then -X- _ O
used -X- _ O
as -X- _ O
features -X- _ O
in -X- _ O
a -X- _ O
supervised -X- _ O
model -X- _ O
[ -X- _ O
33 -X- _ O
] -X- _ O
. -X- _ O

This -X- _ O
paradigm -X- _ O
has -X- _ O
attracted -X- _ O
significant -X- _ O
interest -X- _ O
, -X- _ O
with -X- _ O
applications -X- _ O
to -X- _ O
tasks -X- _ O
like -X- _ O
sequence -X- _ B-TaskName
labeling -X- _ I-TaskName
[ -X- _ O
24 -X- _ O
, -X- _ O
33 -X- _ O
, -X- _ O
57 -X- _ O
] -X- _ O
or -X- _ O
text -X- _ B-TaskName
classification -X- _ I-TaskName
[ -X- _ O
41 -X- _ O
, -X- _ O
70 -X- _ O
] -X- _ O
. -X- _ O

2 -X- _ O
Related -X- _ O
Work -X- _ O
Semi -X- _ O
- -X- _ O
supervised -X- _ O
learning -X- _ O
for -X- _ O
NLP -X- _ B-TaskName
Our -X- _ O
work -X- _ O
broadly -X- _ O
falls -X- _ O
under -X- _ O
the -X- _ O
category -X- _ O
of -X- _ O
semi -X- _ O
- -X- _ O
supervised -X- _ O
learning -X- _ O
for -X- _ O
natural -X- _ O
language -X- _ O
. -X- _ O

We -X- _ O
also -X- _ O
analyzed -X- _ O
zero -X- _ B-TaskName
- -X- _ I-TaskName
shot -X- _ I-TaskName
behaviors -X- _ O
of -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
model -X- _ O
on -X- _ O
four -X- _ O
different -X- _ O
settings -X- _ O
and -X- _ O
demonstrate -X- _ O
that -X- _ O
it -X- _ O
acquires -X- _ O
useful -X- _ O
linguistic -X- _ O
knowledge -X- _ O
for -X- _ O
downstream -X- _ O
tasks -X- _ O
. -X- _ O

[ -X- _ O
30 -X- _ O
] -X- _ O
, -X- _ O
1.5 -X- _ B-MetricValue
% -X- _ I-MetricValue
on -X- _ O
textual -X- _ B-TaskName
entailment -X- _ I-TaskName
( -X- _ O
MultiNLI -X- _ B-DatasetName
) -X- _ O
[ -X- _ O
66 -X- _ O
] -X- _ O
and -X- _ O
5.5 -X- _ B-MetricValue
% -X- _ I-MetricValue
on -X- _ O
the -X- _ O
recently -X- _ O
introduced -X- _ O
GLUE -X- _ B-DatasetName
multi -X- _ B-TaskName
- -X- _ I-TaskName
task -X- _ I-TaskName
benchmark -X- _ O
[ -X- _ O
64 -X- _ O
] -X- _ O
. -X- _ O

[ -X- _ O
40 -X- _ O
] -X- _ O
, -X- _ O
5.7 -X- _ B-MetricValue
% -X- _ I-MetricValue
on -X- _ O
question -X- _ B-TaskName
answering -X- _ I-TaskName
( -X- _ O
RACE -X- _ B-DatasetName
) -X- _ O

For -X- _ O
instance -X- _ O
, -X- _ O
we -X- _ O
achieve -X- _ O
absolute -X- _ O
improvements -X- _ B-MetricName
of -X- _ O
8.9 -X- _ B-MetricValue
% -X- _ I-MetricValue
on -X- _ O
commonsense -X- _ B-TaskName
reasoning -X- _ I-TaskName
( -X- _ O
Stories -X- _ B-DatasetName
Cloze -X- _ I-DatasetName
Test -X- _ I-DatasetName
) -X- _ O

Our -X- _ O
general -X- _ O
task -X- _ O
- -X- _ O
agnostic -X- _ O
model -X- _ O
outperforms -X- _ O
discriminatively -X- _ O
trained -X- _ O
models -X- _ O
that -X- _ O
employ -X- _ O
architectures -X- _ O
specifically -X- _ O
crafted -X- _ O
for -X- _ O
each -X- _ O
task -X- _ O
, -X- _ O
significantly -X- _ O
improving -X- _ O
upon -X- _ O
the -X- _ O
state -X- _ O
of -X- _ O
the -X- _ O
art -X- _ O
in -X- _ O
9 -X- _ O
out -X- _ O
of -X- _ O
the -X- _ O
12 -X- _ O
tasks -X- _ O
studied -X- _ O
. -X- _ O

We -X- _ O
evaluate -X- _ O
our -X- _ O
approach -X- _ O
on -X- _ O
four -X- _ O
types -X- _ O
of -X- _ O
language -X- _ B-TaskName
understanding -X- _ I-TaskName
tasks -X- _ O
– -X- _ O
natural -X- _ B-TaskName
language -X- _ I-TaskName
inference -X- _ I-TaskName
, -X- _ O
question -X- _ B-TaskName
answering -X- _ I-TaskName
, -X- _ O
semantic -X- _ B-TaskName
similarity -X- _ I-TaskName
, -X- _ O
and -X- _ O
text -X- _ B-TaskName
classification -X- _ I-TaskName
. -X- _ O

As -X- _ O
we -X- _ O
demonstrate -X- _ O
in -X- _ O
our -X- _ O
experiments -X- _ O
, -X- _ O
these -X- _ O
adaptations -X- _ O
enable -X- _ O
us -X- _ O
to -X- _ O
fine -X- _ O
- -X- _ O
tune -X- _ O
effectively -X- _ O
with -X- _ O
minimal -X- _ O
changes -X- _ O
to -X- _ O
the -X- _ O
architecture -X- _ O
of -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
model -X- _ O
. -X- _ O

During -X- _ O
transfer -X- _ O
, -X- _ O
we -X- _ O
utilize -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
input -X- _ O
adaptations -X- _ O
derived -X- _ O
from -X- _ O
traversal -X- _ O
- -X- _ O
style -X- _ O
approaches -X- _ O
[ -X- _ O
52 -X- _ O
] -X- _ O
, -X- _ O
which -X- _ O
process -X- _ O
structured -X- _ O
text -X- _ O
input -X- _ O
as -X- _ O
a -X- _ O
single -X- _ O
contiguous -X- _ O
sequence -X- _ O
of -X- _ O
tokens -X- _ O
. -X- _ O

This -X- _ O
model -X- _ O
choice -X- _ O
provides -X- _ O
us -X- _ O
with -X- _ O
a -X- _ O
more -X- _ O
structured -X- _ O
memory -X- _ O
for -X- _ O
handling -X- _ O
long -X- _ O
- -X- _ O
term -X- _ O
dependencies -X- _ O
in -X- _ O
text -X- _ O
, -X- _ O
compared -X- _ O
to -X- _ O
alternatives -X- _ O
like -X- _ O
recurrent -X- _ B-MethodName
networks -X- _ I-MethodName
, -X- _ O
resulting -X- _ O
in -X- _ O
robust -X- _ O
transfer -X- _ O
performance -X- _ O
across -X- _ O
diverse -X- _ O
tasks -X- _ O
. -X- _ O

For -X- _ O
our -X- _ O
model -X- _ O
architecture -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
Transformer -X- _ B-MethodName
[ -X- _ O
62 -X- _ O
] -X- _ O
, -X- _ O
which -X- _ O
has -X- _ O
been -X- _ O
shown -X- _ O
to -X- _ O
perform -X- _ O
strongly -X- _ O
on -X- _ O
various -X- _ O
tasks -X- _ O
such -X- _ O
as -X- _ O
machine -X- _ B-TaskName
translation -X- _ I-TaskName
[ -X- _ O
62 -X- _ O
] -X- _ O
, -X- _ O
document -X- _ B-TaskName
generation -X- _ I-TaskName
[ -X- _ O
34 -X- _ O
] -X- _ O
, -X- _ O
and -X- _ O
syntactic -X- _ B-TaskName
parsing -X- _ I-TaskName
[ -X- _ O
29 -X- _ O
] -X- _ O
. -X- _ O

Subsequently -X- _ O
, -X- _ O
we -X- _ O
adapt -X- _ O
these -X- _ O
parameters -X- _ O
to -X- _ O
a -X- _ O
target -X- _ O
task -X- _ O
using -X- _ O
the -X- _ O
corresponding -X- _ O
supervised -X- _ O
objective -X- _ O
. -X- _ O

First -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
a -X- _ O
language -X- _ B-TaskName
modeling -X- _ I-TaskName
objective -X- _ O
on -X- _ O
the -X- _ O
unlabeled -X- _ O
data -X- _ O
to -X- _ O
learn -X- _ O
the -X- _ O
initial -X- _ O
parameters -X- _ O
of -X- _ O
a -X- _ O
neural -X- _ O
network -X- _ O
model -X- _ O
. -X- _ O

We -X- _ O
employ -X- _ O
a -X- _ O
two -X- _ O
- -X- _ O
stage -X- _ O
training -X- _ O
procedure -X- _ O
. -X- _ O

Our -X- _ O
setup -X- _ O
does -X- _ O
not -X- _ O
require -X- _ O
these -X- _ O
target -X- _ O
tasks -X- _ O
to -X- _ O
be -X- _ O
in -X- _ O
the -X- _ O
same -X- _ O
domain -X- _ O
as -X- _ O
the -X- _ O
unlabeled -X- _ O
corpus -X- _ O
. -X- _ O

We -X- _ O
assume -X- _ O
access -X- _ O
to -X- _ O
a -X- _ O
large -X- _ O
corpus -X- _ O
of -X- _ O
unlabeled -X- _ O
text -X- _ O
and -X- _ O
several -X- _ O
datasets -X- _ O
with -X- _ O
manually -X- _ O
annotated -X- _ O
training -X- _ O
examples -X- _ O
( -X- _ O
target -X- _ O
tasks -X- _ O
) -X- _ O
. -X- _ O

Our -X- _ O
goal -X- _ O
is -X- _ O
to -X- _ O
learn -X- _ O
a -X- _ O
universal -X- _ O
representation -X- _ O
that -X- _ O
transfers -X- _ O
with -X- _ O
little -X- _ O
adaptation -X- _ O
to -X- _ O
a -X- _ O
wide -X- _ O
range -X- _ O
of -X- _ O
tasks -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
explore -X- _ O
a -X- _ O
semi -X- _ O
- -X- _ O
supervised -X- _ O
approach -X- _ O
for -X- _ O
language -X- _ B-TaskName
understanding -X- _ I-TaskName
tasks -X- _ O
using -X- _ O
a -X- _ O
combination -X- _ O
of -X- _ O
unsupervised -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
and -X- _ O
supervised -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
. -X- _ O


Work -X- _ O
in -X- _ O
progress -X- _ O
. -X- _ O

1 -X- _ O
https://gluebenchmark.com/leaderboard -X- _ O
Preprint -X- _ O
. -X- _ O

These -X- _ O
uncertainties -X- _ O
have -X- _ O
made -X- _ O
it -X- _ O
difficult -X- _ O
to -X- _ O
develop -X- _ O
effective -X- _ O
semi -X- _ O
- -X- _ O
supervised -X- _ O
learning -X- _ O
approaches -X- _ O
for -X- _ O
language -X- _ B-TaskName
processing -X- _ I-TaskName
. -X- _ O

Existing -X- _ O
techniques -X- _ O
involve -X- _ O
a -X- _ O
combination -X- _ O
of -X- _ O
making -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
changes -X- _ O
to -X- _ O
the -X- _ O
model -X- _ O
architecture -X- _ O
[ -X- _ O
43 -X- _ O
, -X- _ O
44 -X- _ O
] -X- _ O
, -X- _ O
using -X- _ O
intricate -X- _ O
learning -X- _ O
schemes -X- _ O
[ -X- _ O
21 -X- _ O
] -X- _ O
and -X- _ O
adding -X- _ O
auxiliary -X- _ O
learning -X- _ O
objectives -X- _ O
[ -X- _ O
50 -X- _ O
] -X- _ O
. -X- _ O

[ -X- _ O
22 -X- _ O
] -X- _ O
, -X- _ O
with -X- _ O
each -X- _ O
method -X- _ O
outperforming -X- _ O
the -X- _ O
others -X- _ O
on -X- _ O
different -X- _ O
tasks.1 -X- _ O
Second -X- _ O
, -X- _ O
there -X- _ O
is -X- _ O
no -X- _ O
consensus -X- _ O
on -X- _ O
the -X- _ O
most -X- _ O
effective -X- _ O
way -X- _ O
to -X- _ O
transfer -X- _ O
these -X- _ O
learned -X- _ O
representations -X- _ O
to -X- _ O
the -X- _ O
target -X- _ O
task -X- _ O
. -X- _ O

Recent -X- _ O
research -X- _ O
has -X- _ O
looked -X- _ O
at -X- _ O
various -X- _ O
objectives -X- _ O
such -X- _ O
as -X- _ O
language -X- _ B-TaskName
modeling -X- _ I-TaskName
[ -X- _ O
44 -X- _ O
] -X- _ O
, -X- _ O
machine -X- _ B-TaskName
translation -X- _ I-TaskName
[ -X- _ O
38 -X- _ O
] -X- _ O
, -X- _ O
and -X- _ O
discourse -X- _ B-TaskName
coherence -X- _ I-TaskName

First -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
unclear -X- _ O
what -X- _ O
type -X- _ O
of -X- _ O
optimization -X- _ O
objectives -X- _ O
are -X- _ O
most -X- _ O
effective -X- _ O
at -X- _ O
learning -X- _ B-TaskName
text -X- _ I-TaskName
representations -X- _ I-TaskName
that -X- _ O
are -X- _ O
useful -X- _ O
for -X- _ O
transfer -X- _ O
. -X- _ O

Leveraging -X- _ O
more -X- _ O
than -X- _ O
word -X- _ O
- -X- _ O
level -X- _ O
information -X- _ O
from -X- _ O
unlabeled -X- _ O
text -X- _ O
, -X- _ O
however -X- _ O
, -X- _ O
is -X- _ O
challenging -X- _ O
for -X- _ O
two -X- _ O
main -X- _ O
reasons -X- _ O
. -X- _ O

The -X- _ O
most -X- _ O
compelling -X- _ O
evidence -X- _ O
for -X- _ O
this -X- _ O
so -X- _ O
far -X- _ O
has -X- _ O
been -X- _ O
the -X- _ O
extensive -X- _ O
use -X- _ O
of -X- _ O
pretrained -X- _ O
word -X- _ B-TaskName
embeddings -X- _ I-TaskName
[ -X- _ O
10 -X- _ O
, -X- _ O
39 -X- _ O
, -X- _ O
42 -X- _ O
] -X- _ O
to -X- _ O
improve -X- _ O
performance -X- _ O
on -X- _ O
a -X- _ O
range -X- _ O
of -X- _ O
NLP -X- _ B-TaskName
tasks -X- _ O
[ -X- _ O
8 -X- _ O
, -X- _ O
11 -X- _ O
, -X- _ O
26 -X- _ O
, -X- _ O
45 -X- _ O
] -X- _ O
. -X- _ O

Further -X- _ O
, -X- _ O
even -X- _ O
in -X- _ O
cases -X- _ O
where -X- _ O
considerable -X- _ O
supervision -X- _ O
is -X- _ O
available -X- _ O
, -X- _ O
learning -X- _ O
good -X- _ O
representations -X- _ O
in -X- _ O
an -X- _ O
unsupervised -X- _ O
fashion -X- _ O
can -X- _ O
provide -X- _ O
a -X- _ O
significant -X- _ O
performance -X- _ O
boost -X- _ O
. -X- _ O

In -X- _ O
these -X- _ O
situations -X- _ O
, -X- _ O
models -X- _ O
that -X- _ O
can -X- _ O
leverage -X- _ O
linguistic -X- _ O
information -X- _ O
from -X- _ O
unlabeled -X- _ O
data -X- _ O
provide -X- _ O
a -X- _ O
valuable -X- _ O
alternative -X- _ O
to -X- _ O
gathering -X- _ O
more -X- _ O
annotation -X- _ O
, -X- _ O
which -X- _ O
can -X- _ O
be -X- _ O
time -X- _ O
- -X- _ O
consuming -X- _ O
and -X- _ O
expensive -X- _ O
. -X- _ O

Most -X- _ O
deep -X- _ O
learning -X- _ O
methods -X- _ O
require -X- _ O
substantial -X- _ O
amounts -X- _ O
of -X- _ O
manually -X- _ O
labeled -X- _ O
data -X- _ O
, -X- _ O
which -X- _ O
restricts -X- _ O
their -X- _ O
applicability -X- _ O
in -X- _ O
many -X- _ O
domains -X- _ O
that -X- _ O
suffer -X- _ O
from -X- _ O
a -X- _ O
dearth -X- _ O
of -X- _ O
annotated -X- _ O
resources -X- _ O
[ -X- _ O
61 -X- _ O
] -X- _ O
. -X- _ O

1 -X- _ O
Introduction -X- _ O
The -X- _ O
ability -X- _ O
to -X- _ O
learn -X- _ O
effectively -X- _ O
from -X- _ O
raw -X- _ O
text -X- _ O
is -X- _ O
crucial -X- _ O
to -X- _ O
alleviating -X- _ O
the -X- _ O
dependence -X- _ O
on -X- _ O
supervised -X- _ O
learning -X- _ O
in -X- _ O
natural -X- _ B-TaskName
language -X- _ I-TaskName
processing -X- _ I-TaskName
( -X- _ O
NLP -X- _ B-TaskName
) -X- _ O
. -X- _ O

For -X- _ O
instance -X- _ O
, -X- _ O
we -X- _ O
achieve -X- _ O
absolute -X- _ O
improvements -X- _ B-MetricName
of -X- _ O
8.9 -X- _ B-MetricValue
% -X- _ I-MetricValue
on -X- _ O
commonsense -X- _ B-TaskName
reasoning -X- _ I-TaskName
( -X- _ O
Stories -X- _ B-DatasetName
Cloze -X- _ I-DatasetName
Test -X- _ I-DatasetName
) -X- _ O
, -X- _ O
5.7 -X- _ B-MetricValue
% -X- _ I-MetricValue
on -X- _ O
question -X- _ B-TaskName
answering -X- _ I-TaskName
( -X- _ O
RACE -X- _ B-DatasetName
) -X- _ O
, -X- _ O
and -X- _ O
1.5 -X- _ B-MetricValue
% -X- _ I-MetricValue
on -X- _ O
textual -X- _ B-TaskName
entailment -X- _ I-TaskName
( -X- _ O
MultiNLI -X- _ B-DatasetName
) -X- _ O
. -X- _ O

Our -X- _ O
general -X- _ O
task -X- _ O
- -X- _ O
agnostic -X- _ O
model -X- _ O
outperforms -X- _ O
discriminatively -X- _ O
trained -X- _ O
models -X- _ O
that -X- _ O
use -X- _ O
architectures -X- _ O
specifically -X- _ O
crafted -X- _ O
for -X- _ O
each -X- _ O
task -X- _ O
, -X- _ O
significantly -X- _ O
improving -X- _ O
upon -X- _ O
the -X- _ O
state -X- _ O
of -X- _ O
the -X- _ O
art -X- _ O
in -X- _ O
9 -X- _ O
out -X- _ O
of -X- _ O
the -X- _ O
12 -X- _ O
tasks -X- _ O
studied -X- _ O
. -X- _ O

We -X- _ O
demonstrate -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
our -X- _ O
approach -X- _ O
on -X- _ O
a -X- _ O
wide -X- _ O
range -X- _ O
of -X- _ O
benchmarks -X- _ O
for -X- _ O
natural -X- _ B-TaskName
language -X- _ I-TaskName
understanding -X- _ I-TaskName
. -X- _ O

In -X- _ O
contrast -X- _ O
to -X- _ O
previous -X- _ O
approaches -X- _ O
, -X- _ O
we -X- _ O
make -X- _ O
use -X- _ O
of -X- _ O
task -X- _ O
- -X- _ O
aware -X- _ O
input -X- _ O
transformations -X- _ O
during -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
to -X- _ O
achieve -X- _ O
effective -X- _ O
transfer -X- _ O
while -X- _ O
requiring -X- _ O
minimal -X- _ O
changes -X- _ O
to -X- _ O
the -X- _ O
model -X- _ O
architecture -X- _ O
. -X- _ O

We -X- _ O
demonstrate -X- _ O
that -X- _ O
large -X- _ O
gains -X- _ O
on -X- _ O
these -X- _ O
tasks -X- _ O
can -X- _ O
be -X- _ O
realized -X- _ O
by -X- _ O
generative -X- _ B-MethodName
pre -X- _ I-MethodName
- -X- _ I-MethodName
training -X- _ I-MethodName
of -X- _ O
a -X- _ O
language -X- _ O
model -X- _ O
on -X- _ O
a -X- _ O
diverse -X- _ O
corpus -X- _ O
of -X- _ O
unlabeled -X- _ O
text -X- _ O
, -X- _ O
followed -X- _ O
by -X- _ O
discriminative -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
on -X- _ O
each -X- _ O
specific -X- _ O
task -X- _ O
. -X- _ O

Although -X- _ O
large -X- _ O
unlabeled -X- _ O
text -X- _ O
corpora -X- _ O
are -X- _ O
abundant -X- _ O
, -X- _ O
labeled -X- _ O
data -X- _ O
for -X- _ O
learning -X- _ O
these -X- _ O
specific -X- _ O
tasks -X- _ O
is -X- _ O
scarce -X- _ O
, -X- _ O
making -X- _ O
it -X- _ O
challenging -X- _ O
for -X- _ O
discriminatively -X- _ O
trained -X- _ O
models -X- _ O
to -X- _ O
perform -X- _ O
adequately -X- _ O
. -X- _ O

Abstract -X- _ O
Natural -X- _ B-TaskName
language -X- _ I-TaskName
understanding -X- _ I-TaskName
comprises -X- _ O
a -X- _ O
wide -X- _ O
range -X- _ O
of -X- _ O
diverse -X- _ O
tasks -X- _ O
such -X- _ O
as -X- _ O
textual -X- _ B-TaskName
entailment -X- _ I-TaskName
, -X- _ O
question -X- _ B-TaskName
answering -X- _ I-TaskName
, -X- _ O
semantic -X- _ B-TaskName
similarity -X- _ I-TaskName
assessment -X- _ I-TaskName
, -X- _ O
and -X- _ O
document -X- _ B-TaskName
classification -X- _ I-TaskName
. -X- _ O

Ilya -X- _ O
Sutskever -X- _ O
OpenAI -X- _ O
ilyasu@openai.com -X- _ O

tim@openai.com -X- _ O

Tim -X- _ O
Salimans -X- _ O
OpenAI -X- _ O

Karthik -X- _ O
Narasimhan -X- _ O
OpenAI -X- _ O
karthikn@openai.com -X- _ O

Improving -X- _ O
Language -X- _ B-TaskName
Understanding -X- _ I-TaskName
by -X- _ O
Generative -X- _ B-MethodName
Pre -X- _ I-MethodName
- -X- _ I-MethodName
Training -X- _ I-MethodName
Alec -X- _ O
Radford -X- _ O
OpenAI -X- _ O
alec@openai.com -X- _ O

