-DOCSTART- -X- O
In -X- _ O
this -X- _ O
work -X- _ O
we -X- _ O
focus -X- _ O
on -X- _ O
a -X- _ O
science -X- _ O
domain -X- _ O
( -X- _ O
chemistry -X- _ O
) -X- _ O
and -X- _ O
demonstrate -X- _ O
the -X- _ O
value -X- _ O
and -X- _ O
limitations -X- _ O
of -X- _ O
large -X- _ O
- -X- _ O
scale -X- _ O
language -X- _ O
models -X- _ O
evaluated -X- _ O
across -X- _ O
a -X- _ O
wide -X- _ O
range -X- _ O
of -X- _ O
in -X- _ O
- -X- _ O
domain -X- _ O
( -X- _ O
science -X- _ O
- -X- _ O
focused -X- _ O
) -X- _ O
and -X- _ O
out -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
domain -X- _ O
tasks -X- _ O
. -X- _ O

arXiv -X- _ O
preprint -X- _ O
arXiv:1909.06146 -X- _ O
. -X- _ O

A -X- _ O
dataset -X- _ O
for -X- _ O
biomedical -X- _ O
research -X- _ O
question -X- _ O
answering -X- _ O
. -X- _ O

Pubmedqa -X- _ O
: -X- _ O

2019 -X- _ O
. -X- _ O

Qiao -X- _ O
Jin -X- _ O
, -X- _ O
Bhuwan -X- _ O
Dhingra -X- _ O
, -X- _ O
Zhengping -X- _ O
Liu -X- _ O
, -X- _ O
William -X- _ O
W -X- _ O
Cohen -X- _ O
, -X- _ O
and -X- _ O
Xinghua -X- _ O
Lu -X- _ O
. -X- _ O

PMLR -X- _ O
. -X- _ O

In -X- _ O
International -X- _ O
Conference -X- _ O
on -X- _ O
Machine -X- _ O
Learning -X- _ O
, -X- _ O
pages -X- _ O
4651–4664 -X- _ O
. -X- _ O

Perceiver -X- _ O
: -X- _ O
General -X- _ O
perception -X- _ O
with -X- _ O
iterative -X- _ O
attention -X- _ O
. -X- _ O

Andrew -X- _ O
Jaegle -X- _ O
, -X- _ O
Felix -X- _ O
Gimeno -X- _ O
, -X- _ O
Andy -X- _ O
Brock -X- _ O
, -X- _ O
Oriol -X- _ O
Vinyals -X- _ O
, -X- _ O
Andrew -X- _ O
Zisserman -X- _ O
, -X- _ O
and -X- _ O
Joao -X- _ O
Carreira -X- _ O
. -X- _ O
2021 -X- _ O
. -X- _ O

arXiv -X- _ O
preprint -X- _ O
arXiv:2009.03300 -X- _ O
. -X- _ O

Measuring -X- _ O
massive -X- _ O
multitask -X- _ O
language -X- _ O
understanding -X- _ O
. -X- _ O

Dan -X- _ O
Hendrycks -X- _ O
, -X- _ O
Collin -X- _ O
Burns -X- _ O
, -X- _ O
Steven -X- _ O
Basart -X- _ O
, -X- _ O
Andy -X- _ O
Zou -X- _ O
, -X- _ O
Mantas -X- _ O
Mazeika -X- _ O
, -X- _ O
Dawn -X- _ O
Song -X- _ O
, -X- _ O
and -X- _ O
Jacob -X- _ O
Steinhardt -X- _ O
. -X- _ O
2020 -X- _ O
. -X- _ O

PMID -X- _ O
: -X- _ O
34115937 -X- _ O
. -X- _ O

Journal -X- _ O
of -X- _ O
Chemical -X- _ O
Information -X- _ O
and -X- _ O
Modeling -X- _ O
, -X- _ O
0(0):null -X- _ O
. -X- _ O

Automated -X- _ O
chemical -X- _ O
reaction -X- _ O
extraction -X- _ O
from -X- _ O
scientific -X- _ O
literature -X- _ O
. -X- _ O

2021 -X- _ O
. -X- _ O

Jiang -X- _ O
Guo -X- _ O
, -X- _ O
A. -X- _ O
Santiago -X- _ O
Ibanez -X- _ O
- -X- _ O
Lopez -X- _ O
, -X- _ O
Hanyu -X- _ O
Gao -X- _ O
, -X- _ O
Victor -X- _ O
Quach -X- _ O
, -X- _ O
Connor -X- _ O
W. -X- _ O
Coley -X- _ O
, -X- _ O
Klavs -X- _ O
F. -X- _ O
Jensen -X- _ O
, -X- _ O
and -X- _ O
Regina -X- _ O
Barzilay -X- _ O
. -X- _ O

ACM -X- _ O
Transactions -X- _ O
on -X- _ O
Computing -X- _ O
for -X- _ O
Healthcare -X- _ O
( -X- _ O
HEALTH -X- _ O
) -X- _ O
, -X- _ O
3(1):1–23 -X- _ O
. -X- _ O

Domain -X- _ O
- -X- _ O
specific -X- _ O
language -X- _ O
model -X- _ O
pretraining -X- _ O
for -X- _ O
biomedical -X- _ O
natural -X- _ O
language -X- _ O
processing -X- _ O
. -X- _ O

A -X- _ O
framework -X- _ O
for -X- _ O
few -X- _ O
- -X- _ O
shot -X- _ O
language -X- _ O
model -X- _ O
evaluation -X- _ O
. -X- _ O

Yu -X- _ O
Gu -X- _ O
, -X- _ O
Robert -X- _ O
Tinn -X- _ O
, -X- _ O
Hao -X- _ O
Cheng -X- _ O
, -X- _ O
Michael -X- _ O
Lucas -X- _ O
, -X- _ O
Naoto -X- _ O
Usuyama -X- _ O
, -X- _ O
Xiaodong -X- _ O
Liu -X- _ O
, -X- _ O
Tristan -X- _ O
Naumann -X- _ O
, -X- _ O
Jianfeng -X- _ O
Gao -X- _ O
, -X- _ O
and -X- _ O
Hoifung -X- _ O
Poon -X- _ O
. -X- _ O
2021 -X- _ O
. -X- _ O

Leo -X- _ O
Gao -X- _ O
, -X- _ O
Jonathan -X- _ O
Tow -X- _ O
, -X- _ O
Stella -X- _ O
Biderman -X- _ O
, -X- _ O
Sid -X- _ O
Black -X- _ O
, -X- _ O
Anthony -X- _ O
DiPofi -X- _ O
, -X- _ O
Charles -X- _ O
Foster -X- _ O
, -X- _ O
Laurence -X- _ O
Golding -X- _ O
, -X- _ O
Jeffrey -X- _ O
Hsu -X- _ O
, -X- _ O
Kyle -X- _ O
McDonell -X- _ O
, -X- _ O
Niklas -X- _ O
Muennighoff -X- _ O
, -X- _ O
Jason -X- _ O
Phang -X- _ O
, -X- _ O
Laria -X- _ O
Reynolds -X- _ O
, -X- _ O
Eric -X- _ O
Tang -X- _ O
, -X- _ O
Anish -X- _ O
Thite -X- _ O
, -X- _ O
Ben -X- _ O
Wang -X- _ O
, -X- _ O
Kevin -X- _ O
Wang -X- _ O
, -X- _ O
and -X- _ O
Andy -X- _ O
Zou -X- _ O
. -X- _ O
2021 -X- _ O
. -X- _ O

arXiv -X- _ O
preprint -X- _ O
arXiv:2101.00027 -X- _ O
. -X- _ O

The -X- _ O
pile -X- _ O
: -X- _ O
An -X- _ O
800 -X- _ O
gb -X- _ O
dataset -X- _ O
of -X- _ O
diverse -X- _ O
text -X- _ O
for -X- _ O
language -X- _ O
modeling -X- _ O
. -X- _ O

Leo -X- _ O
Gao -X- _ O
, -X- _ O
Stella -X- _ O
Biderman -X- _ O
, -X- _ O
Sid -X- _ O
Black -X- _ O
, -X- _ O
Laurence -X- _ O
Golding -X- _ O
, -X- _ O
Travis -X- _ O
Hoppe -X- _ O
, -X- _ O
Charles -X- _ O
Foster -X- _ O
, -X- _ O
Jason -X- _ O
Phang -X- _ O
, -X- _ O
Horace -X- _ O
He -X- _ O
, -X- _ O
Anish -X- _ O
Thite -X- _ O
, -X- _ O
Noa -X- _ O
Nabeshima -X- _ O
, -X- _ O
et -X- _ O
al. -X- _ O
2020 -X- _ O
. -X- _ O

Transactions -X- _ O
of -X- _ O
the -X- _ O
Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
, -X- _ O
5:529–542 -X- _ O
. -X- _ O

Topic -X- _ O
modeling -X- _ O
with -X- _ O
minimal -X- _ O
domain -X- _ O
knowledge -X- _ O
. -X- _ O

Anchored -X- _ O
correlation -X- _ O
explanation -X- _ O
: -X- _ O

Ryan -X- _ O
J -X- _ O
Gallagher -X- _ O
, -X- _ O
Kyle -X- _ O
Reing -X- _ O
, -X- _ O
David -X- _ O
Kale -X- _ O
, -X- _ O
and -X- _ O
Greg -X- _ O
Ver -X- _ O
Steeg -X- _ O
. -X- _ O
2017 -X- _ O
. -X- _ O

arXiv -X- _ O
preprint -X- _ O
arXiv:1810.04805 -X- _ O
. -X- _ O

Bert -X- _ O
: -X- _ O
Pre -X- _ O
- -X- _ O
training -X- _ O
of -X- _ O
deep -X- _ O
bidirectional -X- _ O
transformers -X- _ O
for -X- _ O
language -X- _ O
understanding -X- _ O
. -X- _ O

Jacob -X- _ O
Devlin -X- _ O
, -X- _ O
Ming -X- _ O
- -X- _ O
Wei -X- _ O
Chang -X- _ O
, -X- _ O
Kenton -X- _ O
Lee -X- _ O
, -X- _ O
and -X- _ O
Kristina -X- _ O
Toutanova -X- _ O
. -X- _ O
2018 -X- _ O
. -X- _ O

In -X- _ O
proceedings -X- _ O
of -X- _ O
Sinn -X- _ O
und -X- _ O
Bedeutung -X- _ O
, -X- _ O
volume -X- _ O
23 -X- _ O
, -X- _ O
pages -X- _ O
107–124 -X- _ O
. -X- _ O

The -X- _ O
commitmentbank -X- _ O
: -X- _ O
Investigating -X- _ O
projection -X- _ O
in -X- _ O
naturally -X- _ O
occurring -X- _ O
discourse -X- _ O
. -X- _ O

Marie -X- _ O
- -X- _ O
Catherine -X- _ O
De -X- _ O
Marneffe -X- _ O
, -X- _ O
Mandy -X- _ O
Simons -X- _ O
, -X- _ O
and -X- _ O
Judith -X- _ O
Tonhauser -X- _ O
. -X- _ O
2019 -X- _ O
. -X- _ O

Cord19 -X- _ O
. -X- _ O
https://www.semanticscholar.org/cord19/download -X- _ O
. -X- _ O

arXiv -X- _ O
preprint -X- _ O
arXiv:1803.05457 -X- _ O
. -X- _ O

try -X- _ O
arc -X- _ O
, -X- _ O
the -X- _ O
ai2 -X- _ O
reasoning -X- _ O
challenge -X- _ O
. -X- _ O

Think -X- _ O
you -X- _ O
have -X- _ O
solved -X- _ O
question -X- _ O
answering -X- _ O
? -X- _ O

2018 -X- _ O
. -X- _ O

Peter -X- _ O
Clark -X- _ O
, -X- _ O
Isaac -X- _ O
Cowhey -X- _ O
, -X- _ O
Oren -X- _ O
Etzioni -X- _ O
, -X- _ O
Tushar -X- _ O
Khot -X- _ O
, -X- _ O
Ashish -X- _ O
Sabharwal -X- _ O
, -X- _ O
Carissa -X- _ O
Schoenick -X- _ O
, -X- _ O
and -X- _ O
Oyvind -X- _ O
Tafjord -X- _ O
. -X- _ O

In -X- _ O
NAACL -X- _ O
. -X- _ O

Boolq -X- _ O
: -X- _ O
Exploring -X- _ O
the -X- _ O
surprising -X- _ O
difficulty -X- _ O
of -X- _ O
natural -X- _ O
yes -X- _ O
/ -X- _ O
no -X- _ O
questions -X- _ O
. -X- _ O

Christopher -X- _ O
Clark -X- _ O
, -X- _ O
Kenton -X- _ O
Lee -X- _ O
, -X- _ O
Ming -X- _ O
- -X- _ O
Wei -X- _ O
Chang -X- _ O
, -X- _ O
Tom -X- _ O
Kwiatkowski -X- _ O
, -X- _ O
Michael -X- _ O
Collins -X- _ O
, -X- _ O
and -X- _ O
Kristina -X- _ O
Toutanova -X- _ O
. -X- _ O
2019 -X- _ O
. -X- _ O

arXiv -X- _ O
preprint -X- _ O
arXiv:2202.07646 -X- _ O
. -X- _ O

Quantifying -X- _ O
memorization -X- _ O
across -X- _ O
neural -X- _ O
language -X- _ O
models -X- _ O
. -X- _ O

Nicholas -X- _ O
Carlini -X- _ O
, -X- _ O
Daphne -X- _ O
Ippolito -X- _ O
, -X- _ O
Matthew -X- _ O
Jagielski -X- _ O
, -X- _ O
Katherine -X- _ O
Lee -X- _ O
, -X- _ O
Florian -X- _ O
Tramer -X- _ O
, -X- _ O
and -X- _ O
Chiyuan -X- _ O
Zhang -X- _ O
. -X- _ O
2022 -X- _ O
. -X- _ O

Advances -X- _ O
in -X- _ O
neural -X- _ O
information -X- _ O
processing -X- _ O
systems -X- _ O
, -X- _ O
33:1877–1901 -X- _ O
. -X- _ O

Language -X- _ O
models -X- _ O
are -X- _ O
few -X- _ O
- -X- _ O
shot -X- _ O
learners -X- _ O
. -X- _ O

Tom -X- _ O
Brown -X- _ O
, -X- _ O
Benjamin -X- _ O
Mann -X- _ O
, -X- _ O
Nick -X- _ O
Ryder -X- _ O
, -X- _ O
Melanie -X- _ O
Subbiah -X- _ O
, -X- _ O
Jared -X- _ O
D -X- _ O
Kaplan -X- _ O
, -X- _ O
Prafulla -X- _ O
Dhariwal -X- _ O
, -X- _ O
Arvind -X- _ O
Neelakantan -X- _ O
, -X- _ O
Pranav -X- _ O
Shyam -X- _ O
, -X- _ O
Girish -X- _ O
Sastry -X- _ O
, -X- _ O
Amanda -X- _ O
Askell -X- _ O
, -X- _ O
et -X- _ O
al. -X- _ O
2020 -X- _ O
. -X- _ O

arXiv -X- _ O
preprint -X- _ O
arXiv:2108.07258 -X- _ O
. -X- _ O

On -X- _ O
the -X- _ O
opportunities -X- _ O
and -X- _ O
risks -X- _ O
of -X- _ O
foundation -X- _ O
models -X- _ O
. -X- _ O

Rishi -X- _ O
Bommasani -X- _ O
, -X- _ O
Drew -X- _ O
A -X- _ O
Hudson -X- _ O
, -X- _ O
Ehsan -X- _ O
Adeli -X- _ O
, -X- _ O
Russ -X- _ O
Altman -X- _ O
, -X- _ O
Simran -X- _ O
Arora -X- _ O
, -X- _ O
Sydney -X- _ O
von -X- _ O
Arx -X- _ O
, -X- _ O
Michael -X- _ O
S -X- _ O
Bernstein -X- _ O
, -X- _ O
Jeannette -X- _ O
Bohg -X- _ O
, -X- _ O
Antoine -X- _ O
Bosselut -X- _ O
, -X- _ O
Emma -X- _ O
Brunskill -X- _ O
, -X- _ O
et -X- _ O
al. -X- _ O
2021 -X- _ O
. -X- _ O

Gpt -X- _ O
- -X- _ O
neox-20b -X- _ O
: -X- _ O
An -X- _ O
open -X- _ O
- -X- _ O
source -X- _ O
autoregressive -X- _ O
language -X- _ O
model -X- _ O
. -X- _ O

Sid -X- _ O
Black -X- _ O
, -X- _ O
Stella -X- _ O
Biderman -X- _ O
, -X- _ O
Eric -X- _ O
Hallahan -X- _ O
, -X- _ O
Quentin -X- _ O
Anthony -X- _ O
, -X- _ O
Leo -X- _ O
Gao -X- _ O
, -X- _ O
Laurence -X- _ O
Golding -X- _ O
, -X- _ O
Horace -X- _ O
He -X- _ O
, -X- _ O
Connor -X- _ O
Leahy -X- _ O
, -X- _ O
Kyle -X- _ O
McDonell -X- _ O
, -X- _ O
Jason -X- _ O
Phang -X- _ O
, -X- _ O
et -X- _ O
al. -X- _ O
2022 -X- _ O
. -X- _ O

In -X- _ O
Proceedings -X- _ O
of -X- _ O
the -X- _ O
AAAI -X- _ O
conference -X- _ O
on -X- _ O
artificial -X- _ O
intelligence -X- _ O
, -X- _ O
volume -X- _ O
34 -X- _ O
, -X- _ O
pages -X- _ O
7432–7439 -X- _ O
. -X- _ O

Reasoning -X- _ O
about -X- _ O
physical -X- _ O
commonsense -X- _ O
in -X- _ O
natural -X- _ O
language -X- _ O
. -X- _ O

Piqa -X- _ O
: -X- _ O

Yonatan -X- _ O
Bisk -X- _ O
, -X- _ O
Rowan -X- _ O
Zellers -X- _ O
, -X- _ O
Jianfeng -X- _ O
Gao -X- _ O
, -X- _ O
Yejin -X- _ O
Choi -X- _ O
, -X- _ O
et -X- _ O
al. -X- _ O
2020 -X- _ O
. -X- _ O

arXiv -X- _ O
preprint -X- _ O
arXiv:1903.10676 -X- _ O
. -X- _ O

Scibert -X- _ O
: -X- _ O
A -X- _ O
pretrained -X- _ O
language -X- _ O
model -X- _ O
for -X- _ O
scientific -X- _ O
text -X- _ O
. -X- _ O

Iz -X- _ O
Beltagy -X- _ O
, -X- _ O
Kyle -X- _ O
Lo -X- _ O
, -X- _ O
and -X- _ O
Arman -X- _ O
Cohan -X- _ O
. -X- _ O
2019 -X- _ O
. -X- _ O

GPT -X- _ O
- -X- _ O
NeoX -X- _ O
: -X- _ O
Large -X- _ O
scale -X- _ O
autoregressive -X- _ O
language -X- _ O
modeling -X- _ O
in -X- _ O
pytorch -X- _ O
. -X- _ O

Alex -X- _ O
Andonian -X- _ O
, -X- _ O
Quentin -X- _ O
Anthony -X- _ O
, -X- _ O
Stella -X- _ O
Biderman -X- _ O
, -X- _ O
Sid -X- _ O
Black -X- _ O
, -X- _ O
Preetham -X- _ O
Gali -X- _ O
, -X- _ O
Leo -X- _ O
Gao -X- _ O
, -X- _ O
Eric -X- _ O
Hallahan -X- _ O
, -X- _ O
Josh -X- _ O
Levy -X- _ O
- -X- _ O
Kramer -X- _ O
, -X- _ O
Connor -X- _ O
Leahy -X- _ O
, -X- _ O
Lucas -X- _ O
Nestler -X- _ O
, -X- _ O
Kip -X- _ O
Parker -X- _ O
, -X- _ O
Michael -X- _ O
Pieler -X- _ O
, -X- _ O
Shivanshu -X- _ O
Purohit -X- _ O
, -X- _ O
Tri -X- _ O
Songz -X- _ O
, -X- _ O
Phil -X- _ O
Wang -X- _ O
, -X- _ O
and -X- _ O
Samuel -X- _ O
Weinbach -X- _ O
. -X- _ O
2021 -X- _ O
. -X- _ O

arXiv -X- _ O
preprint -X- _ O
arXiv:1905.13319 -X- _ O
. -X- _ O

Towards -X- _ O
interpretable -X- _ O
math -X- _ O
word -X- _ O
problem -X- _ O
solving -X- _ O
with -X- _ O
operation -X- _ O
- -X- _ O
based -X- _ O
formalisms -X- _ O
. -X- _ O

Mathqa -X- _ O
: -X- _ O

Aida -X- _ O
Amini -X- _ O
, -X- _ O
Saadia -X- _ O
Gabriel -X- _ O
, -X- _ O
Peter -X- _ O
Lin -X- _ O
, -X- _ O
Rik -X- _ O
KoncelKedziorski -X- _ O
, -X- _ O
Yejin -X- _ O
Choi -X- _ O
, -X- _ O
and -X- _ O
Hannaneh -X- _ O
Hajishirzi -X- _ O
. -X- _ O
2019 -X- _ O
. -X- _ O

AMiner -X- _ O
. -X- _ O
https://www.aminer.org/. -X- _ O

arXiv -X- _ O
preprint -X- _ O
arXiv:1904.03323 -X- _ O
. -X- _ O

Publicly -X- _ O
available -X- _ O
clinical -X- _ O
bert -X- _ O
embeddings -X- _ O
. -X- _ O

References -X- _ O
Emily -X- _ O
Alsentzer -X- _ O
, -X- _ O
John -X- _ O
R -X- _ O
Murphy -X- _ O
, -X- _ O
Willie -X- _ O
Boag -X- _ O
, -X- _ O
WeiHung -X- _ O
Weng -X- _ O
, -X- _ O
Di -X- _ O
Jin -X- _ O
, -X- _ O
Tristan -X- _ O
Naumann -X- _ O
, -X- _ O
and -X- _ O
Matthew -X- _ O
McDermott -X- _ O
. -X- _ O
2019 -X- _ O
. -X- _ O

167 -X- _ O

We -X- _ O
rigorously -X- _ O
analyzed -X- _ O
model -X- _ O
performance -X- _ O
on -X- _ O
15 -X- _ O
+ -X- _ O
indomain -X- _ O
and -X- _ O
out -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
domain -X- _ O
tasks -X- _ O
. -X- _ O

We -X- _ O
pretrained -X- _ O
and -X- _ O
released -X- _ O
25 -X- _ O
+ -X- _ O
foundation -X- _ O
models -X- _ O
for -X- _ O
chemistry -X- _ O
. -X- _ O

6 -X- _ O
Conclusions -X- _ O
In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
collected -X- _ O
and -X- _ O
released -X- _ O
0.67 -X- _ O
TB -X- _ O
of -X- _ O
research -X- _ O
publication -X- _ O
data -X- _ O
collected -X- _ O
across -X- _ O
10 -X- _ O
+ -X- _ O
sources -X- _ O
for -X- _ O
chemistry -X- _ O
. -X- _ O

This -X- _ O
suggests -X- _ O
the -X- _ O
importance -X- _ O
of -X- _ O
compute -X- _ O
budget -X- _ O
required -X- _ O
in -X- _ O
scaling -X- _ O
foundation -X- _ O
models -X- _ O
. -X- _ O

With -X- _ O
such -X- _ O
compute -X- _ O
budget -X- _ O
, -X- _ O
small -X- _ O
( -X- _ O
S -X- _ O
) -X- _ O
models -X- _ O
only -X- _ O
outperforms -X- _ O
the -X- _ O
XL -X- _ O
model -X- _ O
in -X- _ O
21 -X- _ O
% -X- _ O
in -X- _ O
- -X- _ O
domain -X- _ O
and -X- _ O
34 -X- _ O
% -X- _ O
out -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
domain -X- _ O
evaluation -X- _ O
tasks -X- _ O
. -X- _ O

5.6 -X- _ O
Training -X- _ O
Efficiency -X- _ O
We -X- _ O
use -X- _ O
several -X- _ O
dimensions -X- _ O
to -X- _ O
describe -X- _ O
the -X- _ O
training -X- _ B-MetricName
efficiency -X- _ I-MetricName
, -X- _ O
i.e. -X- _ O
, -X- _ O
# -X- _ O
FLOPs -X- _ B-MetricName
, -X- _ O
throughput -X- _ B-MetricName
( -X- _ O
speed -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
memory -X- _ B-MetricName
. -X- _ O

The -X- _ O
smallest -X- _ O
( -X- _ O
S -X- _ O
) -X- _ O
model -X- _ O
has -X- _ O
59 -X- _ B-MetricValue
% -X- _ I-MetricValue
FLOPs -X- _ B-MetricName
of -X- _ O
the -X- _ O
largest -X- _ O
( -X- _ O
XL -X- _ O
) -X- _ O
model -X- _ O
, -X- _ O
twice -X- _ O
the -X- _ O
speed -X- _ B-MetricName
( -X- _ O
steps -X- _ O
/ -X- _ O
s -X- _ O
) -X- _ O
, -X- _ O
32 -X- _ B-MetricValue
% -X- _ I-MetricValue
per -X- _ O
device -X- _ O
GPU -X- _ B-MetricName
memory -X- _ I-MetricName
savings -X- _ I-MetricName
, -X- _ O
and -X- _ O
76 -X- _ B-MetricValue
% -X- _ I-MetricValue
total -X- _ B-MetricName
parameter -X- _ I-MetricName
savings -X- _ I-MetricName
( -X- _ O
see -X- _ O
Figure -X- _ O
4 -X- _ O
) -X- _ O
. -X- _ O

across -X- _ O
the -X- _ O
four -X- _ O
model -X- _ B-HyperparameterName
sizes -X- _ I-HyperparameterName
described -X- _ O
in -X- _ O
the -X- _ O
Table -X- _ O
2 -X- _ O
. -X- _ O

We -X- _ O
compare -X- _ O
these -X- _ O
compute -X- _ O
dimensions -X- _ O
( -X- _ O
a -X- _ O
) -X- _ O
GPU -X- _ O
computation -X- _ O
in -X- _ O
# -X- _ O
Floating -X- _ O
Point -X- _ O
Operations -X- _ O
( -X- _ O
b -X- _ O
) -X- _ O
GPU -X- _ O
Memory -X- _ O
Allocation -X- _ O
Figure -X- _ O
4 -X- _ O
: -X- _ O
GPU -X- _ O
system -X- _ O
performance -X- _ O
during -X- _ O
pretraining -X- _ O
. -X- _ O

This -X- _ O
initialization -X- _ O
may -X- _ O
diverge -X- _ O
the -X- _ O
model -X- _ O
in -X- _ O
the -X- _ O
optimization -X- _ O
process -X- _ O
that -X- _ O
may -X- _ O
not -X- _ O
be -X- _ O
recovered -X- _ O
. -X- _ O

On -X- _ O
the -X- _ O
other -X- _ O
hand -X- _ O
, -X- _ O
the -X- _ O
tuned -X- _ O
model -X- _ O
starts -X- _ O
with -X- _ O
the -X- _ O
suboptimal -X- _ O
initialization -X- _ O
from -X- _ O
the -X- _ O
general -X- _ O
- -X- _ O
domain -X- _ O
language -X- _ O
model -X- _ O
( -X- _ O
Gu -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O

As -X- _ O
the -X- _ O
tuned -X- _ O
model -X- _ O
uses -X- _ O
the -X- _ O
original -X- _ O
GPT-2 -X- _ B-MethodName
vocabulary -X- _ O
, -X- _ O
it -X- _ O
must -X- _ O
use -X- _ O
the -X- _ O
fragmented -X- _ O
general -X- _ O
subwords -X- _ O
to -X- _ O
tokenize -X- _ O
the -X- _ O
chemistry -X- _ O
terms -X- _ O
available -X- _ O
in -X- _ O
our -X- _ O
corpora -X- _ O
. -X- _ O

There -X- _ O
are -X- _ O
several -X- _ O
factors -X- _ O
in -X- _ O
the -X- _ O
continual -X- _ O
pretraining -X- _ O
that -X- _ O
may -X- _ O
contribute -X- _ O
to -X- _ O
this -X- _ O
. -X- _ O

For -X- _ O
example -X- _ O
, -X- _ O
the -X- _ O
tuned -X- _ O
model -X- _ O
records -X- _ O
6x -X- _ O
performance -X- _ O
drop -X- _ O
in -X- _ O
the -X- _ O
Wikitext -X- _ B-DatasetName
compared -X- _ O
to -X- _ O
the -X- _ O
best -X- _ O
performing -X- _ O
model -X- _ O
. -X- _ O

Second -X- _ O
, -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
models -X- _ O
have -X- _ O
a -X- _ O
significant -X- _ O
performance -X- _ O
drop -X- _ O
in -X- _ O
the -X- _ O
general -X- _ O
language -X- _ B-TaskName
modeling -X- _ I-TaskName
tasks -X- _ O
( -X- _ O
Lambada -X- _ B-TaskName
and -X- _ O
Wikitext -X- _ B-TaskName
) -X- _ O
. -X- _ O

HT -X- _ B-DatasetName
- -X- _ I-DatasetName
CC -X- _ I-DatasetName
is -X- _ O
the -X- _ O
only -X- _ O
in -X- _ O
- -X- _ O
domain -X- _ O
task -X- _ O
that -X- _ O
the -X- _ O
tuned -X- _ O
model -X- _ O
outperforms -X- _ O
the -X- _ O
rest -X- _ O
of -X- _ O
models -X- _ O
, -X- _ O
yet -X- _ O
fails -X- _ O
to -X- _ O
outperform -X- _ O
the -X- _ O
best -X- _ O
performing -X- _ O
model -X- _ O
trained -X- _ O
from -X- _ O
scratch -X- _ O
. -X- _ O

First -X- _ O
, -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
models -X- _ O
fall -X- _ O
behind -X- _ O
other -X- _ O
baselines -X- _ O
in -X- _ O
a -X- _ O
majority -X- _ O
of -X- _ O
in -X- _ O
- -X- _ O
domain -X- _ O
tasks -X- _ O
. -X- _ O

We -X- _ O
have -X- _ O
two -X- _ O
main -X- _ O
observations -X- _ O
from -X- _ O
this -X- _ O
experiment -X- _ O
. -X- _ O

We -X- _ O
report -X- _ O
the -X- _ O
zero -X- _ O
- -X- _ O
shot -X- _ O
performance -X- _ O
of -X- _ O
the -X- _ O
tuned -X- _ O
model -X- _ O
across -X- _ O
in -X- _ O
- -X- _ O
domain -X- _ O
( -X- _ O
Table -X- _ O
4 -X- _ O
) -X- _ O
and -X- _ O
out -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
domain -X- _ O
( -X- _ O
Table -X- _ O
5 -X- _ O
) -X- _ O
tasks -X- _ O
. -X- _ O

Pretraining -X- _ O
In -X- _ O
this -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
test -X- _ O
whether -X- _ O
the -X- _ O
continual -X- _ O
pretraining -X- _ O
of -X- _ O
a -X- _ O
base -X- _ O
GPT -X- _ O
model -X- _ O
with -X- _ O
additional -X- _ O
domain -X- _ O
- -X- _ O
specific -X- _ O
data -X- _ O
is -X- _ O
helpful -X- _ O
in -X- _ O
the -X- _ O
downstream -X- _ O
task -X- _ O
performance -X- _ O
. -X- _ O

5.5 -X- _ O
Continual -X- _ O
vs. -X- _ O
From -X- _ O
Scratch -X- _ O

vestigate -X- _ O
other -X- _ O
confounding -X- _ O
factors -X- _ O
that -X- _ O
may -X- _ O
contribute -X- _ O
to -X- _ O
this -X- _ O
performance -X- _ O
patterns -X- _ O
. -X- _ O

We -X- _ O
repeat -X- _ O
the -X- _ O
process -X- _ O
in -X- _ O
a -X- _ O
randomly -X- _ O
- -X- _ O
ordered -X- _ O
corpus -X- _ O
for -X- _ O
comparison -X- _ O
, -X- _ O
recording -X- _ O
model -X- _ O
checkpoints -X- _ O
after -X- _ O
performing -X- _ O
continual -X- _ O
pretraining -X- _ O
on -X- _ O
each -X- _ O
data -X- _ O
subset -X- _ O
. -X- _ O

We -X- _ O
align -X- _ O
publications -X- _ O
in -X- _ O
the -X- _ O
MAG -X- _ O
corpus -X- _ O
by -X- _ O
year -X- _ O
and -X- _ O
split -X- _ O
them -X- _ O
into -X- _ O
ten -X- _ O
equal -X- _ O
subsets -X- _ O
. -X- _ O

( -X- _ O
a -X- _ O
) -X- _ O
Random -X- _ O
Order -X- _ O
( -X- _ O
b -X- _ O
) -X- _ O
Temporal -X- _ O
Order -X- _ O
Figure -X- _ O
3 -X- _ O
: -X- _ O
The -X- _ O
effect -X- _ O
of -X- _ O
temporal -X- _ O
order -X- _ O
of -X- _ O
publications -X- _ O
during -X- _ O
pretraining -X- _ O
. -X- _ O

Future -X- _ O
work -X- _ O
will -X- _ O
in -X- _ O
166 -X- _ O

This -X- _ O
may -X- _ O
be -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
catastrophic -X- _ O
forgetting -X- _ O
prevalent -X- _ O
in -X- _ O
continual -X- _ O
learning -X- _ O
( -X- _ O
Ramasesh -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O

On -X- _ O
the -X- _ O
other -X- _ O
hand -X- _ O
, -X- _ O
there -X- _ O
is -X- _ O
a -X- _ O
performance -X- _ O
drop -X- _ O
in -X- _ O
the -X- _ O
BoolQ -X- _ B-DatasetName
and -X- _ O
WSC -X- _ B-DatasetName
over -X- _ O
time -X- _ O
. -X- _ O

For -X- _ O
example -X- _ O
, -X- _ O
a -X- _ O
slight -X- _ O
performance -X- _ O
increase -X- _ O
in -X- _ O
the -X- _ O
PIQA -X- _ B-DatasetName
, -X- _ O
CB -X- _ B-DatasetName
, -X- _ O
PubMedQA -X- _ B-DatasetName
, -X- _ O
and -X- _ O
WIC -X- _ B-DatasetName
over -X- _ O
time -X- _ O
with -X- _ O
the -X- _ O
models -X- _ O
trained -X- _ O
with -X- _ O
temporally -X- _ O
- -X- _ O
ordered -X- _ O
scientific -X- _ O
texts -X- _ O
. -X- _ O

There -X- _ O
are -X- _ O
mixed -X- _ O
patterns -X- _ O
in -X- _ O
performance -X- _ O
across -X- _ O
out -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
domain -X- _ O
tasks -X- _ O
. -X- _ O

When -X- _ O
the -X- _ O
model -X- _ O
was -X- _ O
pretrained -X- _ O
with -X- _ O
random -X- _ O
- -X- _ O
ordered -X- _ O
data -X- _ O
subsets -X- _ O
, -X- _ O
we -X- _ O
observe -X- _ O
only -X- _ O
a -X- _ O
slight -X- _ O
( -X- _ O
< -X- _ O
1 -X- _ B-MetricValue
% -X- _ I-MetricValue
) -X- _ O
performance -X- _ O
increase -X- _ O
( -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
3a -X- _ O
) -X- _ O
. -X- _ O

This -X- _ O
is -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
temporal -X- _ O
order -X- _ O
of -X- _ O
the -X- _ O
knowledge -X- _ O
acquired -X- _ O
by -X- _ O
the -X- _ O
model -X- _ O
. -X- _ O

Similarly -X- _ O
, -X- _ O
ARC -X- _ B-DatasetName
- -X- _ I-DatasetName
E -X- _ I-DatasetName
accuracy -X- _ B-MetricName
improves -X- _ O
from -X- _ O
0.43 -X- _ B-MetricValue
to -X- _ O
0.45 -X- _ B-MetricValue
. -X- _ O

For -X- _ O
example -X- _ O
, -X- _ O
SciQ -X- _ B-DatasetName
accuracy -X- _ B-MetricName
improves -X- _ O
from -X- _ O
0.64 -X- _ B-MetricValue
to -X- _ O
0.73 -X- _ B-MetricValue
from -X- _ O
the -X- _ O
base -X- _ O
model -X- _ O
checkpoint -X- _ O
to -X- _ O
the -X- _ O
final -X- _ O
model -X- _ O
checkpoint -X- _ O
. -X- _ O

First -X- _ O
, -X- _ O
SciQ -X- _ B-DatasetName
and -X- _ O
ARCE -X- _ B-DatasetName
zero -X- _ O
- -X- _ O
shot -X- _ O
task -X- _ O
performances -X- _ O
improve -X- _ O
over -X- _ O
time -X- _ O
with -X- _ O
the -X- _ O
models -X- _ O
trained -X- _ O
with -X- _ O
temporally -X- _ O
- -X- _ O
ordered -X- _ O
scientific -X- _ O
texts -X- _ O
( -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
3b -X- _ O
) -X- _ O
. -X- _ O

There -X- _ O
are -X- _ O
two -X- _ O
key -X- _ O
findings -X- _ O
. -X- _ O

Figure -X- _ O
3 -X- _ O
shows -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
model -X- _ O
checkpoints -X- _ O
across -X- _ O
in -X- _ O
- -X- _ O
domain -X- _ O
and -X- _ O
out -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
domain -X- _ O
tasks -X- _ O
. -X- _ O

We -X- _ O
train -X- _ O
the -X- _ O
initial -X- _ O
model -X- _ O
for -X- _ O
150 -X- _ B-HyperparameterValue
K -X- _ I-HyperparameterValue
steps -X- _ B-HyperparameterName
and -X- _ O
each -X- _ O
subsequent -X- _ O
model -X- _ O
for -X- _ O
10 -X- _ B-HyperparameterValue
K -X- _ I-HyperparameterValue
steps -X- _ B-HyperparameterName
with -X- _ O
additional -X- _ O
data -X- _ O
. -X- _ O

For -X- _ O
example -X- _ O
, -X- _ O
in -X- _ O
the -X- _ O
temporally -X- _ O
- -X- _ O
aligned -X- _ O
experiments -X- _ O
, -X- _ O
we -X- _ O
first -X- _ O
pretrain -X- _ O
a -X- _ O
model -X- _ O
with -X- _ O
3.4 -X- _ O
M -X- _ O
( -X- _ O
10 -X- _ O
% -X- _ O
) -X- _ O
articles -X- _ O
from -X- _ O
before -X- _ O
1978 -X- _ O
, -X- _ O
and -X- _ O
then -X- _ O
use -X- _ O
it -X- _ O
as -X- _ O
the -X- _ O
base -X- _ O
model -X- _ O
to -X- _ O
continue -X- _ O
pretraining -X- _ O
with -X- _ O
another -X- _ O
3.4 -X- _ O
M -X- _ O
( -X- _ O
10 -X- _ O
% -X- _ O
) -X- _ O
articles -X- _ O
from -X- _ O
between -X- _ O
1978 -X- _ O
and -X- _ O
1989 -X- _ O
. -X- _ O

We -X- _ O
continue -X- _ O
pretraining -X- _ O
a -X- _ O
base -X- _ O
medium -X- _ O
( -X- _ O
M -X- _ O
) -X- _ O
sized -X- _ O
model -X- _ O
iteratively -X- _ O
with -X- _ O
the -X- _ O
subsets -X- _ O
in -X- _ O
the -X- _ O
order -X- _ O
they -X- _ O
appeared -X- _ O
in -X- _ O
the -X- _ O
respective -X- _ O
data -X- _ O
variant -X- _ O
. -X- _ O

For -X- _ O
this -X- _ O
experiment -X- _ O
, -X- _ O
we -X- _ O
maintain -X- _ O
two -X- _ O
variants -X- _ O
of -X- _ O
the -X- _ O
MAG -X- _ O
dataset -X- _ O
with -X- _ O
random -X- _ O
- -X- _ O
ordered -X- _ O
and -X- _ O
temporal -X- _ O
- -X- _ O
ordered -X- _ O
articles -X- _ O
, -X- _ O
splitting -X- _ O
each -X- _ O
into -X- _ O
ten -X- _ O
equal -X- _ O
subsets -X- _ O
. -X- _ O

Third -X- _ O
, -X- _ O
we -X- _ O
compare -X- _ O
model -X- _ O
performance -X- _ O
trained -X- _ O
with -X- _ O
abstracts -X- _ O
vs. -X- _ O
full -X- _ O
texts -X- _ O
in -X- _ O
the -X- _ O
HT -X- _ B-DatasetName
task -X- _ O
and -X- _ O
see -X- _ O
that -X- _ O
the -X- _ O
best -X- _ O
accuracy -X- _ O
is -X- _ O
achieved -X- _ O
using -X- _ O
the -X- _ O
MAG -X- _ O
and -X- _ O
S2ORC -X- _ O
datasets -X- _ O
rather -X- _ O
than -X- _ O
the -X- _ O
combined -X- _ O
abstracts -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
test -X- _ O
how -X- _ O
continual -X- _ O
pretraining -X- _ O
on -X- _ O
temporal -X- _ O
- -X- _ O
aligned -X- _ O
scientific -X- _ O
publications -X- _ O
impacts -X- _ O
downstream -X- _ O
performance -X- _ O
. -X- _ O

5.4 -X- _ O
Temporal -X- _ O
Effect -X- _ O
Scientific -X- _ O
knowledge -X- _ O
evolves -X- _ O
over -X- _ O
time -X- _ O
reflecting -X- _ O
new -X- _ O
research -X- _ O
ideas -X- _ O
, -X- _ O
innovations -X- _ O
, -X- _ O
and -X- _ O
findings -X- _ O
. -X- _ O

Thus -X- _ O
, -X- _ O
expanding -X- _ O
full -X- _ O
text -X- _ O
coverage -X- _ O
may -X- _ O
improve -X- _ O
out -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
domain -X- _ O
task -X- _ O
generalization -X- _ O
. -X- _ O

This -X- _ O
performance -X- _ O
difference -X- _ O
may -X- _ O
be -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
more -X- _ O
expressive -X- _ O
and -X- _ O
diverse -X- _ O
language -X- _ O
presented -X- _ O
in -X- _ O
the -X- _ O
full -X- _ O
texts -X- _ O
than -X- _ O
in -X- _ O
the -X- _ O
abstracts -X- _ O
. -X- _ O

Finally -X- _ O
, -X- _ O
combined -X- _ O
full -X- _ O
text -X- _ O
model -X- _ O
performs -X- _ O
better -X- _ O
than -X- _ O
the -X- _ O
model -X- _ O
trained -X- _ O
with -X- _ O
the -X- _ O
abstracts -X- _ O
in -X- _ O
all -X- _ O
outof -X- _ O
- -X- _ O
domain -X- _ O
tasks -X- _ O
except -X- _ O
PIQA -X- _ B-TaskName
. -X- _ O

This -X- _ O
suggests -X- _ O
the -X- _ O
importance -X- _ O
of -X- _ O
contextual -X- _ O
knowledge -X- _ O
provided -X- _ O
by -X- _ O
different -X- _ O
data -X- _ O
sources -X- _ O
. -X- _ O

We -X- _ O
believe -X- _ O
the -X- _ O
diversity -X- _ O
of -X- _ O
scientific -X- _ O
knowledge -X- _ O
provided -X- _ O
from -X- _ O
the -X- _ O
abstract -X- _ O
data -X- _ O
is -X- _ O
useful -X- _ O
since -X- _ O
SciQ -X- _ B-DatasetName
questions -X- _ O
span -X- _ O
biology -X- _ O
, -X- _ O
chemistry -X- _ O
, -X- _ O
earth -X- _ O
science -X- _ O
, -X- _ O
and -X- _ O
physics -X- _ O
. -X- _ O

Second -X- _ O
, -X- _ O
the -X- _ O
model -X- _ O
trained -X- _ O
with -X- _ O
the -X- _ O
combined -X- _ O
abstracts -X- _ O
achieves -X- _ O
the -X- _ O
second -X- _ O
best -X- _ O
accuracy -X- _ B-MetricName
( -X- _ O
0.83 -X- _ B-MetricValue
in -X- _ O
comparison -X- _ O
to -X- _ O
0.79 -X- _ B-MetricValue
for -X- _ O
the -X- _ O
full -X- _ O
text -X- _ O
model -X- _ O
) -X- _ O
in -X- _ O
SciQ. -X- _ B-DatasetName
Some -X- _ O
of -X- _ O
the -X- _ O
models -X- _ O
pretrained -X- _ O
on -X- _ O
individual -X- _ O
abstract -X- _ O
data -X- _ O
achieve -X- _ O
comparable -X- _ O
performance -X- _ O
in -X- _ O
SciQ -X- _ B-DatasetName
, -X- _ O
e.g. -X- _ O
, -X- _ O
MAG -X- _ B-MethodName
and -X- _ O
AMiner -X- _ B-MethodName
models -X- _ O
achieve -X- _ O
0.8 -X- _ B-MetricValue
and -X- _ O
0.78 -X- _ B-MetricValue
accuracy -X- _ B-MetricName
, -X- _ O
respectively -X- _ O
. -X- _ O

There -X- _ O
are -X- _ O
might -X- _ O
be -X- _ O
several -X- _ O
factors -X- _ O
that -X- _ O
contribute -X- _ O
to -X- _ O
this -X- _ O
, -X- _ O
but -X- _ O
one -X- _ O
may -X- _ O
be -X- _ O
the -X- _ O
focused -X- _ O
language -X- _ O
in -X- _ O
abstracts -X- _ O
. -X- _ O

First -X- _ O
, -X- _ O
the -X- _ O
XL -X- _ O
models -X- _ O
trained -X- _ O
with -X- _ O
the -X- _ O
combined -X- _ O
abstract -X- _ O
dataset -X- _ O
achieve -X- _ O
the -X- _ O
lowest -X- _ O
perplexity -X- _ B-MetricName
score -X- _ O
( -X- _ O
22.77 -X- _ B-MetricValue
) -X- _ O
on -X- _ O
the -X- _ O
Pile -X- _ B-DatasetName
– -X- _ O
a -X- _ O
45 -X- _ B-MetricValue
% -X- _ I-MetricValue
performance -X- _ O
advantage -X- _ O
over -X- _ O
the -X- _ O
full -X- _ O
text -X- _ O
version -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
analyze -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
models -X- _ O
trained -X- _ O
on -X- _ O
paper -X- _ O
abstracts -X- _ O
versus -X- _ O
full -X- _ O
texts -X- _ O
. -X- _ O

5.3 -X- _ O
Diversity -X- _ O
Effect -X- _ O
While -X- _ O
abstracts -X- _ O
often -X- _ O
provide -X- _ O
a -X- _ O
summary -X- _ O
of -X- _ O
scientific -X- _ O
publications -X- _ O
, -X- _ O
the -X- _ O
full -X- _ O
text -X- _ O
contains -X- _ O
more -X- _ O
details -X- _ O
. -X- _ O

However -X- _ O
, -X- _ O
model -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
significantly -X- _ O
contributes -X- _ O
to -X- _ O
the -X- _ O
task -X- _ O
performance -X- _ O
. -X- _ O

We -X- _ O
suggest -X- _ O
that -X- _ O
pretraining -X- _ O
performance -X- _ O
may -X- _ O
not -X- _ O
be -X- _ O
the -X- _ O
ideal -X- _ O
indicator -X- _ O
to -X- _ O
speculate -X- _ O
the -X- _ O
overall -X- _ O
downstream -X- _ O
task -X- _ O
performance -X- _ O
, -X- _ O
especially -X- _ O
in -X- _ O
the -X- _ O
zero -X- _ O
- -X- _ O
shot -X- _ O
setting -X- _ O
. -X- _ O

However -X- _ O
, -X- _ O
there -X- _ O
is -X- _ O
no -X- _ O
clear -X- _ O
relationship -X- _ O
between -X- _ O
the -X- _ O
task -X- _ O
performance -X- _ O
and -X- _ O
the -X- _ O
model -X- _ B-HyperparameterName
sizes -X- _ I-HyperparameterName
in -X- _ O
the -X- _ O
rest -X- _ O
of -X- _ O
benchmark -X- _ O
datasets -X- _ O
. -X- _ O

Third -X- _ O
, -X- _ O
we -X- _ O
find -X- _ O
that -X- _ O
zero -X- _ O
- -X- _ O
shot -X- _ O
task -X- _ O
performance -X- _ O
in -X- _ O
SciQ -X- _ B-DatasetName
, -X- _ O
HT -X- _ B-DatasetName
- -X- _ I-DatasetName
CC -X- _ I-DatasetName
and -X- _ O
ARC -X- _ B-DatasetName
- -X- _ I-DatasetName
E -X- _ I-DatasetName
increases -X- _ O
as -X- _ O
we -X- _ O
increase -X- _ O
the -X- _ O
model -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
( -X- _ O
see -X- _ O
Table -X- _ O
5 -X- _ O
) -X- _ O
. -X- _ O

We -X- _ O
believe -X- _ O
that -X- _ O
the -X- _ O
XL -X- _ B-MethodName
( -X- _ I-MethodName
4x -X- _ I-MethodName
) -X- _ I-MethodName
model -X- _ O
can -X- _ O
reach -X- _ O
the -X- _ O
similar -X- _ O
perplexity -X- _ B-MetricName
values -X- _ O
when -X- _ O
trained -X- _ O
for -X- _ O
this -X- _ O
data -X- _ O
scale -X- _ O
. -X- _ O

We -X- _ O
note -X- _ O
that -X- _ O
the -X- _ O
baseline -X- _ O
models -X- _ O
( -X- _ O
Radford -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
were -X- _ O
trained -X- _ O
with -X- _ O
4x -X- _ O
larger -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
( -X- _ O
total -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
512 -X- _ B-HyperparameterValue
) -X- _ O
than -X- _ O
what -X- _ O
used -X- _ O
in -X- _ O
XL -X- _ B-MethodName
( -X- _ I-MethodName
4x -X- _ I-MethodName
) -X- _ I-MethodName
model -X- _ O
. -X- _ O

This -X- _ O
experiment -X- _ O
highlights -X- _ O
the -X- _ O
importance -X- _ O
of -X- _ O
training -X- _ O
models -X- _ O
with -X- _ O
larger -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
. -X- _ O

The -X- _ O
same -X- _ O
model -X- _ O
also -X- _ O
achieves -X- _ O
the -X- _ O
best -X- _ O
SciQ -X- _ B-DatasetName
performance -X- _ O
with -X- _ O
0.84 -X- _ B-MetricValue
accuracy -X- _ B-MetricName
and -X- _ O
comparable -X- _ O
in -X- _ O
other -X- _ O
tasks -X- _ O
performance -X- _ O
with -X- _ O
the -X- _ O
XL -X- _ O
model -X- _ O
. -X- _ O

As -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
4 -X- _ O
, -X- _ O
larger -X- _ O
models -X- _ O
perform -X- _ O
well -X- _ O
on -X- _ O
these -X- _ O
language -X- _ O
modeling -X- _ O
tasks -X- _ O
. -X- _ O

Second -X- _ O
, -X- _ O
we -X- _ O
noticed -X- _ O
that -X- _ O
the -X- _ O
XL -X- _ B-MethodName
( -X- _ I-MethodName
4x -X- _ I-MethodName
) -X- _ I-MethodName
model -X- _ O
trained -X- _ O
for -X- _ O
more -X- _ O
tokens -X- _ O
performs -X- _ O
significantly -X- _ O
better -X- _ O
than -X- _ O
the -X- _ O
similar -X- _ O
sized -X- _ O
XL -X- _ O
model -X- _ O
. -X- _ O

Specifically -X- _ O
, -X- _ O
XL -X- _ B-MethodName
( -X- _ I-MethodName
4x -X- _ I-MethodName
) -X- _ I-MethodName
model -X- _ O
was -X- _ O
trained -X- _ O
with -X- _ O
128 -X- _ B-HyperparameterValue
total -X- _ O
batch -X- _ B-HyperparameterName
165 -X- _ O

XL -X- _ B-MethodName
( -X- _ I-MethodName
4x -X- _ I-MethodName
) -X- _ I-MethodName
model -X- _ O
achieves -X- _ O
the -X- _ O
lowest -X- _ O
Lambada -X- _ B-DatasetName
and -X- _ O
WikiText -X- _ B-DatasetName
perplexity -X- _ B-MetricName
values -X- _ O
across -X- _ O
all -X- _ O
our -X- _ O
models -X- _ O
trained -X- _ O
from -X- _ O
scratch -X- _ O
( -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
5 -X- _ O
) -X- _ O
. -X- _ O

size -X- _ O
compared -X- _ O
to -X- _ O
the -X- _ O
32 -X- _ B-HyperparameterValue
total -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
used -X- _ O
in -X- _ O
XL -X- _ O
model -X- _ O
. -X- _ O

It -X- _ O
is -X- _ O
i -X- _ O
m -X- _ O
portant -X- _ O
to -X- _ O
note -X- _ O
that -X- _ O
we -X- _ O
exclude -X- _ O
PubMed -X- _ O
Abstracts -X- _ O
in -X- _ O
the -X- _ O
individual -X- _ O
data -X- _ O
collection -X- _ O
to -X- _ O
avoid -X- _ O
potential -X- _ O
contamination -X- _ O
between -X- _ O
the -X- _ O
training -X- _ O
and -X- _ O
Pile -X- _ O
testing -X- _ O
data -X- _ O
. -X- _ O

This -X- _ O
may -X- _ O
be -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
models -X- _ O
capturing -X- _ O
scientific -X- _ O
language -X- _ O
better -X- _ O
than -X- _ O
general -X- _ O
language -X- _ O
. -X- _ O

There -X- _ O
is -X- _ O
a -X- _ O
48 -X- _ B-MetricValue
% -X- _ I-MetricValue
performance -X- _ O
advantage -X- _ O
in -X- _ O
this -X- _ O
task -X- _ O
over -X- _ O
the -X- _ O
best -X- _ O
performing -X- _ O
baseline -X- _ O
GPT-2 -X- _ B-MethodName
model -X- _ O
. -X- _ O

First -X- _ O
, -X- _ O
we -X- _ O
find -X- _ O
that -X- _ O
the -X- _ O
models -X- _ O
perform -X- _ O
considerably -X- _ O
well -X- _ O
on -X- _ O
Pile -X- _ B-DatasetName
in -X- _ O
comparison -X- _ O
to -X- _ O
the -X- _ O
Lambada -X- _ B-DatasetName
or -X- _ O
WikiText -X- _ B-DatasetName
. -X- _ O

Analyzing -X- _ O
downstream -X- _ O
task -X- _ O
performance -X- _ O
Can -X- _ O
we -X- _ O
speculate -X- _ O
downstream -X- _ O
task -X- _ O
performance -X- _ O
of -X- _ O
a -X- _ O
model -X- _ O
from -X- _ O
the -X- _ O
pretraining -X- _ O
performance -X- _ O
? -X- _ O

Figure -X- _ O
2 -X- _ O
: -X- _ O
Distribution -X- _ O
of -X- _ O
validation -X- _ O
loss -X- _ O
by -X- _ O
model -X- _ O
size -X- _ O
: -X- _ O
performance -X- _ O
improves -X- _ O
as -X- _ O
the -X- _ O
model -X- _ O
size -X- _ O
increases -X- _ O
. -X- _ O

This -X- _ O
observation -X- _ O
illustrates -X- _ O
the -X- _ O
relationship -X- _ O
between -X- _ O
model -X- _ O
performance -X- _ O
( -X- _ O
as -X- _ O
measured -X- _ O
by -X- _ O
the -X- _ O
upstream -X- _ O
cross -X- _ O
entropy -X- _ O
loss -X- _ O
) -X- _ O
and -X- _ O
model -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
, -X- _ O
confirming -X- _ O
( -X- _ O
Kaplan -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O

Larger -X- _ O
models -X- _ O
reach -X- _ O
a -X- _ O
given -X- _ O
loss -X- _ O
value -X- _ O
in -X- _ O
a -X- _ O
higher -X- _ O
rate -X- _ O
than -X- _ O
the -X- _ O
smaller -X- _ O
models -X- _ O
. -X- _ O

We -X- _ O
find -X- _ O
that -X- _ O
the -X- _ O
cross -X- _ O
entropy -X- _ O
loss -X- _ O
decreases -X- _ O
as -X- _ O
we -X- _ O
increase -X- _ O
the -X- _ O
model -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
( -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
2 -X- _ O
) -X- _ O
. -X- _ O

This -X- _ O
measure -X- _ O
will -X- _ O
be -X- _ O
averaged -X- _ O
over -X- _ O
the -X- _ O
2048 -X- _ O
- -X- _ O
token -X- _ O
context -X- _ O
. -X- _ O

Model -X- _ O
Baseline -X- _ O
AMiner -X- _ B-MethodName
CORE -X- _ B-MethodName
MAG -X- _ B-MethodName
PubMed -X- _ B-MethodName
- -X- _ I-MethodName
F -X- _ I-MethodName
S2ORC -X- _ B-MethodName
WoS -X- _ B-MethodName
Combined -X- _ B-MethodName
- -X- _ I-MethodName
A -X- _ I-MethodName
Combined -X- _ B-MethodName
- -X- _ I-MethodName
F -X- _ I-MethodName
Combined -X- _ B-MethodName
- -X- _ I-MethodName
A+F -X- _ I-MethodName
Combined -X- _ B-MethodName
- -X- _ I-MethodName
A+F -X- _ I-MethodName
Size -X- _ B-HyperparameterName
S -X- _ O
M -X- _ O
L -X- _ O
XL -X- _ O
M‡ -X- _ O
S -X- _ O
M -X- _ O
L -X- _ O
XL -X- _ O
S -X- _ O
M -X- _ O
L -X- _ O
XL -X- _ O
S -X- _ O
M -X- _ O
L -X- _ O
XL -X- _ O
S -X- _ O
M -X- _ O
L -X- _ O
XL -X- _ O
S -X- _ O
M -X- _ O
L -X- _ O
XL -X- _ O
S -X- _ O
M -X- _ O
L -X- _ O
XL -X- _ O
XL -X- _ O
XL -X- _ O
XL -X- _ O
XL -X- _ O
( -X- _ O
4x -X- _ O
) -X- _ O
BoolQ -X- _ B-DatasetName
CB -X- _ B-DatasetName
WIC -X- _ B-DatasetName
WSC -X- _ B-DatasetName
MathQA -X- _ B-DatasetName
PIQA -X- _ B-DatasetName
PubMedQA -X- _ B-DatasetName
Lambada -X- _ B-DatasetName
Wikitext -X- _ B-DatasetName
0.49 -X- _ O
0.59 -X- _ O
0.60 -X- _ O
0.61 -X- _ O
0.62 -X- _ O
0.41 -X- _ O
0.40 -X- _ O
0.61 -X- _ O
0.50 -X- _ O
0.62 -X- _ O
0.62 -X- _ O
0.61 -X- _ O
0.61 -X- _ O
0.41 -X- _ O
0.38 -X- _ O
0.51 -X- _ O
0.40 -X- _ O
0.58 -X- _ O
0.61 -X- _ O
0.57 -X- _ O
0.60 -X- _ O
0.38 -X- _ O
0.38 -X- _ O
0.38 -X- _ O
0.38 -X- _ O
0.38 -X- _ O
0.38 -X- _ O
0.41 -X- _ O
0.57 -X- _ O
0.56 -X- _ O
0.62 -X- _ O
0.61 -X- _ O
0.61 -X- _ O
0.41 -X- _ O
0.43 -X- _ O
0.45 -X- _ O
0.39 -X- _ O
0.34 -X- _ O
0.39 -X- _ O
0.39 -X- _ O
0.48 -X- _ O
0.39 -X- _ O
0.41 -X- _ O
0.41 -X- _ O
0.41 -X- _ O
0.38 -X- _ O
0.23 -X- _ O
0.07 -X- _ O
0.14 -X- _ O
0.11 -X- _ O
0.41 -X- _ O
0.39 -X- _ O
0.41 -X- _ O
0.41 -X- _ O
0.41 -X- _ O
0.43 -X- _ O
0.46 -X- _ O
0.50 -X- _ O
0.39 -X- _ O
0.45 -X- _ O
0.36 -X- _ O
0.34 -X- _ O
0.16 -X- _ O
0.38 -X- _ O
0.41 -X- _ O
0.41 -X- _ O
0.49 -X- _ O
0.50 -X- _ O
0.50 -X- _ O
0.50 -X- _ O
0.50 -X- _ O
0.50 -X- _ O
0.51 -X- _ O
0.50 -X- _ O
0.50 -X- _ O
0.50 -X- _ O
0.50 -X- _ O
0.50 -X- _ O
0.50 -X- _ O
0.50 -X- _ O
0.50 -X- _ O
0.50 -X- _ O
0.51 -X- _ O
0.50 -X- _ O
0.50 -X- _ O
0.50 -X- _ O
0.50 -X- _ O
0.50 -X- _ O
0.50 -X- _ O
0.50 -X- _ O
0.50 -X- _ O
0.50 -X- _ O
0.50 -X- _ O
0.47 -X- _ O
0.50 -X- _ O
0.50 -X- _ O
0.50 -X- _ O
0.50 -X- _ O
0.50 -X- _ O
0.43 -X- _ O
0.40 -X- _ O
0.46 -X- _ O
0.50 -X- _ O
0.36 -X- _ O
0.44 -X- _ O
0.41 -X- _ O
0.47 -X- _ O
0.37 -X- _ O
0.37 -X- _ O
0.37 -X- _ O
0.37 -X- _ O
0.37 -X- _ O
0.40 -X- _ O
0.37 -X- _ O
0.35 -X- _ O
0.62 -X- _ O
0.45 -X- _ O
0.38 -X- _ O
0.38 -X- _ O
0.39 -X- _ O
0.63 -X- _ O
0.63 -X- _ O
0.63 -X- _ O
0.63 -X- _ O
0.63 -X- _ O
0.63 -X- _ O
0.54 -X- _ O
0.37 -X- _ O
0.37 -X- _ O
0.37 -X- _ O
0.39 -X- _ O
0.37 -X- _ O
0.21 -X- _ O
0.23 -X- _ O
0.23 -X- _ O
0.24 -X- _ O
0.20 -X- _ O
0.22 -X- _ O
0.21 -X- _ O
0.22 -X- _ O
0.21 -X- _ O
0.20 -X- _ O
0.21 -X- _ O
0.21 -X- _ O
0.22 -X- _ O
0.21 -X- _ O
0.21 -X- _ O
0.22 -X- _ O
0.22 -X- _ O
0.21 -X- _ O
0.20 -X- _ O
0.21 -X- _ O
0.22 -X- _ O
0.20 -X- _ O
0.22 -X- _ O
0.21 -X- _ O
0.20 -X- _ O
0.21 -X- _ O
0.19 -X- _ O
0.21 -X- _ O
0.20 -X- _ O
0.21 -X- _ O
0.22 -X- _ O
0.23 -X- _ O
0.24 -X- _ O
0.63 -X- _ O
0.68 -X- _ O
0.70 -X- _ O
0.71 -X- _ O
0.55 -X- _ O
0.56 -X- _ O
0.57 -X- _ O
0.58 -X- _ O
0.58 -X- _ O
0.55 -X- _ O
0.56 -X- _ O
0.57 -X- _ O
0.58 -X- _ O
0.56 -X- _ O
0.57 -X- _ O
0.59 -X- _ O
0.59 -X- _ O
0.57 -X- _ O
0.58 -X- _ O
0.59 -X- _ O
0.59 -X- _ O
0.57 -X- _ O
0.56 -X- _ O
0.56 -X- _ O
0.56 -X- _ O
0.55 -X- _ O
0.54 -X- _ O
0.56 -X- _ O
0.55 -X- _ O
0.60 -X- _ O
0.57 -X- _ O
0.59 -X- _ O
0.60 -X- _ O
0.44 -X- _ O
0.53 -X- _ O
0.54 -X- _ O
0.59 -X- _ O
0.55 -X- _ O
0.46 -X- _ O
0.43 -X- _ O
0.36 -X- _ O
0.43 -X- _ O
0.55 -X- _ O
0.55 -X- _ O
0.51 -X- _ O
0.45 -X- _ O
0.43 -X- _ O
0.41 -X- _ O
0.39 -X- _ O
0.34 -X- _ O
0.54 -X- _ O
0.49 -X- _ O
0.42 -X- _ O
0.49 -X- _ O
0.34 -X- _ O
0.34 -X- _ O
0.34 -X- _ O
0.33 -X- _ O
0.34 -X- _ O
0.34 -X- _ O
0.42 -X- _ O
0.56 -X- _ O
0.50 -X- _ O
0.55 -X- _ O
0.48 -X- _ O
0.56 -X- _ O
40.06 -X- _ O
18.25 -X- _ O
12.97 -X- _ O
10.63 -X- _ O
2834.51 -X- _ O
2825.84 -X- _ O
1802.35 -X- _ O
661.81 -X- _ O
786.22 -X- _ O
671.43 -X- _ O
273.06 -X- _ O
173.15 -X- _ O
79.95 -X- _ O
1142.83 -X- _ O
628.72 -X- _ O
282.39 -X- _ O
364.54 -X- _ O
2670.39 -X- _ O
1742.00 -X- _ O
843.83 -X- _ O
679.80 -X- _ O
122739.30 -X- _ O
80151.10 -X- _ O
89136.68 -X- _ O
107065.48 -X- _ O
140552.69 -X- _ O
182967.37 -X- _ O
148609.73 -X- _ O
192970.64 -X- _ O
250.88 -X- _ O
72.50 -X- _ O
71.43 -X- _ O
30.40 -X- _ O
37.37 -X- _ O
26.75 -X- _ O
22.61 -X- _ O
20.38 -X- _ O
126.55 -X- _ O
158.85 -X- _ O
116.93 -X- _ O
87.23 -X- _ O
91.28 -X- _ O
100.53 -X- _ O
77.96 -X- _ O
69.62 -X- _ O
50.47 -X- _ O
118.40 -X- _ O
91.36 -X- _ O
67.74 -X- _ O
70.71 -X- _ O
148.88 -X- _ O
119.74 -X- _ O
95.75 -X- _ O
90.38 -X- _ O
403.48 -X- _ O
330.56 -X- _ O
327.53 -X- _ O
351.81 -X- _ O
556.00 -X- _ O
498.36 -X- _ O
480.91 -X- _ O
509.06 -X- _ O
61.07 -X- _ O
48.96 -X- _ O
48.65 -X- _ O
33.05 -X- _ O
model -X- _ O
performance -X- _ O
on -X- _ O
validation -X- _ O
data -X- _ O
using -X- _ O
cross -X- _ O
entropy -X- _ O
loss -X- _ O
in -X- _ O
nats -X- _ O
. -X- _ O

XL -X- _ O
( -X- _ O
4x -X- _ O
) -X- _ O
model -X- _ O
is -X- _ O
trained -X- _ O
with -X- _ O
4x -X- _ O
larger -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
that -X- _ O
used -X- _ O
in -X- _ O
other -X- _ O
models -X- _ O
. -X- _ O

Top-4 -X- _ O
performance -X- _ O
highlighted -X- _ O
in -X- _ O
bold -X- _ O
, -X- _ O
with -X- _ O
best -X- _ O
performance -X- _ O
indicated -X- _ O
with -X- _ O
underlines -X- _ O
. -X- _ O

Performance -X- _ O
on -X- _ O
Lambada -X- _ B-DatasetName
and -X- _ O
Wikitext -X- _ B-DatasetName
is -X- _ O
reported -X- _ O
using -X- _ O
perplexity -X- _ B-MetricName
, -X- _ O
all -X- _ O
other -X- _ O
tasks -X- _ O
report -X- _ O
accuracy -X- _ B-MetricName
. -X- _ O

We -X- _ O
use -X- _ O
‡ -X- _ O
to -X- _ O
indicate -X- _ O
the -X- _ O
baseline -X- _ O
model -X- _ O
tuned -X- _ O
from -X- _ O
the -X- _ O
base -X- _ O
GPT-2 -X- _ B-MethodName
model -X- _ O
. -X- _ O

Table -X- _ O
5 -X- _ O
: -X- _ O
Downstream -X- _ O
Out -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
domain -X- _ O
Task -X- _ O
Performance -X- _ O
. -X- _ O

We -X- _ O
report -X- _ O
the -X- _ O
164 -X- _ O

Analyzing -X- _ O
upstream -X- _ O
cross -X- _ O
entropy -X- _ O
loss -X- _ O
During -X- _ O
pretraining -X- _ O
, -X- _ O
we -X- _ O
group -X- _ O
each -X- _ O
dataset -X- _ O
into -X- _ O
training -X- _ B-HyperparameterName
/ -X- _ I-HyperparameterName
validation -X- _ I-HyperparameterName
/ -X- _ I-HyperparameterName
test -X- _ I-HyperparameterName
( -X- _ O
949/50/1 -X- _ B-HyperparameterValue
) -X- _ O
splits -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
revisit -X- _ O
these -X- _ O
claims -X- _ O
on -X- _ O
scaling -X- _ O
Transformer -X- _ O
architectures -X- _ O
. -X- _ O

5.2 -X- _ O
Scaling -X- _ O
Effect -X- _ O
Previous -X- _ O
work -X- _ O
( -X- _ O
Kaplan -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
has -X- _ O
shown -X- _ O
that -X- _ O
upstream -X- _ O
cross -X- _ O
entropy -X- _ O
loss -X- _ O
scales -X- _ O
as -X- _ O
a -X- _ O
power -X- _ O
- -X- _ O
law -X- _ O
with -X- _ O
model -X- _ O
size -X- _ B-HyperparameterName
, -X- _ O
dataset -X- _ O
size -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
amount -X- _ O
of -X- _ O
compute -X- _ O
. -X- _ O

As -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
5 -X- _ O
, -X- _ O
our -X- _ O
models -X- _ O
outperform -X- _ O
baseline -X- _ O
GPT-2 -X- _ B-MethodName
models -X- _ O
for -X- _ O
CB -X- _ O
, -X- _ O
WIC -X- _ B-DatasetName
and -X- _ O
WSC -X- _ B-DatasetName
and -X- _ O
match -X- _ O
the -X- _ O
best -X- _ O
accuracy -X- _ B-MetricName
for -X- _ O
BoolQ -X- _ B-DatasetName
but -X- _ O
the -X- _ O
GPT-2 -X- _ B-MethodName
baselines -X- _ O
outperform -X- _ O
on -X- _ O
the -X- _ O
remaining -X- _ O
tasks -X- _ O
, -X- _ O
particularly -X- _ O
Lambada -X- _ B-TaskName
and -X- _ O
Wikitext -X- _ B-TaskName
– -X- _ O
the -X- _ O
two -X- _ O
general -X- _ O
language -X- _ B-TaskName
modeling -X- _ I-TaskName
tasks -X- _ O
. -X- _ O

Out -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
domain -X- _ O
Evaluation -X- _ O
We -X- _ O
evaluate -X- _ O
outof -X- _ O
- -X- _ O
domain -X- _ O
performance -X- _ O
using -X- _ O
9 -X- _ O
commonly -X- _ O
used -X- _ O
LLM -X- _ B-TaskName
benchmarks -X- _ O
: -X- _ O
BoolQ -X- _ B-DatasetName
( -X- _ O
Clark -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
CB -X- _ B-DatasetName
( -X- _ O
De -X- _ O
Marneffe -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
WIC -X- _ B-DatasetName
( -X- _ O
Pilehvar -X- _ O
and -X- _ O
Camacho -X- _ O
- -X- _ O
Collados -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
WSC -X- _ B-DatasetName
( -X- _ O
Levesque -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2012 -X- _ O
) -X- _ O
, -X- _ O
MathQA -X- _ B-DatasetName
( -X- _ O
Amini -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
PIQA -X- _ B-DatasetName
( -X- _ O
Bisk -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
PubMedQA -X- _ B-DatasetName
( -X- _ O
Jin -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
Lambada -X- _ B-DatasetName
( -X- _ O
Paperno -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
and -X- _ O
WikiText -X- _ B-DatasetName
( -X- _ O
Merity -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
. -X- _ O

Of -X- _ O
the -X- _ O
remaining -X- _ O
tasks -X- _ O
, -X- _ O
our -X- _ O
models -X- _ O
perform -X- _ O
within -X- _ O
1 -X- _ B-MetricValue
- -X- _ I-MetricValue
4 -X- _ I-MetricValue
% -X- _ I-MetricValue
of -X- _ O
GPT-2 -X- _ B-MethodName
baselines -X- _ O
. -X- _ O

As -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
4 -X- _ O
, -X- _ O
one -X- _ O
or -X- _ O
more -X- _ O
of -X- _ O
our -X- _ O
models -X- _ O
outperform -X- _ O
baseline -X- _ O
GPT-2 -X- _ B-MethodName
models -X- _ O
for -X- _ O
the -X- _ O
two -X- _ O
chemistry -X- _ O
tasks -X- _ O
, -X- _ O
general -X- _ O
science -X- _ B-TaskName
QA -X- _ I-TaskName
( -X- _ O
SciQ -X- _ O
) -X- _ O
and -X- _ O
the -X- _ O
sciencefocused -X- _ B-TaskName
language -X- _ I-TaskName
modelling -X- _ I-TaskName
. -X- _ O

( -X- _ O
Mihaylov -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
Pile -X- _ O
- -X- _ O
PubMed -X- _ B-DatasetName
- -X- _ I-DatasetName
Abstracts -X- _ I-DatasetName
( -X- _ O
Gao -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
) -X- _ O
. -X- _ O

In -X- _ O
- -X- _ O
domain -X- _ O
Evaluation -X- _ O
We -X- _ O
consider -X- _ O
five -X- _ O
existing -X- _ O
chemistry -X- _ O
benchmarks -X- _ O
, -X- _ O
specifically -X- _ O
HendrycksTest -X- _ O
( -X- _ O
Hendrycks -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
for -X- _ O
high -X- _ O
school -X- _ O
( -X- _ O
HT -X- _ B-DatasetName
- -X- _ I-DatasetName
HC -X- _ I-DatasetName
) -X- _ O
and -X- _ O
college -X- _ O
( -X- _ O
HT -X- _ B-DatasetName
- -X- _ I-DatasetName
CC -X- _ I-DatasetName
) -X- _ O
levels -X- _ O
, -X- _ O
and -X- _ O
sciencefocused -X- _ O
– -X- _ O
ARC -X- _ B-DatasetName
( -X- _ O
Clark -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
SciQ -X- _ B-DatasetName
( -X- _ O
Welbl -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
, -X- _ O
OpenBookQA -X- _ B-DatasetName

Pile -X- _ O
0.22 -X- _ O
0.18 -X- _ O
0.18 -X- _ O
0.18 -X- _ O
0.19 -X- _ O
0.18 -X- _ O
0.18 -X- _ O
0.23 -X- _ O
0.23 -X- _ O
0.19 -X- _ O
0.22 -X- _ O
0.17 -X- _ O
0.20 -X- _ O
0.24 -X- _ O
0.18 -X- _ O
0.19 -X- _ O
0.20 -X- _ O
0.26 -X- _ O
0.19 -X- _ O
0.18 -X- _ O
0.18 -X- _ O
0.26 -X- _ O
0.27 -X- _ O
0.28 -X- _ O
0.24 -X- _ O
0.22 -X- _ O
0.25 -X- _ O
0.27 -X- _ O
0.23 -X- _ O
0.17 -X- _ O
0.20 -X- _ O
0.18 -X- _ O
0.18 -X- _ O
0.25 -X- _ O
0.27 -X- _ O
0.28 -X- _ O
0.26 -X- _ O
0.31 -X- _ O
0.27 -X- _ O
0.34 -X- _ O
0.34 -X- _ O
0.34 -X- _ O
0.28 -X- _ O
0.34 -X- _ O
0.30 -X- _ O
0.28 -X- _ O
0.28 -X- _ O
0.27 -X- _ O
0.36 -X- _ O
0.36 -X- _ O
0.30 -X- _ O
0.27 -X- _ O
0.28 -X- _ O
0.27 -X- _ O
0.33 -X- _ O
0.22 -X- _ O
0.23 -X- _ O
0.31 -X- _ O
0.31 -X- _ O
0.32 -X- _ O
0.30 -X- _ O
0.34 -X- _ O
0.28 -X- _ O
0.30 -X- _ O
0.30 -X- _ O
0.25 -X- _ O
0.44 -X- _ O
0.49 -X- _ O
0.53 -X- _ O
0.58 -X- _ O
0.35 -X- _ O
0.43 -X- _ O
0.45 -X- _ O
0.49 -X- _ O
0.50 -X- _ O
0.36 -X- _ O
0.40 -X- _ O
0.41 -X- _ O
0.47 -X- _ O
0.41 -X- _ O
0.45 -X- _ O
0.51 -X- _ O
0.50 -X- _ O
0.41 -X- _ O
0.43 -X- _ O
0.43 -X- _ O
0.48 -X- _ O
0.31 -X- _ O
0.33 -X- _ O
0.32 -X- _ O
0.33 -X- _ O
0.33 -X- _ O
0.32 -X- _ O
0.32 -X- _ O
0.34 -X- _ O
0.54 -X- _ O
0.48 -X- _ O
0.48 -X- _ O
0.55 -X- _ O
0.19 -X- _ O
0.22 -X- _ O
0.22 -X- _ O
0.25 -X- _ O
0.19 -X- _ O
0.21 -X- _ O
0.20 -X- _ O
0.23 -X- _ O
0.23 -X- _ O
0.19 -X- _ O
0.20 -X- _ O
0.19 -X- _ O
0.21 -X- _ O
0.20 -X- _ O
0.21 -X- _ O
0.24 -X- _ O
0.22 -X- _ O
0.20 -X- _ O
0.21 -X- _ O
0.22 -X- _ O
0.21 -X- _ O
0.21 -X- _ O
0.18 -X- _ O
0.21 -X- _ O
0.19 -X- _ O
0.22 -X- _ O
0.20 -X- _ O
0.21 -X- _ O
0.21 -X- _ O
0.23 -X- _ O
0.21 -X- _ O
0.22 -X- _ O
0.24 -X- _ O
0.75 -X- _ O
0.77 -X- _ O
0.80 -X- _ O
0.83 -X- _ O
0.61 -X- _ O
0.70 -X- _ O
0.74 -X- _ O
0.78 -X- _ O
0.77 -X- _ O
0.69 -X- _ O
0.71 -X- _ O
0.75 -X- _ O
0.78 -X- _ O
0.66 -X- _ O
0.68 -X- _ O
0.80 -X- _ O
0.80 -X- _ O
0.60 -X- _ O
0.68 -X- _ O
0.74 -X- _ O
0.77 -X- _ O
0.31 -X- _ O
0.31 -X- _ O
0.31 -X- _ O
0.30 -X- _ O
0.37 -X- _ O
0.34 -X- _ O
0.37 -X- _ O
0.39 -X- _ O
0.83 -X- _ O
0.79 -X- _ O
0.79 -X- _ O
0.84 -X- _ O
0.16 -X- _ O
0.19 -X- _ O
0.19 -X- _ O
0.22 -X- _ O
0.13 -X- _ O
0.17 -X- _ O
0.16 -X- _ O
0.18 -X- _ O
0.17 -X- _ O
0.15 -X- _ O
0.15 -X- _ O
0.14 -X- _ O
0.15 -X- _ O
0.17 -X- _ O
0.17 -X- _ O
0.18 -X- _ O
0.20 -X- _ O
0.16 -X- _ O
0.18 -X- _ O
0.17 -X- _ O
0.16 -X- _ O
0.17 -X- _ O
0.16 -X- _ O
0.17 -X- _ O
0.18 -X- _ O
0.17 -X- _ O
0.16 -X- _ O
0.17 -X- _ O
0.16 -X- _ O
0.18 -X- _ O
0.15 -X- _ O
0.17 -X- _ O
0.17 -X- _ O
96.50 -X- _ O
61.26 -X- _ O
48.86 -X- _ O
42.29 -X- _ O
87.57 -X- _ O
38.40 -X- _ O
30.55 -X- _ O
24.18 -X- _ O
25.52 -X- _ O
78.24 -X- _ O
59.19 -X- _ O
52.95 -X- _ O
39.46 -X- _ O
38.03 -X- _ O
30.88 -X- _ O
24.78 -X- _ O
26.09 -X- _ O
56.03 -X- _ O
45.69 -X- _ O
37.22 -X- _ O
35.14 -X- _ O
59.20 -X- _ O
45.60 -X- _ O
42.14 -X- _ O
42.35 -X- _ O
54.41 -X- _ O
48.31 -X- _ O
46.44 -X- _ O
45.86 -X- _ O
22.77 -X- _ O
40.18 -X- _ O
31.03 -X- _ O
23.01 -X- _ O
2021 -X- _ O
) -X- _ O
for -X- _ O
the -X- _ O
benchmark -X- _ O
implementation -X- _ O
. -X- _ O

Model -X- _ O
Baseline -X- _ O
AMiner -X- _ B-MethodName
CORE -X- _ B-MethodName
MAG -X- _ B-MethodName
PubMed -X- _ B-MethodName
- -X- _ I-MethodName
F -X- _ I-MethodName
S2ORC -X- _ B-MethodName
WoS -X- _ B-MethodName
Combined -X- _ B-MethodName
- -X- _ I-MethodName
A -X- _ I-MethodName
Combined -X- _ B-MethodName
- -X- _ I-MethodName
F -X- _ I-MethodName
Combined -X- _ B-MethodName
- -X- _ I-MethodName
A+F -X- _ I-MethodName
Combined -X- _ B-MethodName
- -X- _ I-MethodName
A+F -X- _ I-MethodName
Size -X- _ B-HyperparameterName
S -X- _ O
M -X- _ O
L -X- _ O
XL -X- _ O
M‡ -X- _ O
S -X- _ O
M -X- _ O
L -X- _ O
XL -X- _ O
S -X- _ O
M -X- _ O
L -X- _ O
XL -X- _ O
S -X- _ O
M -X- _ O
L -X- _ O
XL -X- _ O
S -X- _ O
M -X- _ O
L -X- _ O
XL -X- _ O
S -X- _ O
M -X- _ O
L -X- _ O
XL -X- _ O
S -X- _ O
M -X- _ O
L -X- _ O
XL -X- _ O
XL -X- _ O
XL -X- _ O
XL -X- _ O
XL -X- _ O
( -X- _ O
4x -X- _ O
) -X- _ O
HT -X- _ B-DatasetName
- -X- _ I-DatasetName
HC -X- _ I-DatasetName
HT -X- _ B-DatasetName
- -X- _ I-DatasetName
CC -X- _ I-DatasetName
ARC -X- _ B-DatasetName
- -X- _ I-DatasetName
E -X- _ I-DatasetName
ARC -X- _ B-DatasetName
- -X- _ I-DatasetName
C -X- _ I-DatasetName
SciQ -X- _ B-DatasetName
OpenBookQA -X- _ B-DatasetName

XL -X- _ O
( -X- _ O
4x -X- _ O
) -X- _ O
model -X- _ O
is -X- _ O
trained -X- _ O
with -X- _ O
4x -X- _ O
larger -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
that -X- _ O
used -X- _ O
in -X- _ O
other -X- _ O
models -X- _ O
. -X- _ O

We -X- _ O
highlight -X- _ O
the -X- _ O
top-4 -X- _ O
performance -X- _ O
per -X- _ O
task -X- _ O
in -X- _ O
bold -X- _ O
, -X- _ O
with -X- _ O
top -X- _ O
performance -X- _ O
indicated -X- _ O
with -X- _ O
an -X- _ O
underline -X- _ O
. -X- _ O

Pile -X- _ O
performance -X- _ O
is -X- _ O
reported -X- _ O
using -X- _ O
perplexity -X- _ B-MetricName
, -X- _ O
with -X- _ O
all -X- _ O
other -X- _ O
tasks -X- _ O
reported -X- _ O
using -X- _ O
accuracy -X- _ B-MetricName
. -X- _ O

We -X- _ O
use -X- _ O
‡ -X- _ O
to -X- _ O
indicate -X- _ O
the -X- _ O
baseline -X- _ O
model -X- _ O
tuned -X- _ O
from -X- _ O
the -X- _ O
base -X- _ O
GPT-2 -X- _ B-MethodName
model -X- _ O
. -X- _ O

Table -X- _ O
4 -X- _ O
: -X- _ O
Downstream -X- _ O
Zero -X- _ O
- -X- _ O
shot -X- _ O
In -X- _ O
- -X- _ O
Domain -X- _ O
Task -X- _ O
Performance -X- _ O
. -X- _ O

The -X- _ O
benchmarks -X- _ O
we -X- _ O
include -X- _ O
are -X- _ O
described -X- _ O
in -X- _ O
Appendix -X- _ O
B. -X- _ O
We -X- _ O
use -X- _ O
the -X- _ O
lmevaluation -X- _ O
- -X- _ O
harness -X- _ O
Python -X- _ O
repository -X- _ O
( -X- _ O
Gao -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
163 -X- _ O

5.1 -X- _ O
Zero -X- _ O
- -X- _ O
shot -X- _ O
Performance -X- _ O
We -X- _ O
evaluate -X- _ O
our -X- _ O
models -X- _ O
using -X- _ O
several -X- _ O
benchmarks -X- _ O
to -X- _ O
assess -X- _ O
the -X- _ O
effectiveness -X- _ O
in -X- _ O
both -X- _ O
in -X- _ O
- -X- _ O
domain -X- _ O
and -X- _ O
out -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
domain -X- _ O
tasks -X- _ O
. -X- _ O

We -X- _ O
also -X- _ O
trained -X- _ O
one -X- _ O
XL -X- _ O
( -X- _ O
4x -X- _ O
) -X- _ O
model -X- _ O
with -X- _ O
4x -X- _ O
larger -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
than -X- _ O
what -X- _ O
used -X- _ O
in -X- _ O
XL -X- _ O
model -X- _ O
to -X- _ O
evaluate -X- _ O
the -X- _ O
impact -X- _ O
of -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
training -X- _ O
tokens -X- _ O
. -X- _ O

This -X- _ O
is -X- _ O
to -X- _ O
control -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
tokens -X- _ O
seen -X- _ O
during -X- _ O
model -X- _ O
pretraining -X- _ O
( -X- _ O
320,000 -X- _ B-HyperparameterValue
steps -X- _ B-HyperparameterName
* -X- _ O
4 -X- _ O
GPUs -X- _ O
* -X- _ O
4 -X- _ B-HyperparameterValue
micro -X- _ B-HyperparameterName
batch -X- _ I-HyperparameterName
size -X- _ I-HyperparameterName
* -X- _ O
2,048 -X- _ B-HyperparameterValue
context -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
= -X- _ O
10B -X- _ O
tokens -X- _ O
) -X- _ O
relative -X- _ O
to -X- _ O
the -X- _ O
maximum -X- _ O
number -X- _ O
of -X- _ O
tokens -X- _ O
available -X- _ O
in -X- _ O
the -X- _ O
respective -X- _ O
datasets -X- _ O
( -X- _ O
as -X- _ O
reported -X- _ O
in -X- _ O
Table -X- _ O
3 -X- _ O
) -X- _ O
. -X- _ O

We -X- _ O
only -X- _ O
use -X- _ O
4 -X- _ O
GPUs -X- _ O
for -X- _ O
the -X- _ O
models -X- _ O
pretrained -X- _ O
with -X- _ O
individual -X- _ O
datasets -X- _ O
and -X- _ O
8 -X- _ O
GPUs -X- _ O
for -X- _ O
the -X- _ O
rest -X- _ O
. -X- _ O

For -X- _ O
example -X- _ O
, -X- _ O
PubMed -X- _ O
publications -X- _ O
cover -X- _ O
mostly -X- _ O
bio -X- _ O
- -X- _ O
medicinal -X- _ O
terms -X- _ O
( -X- _ O
Gu -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
while -X- _ O
the -X- _ O
majority -X- _ O
of -X- _ O
S2ORC -X- _ O
publications -X- _ O
are -X- _ O
from -X- _ O
medicine -X- _ O
, -X- _ O
biology -X- _ O
, -X- _ O
physics -X- _ O
, -X- _ O
and -X- _ O
mathematics -X- _ O
( -X- _ O
Lo -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O

Our -X- _ O
goal -X- _ O
is -X- _ O
to -X- _ O
systematically -X- _ O
study -X- _ O
data -X- _ O
biases -X- _ O
in -X- _ O
the -X- _ O
model -X- _ O
performance -X- _ O
when -X- _ O
pretraining -X- _ O
models -X- _ O
with -X- _ O
individual -X- _ O
datasets -X- _ O
. -X- _ O

Our -X- _ O
Models -X- _ O
We -X- _ O
pretrained -X- _ O
models -X- _ O
with -X- _ O
individual -X- _ O
datasets -X- _ O
( -X- _ O
AMiner -X- _ O
, -X- _ O
CORE -X- _ O
, -X- _ O
MAG -X- _ O
, -X- _ O
PubMed -X- _ O
, -X- _ O
S2ORC -X- _ O
, -X- _ O
WOS -X- _ O
) -X- _ O
and -X- _ O
combined -X- _ O
abstracts -X- _ O
and -X- _ O
fulltexts -X- _ O
. -X- _ O

S2ORC -X- _ O
4.0 -X- _ O
% -X- _ O
AMiner -X- _ O
49.6 -X- _ O
% -X- _ O
MAG -X- _ O
29.9 -X- _ O
% -X- _ O
arXiv -X- _ O
OSTI -X- _ O
Analysis -X- _ O
and -X- _ O
Results -X- _ O
CORD19 -X- _ O
PubMed -X- _ O
DBLP -X- _ O
Distribution -X- _ O
within -X- _ O
Sources -X- _ O
with -X- _ O
< -X- _ O
1 -X- _ O
% -X- _ O
( -X- _ O
upper -X- _ O
right -X- _ O
, -X- _ O
black -X- _ O
box -X- _ O
) -X- _ O
Figure -X- _ O
1 -X- _ O
: -X- _ O
Summary -X- _ O
of -X- _ O
data -X- _ O
source -X- _ O
representation -X- _ O
within -X- _ O
the -X- _ O
Combined -X- _ O
A+F -X- _ O
data -X- _ O
sample -X- _ O
. -X- _ O

We -X- _ O
split -X- _ O
datasets -X- _ O
to -X- _ O
those -X- _ O
that -X- _ O
include -X- _ O
abstracts -X- _ O
〈A〉 -X- _ O
vs. -X- _ O
full -X- _ O
texts -X- _ O
〈FT〉. -X- _ O
0.80 -X- _ O
Data -X- _ O
Collection -X- _ O
and -X- _ O
Processing -X- _ O
PubMed -X- _ O
# -X- _ O
Params -X- _ O
( -X- _ O
B -X- _ O
) -X- _ O
0.11 -X- _ O
0.11 -X- _ O
0.11 -X- _ O
0.11 -X- _ O
0.11 -X- _ O
0.22 -X- _ O
0.77 -X- _ O
0.02 -X- _ O
0.30 -X- _ O
0.34 -X- _ O
0.80 -X- _ O
1.20 -X- _ O
0.11 -X- _ O
0.11 -X- _ O
0.11 -X- _ O
0.11 -X- _ O
0.34 -X- _ O
2016 -X- _ O
) -X- _ O
, -X- _ O
Microsoft -X- _ O
Academic -X- _ O
Graph -X- _ O
( -X- _ O
MAG -X- _ O
) -X- _ O
( -X- _ O
Wang -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2020a -X- _ O
) -X- _ O
, -X- _ O
OSTI -X- _ O
, -X- _ O
PubMed -X- _ O
( -X- _ O
Gao -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
( -X- _ O
abstracts -X- _ O
and -X- _ O
fulltexts -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
Web -X- _ O
of -X- _ O
Science -X- _ O
( -X- _ O
WoS -X- _ O
) -X- _ O
. -X- _ O

Size -X- _ B-HyperparameterName
S -X- _ O
M -X- _ O
L -X- _ O
XL -X- _ O
Model -X- _ O
GPT -X- _ O
- -X- _ O
NeoX -X- _ O
GPT-2 -X- _ B-MethodName
GPT -X- _ O
- -X- _ O
NeoX -X- _ O
GPT-2 -X- _ B-MethodName
GPT -X- _ O
- -X- _ O
NeoX -X- _ O
GPT-2 -X- _ B-MethodName
GPT -X- _ O
- -X- _ O
NeoX -X- _ O
GPT-2 -X- _ B-MethodName
dL -X- _ B-HyperparameterName
12 -X- _ B-HyperparameterValue
12 -X- _ B-HyperparameterValue
24 -X- _ B-HyperparameterValue
24 -X- _ B-HyperparameterValue
24 -X- _ B-HyperparameterValue
36 -X- _ B-HyperparameterValue
24 -X- _ B-HyperparameterValue
48 -X- _ B-HyperparameterValue
ddim -X- _ B-HyperparameterName
768 -X- _ B-HyperparameterValue
768 -X- _ B-HyperparameterValue
1024 -X- _ B-HyperparameterValue
1024 -X- _ B-HyperparameterValue
1536 -X- _ B-HyperparameterValue
1280 -X- _ B-HyperparameterValue
2048 -X- _ B-HyperparameterValue
1600 -X- _ B-HyperparameterValue
dheads -X- _ B-HyperparameterName
12 -X- _ B-HyperparameterValue
12 -X- _ B-HyperparameterValue
16 -X- _ B-HyperparameterValue
16 -X- _ B-HyperparameterValue
16 -X- _ B-HyperparameterValue
20 -X- _ B-HyperparameterValue
16 -X- _ B-HyperparameterValue
25 -X- _ B-HyperparameterValue
# -X- _ B-HyperparameterName
Params -X- _ I-HyperparameterName
( -X- _ O
B -X- _ O
) -X- _ O
0.18 -X- _ B-HyperparameterValue
4 -X- _ B-HyperparameterValue
1.47 -X- _ B-HyperparameterValue
Source -X- _ O
# -X- _ O
Articles -X- _ O
( -X- _ O
M -X- _ O
) -X- _ O
# -X- _ O
Tokens -X- _ O
( -X- _ O
B -X- _ O
) -X- _ O
Size -X- _ O
( -X- _ O
Gb -X- _ O
) -X- _ O
MAG -X- _ O
〈A〉 -X- _ O
34.26 -X- _ O
7.43 -X- _ O
46 -X- _ O
Aminer -X- _ O
〈A〉 -X- _ O
18.50 -X- _ O
5.80 -X- _ O
35 -X- _ O
S2ORC -X- _ O
〈A〉 -X- _ O
10.44 -X- _ O
2.05 -X- _ O
32 -X- _ O
WoS -X- _ O
〈A〉 -X- _ O
7.90 -X- _ O
3.31 -X- _ O
18 -X- _ O
CORD-19 -X- _ O
〈A〉 -X- _ O
< -X- _ O
0.01 -X- _ O
< -X- _ O
0.01 -X- _ O
0.2 -X- _ O
OSTI -X- _ O
〈A〉 -X- _ O
0.05 -X- _ O
< -X- _ O
0.01 -X- _ O
0.1 -X- _ O
Arxiv -X- _ O
〈A〉 -X- _ O
0.38 -X- _ O
0.04 -X- _ O
0.4 -X- _ O
PubMed -X- _ O
〈A〉 -X- _ O
0.28 -X- _ O
0.08 -X- _ O
0.5 -X- _ O
PubMed -X- _ O
〈FT〉 -X- _ O
0.70 -X- _ O
7.34 -X- _ O
32 -X- _ O
CORE -X- _ O
〈FT〉 -X- _ O
7.27 -X- _ O
215.50 -X- _ O
743 -X- _ O

GPT -X- _ O
- -X- _ O
NeoX -X- _ O
architecture -X- _ O
is -X- _ O
originally -X- _ O
from -X- _ O
GPT-3 -X- _ O
( -X- _ O
Brown -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O

We -X- _ O
compare -X- _ O
model -X- _ O
configurations -X- _ O
between -X- _ O
GPT -X- _ O
- -X- _ O
NeoX -X- _ O
and -X- _ O
OpenAI -X- _ O
’s -X- _ O
GPT-2 -X- _ B-MethodName
. -X- _ O

Thus -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
include -X- _ O
a -X- _ O
base -X- _ O
GPT-2 -X- _ B-MethodName
model -X- _ O
( -X- _ O
medium -X- _ O
) -X- _ O
that -X- _ O
has -X- _ O
been -X- _ O
updated -X- _ O
with -X- _ O
continual -X- _ O
pretraining -X- _ O
using -X- _ O
our -X- _ O
Combined -X- _ O
〈A+FT〉 -X- _ O
dataset -X- _ O
. -X- _ O

We -X- _ O
note -X- _ O
that -X- _ O
GPT-2 -X- _ B-MethodName
models -X- _ O
were -X- _ O
pretrained -X- _ O
on -X- _ O
WebText -X- _ O
– -X- _ O
8 -X- _ O
million -X- _ O
web -X- _ O
documents -X- _ O
( -X- _ O
40Gb -X- _ O
) -X- _ O
. -X- _ O

We -X- _ O
compare -X- _ O
our -X- _ O
performance -X- _ O
with -X- _ O
four -X- _ O
variants -X- _ O
of -X- _ O
the -X- _ O
original -X- _ O
GPT-2 -X- _ B-MethodName
models -X- _ O
, -X- _ O
corresponding -X- _ O
to -X- _ O
small -X- _ O
( -X- _ O
S -X- _ O
) -X- _ O
, -X- _ O
medium -X- _ O
( -X- _ O
M -X- _ O
) -X- _ O
, -X- _ O
large -X- _ O
( -X- _ O
L -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
extra -X- _ O
- -X- _ O
large -X- _ O
( -X- _ O
XL -X- _ O
) -X- _ O
sized -X- _ O
transformer -X- _ O
architectures -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
2 -X- _ O
. -X- _ O

Baseline -X- _ O
Models -X- _ O
As -X- _ O
we -X- _ O
use -X- _ O
a -X- _ O
similar -X- _ O
model -X- _ O
architecture -X- _ O
, -X- _ O
we -X- _ O
identify -X- _ O
Open -X- _ O
AI -X- _ O
’s -X- _ O
GPT-2 -X- _ B-MethodName
( -X- _ O
Radford -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
as -X- _ O
a -X- _ O
baseline -X- _ O
comparison -X- _ O
model -X- _ O
. -X- _ O

For -X- _ O
example -X- _ O
, -X- _ O
dimethylnitroxide -X- _ O
was -X- _ O
tokenized -X- _ O
into -X- _ O
# -X- _ O
dimethyl -X- _ O
, -X- _ O
# -X- _ O
nitr -X- _ O
, -X- _ O
# -X- _ O
oxide -X- _ O
using -X- _ O
the -X- _ O
in -X- _ O
- -X- _ O
domain -X- _ O
vocabulary -X- _ O
and -X- _ O
# -X- _ O
dim -X- _ O
, -X- _ O
# -X- _ O
ethyl -X- _ O
, -X- _ O
# -X- _ O
nit -X- _ O
, -X- _ O
# -X- _ O
rox -X- _ O
, -X- _ O
# -X- _ O
ide -X- _ O
using -X- _ O
the -X- _ O
GPT-2 -X- _ B-MethodName
vocabulary -X- _ O
. -X- _ O

We -X- _ O
compare -X- _ O
the -X- _ O
GPT2 -X- _ B-MethodName
vocabulary -X- _ O
generated -X- _ O
from -X- _ O
the -X- _ O
WebText -X- _ O
and -X- _ O
the -X- _ O
in -X- _ O
- -X- _ O
domain -X- _ O
vocabularies -X- _ O
generated -X- _ O
from -X- _ O
our -X- _ O
corpora -X- _ O
and -X- _ O
find -X- _ O
that -X- _ O
the -X- _ O
in -X- _ O
- -X- _ O
domain -X- _ O
vocabulary -X- _ O
breaks -X- _ O
chemical -X- _ O
entities -X- _ O
into -X- _ O
fewer -X- _ O
tokens -X- _ O
. -X- _ O

We -X- _ O
train -X- _ O
BPE -X- _ O
tokenizers -X- _ O
for -X- _ O
each -X- _ O
data -X- _ O
sample -X- _ O
with -X- _ O
a -X- _ O
vocabulary -X- _ O
size -X- _ O
of -X- _ O
64 -X- _ O
K -X- _ O
as -X- _ O
preliminary -X- _ O
experiments -X- _ O
varying -X- _ O
vocabulary -X- _ O
sizes -X- _ O
from -X- _ O
64 -X- _ O
K -X- _ O
to -X- _ O
256 -X- _ O
K -X- _ O
for -X- _ O
smaller -X- _ O
scale -X- _ O
model -X- _ O
pretraining -X- _ O
did -X- _ O
not -X- _ O
show -X- _ O
significant -X- _ O
differences -X- _ O
in -X- _ O
performance -X- _ O
. -X- _ O

Tokenization -X- _ O
As -X- _ O
used -X- _ O
in -X- _ O
GPT-2 -X- _ B-MethodName
model -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
a -X- _ O
Byte -X- _ O
Pair -X- _ O
Encoding -X- _ O
( -X- _ O
BPE -X- _ O
) -X- _ O
tokenizer -X- _ O
. -X- _ O

The -X- _ O
deduplication -X- _ O
process -X- _ O
reduced -X- _ O
our -X- _ O
corpus -X- _ O
from -X- _ O
875 -X- _ O
GB -X- _ O
to -X- _ O
670 -X- _ O
GB -X- _ O
( -X- _ O
67.8 -X- _ O
M -X- _ O
to -X- _ O
53.5 -X- _ O
M -X- _ O
publications -X- _ O
) -X- _ O
, -X- _ O
removing -X- _ O
14.3 -X- _ O
M -X- _ O
duplicates -X- _ O
. -X- _ O

With -X- _ O
this -X- _ O
technique -X- _ O
, -X- _ O
we -X- _ O
were -X- _ O
able -X- _ O
to -X- _ O
remove -X- _ O
significant -X- _ O
amounts -X- _ O
of -X- _ O
duplicate -X- _ O
scientific -X- _ O
articles -X- _ O
both -X- _ O
within -X- _ O
and -X- _ O
across -X- _ O
sources -X- _ O
. -X- _ O

We -X- _ O
processed -X- _ O
titles -X- _ O
to -X- _ O
strip -X- _ O
punctuation -X- _ O
and -X- _ O
casefold -X- _ O
and -X- _ O
considered -X- _ O
two -X- _ O
articles -X- _ O
A1 -X- _ O
and -X- _ O
A2 -X- _ O
to -X- _ O
be -X- _ O
duplicates -X- _ O
if -X- _ O
they -X- _ O
had -X- _ O
the -X- _ O
same -X- _ O
processed -X- _ O
title -X- _ O
. -X- _ O

To -X- _ O
this -X- _ O
end -X- _ O
, -X- _ O
we -X- _ O
performed -X- _ O
deduplication -X- _ O
of -X- _ O
our -X- _ O
corpus -X- _ O
based -X- _ O
on -X- _ O
overlap -X- _ O
of -X- _ O
titles -X- _ O
within -X- _ O
and -X- _ O
across -X- _ O
data -X- _ O
sources -X- _ O
. -X- _ O

Data -X- _ O
Cleaning -X- _ O
Recent -X- _ O
research -X- _ O
has -X- _ O
shown -X- _ O
that -X- _ O
duplicates -X- _ O
in -X- _ O
training -X- _ O
data -X- _ O
can -X- _ O
significantly -X- _ O
impact -X- _ O
the -X- _ O
downstream -X- _ O
task -X- _ O
performance -X- _ O
of -X- _ O
LLMs -X- _ O
( -X- _ O
Lee -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Carlini -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
. -X- _ O

Coloring -X- _ O
illustrates -X- _ O
whether -X- _ O
a -X- _ O
data -X- _ O
source -X- _ O
contains -X- _ O
peer -X- _ O
reviewed -X- _ O
( -X- _ O
Blue -X- _ O
) -X- _ O
, -X- _ O
mixed -X- _ O
( -X- _ O
Purple -X- _ O
) -X- _ O
, -X- _ O
or -X- _ O
not -X- _ O
peer -X- _ O
reviewed -X- _ O
( -X- _ O
Red -X- _ O
) -X- _ O
articles -X- _ O
. -X- _ O

We -X- _ O
also -X- _ O
compare -X- _ O
the -X- _ O
results -X- _ O
from -X- _ O
continual -X- _ O
vs. -X- _ O
from -X- _ O
scratch -X- _ O
pretraining -X- _ O
( -X- _ O
Section -X- _ O
5.5 -X- _ O
) -X- _ O
and -X- _ O
present -X- _ O
the -X- _ O
analysis -X- _ O
of -X- _ O
large -X- _ O
- -X- _ O
scale -X- _ O
training -X- _ O
efficiency -X- _ O
( -X- _ O
Section -X- _ O
5.6 -X- _ O
) -X- _ O
. -X- _ O

We -X- _ O
investigate -X- _ O
the -X- _ O
effects -X- _ O
of -X- _ O
model -X- _ O
and -X- _ O
data -X- _ O
scaling -X- _ O
( -X- _ O
RQ2 -X- _ O
, -X- _ O
Section -X- _ O
5.2 -X- _ O
) -X- _ O
, -X- _ O
knowledge -X- _ O
diversity -X- _ O
( -X- _ O
RQ3 -X- _ O
, -X- _ O
Section -X- _ O
5.3 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
temporal -X- _ O
order -X- _ O
( -X- _ O
RQ4 -X- _ O
, -X- _ O
Section -X- _ O
5.4 -X- _ O
) -X- _ O
on -X- _ O
the -X- _ O
downstream -X- _ O
performance -X- _ O
. -X- _ O

5 -X- _ O
0.8 -X- _ O
% -X- _ O
WoS -X- _ B-DatasetName
3.8 -X- _ O
% -X- _ O
CORE -X- _ B-DatasetName
11.9 -X- _ O
% -X- _ O
This -X- _ O
section -X- _ O
presents -X- _ O
the -X- _ O
analysis -X- _ O
of -X- _ O
28 -X- _ O
pretrained -X- _ O
models -X- _ O
evaluated -X- _ O
on -X- _ O
15 -X- _ O
+ -X- _ O
in -X- _ O
- -X- _ O
domain -X- _ O
and -X- _ O
out -X- _ O
- -X- _ O
ofdomain -X- _ O
downstream -X- _ O
tasks -X- _ O
( -X- _ O
RQ1 -X- _ O
, -X- _ O
Section -X- _ O
5.1 -X- _ O
) -X- _ O
. -X- _ O

This -X- _ O
resulted -X- _ O
in -X- _ O
a -X- _ O
list -X- _ O
of -X- _ O
more -X- _ O
than -X- _ O
1 -X- _ O
K -X- _ O
chemistry -X- _ O
- -X- _ O
related -X- _ O
entities -X- _ O
, -X- _ O
ranging -X- _ O
from -X- _ O
compound -X- _ O
names -X- _ O
like -X- _ O
ethyl -X- _ O
acetate -X- _ O
, -X- _ O
methyl -X- _ O
methacrylate -X- _ O
, -X- _ O
sulfoxide -X- _ O
, -X- _ O
etc -X- _ O
. -X- _ O
to -X- _ O
experiment -X- _ O
and -X- _ O
procedures -X- _ O
like -X- _ O
tunneling -X- _ O
microscopy -X- _ O
, -X- _ O
neutralization -X- _ O
, -X- _ O
enzymatic -X- _ O
hydrolysis -X- _ O
, -X- _ O
etc -X- _ O
. -X- _ O
162 -X- _ O

These -X- _ O
keywords -X- _ O
were -X- _ O
extracted -X- _ O
by -X- _ O
using -X- _ O
a -X- _ O
Correlation -X- _ O
Explanation -X- _ O
( -X- _ O
Gallagher -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
topic -X- _ O
model -X- _ O
followed -X- _ O
by -X- _ O
manual -X- _ O
filtering -X- _ O
by -X- _ O
subject -X- _ O
matter -X- _ O
experts -X- _ O
. -X- _ O

Because -X- _ O
the -X- _ O
data -X- _ O
sources -X- _ O
we -X- _ O
relied -X- _ O
on -X- _ O
comprise -X- _ O
research -X- _ O
publications -X- _ O
from -X- _ O
many -X- _ O
science -X- _ O
domains -X- _ O
, -X- _ O
we -X- _ O
sampled -X- _ O
articles -X- _ O
using -X- _ O
a -X- _ O
list -X- _ O
of -X- _ O
domain -X- _ O
- -X- _ O
specific -X- _ O
keywords -X- _ O
for -X- _ O
chemistry -X- _ O
to -X- _ O
create -X- _ O
the -X- _ O
dataset -X- _ O
summarized -X- _ O
in -X- _ O
Table -X- _ O
3 -X- _ O
. -X- _ O

Corpus -X- _ O
PubMed -X- _ O
MIMIC1 -X- _ O
PubMed -X- _ O
+ -X- _ O
MIMIC -X- _ O
Arxiv -X- _ O
Chemistry -X- _ O
Journals -X- _ O

We -X- _ O
perform -X- _ O
experiments -X- _ O
in -X- _ O
a -X- _ O
single -X- _ O
DGX -X- _ O
- -X- _ O
A100 -X- _ O
machine -X- _ O
with -X- _ O
8 -X- _ O
80Gb -X- _ O
GPUs -X- _ O
. -X- _ O

The -X- _ O
original -X- _ O
GPT-2 -X- _ B-MethodName
models -X- _ O
are -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
for -X- _ O
150 -X- _ B-HyperparameterValue
K -X- _ I-HyperparameterValue
steps -X- _ O
. -X- _ O

Models -X- _ O
are -X- _ O
pretrained -X- _ O
from -X- _ O
scratch -X- _ O
for -X- _ O
a -X- _ O
total -X- _ O
of -X- _ O
320 -X- _ B-HyperparameterValue
K -X- _ I-HyperparameterValue
steps -X- _ O
. -X- _ O

As -X- _ O
the -X- _ O
largest -X- _ O
model -X- _ O
in -X- _ O
our -X- _ O
experiments -X- _ O
fit -X- _ O
on -X- _ O
a -X- _ O
single -X- _ O
GPU -X- _ O
, -X- _ O
we -X- _ O
did -X- _ O
n’t -X- _ O
use -X- _ O
the -X- _ O
model -X- _ O
( -X- _ O
tensor -X- _ O
) -X- _ O
or -X- _ O
pipeline -X- _ O
parallelism -X- _ O
. -X- _ O

Our -X- _ O
models -X- _ O
are -X- _ O
pretrained -X- _ O
across -X- _ O
multiple -X- _ O
workers -X- _ O
with -X- _ O
data -X- _ O
parallelism -X- _ O
. -X- _ O

0.40 -X- _ O
advantages -X- _ O
in -X- _ O
tasks -X- _ O
with -X- _ O
longer -X- _ O
texts -X- _ O
by -X- _ O
capturing -X- _ O
relative -X- _ O
position -X- _ O
dependency -X- _ O
in -X- _ O
self -X- _ O
- -X- _ O
attention -X- _ O
. -X- _ O

See -X- _ O
Appendix -X- _ O
A -X- _ O
for -X- _ O
full -X- _ O
data -X- _ O
descriptions -X- _ O
. -X- _ O

As -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
3 -X- _ O
, -X- _ O
our -X- _ O
corpus -X- _ O
was -X- _ O
collected -X- _ O
from -X- _ O
10 -X- _ O
different -X- _ O
data -X- _ O
sources -X- _ O
: -X- _ O
Arxiv -X- _ B-DatasetName
, -X- _ O
Aminer -X- _ B-DatasetName
( -X- _ O
AMiner -X- _ O
) -X- _ O
, -X- _ O
CORD19 -X- _ B-DatasetName
( -X- _ O
Wang -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2020b -X- _ O
) -X- _ O
, -X- _ O
CORE -X- _ B-DatasetName
( -X- _ O
Pontika -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
PubMed -X- _ B-DatasetName
PubMed -X- _ O
PMC -X- _ O
+ -X- _ O
CS -X- _ O
OAG -X- _ O
PubMed -X- _ O
10 -X- _ O
+ -X- _ O
sources -X- _ O
( -X- _ O
Chemistry -X- _ O
) -X- _ O
Table -X- _ O
3 -X- _ O
: -X- _ O
Dataset -X- _ O
statistics -X- _ O
: -X- _ O
combined -X- _ O
datasets -X- _ O
are -X- _ O
after -X- _ O
the -X- _ O
de -X- _ O
- -X- _ O
duplication -X- _ O
process -X- _ O
. -X- _ O

Combined -X- _ O
〈A〉 -X- _ O
46.94 -X- _ O
16.18 -X- _ O
67 -X- _ O
Combined -X- _ O
〈FT〉 -X- _ O
6.52 -X- _ O
184.42 -X- _ O
603 -X- _ O
Combined -X- _ O
〈A+FT〉 -X- _ O
53.45 -X- _ O
200.61 -X- _ O
670 -X- _ O
1.47 -X- _ O
We -X- _ O
collected -X- _ O
a -X- _ O
large -X- _ O
corpus -X- _ O
of -X- _ O
53.45 -X- _ O
million -X- _ O
chemistry -X- _ O
- -X- _ O
focused -X- _ O
scientific -X- _ O
articles -X- _ O
and -X- _ O
abstracts -X- _ O
, -X- _ O
resulting -X- _ O
in -X- _ O
670 -X- _ O
GB -X- _ O
of -X- _ O
text -X- _ O
data -X- _ O
. -X- _ O

Table -X- _ O
2 -X- _ O
: -X- _ O
Our -X- _ O
model -X- _ O
configurations -X- _ O
: -X- _ O
dL -X- _ B-HyperparameterName
is -X- _ O
the -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
decoder -X- _ I-HyperparameterName
layers -X- _ I-HyperparameterName
, -X- _ O
ddim -X- _ B-HyperparameterName
is -X- _ O
the -X- _ O
hidden -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
the -X- _ O
model -X- _ O
, -X- _ O
dheads -X- _ B-HyperparameterName
is -X- _ O
the -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
attention -X- _ I-HyperparameterName
heads -X- _ I-HyperparameterName
. -X- _ O

Gu -X- _ O
et -X- _ O
al. -X- _ O
2021 -X- _ O
BioELECTRA -X- _ O
ELECTRAMed -X- _ O
SciBERT -X- _ O
OAG -X- _ O
- -X- _ O
BERT -X- _ O
PubMedBERT -X- _ O
PubMed -X- _ O
PubMed -X- _ O
PMC -X- _ O
+ -X- _ O
CS -X- _ O
OAG -X- _ O
PubMed -X- _ O
10 -X- _ O
+ -X- _ O
sources -X- _ O
( -X- _ O
Chemistry -X- _ O
) -X- _ O
continual -X- _ O
pretraining -X- _ O
continual -X- _ O
pretraining -X- _ O
continual -X- _ O
pretraining -X- _ O
from -X- _ O
scratch -X- _ O
continual -X- _ O
pretraining -X- _ O
from -X- _ O
scratch -X- _ O
from -X- _ O
scratch -X- _ O
from -X- _ O
scratch -X- _ O
from -X- _ O
scratch -X- _ O
from -X- _ O
scratch -X- _ O
from -X- _ O
scratch -X- _ O
continual -X- _ O
pretraining -X- _ O
Our -X- _ O
Work -X- _ O
( -X- _ O
autoregressive -X- _ O
) -X- _ O
† -X- _ O

Liu -X- _ O
et -X- _ O
al. -X- _ O
2021 -X- _ O

Beltagy -X- _ O
et -X- _ O
al. -X- _ O
2019 -X- _ O

Miolo -X- _ O
et -X- _ O
al. -X- _ O
2021 -X- _ O

BioMegatron -X- _ O
PubMed -X- _ O
Kanakarajan -X- _ O
et -X- _ O
al. -X- _ O
2021 -X- _ O

Yuan -X- _ O
et -X- _ O
al. -X- _ O
2021 -X- _ O
BioALBERT -X- _ O
BioRoBERTa -X- _ O
KeBioLM -X- _ O
Wiki -X- _ O
+ -X- _ O
Books -X- _ O
Wiki -X- _ O
+ -X- _ O
Books -X- _ O
PubMed -X- _ O
PMC -X- _ O
+ -X- _ O
MIMIC -X- _ O
- -X- _ O
II -X- _ O
PMC -X- _ O
+ -X- _ O
MIMIC -X- _ O
- -X- _ O
III -X- _ O
PubMed -X- _ O
+ -X- _ O
UMLS2 -X- _ O
Shin -X- _ O
et -X- _ O
al. -X- _ O
2020 -X- _ O

Pretraining -X- _ O
continual -X- _ O
pretraining -X- _ O
continual -X- _ O
pretraining -X- _ O
continual -X- _ O
pretraining -X- _ O
continual -X- _ O
pretraining -X- _ O
continual -X- _ O
pretraining -X- _ O
Phan -X- _ O
et -X- _ O
al. -X- _ O
2021 -X- _ O
SciFive -X- _ O
C4 -X- _ O
continual -X- _ O
pretraining -X- _ O
PubMed -X- _ O
Naseem -X- _ O
et -X- _ O
al. -X- _ O
2021 -X- _ O
Lewis -X- _ O
et -X- _ O
al. -X- _ O
2020 -X- _ O

† -X- _ O
Data -X- _ O
Source -X- _ O
Wiki -X- _ O
+ -X- _ O
Books -X- _ O
Wiki -X- _ O
+ -X- _ O
Books -X- _ O
Wiki -X- _ O
+ -X- _ O
Books -X- _ O
Arxiv -X- _ O
Wiki -X- _ O
+ -X- _ O
Books -X- _ O

MATH -X- _ O
- -X- _ O
BERT -X- _ O
Guo -X- _ O
et -X- _ O
al. -X- _ O
2021 -X- _ O
Chem(Rxn)BERT -X- _ O

BioBERT -X- _ O
Alsentzer -X- _ O
et -X- _ O
al. -X- _ O
2019 -X- _ O
ClinicalBERT -X- _ O
Peng -X- _ O
et -X- _ O
al. -X- _ O
2019 -X- _ O
BlueBERT -X- _ O
Liu -X- _ O
et -X- _ O
al. -X- _ O
2021 -X- _ O

Model -X- _ O
Lee -X- _ O
et -X- _ O
al. -X- _ O
2020 -X- _ O

We -X- _ O
use -X- _ O
† -X- _ O
to -X- _ O
indicate -X- _ O
models -X- _ O
trained -X- _ O
for -X- _ O
chemistry -X- _ O
. -X- _ O

Table -X- _ O
1 -X- _ O
: -X- _ O
Foundation -X- _ O
models -X- _ O
for -X- _ O
science -X- _ O
focus -X- _ O
on -X- _ O
the -X- _ O
biomedical -X- _ O
, -X- _ O
math -X- _ O
, -X- _ O
computer -X- _ O
science -X- _ O
and -X- _ O
chemistry -X- _ O
domains -X- _ O
. -X- _ O

We -X- _ O
also -X- _ O
use -X- _ O
the -X- _ O
Rotary -X- _ O
positional -X- _ O
embeddings -X- _ O
( -X- _ O
Su -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
instead -X- _ O
of -X- _ O
the -X- _ O
learned -X- _ O
positional -X- _ O
embeddings -X- _ O
used -X- _ O
in -X- _ O
the -X- _ O
GPT-2 -X- _ B-MethodName
model -X- _ O
( -X- _ O
Radford -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
because -X- _ O
they -X- _ O
offer -X- _ O
performance -X- _ O
161 -X- _ O

To -X- _ O
reduce -X- _ O
memory -X- _ O
and -X- _ O
increase -X- _ O
training -X- _ O
throughput -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
mixed -X- _ B-MethodName
- -X- _ I-MethodName
precision -X- _ I-MethodName
training -X- _ I-MethodName
( -X- _ O
Rasley -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
and -X- _ O
the -X- _ O
parallel -X- _ O
attention -X- _ O
and -X- _ O
feed -X- _ O
- -X- _ O
forward -X- _ O
implementations -X- _ O
available -X- _ O
in -X- _ O
GPT -X- _ O
- -X- _ O
NeoX -X- _ O
( -X- _ O
Black -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
. -X- _ O

In -X- _ O
addition -X- _ O
, -X- _ O
ZeRO -X- _ B-HyperparameterValue
optimizer -X- _ B-HyperparameterName
( -X- _ O
Rajbhandari -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
was -X- _ O
used -X- _ O
to -X- _ O
reduce -X- _ O
memory -X- _ O
footprint -X- _ O
by -X- _ O
distributing -X- _ O
optimizer -X- _ O
states -X- _ O
across -X- _ O
several -X- _ O
processes -X- _ O
. -X- _ O

We -X- _ O
use -X- _ O
an -X- _ O
Adam -X- _ B-HyperparameterValue
optimizer -X- _ B-HyperparameterName
with -X- _ O
β1 -X- _ B-HyperparameterName
= -X- _ O
0.9 -X- _ B-HyperparameterValue
, -X- _ O
β2 -X- _ B-HyperparameterName
= -X- _ O
0.99 -X- _ B-HyperparameterValue
, -X- _ O
and -X- _ O
σ -X- _ B-HyperparameterName
= -X- _ O
10−8 -X- _ B-HyperparameterValue
and -X- _ O
clip -X- _ O
the -X- _ O
gradient -X- _ O
norm -X- _ O
at -X- _ O
1.0 -X- _ B-HyperparameterValue
. -X- _ O

We -X- _ O
set -X- _ O
the -X- _ O
micro -X- _ B-HyperparameterName
batch -X- _ I-HyperparameterName
size -X- _ I-HyperparameterName
per -X- _ O
GPU -X- _ O
as -X- _ O
4 -X- _ B-HyperparameterValue
, -X- _ O
and -X- _ O
the -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
to -X- _ O
2 -X- _ B-HyperparameterValue
× -X- _ I-HyperparameterValue
10−4 -X- _ I-HyperparameterValue
, -X- _ O
and -X- _ O
rely -X- _ O
on -X- _ O
the -X- _ O
cosine -X- _ O
decay -X- _ O
. -X- _ O

We -X- _ O
optimize -X- _ O
the -X- _ O
autoregressive -X- _ O
log -X- _ O
- -X- _ O
likelihood -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
cross -X- _ O
- -X- _ O
entropy -X- _ O
loss -X- _ O
) -X- _ O
averaged -X- _ O
over -X- _ O
a -X- _ O
2048 -X- _ B-HyperparameterValue
- -X- _ O
token -X- _ O
context -X- _ O
. -X- _ O

Our -X- _ O
experiments -X- _ O
leverage -X- _ O
the -X- _ O
GPT -X- _ O
- -X- _ O
NeoX -X- _ O
Python -X- _ O
library -X- _ O
( -X- _ O
Andonian -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
developed -X- _ O
with -X- _ O
Megatron -X- _ O
( -X- _ O
Shoeybi -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
and -X- _ O
DeepSpeed -X- _ O
( -X- _ O
Rasley -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O

These -X- _ O
models -X- _ O
differ -X- _ O
in -X- _ O
the -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
decoder -X- _ I-HyperparameterName
layers -X- _ I-HyperparameterName
, -X- _ O
hidden -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
the -X- _ O
model -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
attention -X- _ I-HyperparameterName
heads -X- _ I-HyperparameterName
in -X- _ O
transformer -X- _ O
blocks -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
2 -X- _ O
. -X- _ O

To -X- _ O
understand -X- _ O
the -X- _ O
impact -X- _ O
of -X- _ O
model -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
( -X- _ O
RQ2 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
experiment -X- _ O
with -X- _ O
four -X- _ O
different -X- _ O
Transformer -X- _ O
sizes -X- _ O
: -X- _ O
small -X- _ O
( -X- _ O
S -X- _ O
) -X- _ O
, -X- _ O
medium -X- _ O
( -X- _ O
M -X- _ O
) -X- _ O
, -X- _ O
large -X- _ O
( -X- _ O
L -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
extra -X- _ O
- -X- _ O
large -X- _ O
( -X- _ O
XL -X- _ O
) -X- _ O
. -X- _ O

3 -X- _ O
Model -X- _ O
Pretraining -X- _ O
Unlike -X- _ O
the -X- _ O
majority -X- _ O
of -X- _ O
related -X- _ O
models -X- _ O
that -X- _ O
rely -X- _ O
on -X- _ O
a -X- _ O
base -X- _ O
BERT -X- _ B-MethodName
( -X- _ O
or -X- _ O
variant -X- _ O
) -X- _ O
model -X- _ O
, -X- _ O
we -X- _ O
adapt -X- _ O
the -X- _ O
OpenAI -X- _ O
’s -X- _ O
GPT-2 -X- _ B-MethodName
transformer -X- _ O
decoder -X- _ O
architecture -X- _ O
( -X- _ O
Radford -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
to -X- _ O
train -X- _ O
autoregressive -X- _ O
language -X- _ O
models -X- _ O
for -X- _ O
Chemistry -X- _ O
. -X- _ O

Unlike -X- _ O
any -X- _ O
previous -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
both -X- _ O
continual -X- _ O
and -X- _ O
from -X- _ O
scratch -X- _ O
pretraining -X- _ O
to -X- _ O
build -X- _ O
the -X- _ O
largest -X- _ O
foundation -X- _ O
model -X- _ O
for -X- _ O
Chemistry -X- _ O
( -X- _ O
1.47B -X- _ B-HyperparameterValue
) -X- _ O
on -X- _ O
the -X- _ O
largest -X- _ O
( -X- _ O
0.67 -X- _ O
TB -X- _ O
) -X- _ O
and -X- _ O
the -X- _ O
most -X- _ O
diverse -X- _ O
corpus -X- _ O
( -X- _ O
10 -X- _ O
+ -X- _ O
sources -X- _ O
) -X- _ O
collected -X- _ O
to -X- _ O
date -X- _ O
. -X- _ O

PubMedBERT -X- _ O
( -X- _ O
Gu -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
is -X- _ O
another -X- _ O
example -X- _ O
of -X- _ O
pretraining -X- _ O
the -X- _ O
base -X- _ O
BERT -X- _ O
model -X- _ O
from -X- _ O
scratch -X- _ O
using -X- _ O
PubMed -X- _ O
. -X- _ O

SciBERT -X- _ B-MethodName
( -X- _ O
Beltagy -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
is -X- _ O
pretrained -X- _ O
according -X- _ O
to -X- _ O
this -X- _ O
procedure -X- _ O
using -X- _ O
the -X- _ O
vocabulary -X- _ O
generated -X- _ O
from -X- _ O
computer -X- _ O
science -X- _ O
and -X- _ O
biomedical -X- _ O
domains -X- _ O
. -X- _ O

This -X- _ O
is -X- _ O
mainly -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
availability -X- _ O
of -X- _ O
in -X- _ O
- -X- _ O
domain -X- _ O
data -X- _ O
for -X- _ O
both -X- _ O
generating -X- _ O
the -X- _ O
vocabulary -X- _ O
and -X- _ O
pretraining -X- _ O
. -X- _ O

In -X- _ B-MethodName
- -X- _ I-MethodName
Domain -X- _ I-MethodName
Pretraining -X- _ I-MethodName
from -X- _ I-MethodName
Scratch -X- _ I-MethodName
Previous -X- _ O
work -X- _ O
has -X- _ O
shown -X- _ O
that -X- _ O
pretraining -X- _ O
models -X- _ O
from -X- _ O
scratch -X- _ O
on -X- _ O
domain -X- _ O
- -X- _ O
specific -X- _ O
data -X- _ O
has -X- _ O
a -X- _ O
significant -X- _ O
benefit -X- _ O
over -X- _ O
continual -X- _ O
pretraining -X- _ O
of -X- _ O
generaldomain -X- _ O
language -X- _ O
models -X- _ O
( -X- _ O
Gu -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O

In -X- _ O
the -X- _ O
Chemistry -X- _ O
domain -X- _ O
, -X- _ O
Guo -X- _ O
et -X- _ O
al. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
performed -X- _ O
continual -X- _ O
pretraining -X- _ O
of -X- _ O
a -X- _ O
base -X- _ O
BERT -X- _ O
model -X- _ O
on -X- _ O
200 -X- _ O
K -X- _ O
chemistry -X- _ O
journal -X- _ O
articles -X- _ O
for -X- _ O
product -X- _ O
extraction -X- _ O
( -X- _ O
ChemBERT -X- _ O
) -X- _ O
and -X- _ O
reaction -X- _ O
role -X- _ O
labeling -X- _ O
( -X- _ O
ChemRxnBERT -X- _ O
) -X- _ O
. -X- _ O

Several -X- _ O
models -X- _ O
have -X- _ O
been -X- _ O
developed -X- _ O
for -X- _ O
the -X- _ O
biomedical -X- _ O
domain -X- _ O
and -X- _ O
the -X- _ O
most -X- _ O
frequently -X- _ O
used -X- _ O
corpora -X- _ O
for -X- _ O
domain -X- _ O
- -X- _ O
specific -X- _ O
continual -X- _ O
preraining -X- _ O
are -X- _ O
PubMed -X- _ B-DatasetName
abstracts -X- _ O
and -X- _ O
PubMed -X- _ B-DatasetName
Central -X- _ I-DatasetName
full -X- _ O
- -X- _ O
text -X- _ O
articles -X- _ O
( -X- _ O
PMC -X- _ O
) -X- _ O
( -X- _ O
Lee -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Peng -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Phan -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O

Mixed -X- _ B-MethodName
- -X- _ I-MethodName
Domain -X- _ I-MethodName
Continual -X- _ I-MethodName
Pretraining -X- _ I-MethodName
Many -X- _ O
efforts -X- _ O
have -X- _ O
focused -X- _ O
on -X- _ O
continual -X- _ O
pretraining -X- _ O
of -X- _ O
a -X- _ O
BERT -X- _ O
( -X- _ O
Devlin -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
base -X- _ O
model -X- _ O
. -X- _ O

We -X- _ O
present -X- _ O
a -X- _ O
model -X- _ O
summary -X- _ O
in -X- _ O
Table -X- _ O
1 -X- _ O
. -X- _ O

2 -X- _ O
Related -X- _ O
Work -X- _ O
In -X- _ O
this -X- _ O
section -X- _ O
we -X- _ O
summarize -X- _ O
previous -X- _ O
efforts -X- _ O
in -X- _ O
two -X- _ O
categories -X- _ O
: -X- _ O
mixed -X- _ O
- -X- _ O
domain -X- _ O
continual -X- _ O
pretraining -X- _ O
that -X- _ O
continues -X- _ O
pretraining -X- _ O
of -X- _ O
a -X- _ O
base -X- _ O
model -X- _ O
on -X- _ O
domain -X- _ O
data -X- _ O
and -X- _ O
in -X- _ O
- -X- _ O
domain -X- _ O
pretraining -X- _ O
from -X- _ O
scratch -X- _ O
that -X- _ O
pretrains -X- _ O
a -X- _ O
from -X- _ O
scratch -X- _ O
on -X- _ O
domain -X- _ O
data -X- _ O
. -X- _ O

Temporal -X- _ O
Effect -X- _ O
How -X- _ O
does -X- _ O
the -X- _ O
recency -X- _ O
of -X- _ O
scientific -X- _ O
knowledge -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
when -X- _ O
manipulating -X- _ O
the -X- _ O
temporal -X- _ O
order -X- _ O
of -X- _ O
the -X- _ O
documents -X- _ O
processed -X- _ O
by -X- _ O
the -X- _ O
model -X- _ O
, -X- _ O
affect -X- _ O
downstream -X- _ O
performance -X- _ O
? -X- _ O

( -X- _ O
RQ4 -X- _ O
) -X- _ O

( -X- _ O
RQ3 -X- _ O
) -X- _ O
Diversity -X- _ O
Effect -X- _ O
How -X- _ O
does -X- _ O
the -X- _ O
depth -X- _ O
of -X- _ O
scientific -X- _ O
knowledge -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
from -X- _ O
paper -X- _ O
abstracts -X- _ O
vs. -X- _ O
full -X- _ O
text -X- _ O
, -X- _ O
affect -X- _ O
downstream -X- _ O
performance -X- _ O
? -X- _ O

Do -X- _ O
neural -X- _ O
scaling -X- _ O
laws -X- _ O
presented -X- _ O
in -X- _ O
( -X- _ O
Kaplan -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
hold -X- _ O
for -X- _ O
the -X- _ O
foundation -X- _ O
models -X- _ O
for -X- _ O
science -X- _ O
? -X- _ O

How -X- _ O
does -X- _ O
model -X- _ O
scale -X- _ O
affect -X- _ O
the -X- _ O
downstream -X- _ O
performance -X- _ O
? -X- _ O

Scaling -X- _ O
Effect -X- _ O

( -X- _ O
RQ2 -X- _ O
) -X- _ O

( -X- _ O
RQ1 -X- _ O
) -X- _ O
Science -X- _ O
- -X- _ O
Focused -X- _ O
Benchmarks -X- _ O
What -X- _ O
are -X- _ O
the -X- _ O
strengths -X- _ O
and -X- _ O
weaknesses -X- _ O
of -X- _ O
foundation -X- _ O
models -X- _ O
pretrained -X- _ O
on -X- _ O
scientific -X- _ O
literature -X- _ O
when -X- _ O
evaluated -X- _ O
on -X- _ O
out -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
domain -X- _ O
vs. -X- _ O
in -X- _ O
- -X- _ O
domain -X- _ O
tasks -X- _ O
? -X- _ O

There -X- _ O
are -X- _ O
three -X- _ O
major -X- _ O
contributions -X- _ O
of -X- _ O
this -X- _ O
work -X- _ O
: -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
we -X- _ O
collect -X- _ O
and -X- _ O
release -X- _ O
a -X- _ O
0.67 -X- _ O
TB -X- _ O
dataset -X- _ O
covering -X- _ O
research -X- _ B-DatasetName
publication -X- _ I-DatasetName
data -X- _ O
across -X- _ O
10 -X- _ O
+ -X- _ O
sources -X- _ O
for -X- _ O
chemistry -X- _ O
; -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
we -X- _ O
release -X- _ O
28 -X- _ O
auto -X- _ B-MethodName
- -X- _ I-MethodName
regressive -X- _ I-MethodName
foundation -X- _ I-MethodName
models -X- _ O
for -X- _ O
chemistry -X- _ O
that -X- _ O
have -X- _ O
been -X- _ O
pretrained -X- _ O
from -X- _ O
scratch -X- _ O
; -X- _ O
and -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
we -X- _ O
present -X- _ O
a -X- _ O
rigorous -X- _ O
evaluation -X- _ O
of -X- _ O
model -X- _ O
performance -X- _ O
on -X- _ O
15 -X- _ O
+ -X- _ O
indomain -X- _ O
and -X- _ O
out -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
domain -X- _ O
tasks -X- _ O
that -X- _ O
investigates -X- _ O
the -X- _ O
effects -X- _ O
of -X- _ O
model -X- _ O
and -X- _ O
data -X- _ O
scaling -X- _ O
, -X- _ O
knowledge -X- _ O
depth -X- _ O
( -X- _ O
aka -X- _ O
diversity -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
temporal -X- _ O
order -X- _ O
on -X- _ O
performance -X- _ O
as -X- _ O
described -X- _ O
in -X- _ O
research -X- _ O
questions -X- _ O
below -X- _ O
. -X- _ O

evaluation -X- _ O
, -X- _ O
model -X- _ O
prompting -X- _ O
and -X- _ O
interactions -X- _ O
. -X- _ O

Challenges -X- _ O
include -X- _ O
limited -X- _ O
benchmarks -X- _ O
that -X- _ O
can -X- _ O
be -X- _ O
used -X- _ O
to -X- _ O
perform -X- _ O
model -X- _ O
160 -X- _ O
Proceedings -X- _ O
of -X- _ O
BigScience -X- _ O
Episode -X- _ O
# -X- _ O
5 -X- _ O
– -X- _ O
Workshop -X- _ O
on -X- _ O
Challenges -X- _ O
& -X- _ O
Perspectives -X- _ O
in -X- _ O
Creating -X- _ O
Large -X- _ O
Language -X- _ O
Models -X- _ O
, -X- _ O
pages -X- _ O
160 -X- _ O
- -X- _ O
172 -X- _ O
May -X- _ O
27 -X- _ O
, -X- _ O
2022 -X- _ O
c -X- _ O
2022 -X- _ O
Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O

Opportunities -X- _ O
include -X- _ O
the -X- _ O
scale -X- _ O
and -X- _ O
diversity -X- _ O
of -X- _ O
scientific -X- _ O
literature -X- _ O
, -X- _ O
the -X- _ O
explicit -X- _ O
structure -X- _ O
, -X- _ O
and -X- _ O
explicit -X- _ O
alignment -X- _ O
across -X- _ O
different -X- _ O
modalities -X- _ O
in -X- _ O
the -X- _ O
papers -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
table -X- _ O
and -X- _ O
figure -X- _ O
references -X- _ O
. -X- _ O

Using -X- _ O
scientific -X- _ O
literature -X- _ O
presents -X- _ O
unique -X- _ O
opportunities -X- _ O
and -X- _ O
challenges -X- _ O
. -X- _ O

Thus -X- _ O
, -X- _ O
in -X- _ O
- -X- _ O
context -X- _ O
learning -X- _ O
allows -X- _ O
foundation -X- _ O
models -X- _ O
to -X- _ O
be -X- _ O
effectively -X- _ O
used -X- _ O
across -X- _ O
new -X- _ O
downstream -X- _ O
tasks -X- _ O
with -X- _ O
only -X- _ O
simple -X- _ O
instructions -X- _ O
and -X- _ O
a -X- _ O
few -X- _ O
optional -X- _ O
examples -X- _ O
. -X- _ O

Another -X- _ O
key -X- _ O
advantage -X- _ O
of -X- _ O
scaling -X- _ O
language -X- _ O
models -X- _ O
is -X- _ O
that -X- _ O
they -X- _ O
perform -X- _ O
competitively -X- _ O
on -X- _ O
language -X- _ O
tasks -X- _ O
using -X- _ O
in -X- _ O
- -X- _ O
context -X- _ O
learning -X- _ O
without -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
or -X- _ O
gradient -X- _ O
updates -X- _ O
. -X- _ O

Homogenization -X- _ O
is -X- _ O
the -X- _ O
consolidation -X- _ O
of -X- _ O
methods -X- _ O
for -X- _ O
building -X- _ O
machine -X- _ O
learning -X- _ O
systems -X- _ O
across -X- _ O
a -X- _ O
wide -X- _ O
range -X- _ O
of -X- _ O
tasks -X- _ O
. -X- _ O

Emergence -X- _ O
, -X- _ O
or -X- _ O
emergent -X- _ O
behavior -X- _ O
, -X- _ O
reflect -X- _ O
new -X- _ O
behaviors -X- _ O
that -X- _ O
a -X- _ O
model -X- _ O
introduces -X- _ O
or -X- _ O
is -X- _ O
capable -X- _ O
of -X- _ O
that -X- _ O
it -X- _ O
was -X- _ O
not -X- _ O
explicitly -X- _ O
trained -X- _ O
to -X- _ O
perform -X- _ O
. -X- _ O

The -X- _ O
wide -X- _ O
community -X- _ O
adoption -X- _ O
of -X- _ O
foundation -X- _ O
models -X- _ O
can -X- _ O
be -X- _ O
explained -X- _ O
by -X- _ O
their -X- _ O
key -X- _ O
properties -X- _ O
, -X- _ O
two -X- _ O
of -X- _ O
which -X- _ O
are -X- _ O
emergent -X- _ O
behavior -X- _ O
and -X- _ O
homogenization -X- _ O
– -X- _ O
which -X- _ O
also -X- _ O
make -X- _ O
foundation -X- _ O
models -X- _ O
appealing -X- _ O
for -X- _ O
adaption -X- _ O
across -X- _ O
science -X- _ O
and -X- _ O
security -X- _ O
domains -X- _ O
. -X- _ O

Our -X- _ O
novel -X- _ O
findings -X- _ O
demonstrate -X- _ O
that -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
model -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
significantly -X- _ O
contributes -X- _ O
to -X- _ O
the -X- _ O
task -X- _ O
performance -X- _ O
when -X- _ O
evaluated -X- _ O
in -X- _ O
a -X- _ O
zero -X- _ O
- -X- _ O
shot -X- _ O
setting -X- _ O
; -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
data -X- _ O
quality -X- _ O
( -X- _ O
aka -X- _ O
diversity -X- _ O
) -X- _ O
affects -X- _ O
model -X- _ O
performance -X- _ O
more -X- _ O
than -X- _ O
data -X- _ O
quantity -X- _ O
; -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
similarly -X- _ O
, -X- _ O
unlike -X- _ O
previous -X- _ O
work -X- _ O
( -X- _ O
Luu -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
temporal -X- _ O
order -X- _ O
of -X- _ O
the -X- _ O
documents -X- _ O
in -X- _ O
the -X- _ O
corpus -X- _ O
boosts -X- _ O
model -X- _ O
performance -X- _ O
only -X- _ O
for -X- _ O
specific -X- _ O
tasks -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
SciQ -X- _ B-TaskName
; -X- _ O
and -X- _ O
( -X- _ O
4 -X- _ O
) -X- _ O
models -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
from -X- _ O
scratch -X- _ O
perform -X- _ O
better -X- _ O
on -X- _ O
in -X- _ O
- -X- _ O
domain -X- _ O
tasks -X- _ O
than -X- _ O
those -X- _ O
tuned -X- _ O
from -X- _ O
general -X- _ O
- -X- _ O
purpose -X- _ O
models -X- _ O
like -X- _ O
Open -X- _ O
AI -X- _ O
’s -X- _ O
GPT-2 -X- _ B-MethodName
. -X- _ O

Evaluating -X- _ O
these -X- _ O
models -X- _ O
in -X- _ O
a -X- _ O
zero -X- _ O
- -X- _ O
shot -X- _ O
setting -X- _ O
, -X- _ O
we -X- _ O
analyze -X- _ O
the -X- _ O
effect -X- _ O
of -X- _ O
model -X- _ O
and -X- _ O
data -X- _ O
scaling -X- _ O
, -X- _ O
knowledge -X- _ O
depth -X- _ O
, -X- _ O
and -X- _ O
temporality -X- _ O
on -X- _ O
model -X- _ O
performance -X- _ O
in -X- _ O
context -X- _ O
of -X- _ O
model -X- _ O
training -X- _ O
efficiency -X- _ O
. -X- _ O

Specifically -X- _ O
, -X- _ O
we -X- _ O
build -X- _ O
large -X- _ O
- -X- _ O
scale -X- _ O
( -X- _ O
1.47B -X- _ B-HyperparameterValue
parameter -X- _ O
) -X- _ O
general -X- _ O
- -X- _ O
purpose -X- _ O
models -X- _ O
for -X- _ O
chemistry -X- _ O
that -X- _ O
can -X- _ O
be -X- _ O
effectively -X- _ O
used -X- _ O
to -X- _ O
perform -X- _ O
a -X- _ O
wide -X- _ O
range -X- _ O
of -X- _ O
in -X- _ O
- -X- _ O
domain -X- _ O
and -X- _ O
out -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
domain -X- _ O
tasks -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
develop -X- _ O
foundation -X- _ O
models -X- _ O
of -X- _ O
scientific -X- _ O
knowledge -X- _ O
for -X- _ O
chemistry -X- _ O
to -X- _ O
augment -X- _ O
scientists -X- _ O
with -X- _ O
the -X- _ O
advanced -X- _ O
ability -X- _ O
to -X- _ O
perceive -X- _ O
and -X- _ O
reason -X- _ O
at -X- _ O
scale -X- _ O
previously -X- _ O
unimagined -X- _ O
. -X- _ O

However -X- _ O
, -X- _ O
only -X- _ O
limited -X- _ O
efforts -X- _ O
have -X- _ O
investigated -X- _ O
the -X- _ O
opportunities -X- _ O
and -X- _ O
limitations -X- _ O
of -X- _ O
applying -X- _ O
these -X- _ O
powerful -X- _ O
models -X- _ O
to -X- _ O
science -X- _ O
and -X- _ O
security -X- _ O
applications -X- _ O
. -X- _ O

Sameera -X- _ O
Horawalavithana -X- _ O
, -X- _ O
Ellyn -X- _ O
Ayton -X- _ O
, -X- _ O
Shivam -X- _ O
Sharma -X- _ O
, -X- _ O
Scott -X- _ O
Howland -X- _ O
, -X- _ O
Megha -X- _ O
Subramanian -X- _ O
, -X- _ O
Scott -X- _ O
Vasquez -X- _ O
, -X- _ O
Robin -X- _ O
Cosbey -X- _ O
, -X- _ O
Maria -X- _ O
Glenski -X- _ O
, -X- _ O
Svitlana -X- _ O
Volkova -X- _ O
Pacific -X- _ O
Northwest -X- _ O
National -X- _ O
Laboratory -X- _ O
, -X- _ O
Richland -X- _ O
, -X- _ O
WA -X- _ O
Abstract -X- _ O
Foundation -X- _ O
models -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
on -X- _ O
large -X- _ O
corpora -X- _ O
demonstrate -X- _ O
significant -X- _ O
gains -X- _ O
across -X- _ O
many -X- _ O
natural -X- _ O
language -X- _ O
processing -X- _ O
tasks -X- _ O
and -X- _ O
domains -X- _ O
e.g. -X- _ O
, -X- _ O
law -X- _ O
, -X- _ O
healthcare -X- _ O
, -X- _ O
education -X- _ O
, -X- _ O
etc -X- _ O
. -X- _ O

Foundation -X- _ O
Models -X- _ O
of -X- _ O
Scientific -X- _ O
Knowledge -X- _ O
for -X- _ O
Chemistry -X- _ O
: -X- _ O
Opportunities -X- _ O
, -X- _ O
Challenges -X- _ O
and -X- _ O
Lessons -X- _ O
Learned -X- _ O

